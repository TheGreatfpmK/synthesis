2024-04-10 21:05:20,963 - cli.py - This is Paynt version 0.1.0.
2024-04-10 21:05:20,964 - sketch.py - loading sketch from ../sarsop/models/0999/cheng.D3-1.pomdp ...
2024-04-10 21:05:20,964 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 1:1:  expecting <model type>, here:
	# Data Set D3.1
	^

2024-04-10 21:05:20,969 - sketch.py - assuming sketch in DRN format...
ERROR (DirectEncodingParser.cpp:124): Could not parse line '# Data Set D3.1'.
2024-04-10 21:05:20,970 - sketch.py - assuming sketch in Cassandra format...
MADP: trying to parse as POMDP...
MADP: parsing success
2024-04-10 21:05:20,975 - sketch.py - applying discount factor transformation...
2024-04-10 21:05:20,976 - sketch.py - sketch parsing OK
2024-04-10 21:05:20,977 - sketch.py - constructed explicit quotient having 13 states and 37 actions
2024-04-10 21:05:20,977 - sketch.py - found the following specification optimality: R[exp]{"reward"}max=? [C{999/1000}] 
2024-04-10 21:05:20,978 - pomdp.py - constructed POMDP having 5 observations.
2024-04-10 21:05:20,978 - pomdp.py - unfolding 1-FSC template into POMDP ...
2024-04-10 21:05:20,978 - pomdp.py - constructed quotient MDP having 13 states and 37 actions.
2024-04-10 21:05:20,978 - pomdp.py - creating coloring ...
2024-04-10 21:05:20,986 - synthesizer_pomdp.py - Storm POMDP option enabled
2024-04-10 21:05:20,986 - synthesizer_pomdp.py - Storm settings: iterative - (900, 90, 10), get_storm_result - None, storm_options - cutoff, prune_storm - False, unfold_strategy - (True, False), use_storm_cutoffs - False, enhanced_saynt - None, saynt_overapprox - False
2024-04-10 21:05:20,986 - synthesizer.py - synthesis initiated, design space: 81
2024-04-10 21:05:20,987 - synthesizer_pomdp.py - Timeout for PAYNT started
-----------PAYNT-----------                     
Value = 6084.429314832526 | Time elapsed = 0.0s | FSC size = 10

-----------PAYNT-----------                     
Value = 6416.931490750676 | Time elapsed = 0.1s | FSC size = 10

2024-04-10 21:05:21,054 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:05:21,054 - synthesizer.py - A(o0,0)=(a2), A(o1,0)=(a2), A(o2,0)=(a1), A(__no_obs__,0)=(a2)
2024-04-10 21:05:21,056 - synthesizer.py - double-checking specification satisfiability:  : 6416.931490750676
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{999/1000}] 

method: AR, synthesis time: 0.07 s
number of holes: 4, family size: 81, quotient: 13 states / 37 actions
explored: 100 %
MDP stats: avg MDP size: 13, iterations: 22

optimum: 6416.931491
--------------------
2024-04-10 21:05:21,057 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:05:21,057 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:05:21,057 - pomdp.py - unfolding 2-FSC template into POMDP ...
2024-04-10 21:05:21,058 - pomdp.py - constructed quotient MDP having 25 states and 146 actions.
2024-04-10 21:05:21,058 - pomdp.py - creating coloring ...
2024-04-10 21:05:21,058 - synthesizer.py - synthesis initiated, design space: 1e6
2024-04-10 21:05:23,579 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:05:23,579 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{999/1000}] 

method: AR, synthesis time: 2.52 s
number of holes: 17, family size: 1e6, quotient: 25 states / 146 actions
explored: 100 %
MDP stats: avg MDP size: 25, iterations: 246

optimum: 6416.931491
--------------------
2024-04-10 21:05:23,579 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:05:23,579 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:05:23,579 - pomdp.py - unfolding 3-FSC template into POMDP ...
2024-04-10 21:05:23,580 - pomdp.py - constructed quotient MDP having 37 states and 327 actions.
2024-04-10 21:05:23,580 - pomdp.py - creating coloring ...
2024-04-10 21:05:23,580 - synthesizer.py - synthesis initiated, design space: 1e11
> progress 3.82%, elapsed 3 s, estimated 79 s, iters = {MDP: 133}, opt = 6416.931
> progress 5.486%, elapsed 6 s, estimated 109 s, iters = {MDP: 264}, opt = 6416.931
> progress 11.222%, elapsed 9 s, estimated 80 s, iters = {MDP: 396}, opt = 6416.931
> progress 12.787%, elapsed 12 s, estimated 94 s, iters = {MDP: 527}, opt = 6416.931
> progress 14.891%, elapsed 15 s, estimated 101 s, iters = {MDP: 665}, opt = 6416.931
> progress 15.241%, elapsed 18 s, estimated 118 s, iters = {MDP: 817}, opt = 6416.931
> progress 16.051%, elapsed 21 s, estimated 131 s, iters = {MDP: 960}, opt = 6416.931
> progress 16.511%, elapsed 24 s, estimated 145 s, iters = {MDP: 1108}, opt = 6416.931
> progress 19.753%, elapsed 27 s, estimated 137 s, iters = {MDP: 1241}, opt = 6416.931
> progress 33.355%, elapsed 30 s, estimated 90 s, iters = {MDP: 1368}, opt = 6416.931
> progress 34.247%, elapsed 33 s, estimated 96 s, iters = {MDP: 1510}, opt = 6416.931
> progress 37.075%, elapsed 36 s, estimated 97 s, iters = {MDP: 1650}, opt = 6416.931
> progress 37.452%, elapsed 39 s, estimated 104 s, iters = {MDP: 1806}, opt = 6416.931
> progress 37.971%, elapsed 42 s, estimated 111 s, iters = {MDP: 1959}, opt = 6416.931
> progress 38.683%, elapsed 45 s, estimated 116 s, iters = {MDP: 2112}, opt = 6416.931
> progress 41.06%, elapsed 48 s, estimated 117 s, iters = {MDP: 2246}, opt = 6416.931
> progress 44.535%, elapsed 51 s, estimated 114 s, iters = {MDP: 2388}, opt = 6416.931
> progress 44.881%, elapsed 54 s, estimated 120 s, iters = {MDP: 2540}, opt = 6416.931
> progress 45.685%, elapsed 57 s, estimated 125 s, iters = {MDP: 2684}, opt = 6416.931
> progress 46.258%, elapsed 60 s, estimated 130 s, iters = {MDP: 2836}, opt = 6416.931
> progress 48.21%, elapsed 63 s, estimated 131 s, iters = {MDP: 2975}, opt = 6416.931
> progress 48.286%, elapsed 66 s, estimated 137 s, iters = {MDP: 3243}, opt = 6416.931
> progress 48.286%, elapsed 69 s, estimated 143 s, iters = {MDP: 3570}, opt = 6416.931
> progress 48.286%, elapsed 72 s, estimated 149 s, iters = {MDP: 3888}, opt = 6416.931
> progress 48.286%, elapsed 75 s, estimated 155 s, iters = {MDP: 4200}, opt = 6416.931
> progress 48.286%, elapsed 78 s, estimated 162 s, iters = {MDP: 4529}, opt = 6416.931
> progress 48.286%, elapsed 81 s, estimated 168 s, iters = {MDP: 4833}, opt = 6416.931
> progress 48.287%, elapsed 84 s, estimated 174 s, iters = {MDP: 5148}, opt = 6416.931
> progress 48.287%, elapsed 87 s, estimated 180 s, iters = {MDP: 5485}, opt = 6416.931
2024-04-10 21:06:51,102 - synthesizer_ar_storm.py - Pausing synthesis
2024-04-10 21:06:51,202 - storm_pomdp_control.py - Interactive Storm started
2024-04-10 21:06:51,203 - storm_pomdp_control.py - starting Storm POMDP analysis
2024-04-10 21:07:01,243 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 6416.932176148595 | Time elapsed = 915.1s | FSC size = 3647


------------------------------------

PAYNT results: 
6416.931490750676
controller size: 10

Storm results: 
6416.932176148595
controller size: 3647

------------------------------------

2024-04-10 21:20:36,573 - synthesizer_ar_storm.py - Terminating controller synthesis
2024-04-10 21:20:36,573 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:20:36,578 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{999/1000}] 

method: AR, synthesis time: 87.52 s
number of holes: 25, family size: 1e11, quotient: 37 states / 327 actions
explored: 48 %
MDP stats: avg MDP size: 37, iterations: 5511

optimum: 6416.931491
--------------------
2024-04-10 21:20:36,579 - synthesizer_pomdp.py - Terminate: True
2024-04-10 21:20:36,579 - storm_pomdp_control.py - Storm POMDP analysis completed

------------------------------------

PAYNT results: 
6416.931490750676
controller size: 10

Storm results: 
6416.932176148595
controller size: 3647

------------------------------------

