2024-04-13 12:25:49,326 - cli.py - This is Paynt version 0.1.0.
2024-04-13 12:25:49,327 - sketch.py - loading sketch from ../sarsop/models/08/ejs1.pomdp ...
2024-04-13 12:25:49,327 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 1:1:  expecting <model type>, here:
	discount: 0.8
	^

2024-04-13 12:25:49,341 - sketch.py - assuming sketch in DRN format...
ERROR (DirectEncodingParser.cpp:124): Could not parse line 'discount: 0.8'.
2024-04-13 12:25:49,341 - sketch.py - assuming sketch in Cassandra format...
MADP: trying to parse as POMDP...
MADP: parsing success
2024-04-13 12:25:49,347 - sketch.py - applying discount factor transformation...
2024-04-13 12:25:49,356 - sketch.py - sketch parsing OK
2024-04-13 12:25:49,360 - sketch.py - constructed explicit quotient having 9 states and 33 actions
2024-04-13 12:25:49,360 - sketch.py - found the following specification optimality: R[exp]{"reward"}max=? [C{4/5}] 
2024-04-13 12:25:49,362 - pomdp.py - constructed POMDP having 4 observations.
2024-04-13 12:25:49,362 - pomdp.py - unfolding 1-FSC template into POMDP ...
2024-04-13 12:25:49,362 - pomdp.py - constructed quotient MDP having 9 states and 33 actions.
2024-04-13 12:25:49,362 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,370 - synthesizer_pomdp.py - Storm POMDP option enabled
2024-04-13 12:25:49,370 - synthesizer_pomdp.py - Storm settings: iterative - (900, 90, 10), get_storm_result - None, storm_options - cutoff, prune_storm - False, unfold_strategy - (True, False), use_storm_cutoffs - False, enhanced_saynt - None, saynt_overapprox - False
2024-04-13 12:25:49,372 - synthesizer.py - synthesis initiated, design space: 64
2024-04-13 12:25:49,372 - synthesizer_pomdp.py - Timeout for PAYNT started
-----------PAYNT-----------                     
Value = 2.245291280404411 | Time elapsed = 0.0s | FSC size = 8

2024-04-13 12:25:49,379 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,379 - synthesizer.py - A(good,0)=(Manufacture), A(defective,0)=(Manufacture), A(__no_obs__,0)=(Manufacture)
2024-04-13 12:25:49,379 - synthesizer.py - double-checking specification satisfiability:  : 2.245291280404411
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 3, family size: 64, quotient: 9 states / 33 actions
explored: 100 %
MDP stats: avg MDP size: 9, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,379 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,379 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,379 - pomdp.py - unfolding 2-FSC template into POMDP ...
2024-04-13 12:25:49,379 - pomdp.py - constructed quotient MDP having 17 states and 130 actions.
2024-04-13 12:25:49,379 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,379 - synthesizer.py - synthesis initiated, design space: 524288
2024-04-13 12:25:49,380 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,380 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 13, family size: 524288, quotient: 17 states / 130 actions
explored: 100 %
MDP stats: avg MDP size: 17, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,380 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,380 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,380 - pomdp.py - unfolding 3-FSC template into POMDP ...
2024-04-13 12:25:49,380 - pomdp.py - constructed quotient MDP having 25 states and 291 actions.
2024-04-13 12:25:49,380 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,380 - synthesizer.py - synthesis initiated, design space: 1e10
2024-04-13 12:25:49,380 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,380 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 19, family size: 1e10, quotient: 25 states / 291 actions
explored: 100 %
MDP stats: avg MDP size: 25, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,380 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,380 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,381 - pomdp.py - unfolding 4-FSC template into POMDP ...
2024-04-13 12:25:49,381 - pomdp.py - constructed quotient MDP having 33 states and 516 actions.
2024-04-13 12:25:49,381 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,381 - synthesizer.py - synthesis initiated, design space: 1e15
2024-04-13 12:25:49,382 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,382 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 25, family size: 1e15, quotient: 33 states / 516 actions
explored: 100 %
MDP stats: avg MDP size: 33, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,382 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,382 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,382 - pomdp.py - unfolding 5-FSC template into POMDP ...
2024-04-13 12:25:49,382 - pomdp.py - constructed quotient MDP having 41 states and 805 actions.
2024-04-13 12:25:49,382 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,383 - synthesizer.py - synthesis initiated, design space: 1e20
2024-04-13 12:25:49,383 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,383 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 31, family size: 1e20, quotient: 41 states / 805 actions
explored: 100 %
MDP stats: avg MDP size: 41, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,383 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,383 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,383 - pomdp.py - unfolding 6-FSC template into POMDP ...
2024-04-13 12:25:49,383 - pomdp.py - constructed quotient MDP having 49 states and 1158 actions.
2024-04-13 12:25:49,383 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,384 - synthesizer.py - synthesis initiated, design space: 1e25
2024-04-13 12:25:49,384 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,384 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 37, family size: 1e25, quotient: 49 states / 1158 actions
explored: 100 %
MDP stats: avg MDP size: 49, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,384 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,384 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,385 - pomdp.py - unfolding 7-FSC template into POMDP ...
2024-04-13 12:25:49,385 - pomdp.py - constructed quotient MDP having 57 states and 1575 actions.
2024-04-13 12:25:49,385 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,386 - synthesizer.py - synthesis initiated, design space: 1e31
2024-04-13 12:25:49,386 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,386 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 43, family size: 1e31, quotient: 57 states / 1575 actions
explored: 100 %
MDP stats: avg MDP size: 57, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,386 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,386 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,386 - pomdp.py - unfolding 8-FSC template into POMDP ...
2024-04-13 12:25:49,387 - pomdp.py - constructed quotient MDP having 65 states and 2056 actions.
2024-04-13 12:25:49,387 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,388 - synthesizer.py - synthesis initiated, design space: 1e37
2024-04-13 12:25:49,388 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,388 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 49, family size: 1e37, quotient: 65 states / 2056 actions
explored: 100 %
MDP stats: avg MDP size: 65, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,389 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,389 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,389 - pomdp.py - unfolding 9-FSC template into POMDP ...
2024-04-13 12:25:49,389 - pomdp.py - constructed quotient MDP having 73 states and 2601 actions.
2024-04-13 12:25:49,389 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,390 - synthesizer.py - synthesis initiated, design space: 1e42
2024-04-13 12:25:49,391 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,391 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 55, family size: 1e42, quotient: 73 states / 2601 actions
explored: 100 %
MDP stats: avg MDP size: 73, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,391 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,391 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,391 - pomdp.py - unfolding 10-FSC template into POMDP ...
2024-04-13 12:25:49,392 - pomdp.py - constructed quotient MDP having 81 states and 3210 actions.
2024-04-13 12:25:49,392 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,398 - synthesizer.py - synthesis initiated, design space: 1e49
2024-04-13 12:25:49,399 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,399 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 61, family size: 1e49, quotient: 81 states / 3210 actions
explored: 100 %
MDP stats: avg MDP size: 81, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,400 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,400 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,400 - pomdp.py - unfolding 11-FSC template into POMDP ...
2024-04-13 12:25:49,400 - pomdp.py - constructed quotient MDP having 89 states and 3883 actions.
2024-04-13 12:25:49,400 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,402 - synthesizer.py - synthesis initiated, design space: 1e55
2024-04-13 12:25:49,403 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,403 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 67, family size: 1e55, quotient: 89 states / 3883 actions
explored: 100 %
MDP stats: avg MDP size: 89, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,403 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,403 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,404 - pomdp.py - unfolding 12-FSC template into POMDP ...
2024-04-13 12:25:49,404 - pomdp.py - constructed quotient MDP having 97 states and 4620 actions.
2024-04-13 12:25:49,404 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,407 - synthesizer.py - synthesis initiated, design space: 1e61
2024-04-13 12:25:49,408 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,408 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 73, family size: 1e61, quotient: 97 states / 4620 actions
explored: 100 %
MDP stats: avg MDP size: 97, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,408 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,408 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,408 - pomdp.py - unfolding 13-FSC template into POMDP ...
2024-04-13 12:25:49,409 - pomdp.py - constructed quotient MDP having 105 states and 5421 actions.
2024-04-13 12:25:49,409 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,412 - synthesizer.py - synthesis initiated, design space: 1e68
2024-04-13 12:25:49,413 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,413 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 79, family size: 1e68, quotient: 105 states / 5421 actions
explored: 100 %
MDP stats: avg MDP size: 105, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,413 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,413 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,413 - pomdp.py - unfolding 14-FSC template into POMDP ...
2024-04-13 12:25:49,414 - pomdp.py - constructed quotient MDP having 113 states and 6286 actions.
2024-04-13 12:25:49,414 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,418 - synthesizer.py - synthesis initiated, design space: 1e74
2024-04-13 12:25:49,419 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,419 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 85, family size: 1e74, quotient: 113 states / 6286 actions
explored: 100 %
MDP stats: avg MDP size: 113, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,419 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,419 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,419 - pomdp.py - unfolding 15-FSC template into POMDP ...
2024-04-13 12:25:49,420 - pomdp.py - constructed quotient MDP having 121 states and 7215 actions.
2024-04-13 12:25:49,420 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,430 - synthesizer.py - synthesis initiated, design space: 1e81
2024-04-13 12:25:49,431 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,431 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 91, family size: 1e81, quotient: 121 states / 7215 actions
explored: 100 %
MDP stats: avg MDP size: 121, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,431 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,431 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,432 - pomdp.py - unfolding 16-FSC template into POMDP ...
2024-04-13 12:25:49,433 - pomdp.py - constructed quotient MDP having 129 states and 8208 actions.
2024-04-13 12:25:49,433 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,437 - synthesizer.py - synthesis initiated, design space: 1e87
2024-04-13 12:25:49,439 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,439 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 97, family size: 1e87, quotient: 129 states / 8208 actions
explored: 100 %
MDP stats: avg MDP size: 129, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,439 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,439 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,440 - pomdp.py - unfolding 17-FSC template into POMDP ...
2024-04-13 12:25:49,441 - pomdp.py - constructed quotient MDP having 137 states and 9265 actions.
2024-04-13 12:25:49,441 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,446 - synthesizer.py - synthesis initiated, design space: 1e94
2024-04-13 12:25:49,448 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,448 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 103, family size: 1e94, quotient: 137 states / 9265 actions
explored: 100 %
MDP stats: avg MDP size: 137, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,449 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,449 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,449 - pomdp.py - unfolding 18-FSC template into POMDP ...
2024-04-13 12:25:49,450 - pomdp.py - constructed quotient MDP having 145 states and 10386 actions.
2024-04-13 12:25:49,451 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,461 - synthesizer.py - synthesis initiated, design space: 1e101
2024-04-13 12:25:49,463 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,463 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 109, family size: 1e101, quotient: 145 states / 10386 actions
explored: 100 %
MDP stats: avg MDP size: 145, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,463 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,463 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,464 - pomdp.py - unfolding 19-FSC template into POMDP ...
2024-04-13 12:25:49,466 - pomdp.py - constructed quotient MDP having 153 states and 11571 actions.
2024-04-13 12:25:49,466 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,473 - synthesizer.py - synthesis initiated, design space: 1e108
2024-04-13 12:25:49,476 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,476 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 115, family size: 1e108, quotient: 153 states / 11571 actions
explored: 100 %
MDP stats: avg MDP size: 153, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,476 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,476 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,476 - pomdp.py - unfolding 20-FSC template into POMDP ...
2024-04-13 12:25:49,478 - pomdp.py - constructed quotient MDP having 161 states and 12820 actions.
2024-04-13 12:25:49,478 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,492 - synthesizer.py - synthesis initiated, design space: 1e115
2024-04-13 12:25:49,495 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,495 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 121, family size: 1e115, quotient: 161 states / 12820 actions
explored: 100 %
MDP stats: avg MDP size: 161, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,495 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,495 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,495 - pomdp.py - unfolding 21-FSC template into POMDP ...
2024-04-13 12:25:49,498 - pomdp.py - constructed quotient MDP having 169 states and 14133 actions.
2024-04-13 12:25:49,498 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,505 - synthesizer.py - synthesis initiated, design space: 1e122
2024-04-13 12:25:49,508 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,508 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 127, family size: 1e122, quotient: 169 states / 14133 actions
explored: 100 %
MDP stats: avg MDP size: 169, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,508 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,509 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,509 - pomdp.py - unfolding 22-FSC template into POMDP ...
2024-04-13 12:25:49,517 - pomdp.py - constructed quotient MDP having 177 states and 15510 actions.
2024-04-13 12:25:49,517 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,525 - synthesizer.py - synthesis initiated, design space: 1e129
2024-04-13 12:25:49,528 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,528 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 133, family size: 1e129, quotient: 177 states / 15510 actions
explored: 100 %
MDP stats: avg MDP size: 177, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,528 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,528 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,529 - pomdp.py - unfolding 23-FSC template into POMDP ...
2024-04-13 12:25:49,532 - pomdp.py - constructed quotient MDP having 185 states and 16951 actions.
2024-04-13 12:25:49,532 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,547 - synthesizer.py - synthesis initiated, design space: 1e136
2024-04-13 12:25:49,551 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,551 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 139, family size: 1e136, quotient: 185 states / 16951 actions
explored: 100 %
MDP stats: avg MDP size: 185, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,551 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,551 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,551 - pomdp.py - unfolding 24-FSC template into POMDP ...
2024-04-13 12:25:49,554 - pomdp.py - constructed quotient MDP having 193 states and 18456 actions.
2024-04-13 12:25:49,554 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,571 - synthesizer.py - synthesis initiated, design space: 1e144
2024-04-13 12:25:49,575 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,575 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 145, family size: 1e144, quotient: 193 states / 18456 actions
explored: 100 %
MDP stats: avg MDP size: 193, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,575 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,575 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,575 - pomdp.py - unfolding 25-FSC template into POMDP ...
2024-04-13 12:25:49,579 - pomdp.py - constructed quotient MDP having 201 states and 20025 actions.
2024-04-13 12:25:49,579 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,589 - synthesizer.py - synthesis initiated, design space: 1e151
2024-04-13 12:25:49,593 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,593 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 151, family size: 1e151, quotient: 201 states / 20025 actions
explored: 100 %
MDP stats: avg MDP size: 201, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,593 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,593 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,594 - pomdp.py - unfolding 26-FSC template into POMDP ...
2024-04-13 12:25:49,604 - pomdp.py - constructed quotient MDP having 209 states and 21658 actions.
2024-04-13 12:25:49,604 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,616 - synthesizer.py - synthesis initiated, design space: 1e158
2024-04-13 12:25:49,620 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,620 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 157, family size: 1e158, quotient: 209 states / 21658 actions
explored: 100 %
MDP stats: avg MDP size: 209, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,620 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,620 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,621 - pomdp.py - unfolding 27-FSC template into POMDP ...
2024-04-13 12:25:49,634 - pomdp.py - constructed quotient MDP having 217 states and 23355 actions.
2024-04-13 12:25:49,634 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,647 - synthesizer.py - synthesis initiated, design space: 1e166
2024-04-13 12:25:49,652 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,652 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 163, family size: 1e166, quotient: 217 states / 23355 actions
explored: 100 %
MDP stats: avg MDP size: 217, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,652 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,652 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,653 - pomdp.py - unfolding 28-FSC template into POMDP ...
2024-04-13 12:25:49,664 - pomdp.py - constructed quotient MDP having 225 states and 25116 actions.
2024-04-13 12:25:49,665 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,688 - synthesizer.py - synthesis initiated, design space: 1e173
2024-04-13 12:25:49,693 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,693 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 169, family size: 1e173, quotient: 225 states / 25116 actions
explored: 100 %
MDP stats: avg MDP size: 225, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,694 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,694 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,695 - pomdp.py - unfolding 29-FSC template into POMDP ...
2024-04-13 12:25:49,699 - pomdp.py - constructed quotient MDP having 233 states and 26941 actions.
2024-04-13 12:25:49,699 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,728 - synthesizer.py - synthesis initiated, design space: 1e181
2024-04-13 12:25:49,734 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,734 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 175, family size: 1e181, quotient: 233 states / 26941 actions
explored: 100 %
MDP stats: avg MDP size: 233, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,734 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,734 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,735 - pomdp.py - unfolding 30-FSC template into POMDP ...
2024-04-13 12:25:49,741 - pomdp.py - constructed quotient MDP having 241 states and 28830 actions.
2024-04-13 12:25:49,741 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,769 - synthesizer.py - synthesis initiated, design space: 1e188
2024-04-13 12:25:49,776 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,776 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 181, family size: 1e188, quotient: 241 states / 28830 actions
explored: 100 %
MDP stats: avg MDP size: 241, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,776 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,776 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,777 - pomdp.py - unfolding 31-FSC template into POMDP ...
2024-04-13 12:25:49,783 - pomdp.py - constructed quotient MDP having 249 states and 30783 actions.
2024-04-13 12:25:49,783 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,812 - synthesizer.py - synthesis initiated, design space: 1e196
2024-04-13 12:25:49,818 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,818 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 187, family size: 1e196, quotient: 249 states / 30783 actions
explored: 100 %
MDP stats: avg MDP size: 249, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,819 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,819 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,820 - pomdp.py - unfolding 32-FSC template into POMDP ...
2024-04-13 12:25:49,835 - pomdp.py - constructed quotient MDP having 257 states and 32800 actions.
2024-04-13 12:25:49,835 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,868 - synthesizer.py - synthesis initiated, design space: 1e203
2024-04-13 12:25:49,875 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,875 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 193, family size: 1e203, quotient: 257 states / 32800 actions
explored: 100 %
MDP stats: avg MDP size: 257, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,875 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,875 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,877 - pomdp.py - unfolding 33-FSC template into POMDP ...
2024-04-13 12:25:49,884 - pomdp.py - constructed quotient MDP having 265 states and 34881 actions.
2024-04-13 12:25:49,884 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,921 - synthesizer.py - synthesis initiated, design space: 1e211
2024-04-13 12:25:49,929 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,929 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 199, family size: 1e211, quotient: 265 states / 34881 actions
explored: 100 %
MDP stats: avg MDP size: 265, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,929 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,929 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,931 - pomdp.py - unfolding 34-FSC template into POMDP ...
2024-04-13 12:25:49,951 - pomdp.py - constructed quotient MDP having 273 states and 37026 actions.
2024-04-13 12:25:49,951 - pomdp.py - creating coloring ...
2024-04-13 12:25:49,981 - synthesizer.py - synthesis initiated, design space: 1e219
2024-04-13 12:25:49,988 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:49,988 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 205, family size: 1e219, quotient: 273 states / 37026 actions
explored: 100 %
MDP stats: avg MDP size: 273, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:49,988 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:49,988 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:49,989 - pomdp.py - unfolding 35-FSC template into POMDP ...
2024-04-13 12:25:49,996 - pomdp.py - constructed quotient MDP having 281 states and 39235 actions.
2024-04-13 12:25:49,996 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,037 - synthesizer.py - synthesis initiated, design space: 1e226
2024-04-13 12:25:50,045 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,045 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 211, family size: 1e226, quotient: 281 states / 39235 actions
explored: 100 %
MDP stats: avg MDP size: 281, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,045 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,045 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,047 - pomdp.py - unfolding 36-FSC template into POMDP ...
2024-04-13 12:25:50,054 - pomdp.py - constructed quotient MDP having 289 states and 41508 actions.
2024-04-13 12:25:50,054 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,092 - synthesizer.py - synthesis initiated, design space: 1e234
2024-04-13 12:25:50,101 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,101 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 217, family size: 1e234, quotient: 289 states / 41508 actions
explored: 100 %
MDP stats: avg MDP size: 289, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,101 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,101 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,103 - pomdp.py - unfolding 37-FSC template into POMDP ...
2024-04-13 12:25:50,119 - pomdp.py - constructed quotient MDP having 297 states and 43845 actions.
2024-04-13 12:25:50,119 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,154 - synthesizer.py - synthesis initiated, design space: 1e242
2024-04-13 12:25:50,163 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,163 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 223, family size: 1e242, quotient: 297 states / 43845 actions
explored: 100 %
MDP stats: avg MDP size: 297, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,163 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,163 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,165 - pomdp.py - unfolding 38-FSC template into POMDP ...
2024-04-13 12:25:50,180 - pomdp.py - constructed quotient MDP having 305 states and 46246 actions.
2024-04-13 12:25:50,180 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,217 - synthesizer.py - synthesis initiated, design space: 1e250
2024-04-13 12:25:50,226 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,226 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 229, family size: 1e250, quotient: 305 states / 46246 actions
explored: 100 %
MDP stats: avg MDP size: 305, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,226 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,226 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,228 - pomdp.py - unfolding 39-FSC template into POMDP ...
2024-04-13 12:25:50,245 - pomdp.py - constructed quotient MDP having 313 states and 48711 actions.
2024-04-13 12:25:50,245 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,282 - synthesizer.py - synthesis initiated, design space: 1e258
2024-04-13 12:25:50,291 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,291 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 235, family size: 1e258, quotient: 313 states / 48711 actions
explored: 100 %
MDP stats: avg MDP size: 313, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,292 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,292 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,293 - pomdp.py - unfolding 40-FSC template into POMDP ...
2024-04-13 12:25:50,310 - pomdp.py - constructed quotient MDP having 321 states and 51240 actions.
2024-04-13 12:25:50,310 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,364 - synthesizer.py - synthesis initiated, design space: 1e266
2024-04-13 12:25:50,374 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,374 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 241, family size: 1e266, quotient: 321 states / 51240 actions
explored: 100 %
MDP stats: avg MDP size: 321, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,374 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,374 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,376 - pomdp.py - unfolding 41-FSC template into POMDP ...
2024-04-13 12:25:50,385 - pomdp.py - constructed quotient MDP having 329 states and 53833 actions.
2024-04-13 12:25:50,385 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,446 - synthesizer.py - synthesis initiated, design space: 1e274
2024-04-13 12:25:50,456 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,456 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 247, family size: 1e274, quotient: 329 states / 53833 actions
explored: 100 %
MDP stats: avg MDP size: 329, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,456 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,456 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,458 - pomdp.py - unfolding 42-FSC template into POMDP ...
2024-04-13 12:25:50,478 - pomdp.py - constructed quotient MDP having 337 states and 56490 actions.
2024-04-13 12:25:50,478 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,520 - synthesizer.py - synthesis initiated, design space: 1e282
2024-04-13 12:25:50,532 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,532 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 253, family size: 1e282, quotient: 337 states / 56490 actions
explored: 100 %
MDP stats: avg MDP size: 337, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,532 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,532 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,534 - pomdp.py - unfolding 43-FSC template into POMDP ...
2024-04-13 12:25:50,553 - pomdp.py - constructed quotient MDP having 345 states and 59211 actions.
2024-04-13 12:25:50,554 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,611 - synthesizer.py - synthesis initiated, design space: 1e290
2024-04-13 12:25:50,622 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,622 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 259, family size: 1e290, quotient: 345 states / 59211 actions
explored: 100 %
MDP stats: avg MDP size: 345, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,622 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,622 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,624 - pomdp.py - unfolding 44-FSC template into POMDP ...
2024-04-13 12:25:50,647 - pomdp.py - constructed quotient MDP having 353 states and 61996 actions.
2024-04-13 12:25:50,647 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,708 - synthesizer.py - synthesis initiated, design space: 1e298
2024-04-13 12:25:50,720 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,720 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 265, family size: 1e298, quotient: 353 states / 61996 actions
explored: 100 %
MDP stats: avg MDP size: 353, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,720 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,720 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,723 - pomdp.py - unfolding 45-FSC template into POMDP ...
2024-04-13 12:25:50,733 - pomdp.py - constructed quotient MDP having 361 states and 64845 actions.
2024-04-13 12:25:50,733 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,791 - synthesizer.py - synthesis initiated, design space: 1e306
2024-04-13 12:25:50,803 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,803 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 271, family size: 1e306, quotient: 361 states / 64845 actions
explored: 100 %
MDP stats: avg MDP size: 361, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,803 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,803 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,806 - pomdp.py - unfolding 46-FSC template into POMDP ...
2024-04-13 12:25:50,827 - pomdp.py - constructed quotient MDP having 369 states and 67758 actions.
2024-04-13 12:25:50,827 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,885 - synthesizer.py - synthesis initiated, design space: 1e314
2024-04-13 12:25:50,898 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:50,898 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 277, family size: 1e314, quotient: 369 states / 67758 actions
explored: 100 %
MDP stats: avg MDP size: 369, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:50,898 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:50,898 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:50,900 - pomdp.py - unfolding 47-FSC template into POMDP ...
2024-04-13 12:25:50,922 - pomdp.py - constructed quotient MDP having 377 states and 70735 actions.
2024-04-13 12:25:50,922 - pomdp.py - creating coloring ...
2024-04-13 12:25:50,988 - synthesizer.py - synthesis initiated, design space: 1e322
2024-04-13 12:25:51,001 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:51,001 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 283, family size: 1e322, quotient: 377 states / 70735 actions
explored: 100 %
MDP stats: avg MDP size: 377, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:51,002 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:51,002 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:51,004 - pomdp.py - unfolding 48-FSC template into POMDP ...
2024-04-13 12:25:51,027 - pomdp.py - constructed quotient MDP having 385 states and 73776 actions.
2024-04-13 12:25:51,028 - pomdp.py - creating coloring ...
2024-04-13 12:25:51,102 - synthesizer.py - synthesis initiated, design space: 1e330
2024-04-13 12:25:51,116 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:51,116 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 289, family size: 1e330, quotient: 385 states / 73776 actions
explored: 100 %
MDP stats: avg MDP size: 385, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:51,117 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:51,117 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:51,119 - pomdp.py - unfolding 49-FSC template into POMDP ...
2024-04-13 12:25:51,142 - pomdp.py - constructed quotient MDP having 393 states and 76881 actions.
2024-04-13 12:25:51,142 - pomdp.py - creating coloring ...
2024-04-13 12:25:51,230 - synthesizer.py - synthesis initiated, design space: 1e338
2024-04-13 12:25:51,244 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:51,244 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 295, family size: 1e338, quotient: 393 states / 76881 actions
explored: 100 %
MDP stats: avg MDP size: 393, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:51,244 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:51,244 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:51,247 - pomdp.py - unfolding 50-FSC template into POMDP ...
2024-04-13 12:25:51,261 - pomdp.py - constructed quotient MDP having 401 states and 80050 actions.
2024-04-13 12:25:51,261 - pomdp.py - creating coloring ...
2024-04-13 12:25:51,349 - synthesizer.py - synthesis initiated, design space: 1e346
2024-04-13 12:25:51,364 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:51,364 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 301, family size: 1e346, quotient: 401 states / 80050 actions
explored: 100 %
MDP stats: avg MDP size: 401, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:51,364 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:51,364 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:51,367 - pomdp.py - unfolding 51-FSC template into POMDP ...
2024-04-13 12:25:51,381 - pomdp.py - constructed quotient MDP having 409 states and 83283 actions.
2024-04-13 12:25:51,381 - pomdp.py - creating coloring ...
2024-04-13 12:25:51,471 - synthesizer.py - synthesis initiated, design space: 1e355
2024-04-13 12:25:51,486 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:51,486 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 307, family size: 1e355, quotient: 409 states / 83283 actions
explored: 100 %
MDP stats: avg MDP size: 409, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:51,487 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:51,487 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:51,489 - pomdp.py - unfolding 52-FSC template into POMDP ...
2024-04-13 12:25:51,518 - pomdp.py - constructed quotient MDP having 417 states and 86580 actions.
2024-04-13 12:25:51,518 - pomdp.py - creating coloring ...
2024-04-13 12:25:51,597 - synthesizer.py - synthesis initiated, design space: 1e363
2024-04-13 12:25:51,611 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:51,612 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 313, family size: 1e363, quotient: 417 states / 86580 actions
explored: 100 %
MDP stats: avg MDP size: 417, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:51,612 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:51,612 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:51,614 - pomdp.py - unfolding 53-FSC template into POMDP ...
2024-04-13 12:25:51,646 - pomdp.py - constructed quotient MDP having 425 states and 89941 actions.
2024-04-13 12:25:51,646 - pomdp.py - creating coloring ...
2024-04-13 12:25:51,735 - synthesizer.py - synthesis initiated, design space: 1e371
2024-04-13 12:25:51,754 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:51,754 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 319, family size: 1e371, quotient: 425 states / 89941 actions
explored: 100 %
MDP stats: avg MDP size: 425, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:51,754 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:51,754 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:51,758 - pomdp.py - unfolding 54-FSC template into POMDP ...
2024-04-13 12:25:51,784 - pomdp.py - constructed quotient MDP having 433 states and 93366 actions.
2024-04-13 12:25:51,784 - pomdp.py - creating coloring ...
2024-04-13 12:25:51,882 - synthesizer.py - synthesis initiated, design space: 1e379
2024-04-13 12:25:51,899 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:51,899 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 325, family size: 1e379, quotient: 433 states / 93366 actions
explored: 100 %
MDP stats: avg MDP size: 433, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:51,899 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:51,899 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:51,902 - pomdp.py - unfolding 55-FSC template into POMDP ...
2024-04-13 12:25:51,933 - pomdp.py - constructed quotient MDP having 441 states and 96855 actions.
2024-04-13 12:25:51,933 - pomdp.py - creating coloring ...
2024-04-13 12:25:52,016 - synthesizer.py - synthesis initiated, design space: 1e388
2024-04-13 12:25:52,034 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:52,034 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 331, family size: 1e388, quotient: 441 states / 96855 actions
explored: 100 %
MDP stats: avg MDP size: 441, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:52,034 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:52,034 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:52,038 - pomdp.py - unfolding 56-FSC template into POMDP ...
2024-04-13 12:25:52,068 - pomdp.py - constructed quotient MDP having 449 states and 100408 actions.
2024-04-13 12:25:52,068 - pomdp.py - creating coloring ...
2024-04-13 12:25:52,183 - synthesizer.py - synthesis initiated, design space: 1e396
2024-04-13 12:25:52,204 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:52,204 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 337, family size: 1e396, quotient: 449 states / 100408 actions
explored: 100 %
MDP stats: avg MDP size: 449, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:52,204 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:52,204 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:52,208 - pomdp.py - unfolding 57-FSC template into POMDP ...
2024-04-13 12:25:52,239 - pomdp.py - constructed quotient MDP having 457 states and 104025 actions.
2024-04-13 12:25:52,239 - pomdp.py - creating coloring ...
2024-04-13 12:25:52,354 - synthesizer.py - synthesis initiated, design space: 1e404
2024-04-13 12:25:52,374 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:52,374 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 343, family size: 1e404, quotient: 457 states / 104025 actions
explored: 100 %
MDP stats: avg MDP size: 457, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:52,374 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:52,374 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:52,379 - pomdp.py - unfolding 58-FSC template into POMDP ...
2024-04-13 12:25:52,415 - pomdp.py - constructed quotient MDP having 465 states and 107706 actions.
2024-04-13 12:25:52,415 - pomdp.py - creating coloring ...
2024-04-13 12:25:52,539 - synthesizer.py - synthesis initiated, design space: 1e413
2024-04-13 12:25:52,559 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:52,560 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 349, family size: 1e413, quotient: 465 states / 107706 actions
explored: 100 %
MDP stats: avg MDP size: 465, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:52,560 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:52,560 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:52,563 - pomdp.py - unfolding 59-FSC template into POMDP ...
2024-04-13 12:25:52,599 - pomdp.py - constructed quotient MDP having 473 states and 111451 actions.
2024-04-13 12:25:52,599 - pomdp.py - creating coloring ...
2024-04-13 12:25:52,736 - synthesizer.py - synthesis initiated, design space: 1e421
2024-04-13 12:25:52,759 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:52,759 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 355, family size: 1e421, quotient: 473 states / 111451 actions
explored: 100 %
MDP stats: avg MDP size: 473, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:52,759 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:52,759 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:52,764 - pomdp.py - unfolding 60-FSC template into POMDP ...
2024-04-13 12:25:52,809 - pomdp.py - constructed quotient MDP having 481 states and 115260 actions.
2024-04-13 12:25:52,809 - pomdp.py - creating coloring ...
2024-04-13 12:25:52,961 - synthesizer.py - synthesis initiated, design space: 1e430
2024-04-13 12:25:52,986 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:52,986 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 361, family size: 1e430, quotient: 481 states / 115260 actions
explored: 100 %
MDP stats: avg MDP size: 481, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:52,986 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:52,986 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:52,991 - pomdp.py - unfolding 61-FSC template into POMDP ...
2024-04-13 12:25:53,030 - pomdp.py - constructed quotient MDP having 489 states and 119133 actions.
2024-04-13 12:25:53,030 - pomdp.py - creating coloring ...
2024-04-13 12:25:53,157 - synthesizer.py - synthesis initiated, design space: 1e438
2024-04-13 12:25:53,182 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:53,182 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 367, family size: 1e438, quotient: 489 states / 119133 actions
explored: 100 %
MDP stats: avg MDP size: 489, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:53,182 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:53,182 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:53,187 - pomdp.py - unfolding 62-FSC template into POMDP ...
2024-04-13 12:25:53,224 - pomdp.py - constructed quotient MDP having 497 states and 123070 actions.
2024-04-13 12:25:53,224 - pomdp.py - creating coloring ...
2024-04-13 12:25:53,351 - synthesizer.py - synthesis initiated, design space: 1e447
2024-04-13 12:25:53,373 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:53,374 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 373, family size: 1e447, quotient: 497 states / 123070 actions
explored: 100 %
MDP stats: avg MDP size: 497, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:53,374 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:53,374 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:53,378 - pomdp.py - unfolding 63-FSC template into POMDP ...
2024-04-13 12:25:53,412 - pomdp.py - constructed quotient MDP having 505 states and 127071 actions.
2024-04-13 12:25:53,412 - pomdp.py - creating coloring ...
2024-04-13 12:25:53,545 - synthesizer.py - synthesis initiated, design space: 1e455
2024-04-13 12:25:53,567 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:53,568 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 379, family size: 1e455, quotient: 505 states / 127071 actions
explored: 100 %
MDP stats: avg MDP size: 505, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:53,568 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:53,568 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:53,573 - pomdp.py - unfolding 64-FSC template into POMDP ...
2024-04-13 12:25:53,612 - pomdp.py - constructed quotient MDP having 513 states and 131136 actions.
2024-04-13 12:25:53,612 - pomdp.py - creating coloring ...
2024-04-13 12:25:53,751 - synthesizer.py - synthesis initiated, design space: 1e464
2024-04-13 12:25:53,784 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:53,784 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 385, family size: 1e464, quotient: 513 states / 131136 actions
explored: 100 %
MDP stats: avg MDP size: 513, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:53,784 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:53,784 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:53,794 - pomdp.py - unfolding 65-FSC template into POMDP ...
2024-04-13 12:25:53,874 - pomdp.py - constructed quotient MDP having 521 states and 135265 actions.
2024-04-13 12:25:53,874 - pomdp.py - creating coloring ...
2024-04-13 12:25:54,010 - synthesizer.py - synthesis initiated, design space: 1e472
2024-04-13 12:25:54,038 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:54,038 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 391, family size: 1e472, quotient: 521 states / 135265 actions
explored: 100 %
MDP stats: avg MDP size: 521, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:54,039 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:54,039 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:54,045 - pomdp.py - unfolding 66-FSC template into POMDP ...
2024-04-13 12:25:54,089 - pomdp.py - constructed quotient MDP having 529 states and 139458 actions.
2024-04-13 12:25:54,089 - pomdp.py - creating coloring ...
2024-04-13 12:25:54,244 - synthesizer.py - synthesis initiated, design space: 1e481
2024-04-13 12:25:54,272 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:54,272 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 397, family size: 1e481, quotient: 529 states / 139458 actions
explored: 100 %
MDP stats: avg MDP size: 529, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:54,272 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:54,272 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:54,278 - pomdp.py - unfolding 67-FSC template into POMDP ...
2024-04-13 12:25:54,347 - pomdp.py - constructed quotient MDP having 537 states and 143715 actions.
2024-04-13 12:25:54,347 - pomdp.py - creating coloring ...
2024-04-13 12:25:54,485 - synthesizer.py - synthesis initiated, design space: 1e489
2024-04-13 12:25:54,512 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:54,512 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 403, family size: 1e489, quotient: 537 states / 143715 actions
explored: 100 %
MDP stats: avg MDP size: 537, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:54,512 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:54,512 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:54,518 - pomdp.py - unfolding 68-FSC template into POMDP ...
2024-04-13 12:25:54,566 - pomdp.py - constructed quotient MDP having 545 states and 148036 actions.
2024-04-13 12:25:54,566 - pomdp.py - creating coloring ...
2024-04-13 12:25:54,726 - synthesizer.py - synthesis initiated, design space: 1e498
2024-04-13 12:25:54,754 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:54,754 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 409, family size: 1e498, quotient: 545 states / 148036 actions
explored: 100 %
MDP stats: avg MDP size: 545, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:54,755 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:54,755 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:54,761 - pomdp.py - unfolding 69-FSC template into POMDP ...
2024-04-13 12:25:54,831 - pomdp.py - constructed quotient MDP having 553 states and 152421 actions.
2024-04-13 12:25:54,831 - pomdp.py - creating coloring ...
2024-04-13 12:25:54,978 - synthesizer.py - synthesis initiated, design space: 1e507
2024-04-13 12:25:55,008 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:55,008 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 415, family size: 1e507, quotient: 553 states / 152421 actions
explored: 100 %
MDP stats: avg MDP size: 553, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:55,008 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:55,008 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:55,014 - pomdp.py - unfolding 70-FSC template into POMDP ...
2024-04-13 12:25:55,088 - pomdp.py - constructed quotient MDP having 561 states and 156870 actions.
2024-04-13 12:25:55,088 - pomdp.py - creating coloring ...
2024-04-13 12:25:55,246 - synthesizer.py - synthesis initiated, design space: 1e515
2024-04-13 12:25:55,276 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:55,276 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 421, family size: 1e515, quotient: 561 states / 156870 actions
explored: 100 %
MDP stats: avg MDP size: 561, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:55,276 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:55,276 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:55,282 - pomdp.py - unfolding 71-FSC template into POMDP ...
2024-04-13 12:25:55,337 - pomdp.py - constructed quotient MDP having 569 states and 161383 actions.
2024-04-13 12:25:55,337 - pomdp.py - creating coloring ...
2024-04-13 12:25:55,509 - synthesizer.py - synthesis initiated, design space: 1e524
2024-04-13 12:25:55,538 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:55,538 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 427, family size: 1e524, quotient: 569 states / 161383 actions
explored: 100 %
MDP stats: avg MDP size: 569, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:55,538 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:55,538 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:55,544 - pomdp.py - unfolding 72-FSC template into POMDP ...
2024-04-13 12:25:55,618 - pomdp.py - constructed quotient MDP having 577 states and 165960 actions.
2024-04-13 12:25:55,618 - pomdp.py - creating coloring ...
2024-04-13 12:25:55,771 - synthesizer.py - synthesis initiated, design space: 1e533
2024-04-13 12:25:55,801 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:55,801 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 433, family size: 1e533, quotient: 577 states / 165960 actions
explored: 100 %
MDP stats: avg MDP size: 577, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:55,801 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:55,801 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:55,807 - pomdp.py - unfolding 73-FSC template into POMDP ...
2024-04-13 12:25:55,879 - pomdp.py - constructed quotient MDP having 585 states and 170601 actions.
2024-04-13 12:25:55,879 - pomdp.py - creating coloring ...
2024-04-13 12:25:56,069 - synthesizer.py - synthesis initiated, design space: 1e541
2024-04-13 12:25:56,100 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:56,100 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 439, family size: 1e541, quotient: 585 states / 170601 actions
explored: 100 %
MDP stats: avg MDP size: 585, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:56,100 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:56,100 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:56,106 - pomdp.py - unfolding 74-FSC template into POMDP ...
2024-04-13 12:25:56,163 - pomdp.py - constructed quotient MDP having 593 states and 175306 actions.
2024-04-13 12:25:56,163 - pomdp.py - creating coloring ...
2024-04-13 12:25:56,344 - synthesizer.py - synthesis initiated, design space: 1e550
2024-04-13 12:25:56,375 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:56,375 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 445, family size: 1e550, quotient: 593 states / 175306 actions
explored: 100 %
MDP stats: avg MDP size: 593, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:56,375 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:56,376 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:56,382 - pomdp.py - unfolding 75-FSC template into POMDP ...
2024-04-13 12:25:56,461 - pomdp.py - constructed quotient MDP having 601 states and 180075 actions.
2024-04-13 12:25:56,461 - pomdp.py - creating coloring ...
2024-04-13 12:25:56,657 - synthesizer.py - synthesis initiated, design space: 1e559
2024-04-13 12:25:56,694 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:56,694 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 451, family size: 1e559, quotient: 601 states / 180075 actions
explored: 100 %
MDP stats: avg MDP size: 601, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:56,694 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:56,694 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:56,701 - pomdp.py - unfolding 76-FSC template into POMDP ...
2024-04-13 12:25:56,788 - pomdp.py - constructed quotient MDP having 609 states and 184908 actions.
2024-04-13 12:25:56,788 - pomdp.py - creating coloring ...
2024-04-13 12:25:56,965 - synthesizer.py - synthesis initiated, design space: 1e567
2024-04-13 12:25:56,999 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:56,999 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 457, family size: 1e567, quotient: 609 states / 184908 actions
explored: 100 %
MDP stats: avg MDP size: 609, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:57,000 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:57,000 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:57,007 - pomdp.py - unfolding 77-FSC template into POMDP ...
2024-04-13 12:25:57,092 - pomdp.py - constructed quotient MDP having 617 states and 189805 actions.
2024-04-13 12:25:57,093 - pomdp.py - creating coloring ...
2024-04-13 12:25:57,291 - synthesizer.py - synthesis initiated, design space: 1e576
2024-04-13 12:25:57,339 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:57,339 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 463, family size: 1e576, quotient: 617 states / 189805 actions
explored: 100 %
MDP stats: avg MDP size: 617, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:57,339 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:57,339 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:57,347 - pomdp.py - unfolding 78-FSC template into POMDP ...
2024-04-13 12:25:57,439 - pomdp.py - constructed quotient MDP having 625 states and 194766 actions.
2024-04-13 12:25:57,439 - pomdp.py - creating coloring ...
2024-04-13 12:25:57,623 - synthesizer.py - synthesis initiated, design space: 1e585
2024-04-13 12:25:57,659 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:57,659 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 469, family size: 1e585, quotient: 625 states / 194766 actions
explored: 100 %
MDP stats: avg MDP size: 625, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:57,660 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:57,660 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:57,668 - pomdp.py - unfolding 79-FSC template into POMDP ...
2024-04-13 12:25:57,758 - pomdp.py - constructed quotient MDP having 633 states and 199791 actions.
2024-04-13 12:25:57,758 - pomdp.py - creating coloring ...
2024-04-13 12:25:57,980 - synthesizer.py - synthesis initiated, design space: 1e594
2024-04-13 12:25:58,019 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:58,019 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 475, family size: 1e594, quotient: 633 states / 199791 actions
explored: 100 %
MDP stats: avg MDP size: 633, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:58,020 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:58,020 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:58,027 - pomdp.py - unfolding 80-FSC template into POMDP ...
2024-04-13 12:25:58,117 - pomdp.py - constructed quotient MDP having 641 states and 204880 actions.
2024-04-13 12:25:58,117 - pomdp.py - creating coloring ...
2024-04-13 12:25:58,350 - synthesizer.py - synthesis initiated, design space: 1e603
2024-04-13 12:25:58,393 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:58,393 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 481, family size: 1e603, quotient: 641 states / 204880 actions
explored: 100 %
MDP stats: avg MDP size: 641, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:58,393 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:58,393 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:58,402 - pomdp.py - unfolding 81-FSC template into POMDP ...
2024-04-13 12:25:58,501 - pomdp.py - constructed quotient MDP having 649 states and 210033 actions.
2024-04-13 12:25:58,502 - pomdp.py - creating coloring ...
2024-04-13 12:25:58,701 - synthesizer.py - synthesis initiated, design space: 1e611
2024-04-13 12:25:58,740 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:58,740 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 487, family size: 1e611, quotient: 649 states / 210033 actions
explored: 100 %
MDP stats: avg MDP size: 649, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:58,740 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:58,740 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:58,749 - pomdp.py - unfolding 82-FSC template into POMDP ...
2024-04-13 12:25:58,834 - pomdp.py - constructed quotient MDP having 657 states and 215250 actions.
2024-04-13 12:25:58,834 - pomdp.py - creating coloring ...
2024-04-13 12:25:59,047 - synthesizer.py - synthesis initiated, design space: 1e620
2024-04-13 12:25:59,084 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:59,084 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 493, family size: 1e620, quotient: 657 states / 215250 actions
explored: 100 %
MDP stats: avg MDP size: 657, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:59,084 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:59,084 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:59,092 - pomdp.py - unfolding 83-FSC template into POMDP ...
2024-04-13 12:25:59,182 - pomdp.py - constructed quotient MDP having 665 states and 220531 actions.
2024-04-13 12:25:59,182 - pomdp.py - creating coloring ...
2024-04-13 12:25:59,410 - synthesizer.py - synthesis initiated, design space: 1e629
2024-04-13 12:25:59,453 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:59,453 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 499, family size: 1e629, quotient: 665 states / 220531 actions
explored: 100 %
MDP stats: avg MDP size: 665, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:59,453 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:59,453 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:59,462 - pomdp.py - unfolding 84-FSC template into POMDP ...
2024-04-13 12:25:59,551 - pomdp.py - constructed quotient MDP having 673 states and 225876 actions.
2024-04-13 12:25:59,552 - pomdp.py - creating coloring ...
2024-04-13 12:25:59,741 - synthesizer.py - synthesis initiated, design space: 1e638
2024-04-13 12:25:59,786 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:25:59,786 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 505, family size: 1e638, quotient: 673 states / 225876 actions
explored: 100 %
MDP stats: avg MDP size: 673, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:25:59,786 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:25:59,786 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:25:59,795 - pomdp.py - unfolding 85-FSC template into POMDP ...
2024-04-13 12:25:59,904 - pomdp.py - constructed quotient MDP having 681 states and 231285 actions.
2024-04-13 12:25:59,904 - pomdp.py - creating coloring ...
2024-04-13 12:26:00,104 - synthesizer.py - synthesis initiated, design space: 1e647
2024-04-13 12:26:00,144 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:00,145 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 511, family size: 1e647, quotient: 681 states / 231285 actions
explored: 100 %
MDP stats: avg MDP size: 681, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:00,145 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:00,145 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:00,154 - pomdp.py - unfolding 86-FSC template into POMDP ...
2024-04-13 12:26:00,273 - pomdp.py - constructed quotient MDP having 689 states and 236758 actions.
2024-04-13 12:26:00,273 - pomdp.py - creating coloring ...
2024-04-13 12:26:00,481 - synthesizer.py - synthesis initiated, design space: 1e656
2024-04-13 12:26:00,524 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:00,524 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 517, family size: 1e656, quotient: 689 states / 236758 actions
explored: 100 %
MDP stats: avg MDP size: 689, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:00,524 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:00,524 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:00,533 - pomdp.py - unfolding 87-FSC template into POMDP ...
2024-04-13 12:26:00,635 - pomdp.py - constructed quotient MDP having 697 states and 242295 actions.
2024-04-13 12:26:00,635 - pomdp.py - creating coloring ...
2024-04-13 12:26:00,880 - synthesizer.py - synthesis initiated, design space: 1e665
2024-04-13 12:26:00,922 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:00,922 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 523, family size: 1e665, quotient: 697 states / 242295 actions
explored: 100 %
MDP stats: avg MDP size: 697, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:00,922 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:00,922 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:00,932 - pomdp.py - unfolding 88-FSC template into POMDP ...
2024-04-13 12:26:01,031 - pomdp.py - constructed quotient MDP having 705 states and 247896 actions.
2024-04-13 12:26:01,032 - pomdp.py - creating coloring ...
2024-04-13 12:26:01,253 - synthesizer.py - synthesis initiated, design space: 1e674
2024-04-13 12:26:01,294 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:01,294 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 529, family size: 1e674, quotient: 705 states / 247896 actions
explored: 100 %
MDP stats: avg MDP size: 705, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:01,294 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:01,294 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:01,304 - pomdp.py - unfolding 89-FSC template into POMDP ...
2024-04-13 12:26:01,403 - pomdp.py - constructed quotient MDP having 713 states and 253561 actions.
2024-04-13 12:26:01,403 - pomdp.py - creating coloring ...
2024-04-13 12:26:01,655 - synthesizer.py - synthesis initiated, design space: 1e683
2024-04-13 12:26:01,701 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:01,702 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 535, family size: 1e683, quotient: 713 states / 253561 actions
explored: 100 %
MDP stats: avg MDP size: 713, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:01,702 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:01,702 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:01,711 - pomdp.py - unfolding 90-FSC template into POMDP ...
2024-04-13 12:26:01,814 - pomdp.py - constructed quotient MDP having 721 states and 259290 actions.
2024-04-13 12:26:01,815 - pomdp.py - creating coloring ...
2024-04-13 12:26:02,066 - synthesizer.py - synthesis initiated, design space: 1e692
2024-04-13 12:26:02,114 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:02,114 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 541, family size: 1e692, quotient: 721 states / 259290 actions
explored: 100 %
MDP stats: avg MDP size: 721, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:02,114 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:02,114 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:02,124 - pomdp.py - unfolding 91-FSC template into POMDP ...
2024-04-13 12:26:02,269 - pomdp.py - constructed quotient MDP having 729 states and 265083 actions.
2024-04-13 12:26:02,269 - pomdp.py - creating coloring ...
2024-04-13 12:26:02,534 - synthesizer.py - synthesis initiated, design space: 1e701
2024-04-13 12:26:02,586 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:02,587 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 547, family size: 1e701, quotient: 729 states / 265083 actions
explored: 100 %
MDP stats: avg MDP size: 729, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:02,587 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:02,587 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:02,600 - pomdp.py - unfolding 92-FSC template into POMDP ...
2024-04-13 12:26:02,720 - pomdp.py - constructed quotient MDP having 737 states and 270940 actions.
2024-04-13 12:26:02,720 - pomdp.py - creating coloring ...
2024-04-13 12:26:02,957 - synthesizer.py - synthesis initiated, design space: 1e710
2024-04-13 12:26:03,005 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:03,005 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 553, family size: 1e710, quotient: 737 states / 270940 actions
explored: 100 %
MDP stats: avg MDP size: 737, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:03,006 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:03,006 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:03,015 - pomdp.py - unfolding 93-FSC template into POMDP ...
2024-04-13 12:26:03,145 - pomdp.py - constructed quotient MDP having 745 states and 276861 actions.
2024-04-13 12:26:03,145 - pomdp.py - creating coloring ...
2024-04-13 12:26:03,377 - synthesizer.py - synthesis initiated, design space: 1e719
2024-04-13 12:26:03,428 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:03,428 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 559, family size: 1e719, quotient: 745 states / 276861 actions
explored: 100 %
MDP stats: avg MDP size: 745, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:03,428 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:03,428 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:03,440 - pomdp.py - unfolding 94-FSC template into POMDP ...
2024-04-13 12:26:03,576 - pomdp.py - constructed quotient MDP having 753 states and 282846 actions.
2024-04-13 12:26:03,576 - pomdp.py - creating coloring ...
2024-04-13 12:26:03,858 - synthesizer.py - synthesis initiated, design space: 1e728
2024-04-13 12:26:03,909 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:03,910 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 565, family size: 1e728, quotient: 753 states / 282846 actions
explored: 100 %
MDP stats: avg MDP size: 753, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:03,910 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:03,910 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:03,920 - pomdp.py - unfolding 95-FSC template into POMDP ...
2024-04-13 12:26:04,040 - pomdp.py - constructed quotient MDP having 761 states and 288895 actions.
2024-04-13 12:26:04,040 - pomdp.py - creating coloring ...
2024-04-13 12:26:04,298 - synthesizer.py - synthesis initiated, design space: 1e737
2024-04-13 12:26:04,351 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:04,351 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 571, family size: 1e737, quotient: 761 states / 288895 actions
explored: 100 %
MDP stats: avg MDP size: 761, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:04,351 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:04,351 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:04,362 - pomdp.py - unfolding 96-FSC template into POMDP ...
2024-04-13 12:26:04,481 - pomdp.py - constructed quotient MDP having 769 states and 295008 actions.
2024-04-13 12:26:04,482 - pomdp.py - creating coloring ...
2024-04-13 12:26:04,775 - synthesizer.py - synthesis initiated, design space: 1e746
2024-04-13 12:26:04,828 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:04,828 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 577, family size: 1e746, quotient: 769 states / 295008 actions
explored: 100 %
MDP stats: avg MDP size: 769, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:04,829 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:04,829 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:04,841 - pomdp.py - unfolding 97-FSC template into POMDP ...
2024-04-13 12:26:04,961 - pomdp.py - constructed quotient MDP having 777 states and 301185 actions.
2024-04-13 12:26:04,961 - pomdp.py - creating coloring ...
2024-04-13 12:26:05,259 - synthesizer.py - synthesis initiated, design space: 1e755
2024-04-13 12:26:05,314 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:05,314 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 583, family size: 1e755, quotient: 777 states / 301185 actions
explored: 100 %
MDP stats: avg MDP size: 777, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:05,314 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:05,314 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:05,326 - pomdp.py - unfolding 98-FSC template into POMDP ...
2024-04-13 12:26:05,449 - pomdp.py - constructed quotient MDP having 785 states and 307426 actions.
2024-04-13 12:26:05,449 - pomdp.py - creating coloring ...
2024-04-13 12:26:05,713 - synthesizer.py - synthesis initiated, design space: 1e764
2024-04-13 12:26:05,769 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:05,769 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 589, family size: 1e764, quotient: 785 states / 307426 actions
explored: 100 %
MDP stats: avg MDP size: 785, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:05,769 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:05,770 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:05,781 - pomdp.py - unfolding 99-FSC template into POMDP ...
2024-04-13 12:26:05,904 - pomdp.py - constructed quotient MDP having 793 states and 313731 actions.
2024-04-13 12:26:05,904 - pomdp.py - creating coloring ...
2024-04-13 12:26:06,197 - synthesizer.py - synthesis initiated, design space: 1e773
2024-04-13 12:26:06,252 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:06,252 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 595, family size: 1e773, quotient: 793 states / 313731 actions
explored: 100 %
MDP stats: avg MDP size: 793, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:06,252 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:06,252 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:06,266 - pomdp.py - unfolding 100-FSC template into POMDP ...
2024-04-13 12:26:06,420 - pomdp.py - constructed quotient MDP having 801 states and 320100 actions.
2024-04-13 12:26:06,420 - pomdp.py - creating coloring ...
2024-04-13 12:26:06,691 - synthesizer.py - synthesis initiated, design space: 1e782
2024-04-13 12:26:06,750 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:06,750 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 601, family size: 1e782, quotient: 801 states / 320100 actions
explored: 100 %
MDP stats: avg MDP size: 801, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:06,751 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:06,751 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:06,763 - pomdp.py - unfolding 101-FSC template into POMDP ...
2024-04-13 12:26:06,913 - pomdp.py - constructed quotient MDP having 809 states and 326533 actions.
2024-04-13 12:26:06,913 - pomdp.py - creating coloring ...
2024-04-13 12:26:07,234 - synthesizer.py - synthesis initiated, design space: 1e791
2024-04-13 12:26:07,292 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:07,292 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 607, family size: 1e791, quotient: 809 states / 326533 actions
explored: 100 %
MDP stats: avg MDP size: 809, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:07,292 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:07,292 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:07,305 - pomdp.py - unfolding 102-FSC template into POMDP ...
2024-04-13 12:26:07,442 - pomdp.py - constructed quotient MDP having 817 states and 333030 actions.
2024-04-13 12:26:07,442 - pomdp.py - creating coloring ...
2024-04-13 12:26:07,777 - synthesizer.py - synthesis initiated, design space: 1e800
2024-04-13 12:26:07,839 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:07,839 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 613, family size: 1e800, quotient: 817 states / 333030 actions
explored: 100 %
MDP stats: avg MDP size: 817, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:07,840 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:07,840 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:07,852 - pomdp.py - unfolding 103-FSC template into POMDP ...
2024-04-13 12:26:07,986 - pomdp.py - constructed quotient MDP having 825 states and 339591 actions.
2024-04-13 12:26:07,986 - pomdp.py - creating coloring ...
2024-04-13 12:26:08,272 - synthesizer.py - synthesis initiated, design space: 1e810
2024-04-13 12:26:08,333 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:08,333 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 619, family size: 1e810, quotient: 825 states / 339591 actions
explored: 100 %
MDP stats: avg MDP size: 825, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:08,333 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:08,333 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:08,346 - pomdp.py - unfolding 104-FSC template into POMDP ...
2024-04-13 12:26:08,474 - pomdp.py - constructed quotient MDP having 833 states and 346216 actions.
2024-04-13 12:26:08,474 - pomdp.py - creating coloring ...
2024-04-13 12:26:08,810 - synthesizer.py - synthesis initiated, design space: 1e819
2024-04-13 12:26:08,871 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:08,871 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 625, family size: 1e819, quotient: 833 states / 346216 actions
explored: 100 %
MDP stats: avg MDP size: 833, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:08,872 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:08,872 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:08,885 - pomdp.py - unfolding 105-FSC template into POMDP ...
2024-04-13 12:26:09,018 - pomdp.py - constructed quotient MDP having 841 states and 352905 actions.
2024-04-13 12:26:09,018 - pomdp.py - creating coloring ...
2024-04-13 12:26:09,350 - synthesizer.py - synthesis initiated, design space: 1e828
2024-04-13 12:26:09,411 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:09,411 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 631, family size: 1e828, quotient: 841 states / 352905 actions
explored: 100 %
MDP stats: avg MDP size: 841, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:09,412 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:09,412 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:09,426 - pomdp.py - unfolding 106-FSC template into POMDP ...
2024-04-13 12:26:09,593 - pomdp.py - constructed quotient MDP having 849 states and 359658 actions.
2024-04-13 12:26:09,593 - pomdp.py - creating coloring ...
2024-04-13 12:26:09,938 - synthesizer.py - synthesis initiated, design space: 1e837
2024-04-13 12:26:10,004 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:10,004 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 637, family size: 1e837, quotient: 849 states / 359658 actions
explored: 100 %
MDP stats: avg MDP size: 849, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:10,005 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:10,005 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:10,018 - pomdp.py - unfolding 107-FSC template into POMDP ...
2024-04-13 12:26:10,162 - pomdp.py - constructed quotient MDP having 857 states and 366475 actions.
2024-04-13 12:26:10,162 - pomdp.py - creating coloring ...
2024-04-13 12:26:10,462 - synthesizer.py - synthesis initiated, design space: 1e846
2024-04-13 12:26:10,529 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:10,529 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 643, family size: 1e846, quotient: 857 states / 366475 actions
explored: 100 %
MDP stats: avg MDP size: 857, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:10,529 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:10,529 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:10,543 - pomdp.py - unfolding 108-FSC template into POMDP ...
2024-04-13 12:26:10,706 - pomdp.py - constructed quotient MDP having 865 states and 373356 actions.
2024-04-13 12:26:10,706 - pomdp.py - creating coloring ...
2024-04-13 12:26:11,072 - synthesizer.py - synthesis initiated, design space: 1e855
2024-04-13 12:26:11,146 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:11,146 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 649, family size: 1e855, quotient: 865 states / 373356 actions
explored: 100 %
MDP stats: avg MDP size: 865, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:11,147 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:11,147 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:11,161 - pomdp.py - unfolding 109-FSC template into POMDP ...
2024-04-13 12:26:11,342 - pomdp.py - constructed quotient MDP having 873 states and 380301 actions.
2024-04-13 12:26:11,342 - pomdp.py - creating coloring ...
2024-04-13 12:26:11,665 - synthesizer.py - synthesis initiated, design space: 1e865
2024-04-13 12:26:11,735 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:11,735 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 655, family size: 1e865, quotient: 873 states / 380301 actions
explored: 100 %
MDP stats: avg MDP size: 873, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:11,735 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:11,735 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:11,750 - pomdp.py - unfolding 110-FSC template into POMDP ...
2024-04-13 12:26:11,930 - pomdp.py - constructed quotient MDP having 881 states and 387310 actions.
2024-04-13 12:26:11,930 - pomdp.py - creating coloring ...
2024-04-13 12:26:12,255 - synthesizer.py - synthesis initiated, design space: 1e874
2024-04-13 12:26:12,328 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:12,328 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 661, family size: 1e874, quotient: 881 states / 387310 actions
explored: 100 %
MDP stats: avg MDP size: 881, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:12,328 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:12,328 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:12,345 - pomdp.py - unfolding 111-FSC template into POMDP ...
2024-04-13 12:26:12,545 - pomdp.py - constructed quotient MDP having 889 states and 394383 actions.
2024-04-13 12:26:12,545 - pomdp.py - creating coloring ...
2024-04-13 12:26:12,899 - synthesizer.py - synthesis initiated, design space: 1e883
2024-04-13 12:26:12,971 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:12,971 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 667, family size: 1e883, quotient: 889 states / 394383 actions
explored: 100 %
MDP stats: avg MDP size: 889, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:12,971 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:12,971 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:12,986 - pomdp.py - unfolding 112-FSC template into POMDP ...
2024-04-13 12:26:13,130 - pomdp.py - constructed quotient MDP having 897 states and 401520 actions.
2024-04-13 12:26:13,130 - pomdp.py - creating coloring ...
2024-04-13 12:26:13,504 - synthesizer.py - synthesis initiated, design space: 1e892
2024-04-13 12:26:13,574 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:13,575 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 673, family size: 1e892, quotient: 897 states / 401520 actions
explored: 100 %
MDP stats: avg MDP size: 897, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:13,575 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:13,575 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:13,592 - pomdp.py - unfolding 113-FSC template into POMDP ...
2024-04-13 12:26:13,787 - pomdp.py - constructed quotient MDP having 905 states and 408721 actions.
2024-04-13 12:26:13,787 - pomdp.py - creating coloring ...
2024-04-13 12:26:14,129 - synthesizer.py - synthesis initiated, design space: 1e902
2024-04-13 12:26:14,198 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:14,198 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 679, family size: 1e902, quotient: 905 states / 408721 actions
explored: 100 %
MDP stats: avg MDP size: 905, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:14,198 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:14,198 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:14,214 - pomdp.py - unfolding 114-FSC template into POMDP ...
2024-04-13 12:26:14,364 - pomdp.py - constructed quotient MDP having 913 states and 415986 actions.
2024-04-13 12:26:14,364 - pomdp.py - creating coloring ...
2024-04-13 12:26:14,737 - synthesizer.py - synthesis initiated, design space: 1e911
2024-04-13 12:26:14,816 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:14,816 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.08 s
number of holes: 685, family size: 1e911, quotient: 913 states / 415986 actions
explored: 100 %
MDP stats: avg MDP size: 913, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:14,816 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:14,816 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:14,832 - pomdp.py - unfolding 115-FSC template into POMDP ...
2024-04-13 12:26:15,013 - pomdp.py - constructed quotient MDP having 921 states and 423315 actions.
2024-04-13 12:26:15,013 - pomdp.py - creating coloring ...
2024-04-13 12:26:15,396 - synthesizer.py - synthesis initiated, design space: 1e920
2024-04-13 12:26:15,475 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:15,475 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.08 s
number of holes: 691, family size: 1e920, quotient: 921 states / 423315 actions
explored: 100 %
MDP stats: avg MDP size: 921, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:15,476 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:15,476 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:15,491 - pomdp.py - unfolding 116-FSC template into POMDP ...
2024-04-13 12:26:15,690 - pomdp.py - constructed quotient MDP having 929 states and 430708 actions.
2024-04-13 12:26:15,690 - pomdp.py - creating coloring ...
2024-04-13 12:26:16,040 - synthesizer.py - synthesis initiated, design space: 1e930
2024-04-13 12:26:16,115 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:16,115 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 697, family size: 1e930, quotient: 929 states / 430708 actions
explored: 100 %
MDP stats: avg MDP size: 929, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:16,115 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:16,115 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:16,131 - pomdp.py - unfolding 117-FSC template into POMDP ...
2024-04-13 12:26:16,325 - pomdp.py - constructed quotient MDP having 937 states and 438165 actions.
2024-04-13 12:26:16,325 - pomdp.py - creating coloring ...
2024-04-13 12:26:16,752 - synthesizer.py - synthesis initiated, design space: 1e939
2024-04-13 12:26:16,826 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:16,826 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 703, family size: 1e939, quotient: 937 states / 438165 actions
explored: 100 %
MDP stats: avg MDP size: 937, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:16,827 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:16,827 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:16,843 - pomdp.py - unfolding 118-FSC template into POMDP ...
2024-04-13 12:26:17,022 - pomdp.py - constructed quotient MDP having 945 states and 445686 actions.
2024-04-13 12:26:17,022 - pomdp.py - creating coloring ...
2024-04-13 12:26:17,413 - synthesizer.py - synthesis initiated, design space: 1e948
2024-04-13 12:26:17,495 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:17,496 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.08 s
number of holes: 709, family size: 1e948, quotient: 945 states / 445686 actions
explored: 100 %
MDP stats: avg MDP size: 945, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:17,496 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:17,496 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:17,515 - pomdp.py - unfolding 119-FSC template into POMDP ...
2024-04-13 12:26:17,683 - pomdp.py - constructed quotient MDP having 953 states and 453271 actions.
2024-04-13 12:26:17,683 - pomdp.py - creating coloring ...
2024-04-13 12:26:18,099 - synthesizer.py - synthesis initiated, design space: 1e957
2024-04-13 12:26:18,183 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:18,183 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.08 s
number of holes: 715, family size: 1e957, quotient: 953 states / 453271 actions
explored: 100 %
MDP stats: avg MDP size: 953, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:18,183 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:18,183 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:18,202 - pomdp.py - unfolding 120-FSC template into POMDP ...
2024-04-13 12:26:18,412 - pomdp.py - constructed quotient MDP having 961 states and 460920 actions.
2024-04-13 12:26:18,412 - pomdp.py - creating coloring ...
2024-04-13 12:26:18,785 - synthesizer.py - synthesis initiated, design space: 1e967
2024-04-13 12:26:18,867 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:18,867 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.08 s
number of holes: 721, family size: 1e967, quotient: 961 states / 460920 actions
explored: 100 %
MDP stats: avg MDP size: 961, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:18,867 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:18,868 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:18,886 - pomdp.py - unfolding 121-FSC template into POMDP ...
2024-04-13 12:26:19,096 - pomdp.py - constructed quotient MDP having 969 states and 468633 actions.
2024-04-13 12:26:19,096 - pomdp.py - creating coloring ...
2024-04-13 12:26:19,534 - synthesizer.py - synthesis initiated, design space: 1e976
2024-04-13 12:26:19,620 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:19,620 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.09 s
number of holes: 727, family size: 1e976, quotient: 969 states / 468633 actions
explored: 100 %
MDP stats: avg MDP size: 969, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:19,621 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:19,621 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:19,640 - pomdp.py - unfolding 122-FSC template into POMDP ...
2024-04-13 12:26:19,861 - pomdp.py - constructed quotient MDP having 977 states and 476410 actions.
2024-04-13 12:26:19,861 - pomdp.py - creating coloring ...
2024-04-13 12:26:20,256 - synthesizer.py - synthesis initiated, design space: 1e986
2024-04-13 12:26:20,342 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:20,342 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.09 s
number of holes: 733, family size: 1e986, quotient: 977 states / 476410 actions
explored: 100 %
MDP stats: avg MDP size: 977, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:20,342 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:20,342 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:20,361 - pomdp.py - unfolding 123-FSC template into POMDP ...
2024-04-13 12:26:20,584 - pomdp.py - constructed quotient MDP having 985 states and 484251 actions.
2024-04-13 12:26:20,584 - pomdp.py - creating coloring ...
2024-04-13 12:26:20,981 - synthesizer.py - synthesis initiated, design space: 1e995
2024-04-13 12:26:21,071 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:21,071 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.09 s
number of holes: 739, family size: 1e995, quotient: 985 states / 484251 actions
explored: 100 %
MDP stats: avg MDP size: 985, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:21,071 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:21,071 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:21,090 - pomdp.py - unfolding 124-FSC template into POMDP ...
2024-04-13 12:26:21,308 - pomdp.py - constructed quotient MDP having 993 states and 492156 actions.
2024-04-13 12:26:21,308 - pomdp.py - creating coloring ...
2024-04-13 12:26:21,792 - synthesizer.py - synthesis initiated, design space: 1e1004
2024-04-13 12:26:21,889 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:21,889 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 745, family size: 1e1004, quotient: 993 states / 492156 actions
explored: 100 %
MDP stats: avg MDP size: 993, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:21,889 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:21,889 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:21,913 - pomdp.py - unfolding 125-FSC template into POMDP ...
2024-04-13 12:26:22,136 - pomdp.py - constructed quotient MDP having 1001 states and 500125 actions.
2024-04-13 12:26:22,136 - pomdp.py - creating coloring ...
2024-04-13 12:26:22,571 - synthesizer.py - synthesis initiated, design space: 1e1014
2024-04-13 12:26:22,672 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:22,672 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 751, family size: 1e1014, quotient: 1001 states / 500125 actions
explored: 100 %
MDP stats: avg MDP size: 1001, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:22,672 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:22,673 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:22,693 - pomdp.py - unfolding 126-FSC template into POMDP ...
2024-04-13 12:26:22,940 - pomdp.py - constructed quotient MDP having 1009 states and 508158 actions.
2024-04-13 12:26:22,940 - pomdp.py - creating coloring ...
2024-04-13 12:26:23,375 - synthesizer.py - synthesis initiated, design space: 1e1023
2024-04-13 12:26:23,467 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:23,468 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.09 s
number of holes: 757, family size: 1e1023, quotient: 1009 states / 508158 actions
explored: 100 %
MDP stats: avg MDP size: 1009, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:23,468 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:23,468 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:23,492 - pomdp.py - unfolding 127-FSC template into POMDP ...
2024-04-13 12:26:23,756 - pomdp.py - constructed quotient MDP having 1017 states and 516255 actions.
2024-04-13 12:26:23,756 - pomdp.py - creating coloring ...
2024-04-13 12:26:24,216 - synthesizer.py - synthesis initiated, design space: 1e1033
2024-04-13 12:26:24,313 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:24,313 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 763, family size: 1e1033, quotient: 1017 states / 516255 actions
explored: 100 %
MDP stats: avg MDP size: 1017, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:24,313 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:24,313 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:24,336 - pomdp.py - unfolding 128-FSC template into POMDP ...
2024-04-13 12:26:24,533 - pomdp.py - constructed quotient MDP having 1025 states and 524416 actions.
2024-04-13 12:26:24,533 - pomdp.py - creating coloring ...
2024-04-13 12:26:25,117 - synthesizer.py - synthesis initiated, design space: 1e1042
2024-04-13 12:26:25,222 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:25,222 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 769, family size: 1e1042, quotient: 1025 states / 524416 actions
explored: 100 %
MDP stats: avg MDP size: 1025, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:25,223 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:25,223 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:25,248 - pomdp.py - unfolding 129-FSC template into POMDP ...
2024-04-13 12:26:25,468 - pomdp.py - constructed quotient MDP having 1033 states and 532641 actions.
2024-04-13 12:26:25,468 - pomdp.py - creating coloring ...
2024-04-13 12:26:25,933 - synthesizer.py - synthesis initiated, design space: 1e1051
2024-04-13 12:26:26,029 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:26,029 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 775, family size: 1e1051, quotient: 1033 states / 532641 actions
explored: 100 %
MDP stats: avg MDP size: 1033, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:26,029 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:26,029 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:26,051 - pomdp.py - unfolding 130-FSC template into POMDP ...
2024-04-13 12:26:26,343 - pomdp.py - constructed quotient MDP having 1041 states and 540930 actions.
2024-04-13 12:26:26,343 - pomdp.py - creating coloring ...
2024-04-13 12:26:26,830 - synthesizer.py - synthesis initiated, design space: 1e1061
2024-04-13 12:26:26,931 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:26,932 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 781, family size: 1e1061, quotient: 1041 states / 540930 actions
explored: 100 %
MDP stats: avg MDP size: 1041, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:26,932 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:26,932 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:26,955 - pomdp.py - unfolding 131-FSC template into POMDP ...
2024-04-13 12:26:27,229 - pomdp.py - constructed quotient MDP having 1049 states and 549283 actions.
2024-04-13 12:26:27,229 - pomdp.py - creating coloring ...
2024-04-13 12:26:27,739 - synthesizer.py - synthesis initiated, design space: 1e1070
2024-04-13 12:26:27,845 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:27,845 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 787, family size: 1e1070, quotient: 1049 states / 549283 actions
explored: 100 %
MDP stats: avg MDP size: 1049, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:27,846 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:27,846 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:27,869 - pomdp.py - unfolding 132-FSC template into POMDP ...
2024-04-13 12:26:28,074 - pomdp.py - constructed quotient MDP having 1057 states and 557700 actions.
2024-04-13 12:26:28,074 - pomdp.py - creating coloring ...
2024-04-13 12:26:28,666 - synthesizer.py - synthesis initiated, design space: 1e1080
2024-04-13 12:26:28,768 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:28,768 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 793, family size: 1e1080, quotient: 1057 states / 557700 actions
explored: 100 %
MDP stats: avg MDP size: 1057, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:28,768 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:28,768 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:28,790 - pomdp.py - unfolding 133-FSC template into POMDP ...
2024-04-13 12:26:28,997 - pomdp.py - constructed quotient MDP having 1065 states and 566181 actions.
2024-04-13 12:26:28,997 - pomdp.py - creating coloring ...
2024-04-13 12:26:29,450 - synthesizer.py - synthesis initiated, design space: 1e1089
2024-04-13 12:26:29,554 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:29,554 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 799, family size: 1e1089, quotient: 1065 states / 566181 actions
explored: 100 %
MDP stats: avg MDP size: 1065, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:29,554 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:29,554 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:29,577 - pomdp.py - unfolding 134-FSC template into POMDP ...
2024-04-13 12:26:29,822 - pomdp.py - constructed quotient MDP having 1073 states and 574726 actions.
2024-04-13 12:26:29,822 - pomdp.py - creating coloring ...
2024-04-13 12:26:30,349 - synthesizer.py - synthesis initiated, design space: 1e1099
2024-04-13 12:26:30,453 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:30,453 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 805, family size: 1e1099, quotient: 1073 states / 574726 actions
explored: 100 %
MDP stats: avg MDP size: 1073, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:30,454 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:30,454 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:30,477 - pomdp.py - unfolding 135-FSC template into POMDP ...
2024-04-13 12:26:30,738 - pomdp.py - constructed quotient MDP having 1081 states and 583335 actions.
2024-04-13 12:26:30,738 - pomdp.py - creating coloring ...
2024-04-13 12:26:31,295 - synthesizer.py - synthesis initiated, design space: 1e1108
2024-04-13 12:26:31,415 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:31,415 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.12 s
number of holes: 811, family size: 1e1108, quotient: 1081 states / 583335 actions
explored: 100 %
MDP stats: avg MDP size: 1081, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:31,415 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:31,415 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:31,438 - pomdp.py - unfolding 136-FSC template into POMDP ...
2024-04-13 12:26:31,662 - pomdp.py - constructed quotient MDP having 1089 states and 592008 actions.
2024-04-13 12:26:31,662 - pomdp.py - creating coloring ...
2024-04-13 12:26:32,146 - synthesizer.py - synthesis initiated, design space: 1e1118
2024-04-13 12:26:32,254 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:32,254 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 817, family size: 1e1118, quotient: 1089 states / 592008 actions
explored: 100 %
MDP stats: avg MDP size: 1089, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:32,255 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:32,255 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:32,278 - pomdp.py - unfolding 137-FSC template into POMDP ...
2024-04-13 12:26:32,556 - pomdp.py - constructed quotient MDP having 1097 states and 600745 actions.
2024-04-13 12:26:32,556 - pomdp.py - creating coloring ...
2024-04-13 12:26:33,093 - synthesizer.py - synthesis initiated, design space: 1e1127
2024-04-13 12:26:33,207 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:33,207 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 823, family size: 1e1127, quotient: 1097 states / 600745 actions
explored: 100 %
MDP stats: avg MDP size: 1097, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:33,207 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:33,207 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:33,232 - pomdp.py - unfolding 138-FSC template into POMDP ...
2024-04-13 12:26:33,511 - pomdp.py - constructed quotient MDP having 1105 states and 609546 actions.
2024-04-13 12:26:33,511 - pomdp.py - creating coloring ...
2024-04-13 12:26:34,096 - synthesizer.py - synthesis initiated, design space: 1e1137
2024-04-13 12:26:34,209 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:34,209 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 829, family size: 1e1137, quotient: 1105 states / 609546 actions
explored: 100 %
MDP stats: avg MDP size: 1105, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:34,209 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:34,209 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:34,233 - pomdp.py - unfolding 139-FSC template into POMDP ...
2024-04-13 12:26:34,462 - pomdp.py - constructed quotient MDP having 1113 states and 618411 actions.
2024-04-13 12:26:34,462 - pomdp.py - creating coloring ...
2024-04-13 12:26:35,055 - synthesizer.py - synthesis initiated, design space: 1e1146
2024-04-13 12:26:35,193 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:35,193 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 835, family size: 1e1146, quotient: 1113 states / 618411 actions
explored: 100 %
MDP stats: avg MDP size: 1113, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:35,194 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:35,194 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:35,234 - pomdp.py - unfolding 140-FSC template into POMDP ...
2024-04-13 12:26:35,568 - pomdp.py - constructed quotient MDP having 1121 states and 627340 actions.
2024-04-13 12:26:35,568 - pomdp.py - creating coloring ...
2024-04-13 12:26:36,199 - synthesizer.py - synthesis initiated, design space: 1e1156
2024-04-13 12:26:36,317 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:36,317 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.12 s
number of holes: 841, family size: 1e1156, quotient: 1121 states / 627340 actions
explored: 100 %
MDP stats: avg MDP size: 1121, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:36,317 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:36,317 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:36,343 - pomdp.py - unfolding 141-FSC template into POMDP ...
2024-04-13 12:26:36,647 - pomdp.py - constructed quotient MDP having 1129 states and 636333 actions.
2024-04-13 12:26:36,647 - pomdp.py - creating coloring ...
2024-04-13 12:26:37,165 - synthesizer.py - synthesis initiated, design space: 1e1165
2024-04-13 12:26:37,277 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:37,277 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 847, family size: 1e1165, quotient: 1129 states / 636333 actions
explored: 100 %
MDP stats: avg MDP size: 1129, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:37,278 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:37,278 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:37,304 - pomdp.py - unfolding 142-FSC template into POMDP ...
2024-04-13 12:26:37,652 - pomdp.py - constructed quotient MDP having 1137 states and 645390 actions.
2024-04-13 12:26:37,652 - pomdp.py - creating coloring ...
2024-04-13 12:26:38,365 - synthesizer.py - synthesis initiated, design space: 1e1175
2024-04-13 12:26:38,498 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:38,498 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.13 s
number of holes: 853, family size: 1e1175, quotient: 1137 states / 645390 actions
explored: 100 %
MDP stats: avg MDP size: 1137, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:38,498 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:38,498 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:38,528 - pomdp.py - unfolding 143-FSC template into POMDP ...
2024-04-13 12:26:38,797 - pomdp.py - constructed quotient MDP having 1145 states and 654511 actions.
2024-04-13 12:26:38,797 - pomdp.py - creating coloring ...
2024-04-13 12:26:39,353 - synthesizer.py - synthesis initiated, design space: 1e1185
2024-04-13 12:26:39,475 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:39,475 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.12 s
number of holes: 859, family size: 1e1185, quotient: 1145 states / 654511 actions
explored: 100 %
MDP stats: avg MDP size: 1145, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:39,475 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:39,475 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:39,502 - pomdp.py - unfolding 144-FSC template into POMDP ...
2024-04-13 12:26:39,793 - pomdp.py - constructed quotient MDP having 1153 states and 663696 actions.
2024-04-13 12:26:39,793 - pomdp.py - creating coloring ...
2024-04-13 12:26:40,431 - synthesizer.py - synthesis initiated, design space: 1e1194
2024-04-13 12:26:40,558 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:40,558 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.13 s
number of holes: 865, family size: 1e1194, quotient: 1153 states / 663696 actions
explored: 100 %
MDP stats: avg MDP size: 1153, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:40,558 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:40,558 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:40,583 - pomdp.py - unfolding 145-FSC template into POMDP ...
2024-04-13 12:26:40,840 - pomdp.py - constructed quotient MDP having 1161 states and 672945 actions.
2024-04-13 12:26:40,840 - pomdp.py - creating coloring ...
2024-04-13 12:26:41,405 - synthesizer.py - synthesis initiated, design space: 1e1204
2024-04-13 12:26:41,533 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:41,533 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.13 s
number of holes: 871, family size: 1e1204, quotient: 1161 states / 672945 actions
explored: 100 %
MDP stats: avg MDP size: 1161, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:41,533 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:41,533 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:41,560 - pomdp.py - unfolding 146-FSC template into POMDP ...
2024-04-13 12:26:41,858 - pomdp.py - constructed quotient MDP having 1169 states and 682258 actions.
2024-04-13 12:26:41,859 - pomdp.py - creating coloring ...
2024-04-13 12:26:42,424 - synthesizer.py - synthesis initiated, design space: 1e1213
2024-04-13 12:26:42,555 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:42,555 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.13 s
number of holes: 877, family size: 1e1213, quotient: 1169 states / 682258 actions
explored: 100 %
MDP stats: avg MDP size: 1169, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:42,556 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:42,556 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:42,585 - pomdp.py - unfolding 147-FSC template into POMDP ...
2024-04-13 12:26:42,885 - pomdp.py - constructed quotient MDP having 1177 states and 691635 actions.
2024-04-13 12:26:42,885 - pomdp.py - creating coloring ...
2024-04-13 12:26:43,453 - synthesizer.py - synthesis initiated, design space: 1e1223
2024-04-13 12:26:43,582 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:43,582 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.13 s
number of holes: 883, family size: 1e1223, quotient: 1177 states / 691635 actions
explored: 100 %
MDP stats: avg MDP size: 1177, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:43,583 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:43,583 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:43,612 - pomdp.py - unfolding 148-FSC template into POMDP ...
2024-04-13 12:26:43,922 - pomdp.py - constructed quotient MDP having 1185 states and 701076 actions.
2024-04-13 12:26:43,922 - pomdp.py - creating coloring ...
2024-04-13 12:26:44,613 - synthesizer.py - synthesis initiated, design space: 1e1233
2024-04-13 12:26:44,750 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:44,750 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 889, family size: 1e1233, quotient: 1185 states / 701076 actions
explored: 100 %
MDP stats: avg MDP size: 1185, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:44,751 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:44,751 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:44,782 - pomdp.py - unfolding 149-FSC template into POMDP ...
2024-04-13 12:26:45,124 - pomdp.py - constructed quotient MDP having 1193 states and 710581 actions.
2024-04-13 12:26:45,124 - pomdp.py - creating coloring ...
2024-04-13 12:26:45,851 - synthesizer.py - synthesis initiated, design space: 1e1242
2024-04-13 12:26:45,993 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:45,993 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 895, family size: 1e1242, quotient: 1193 states / 710581 actions
explored: 100 %
MDP stats: avg MDP size: 1193, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:45,994 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:45,994 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:46,036 - pomdp.py - unfolding 150-FSC template into POMDP ...
2024-04-13 12:26:46,370 - pomdp.py - constructed quotient MDP having 1201 states and 720150 actions.
2024-04-13 12:26:46,370 - pomdp.py - creating coloring ...
2024-04-13 12:26:47,141 - synthesizer.py - synthesis initiated, design space: 1e1252
2024-04-13 12:26:47,278 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:47,278 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 901, family size: 1e1252, quotient: 1201 states / 720150 actions
explored: 100 %
MDP stats: avg MDP size: 1201, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:47,279 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:47,279 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:47,310 - pomdp.py - unfolding 151-FSC template into POMDP ...
2024-04-13 12:26:47,664 - pomdp.py - constructed quotient MDP having 1209 states and 729783 actions.
2024-04-13 12:26:47,664 - pomdp.py - creating coloring ...
2024-04-13 12:26:48,362 - synthesizer.py - synthesis initiated, design space: 1e1261
2024-04-13 12:26:48,498 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:48,498 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 907, family size: 1e1261, quotient: 1209 states / 729783 actions
explored: 100 %
MDP stats: avg MDP size: 1209, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:48,499 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:48,499 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:48,538 - pomdp.py - unfolding 152-FSC template into POMDP ...
2024-04-13 12:26:48,901 - pomdp.py - constructed quotient MDP having 1217 states and 739480 actions.
2024-04-13 12:26:48,901 - pomdp.py - creating coloring ...
2024-04-13 12:26:49,481 - synthesizer.py - synthesis initiated, design space: 1e1271
2024-04-13 12:26:49,618 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:49,618 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 913, family size: 1e1271, quotient: 1217 states / 739480 actions
explored: 100 %
MDP stats: avg MDP size: 1217, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:49,618 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:49,618 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:49,647 - pomdp.py - unfolding 153-FSC template into POMDP ...
2024-04-13 12:26:49,954 - pomdp.py - constructed quotient MDP having 1225 states and 749241 actions.
2024-04-13 12:26:49,954 - pomdp.py - creating coloring ...
2024-04-13 12:26:50,620 - synthesizer.py - synthesis initiated, design space: 1e1281
2024-04-13 12:26:50,755 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:50,755 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.13 s
number of holes: 919, family size: 1e1281, quotient: 1225 states / 749241 actions
explored: 100 %
MDP stats: avg MDP size: 1225, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:50,756 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:50,756 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:50,798 - pomdp.py - unfolding 154-FSC template into POMDP ...
2024-04-13 12:26:51,127 - pomdp.py - constructed quotient MDP having 1233 states and 759066 actions.
2024-04-13 12:26:51,128 - pomdp.py - creating coloring ...
2024-04-13 12:26:51,809 - synthesizer.py - synthesis initiated, design space: 1e1290
2024-04-13 12:26:51,949 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:51,949 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 925, family size: 1e1290, quotient: 1233 states / 759066 actions
explored: 100 %
MDP stats: avg MDP size: 1233, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:51,950 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:51,950 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:51,980 - pomdp.py - unfolding 155-FSC template into POMDP ...
2024-04-13 12:26:52,326 - pomdp.py - constructed quotient MDP having 1241 states and 768955 actions.
2024-04-13 12:26:52,326 - pomdp.py - creating coloring ...
2024-04-13 12:26:53,124 - synthesizer.py - synthesis initiated, design space: 1e1300
2024-04-13 12:26:53,280 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:53,280 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 931, family size: 1e1300, quotient: 1241 states / 768955 actions
explored: 100 %
MDP stats: avg MDP size: 1241, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:53,280 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:53,280 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:53,324 - pomdp.py - unfolding 156-FSC template into POMDP ...
2024-04-13 12:26:53,676 - pomdp.py - constructed quotient MDP having 1249 states and 778908 actions.
2024-04-13 12:26:53,676 - pomdp.py - creating coloring ...
2024-04-13 12:26:54,504 - synthesizer.py - synthesis initiated, design space: 1e1310
2024-04-13 12:26:54,654 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:54,654 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 937, family size: 1e1310, quotient: 1249 states / 778908 actions
explored: 100 %
MDP stats: avg MDP size: 1249, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:54,654 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:54,654 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:54,690 - pomdp.py - unfolding 157-FSC template into POMDP ...
2024-04-13 12:26:54,973 - pomdp.py - constructed quotient MDP having 1257 states and 788925 actions.
2024-04-13 12:26:54,974 - pomdp.py - creating coloring ...
2024-04-13 12:26:55,868 - synthesizer.py - synthesis initiated, design space: 1e1320
2024-04-13 12:26:56,025 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:56,025 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 943, family size: 1e1320, quotient: 1257 states / 788925 actions
explored: 100 %
MDP stats: avg MDP size: 1257, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:56,025 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:56,025 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:56,061 - pomdp.py - unfolding 158-FSC template into POMDP ...
2024-04-13 12:26:56,423 - pomdp.py - constructed quotient MDP having 1265 states and 799006 actions.
2024-04-13 12:26:56,423 - pomdp.py - creating coloring ...
2024-04-13 12:26:57,115 - synthesizer.py - synthesis initiated, design space: 1e1329
2024-04-13 12:26:57,273 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:57,273 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 949, family size: 1e1329, quotient: 1265 states / 799006 actions
explored: 100 %
MDP stats: avg MDP size: 1265, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:57,274 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:57,274 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:57,309 - pomdp.py - unfolding 159-FSC template into POMDP ...
2024-04-13 12:26:57,692 - pomdp.py - constructed quotient MDP having 1273 states and 809151 actions.
2024-04-13 12:26:57,692 - pomdp.py - creating coloring ...
2024-04-13 12:26:58,607 - synthesizer.py - synthesis initiated, design space: 1e1339
2024-04-13 12:26:58,754 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:58,754 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 955, family size: 1e1339, quotient: 1273 states / 809151 actions
explored: 100 %
MDP stats: avg MDP size: 1273, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:58,754 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:58,754 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:26:58,786 - pomdp.py - unfolding 160-FSC template into POMDP ...
2024-04-13 12:26:59,132 - pomdp.py - constructed quotient MDP having 1281 states and 819360 actions.
2024-04-13 12:26:59,133 - pomdp.py - creating coloring ...
2024-04-13 12:26:59,818 - synthesizer.py - synthesis initiated, design space: 1e1349
2024-04-13 12:26:59,971 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:26:59,972 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 961, family size: 1e1349, quotient: 1281 states / 819360 actions
explored: 100 %
MDP stats: avg MDP size: 1281, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:26:59,972 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:26:59,972 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:00,007 - pomdp.py - unfolding 161-FSC template into POMDP ...
2024-04-13 12:27:00,380 - pomdp.py - constructed quotient MDP having 1289 states and 829633 actions.
2024-04-13 12:27:00,381 - pomdp.py - creating coloring ...
2024-04-13 12:27:01,143 - synthesizer.py - synthesis initiated, design space: 1e1358
2024-04-13 12:27:01,292 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:01,292 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 967, family size: 1e1358, quotient: 1289 states / 829633 actions
explored: 100 %
MDP stats: avg MDP size: 1289, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:01,293 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:01,293 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:01,325 - pomdp.py - unfolding 162-FSC template into POMDP ...
2024-04-13 12:27:01,637 - pomdp.py - constructed quotient MDP having 1297 states and 839970 actions.
2024-04-13 12:27:01,637 - pomdp.py - creating coloring ...
2024-04-13 12:27:02,481 - synthesizer.py - synthesis initiated, design space: 1e1368
2024-04-13 12:27:02,636 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:02,636 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 973, family size: 1e1368, quotient: 1297 states / 839970 actions
explored: 100 %
MDP stats: avg MDP size: 1297, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:02,636 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:02,636 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:02,669 - pomdp.py - unfolding 163-FSC template into POMDP ...
2024-04-13 12:27:02,954 - pomdp.py - constructed quotient MDP having 1305 states and 850371 actions.
2024-04-13 12:27:02,954 - pomdp.py - creating coloring ...
2024-04-13 12:27:03,808 - synthesizer.py - synthesis initiated, design space: 1e1378
2024-04-13 12:27:03,960 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:03,960 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 979, family size: 1e1378, quotient: 1305 states / 850371 actions
explored: 100 %
MDP stats: avg MDP size: 1305, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:03,960 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:03,960 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:03,993 - pomdp.py - unfolding 164-FSC template into POMDP ...
2024-04-13 12:27:04,337 - pomdp.py - constructed quotient MDP having 1313 states and 860836 actions.
2024-04-13 12:27:04,337 - pomdp.py - creating coloring ...
2024-04-13 12:27:05,171 - synthesizer.py - synthesis initiated, design space: 1e1388
2024-04-13 12:27:05,325 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:05,325 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 985, family size: 1e1388, quotient: 1313 states / 860836 actions
explored: 100 %
MDP stats: avg MDP size: 1313, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:05,326 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:05,326 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:05,361 - pomdp.py - unfolding 165-FSC template into POMDP ...
2024-04-13 12:27:05,725 - pomdp.py - constructed quotient MDP having 1321 states and 871365 actions.
2024-04-13 12:27:05,725 - pomdp.py - creating coloring ...
2024-04-13 12:27:06,596 - synthesizer.py - synthesis initiated, design space: 1e1397
2024-04-13 12:27:06,759 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:06,760 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 991, family size: 1e1397, quotient: 1321 states / 871365 actions
explored: 100 %
MDP stats: avg MDP size: 1321, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:06,760 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:06,760 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:06,794 - pomdp.py - unfolding 166-FSC template into POMDP ...
2024-04-13 12:27:07,112 - pomdp.py - constructed quotient MDP having 1329 states and 881958 actions.
2024-04-13 12:27:07,112 - pomdp.py - creating coloring ...
2024-04-13 12:27:07,853 - synthesizer.py - synthesis initiated, design space: 1e1407
2024-04-13 12:27:08,006 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:08,006 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 997, family size: 1e1407, quotient: 1329 states / 881958 actions
explored: 100 %
MDP stats: avg MDP size: 1329, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:08,006 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:08,006 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:08,041 - pomdp.py - unfolding 167-FSC template into POMDP ...
2024-04-13 12:27:08,417 - pomdp.py - constructed quotient MDP having 1337 states and 892615 actions.
2024-04-13 12:27:08,417 - pomdp.py - creating coloring ...
2024-04-13 12:27:09,230 - synthesizer.py - synthesis initiated, design space: 1e1417
2024-04-13 12:27:09,394 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:09,394 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 1003, family size: 1e1417, quotient: 1337 states / 892615 actions
explored: 100 %
MDP stats: avg MDP size: 1337, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:09,395 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:09,395 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:09,430 - pomdp.py - unfolding 168-FSC template into POMDP ...
2024-04-13 12:27:09,737 - pomdp.py - constructed quotient MDP having 1345 states and 903336 actions.
2024-04-13 12:27:09,737 - pomdp.py - creating coloring ...
2024-04-13 12:27:10,537 - synthesizer.py - synthesis initiated, design space: 1e1427
2024-04-13 12:27:10,699 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:10,699 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 1009, family size: 1e1427, quotient: 1345 states / 903336 actions
explored: 100 %
MDP stats: avg MDP size: 1345, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:10,699 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:10,700 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:10,737 - pomdp.py - unfolding 169-FSC template into POMDP ...
2024-04-13 12:27:11,108 - pomdp.py - constructed quotient MDP having 1353 states and 914121 actions.
2024-04-13 12:27:11,108 - pomdp.py - creating coloring ...
2024-04-13 12:27:11,907 - synthesizer.py - synthesis initiated, design space: 1e1437
2024-04-13 12:27:12,090 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:12,090 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.18 s
number of holes: 1015, family size: 1e1437, quotient: 1353 states / 914121 actions
explored: 100 %
MDP stats: avg MDP size: 1353, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:12,091 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:12,091 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:12,130 - pomdp.py - unfolding 170-FSC template into POMDP ...
2024-04-13 12:27:12,521 - pomdp.py - constructed quotient MDP having 1361 states and 924970 actions.
2024-04-13 12:27:12,521 - pomdp.py - creating coloring ...
2024-04-13 12:27:13,332 - synthesizer.py - synthesis initiated, design space: 1e1446
2024-04-13 12:27:13,515 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:13,515 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.18 s
number of holes: 1021, family size: 1e1446, quotient: 1361 states / 924970 actions
explored: 100 %
MDP stats: avg MDP size: 1361, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:13,515 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:13,515 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:13,551 - pomdp.py - unfolding 171-FSC template into POMDP ...
2024-04-13 12:27:13,919 - pomdp.py - constructed quotient MDP having 1369 states and 935883 actions.
2024-04-13 12:27:13,919 - pomdp.py - creating coloring ...
2024-04-13 12:27:14,748 - synthesizer.py - synthesis initiated, design space: 1e1456
2024-04-13 12:27:14,915 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:14,915 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.17 s
number of holes: 1027, family size: 1e1456, quotient: 1369 states / 935883 actions
explored: 100 %
MDP stats: avg MDP size: 1369, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:14,915 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:14,915 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:14,951 - pomdp.py - unfolding 172-FSC template into POMDP ...
2024-04-13 12:27:15,321 - pomdp.py - constructed quotient MDP having 1377 states and 946860 actions.
2024-04-13 12:27:15,321 - pomdp.py - creating coloring ...
2024-04-13 12:27:16,261 - synthesizer.py - synthesis initiated, design space: 1e1466
2024-04-13 12:27:16,429 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:16,429 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.17 s
number of holes: 1033, family size: 1e1466, quotient: 1377 states / 946860 actions
explored: 100 %
MDP stats: avg MDP size: 1377, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:16,429 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:16,429 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:16,467 - pomdp.py - unfolding 173-FSC template into POMDP ...
2024-04-13 12:27:16,800 - pomdp.py - constructed quotient MDP having 1385 states and 957901 actions.
2024-04-13 12:27:16,801 - pomdp.py - creating coloring ...
2024-04-13 12:27:17,711 - synthesizer.py - synthesis initiated, design space: 1e1476
2024-04-13 12:27:17,888 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:17,888 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.18 s
number of holes: 1039, family size: 1e1476, quotient: 1385 states / 957901 actions
explored: 100 %
MDP stats: avg MDP size: 1385, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:17,889 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:17,889 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:17,927 - pomdp.py - unfolding 174-FSC template into POMDP ...
2024-04-13 12:27:18,275 - pomdp.py - constructed quotient MDP having 1393 states and 969006 actions.
2024-04-13 12:27:18,275 - pomdp.py - creating coloring ...
2024-04-13 12:27:19,076 - synthesizer.py - synthesis initiated, design space: 1e1486
2024-04-13 12:27:19,250 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-13 12:27:19,250 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.17 s
number of holes: 1045, family size: 1e1486, quotient: 1393 states / 969006 actions
explored: 100 %
MDP stats: avg MDP size: 1393, iterations: 1

optimum: 2.245291
--------------------
2024-04-13 12:27:19,251 - synthesizer_pomdp.py - Terminate: False
2024-04-13 12:27:19,251 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-13 12:27:19,290 - pomdp.py - unfolding 175-FSC template into POMDP ...
2024-04-13 12:27:19,715 - pomdp.py - constructed quotient MDP having 1401 states and 980175 actions.
2024-04-13 12:27:19,716 - pomdp.py - creating coloring ...
2024-04-13 12:27:20,631 - synthesizer.py - synthesis initiated, design space: 1e1495
2024-04-13 12:27:20,631 - synthesizer_ar_storm.py - Pausing synthesis
2024-04-13 12:27:20,688 - storm_pomdp_control.py - Interactive Storm started
2024-04-13 12:27:20,688 - storm_pomdp_control.py - starting Storm POMDP analysis
2024-04-13 12:27:30,708 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 2.245330402652736 | Time elapsed = 115.4s | FSC size = 33


------------------------------------

PAYNT results: 
2.245291280404411
controller size: 8

Storm results: 
2.245330402652736
controller size: 33

------------------------------------

2024-04-13 12:27:44,837 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-04-13 12:27:45,160 - synthesizer_ar_storm.py - Resuming synthesis
2024-04-13 12:27:45,167 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-04-13 12:27:45,311 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 83082404336658735523131369923130359545436378798482827646693565514456370468541416708253634029937678136987457232007545680065498033331365514032922962832363330196686154908468414000554062878668781356003542069146490787934109268547893471270924806678311795129211710681341643288205983343520134987299232280143542131274026877741951471614791504469439806741930692231407593446888776126251131979310971068705516681310371333479297085186650214823764768370225141225000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 to 6886738761940028290073231789389793617316846183252963203787452994220401294734796069060802170697384961890650735138564564650698371976308875133931183986636828233544767819474985453017621362045029780097896154973620237068989986338719841213080939131567017897899254573997435182672536802093800468001565422134887155680820072580588823494938887521675912309112149705461495841302541729337409325257959217778165101828275975195883697143982824577126979122627569859691678783375017711089954883227321918841372040347236355062715116493983590543065001418817802617696787446324855333834246143403710476616183417890547227705025112408658267377373271228504310041110621863339104929588745354238292802214410908215359490177845631873563678573605704117767375179306929684103369215908808188032949654870842247828490384258138188264552310806312875497156315921939997327702343782280456091208401360883857381319717365554983644494562482524355637683961382695601494459333850513948615317977848306879263540289077587413660882324540997822115575900768218257575341815256331296478867886811342551267660630715850233163923756137288388843091387311359496438207191167819928321543176262797895844977439684664322072649156325496733188629150390625
2024-04-13 12:27:45,880 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 1, Subfamilies - 350
2024-04-13 12:27:46,060 - synthesizer_ar_storm.py - Main family synthesis done
2024-04-13 12:27:46,060 - synthesizer_ar_storm.py - Subfamilies buffer contains: 350 families
> progress 0.0%, elapsed 6 s, estimated 466772494039205708611861588238214437681122271816192463650711464811437203366064994968144147255591575493220593686061532377145838254442150352671319058821279645885155440038506873142456174236283325302964224 s (14801258689726208607694683311569789287660229385246055671776439291883865050370796045224705468963067695822049356299108540241213195108132543937695349439046116006618802325050018640643399945310699520 years), iters = {MDP: 20}, opt = 2.245
> progress 0.0%, elapsed 9 s, estimated 631333823400472265424612871459407741501701311811776064473590811980379125088902166705567351339405905223841278357142449190547127480605484012912867763170481640723215935145541025067299766272 s (20019464212343739459960994614733312849884196910379586977494759864141224351371637617447399084910060568098485147061014719437051202276521217407708873978090464060537565433637743099904 years), iters = {MDP: 45}, opt = 2.245
> progress 0.0%, elapsed 13 s, estimated 55673757867087727584976032471924956581305521229220285407148698369786013728137001036071005388010728168796381165970004437243616320841982615934678502004057804383979087705210003390464 s (1765403280919829238964257748845754730520423629738909589561928269357942875397409192093284151535739782019678760413387666979234302213475490376935161266075096759398674015977472 years), iters = {MDP: 57}, opt = 2.245
> progress 0.0%, elapsed 16 s, estimated 3892711637779193582464580462728608414290306565754587183797830390204037420539522147115031064402584350653351122335107427959246785024161793917375066276726437574371966976 s (123437076286757762405965183861077862550882913033773492685798616359787940178867221481078369348977972196697085115295411870837474713100116014551190746338273787904 years), iters = {MDP: 79}, opt = 2.245
> progress 0.0%, elapsed 20 s, estimated 282893913569420685263783165634275907086565066067296939377726156332391545491812586495826975677605428159165792468985278651418850560665189078173948248765751753703424 s (8970507152759408025773783241623571549258308589662601053167808504351512329398650839556510975668059249827361862152039591027411680863268375089764421316116480 years), iters = {MDP: 86}, opt = 2.245
> progress 0.0%, elapsed 23 s, estimated 77782070490985448406327712007685927070644275700986343332733491928171867782316865534339610831304959300412922055641576614295540380437844515733868121488883712 s (2466453275335662265922770888049950930281394529307472537965495574687249845100687883795121557359815555888243657440922016987120581866820087599125757952 years), iters = {MDP: 97}, opt = 2.245
> progress 0.0%, elapsed 26 s, estimated 78380958878786091320452081601096518441995258497026027759608431324330854507716751707673856334028843361582695334323020600334684571105125990400 s (2485443901534312885433368175613709313710138779191497956632472538407176662132250021540100775259226101300768641863717363456752207527936 years), iters = {MDP: 122}, opt = 2.245
> progress 0.0%, elapsed 29 s, estimated 310920422163434330260059519267819471697612331913478865683917554528694781638670526783959475453817363328580573871810785996439552 s (9859221910306771381178510836751622170931900458167281582557071768008109128036759600194757886841499087120839132810575872 years), iters = {MDP: 146}, opt = 2.245
> progress 0.0%, elapsed 32 s, estimated 19550872512541262853895615380798051316727764311461539656863450429924538879769497350317849976111426255360473694208 s (619954100473784359407862750807098682764654230020206517097057623428969015085672742689880402837238475390976 years), iters = {MDP: 168}, opt = 2.245
> progress 0.0%, elapsed 35 s, estimated 4868176365971429383871391632848039510306514969459349928016362430526294683473554066532843659158618112 s (154368859905233049362933842429219530549660675447236371682751095057431892260175176463802171392 years), iters = {MDP: 189}, opt = 2.245
> progress 0.0%, elapsed 38 s, estimated 83300549203734791683900372489059372325469489834129359722247502946637217165385896198222308393877504 s (2641443087383777119711701884627388133965347444158634324101071031669429053577938155306221568 years), iters = {MDP: 192}, opt = 2.245
> progress 0.0%, elapsed 48 s, estimated 25658665856324041288618167630407965956603072311445985177562177671974232946013015237854705559273472 s (813630956884958138238799245468034207372351777003058600099164954958719655375881185672560640 years), iters = {MDP: 193}, opt = 2.245
> progress 0.0%, elapsed 54 s, estimated 1791281475965315027138321569525689712869967192834545492214088234178435348228779392477331797835776 s (56801162987230948343635079522361780509181649311197747910023558082978990620969718140370944 years), iters = {MDP: 195}, opt = 2.245
> progress 0.0%, elapsed 57 s, estimated 7016832396912056060908715200480861119922531573494626244607994746191657929260243353600 s (222502295691021591114946629715751923179893313245933392078315957668124729278464 years), iters = {MDP: 214}, opt = 2.245
> progress 0.0%, elapsed 60 s, estimated 28213916813407253653779173564006656599268969834436020645105064138994058358947840 s (894657433200382269602645611941742267467080199627811076057889658153992192 years), iters = {MDP: 223}, opt = 2.245
> progress 0.0%, elapsed 64 s, estimated 113161400298735277966429826383406766015942336996804945191446791046974930944 s (3588324464064411456358119662915788562700032932337418866286762393600 years), iters = {MDP: 232}, opt = 2.245
> progress 0.0%, elapsed 67 s, estimated 113493951041445482064409448927834115890894198334933806994364332769280 s (3598869578939798741356686857807058105198790716550086752468992 years), iters = {MDP: 242}, opt = 2.245
> progress 0.0%, elapsed 70 s, estimated 1812959154224934771512241208395727287903748651512953347669753856 s (57488557655534458322758879479139415794089555207779254272 years), iters = {MDP: 250}, opt = 2.245
> progress 0.0%, elapsed 77 s, estimated 31127008531397160128631692285168927137305613012044869365923840 s (987030965607469714339892852963298102545742495060328448 years), iters = {MDP: 253}, opt = 2.245
