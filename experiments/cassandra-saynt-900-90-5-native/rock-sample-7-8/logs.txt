2024-04-03 18:57:46,381 - cli.py - This is Paynt version 0.1.0.
2024-04-03 18:57:46,381 - sketch.py - loading sketch from models/cassandra/pomdp/rock-sample-7-8.pomdp ...
2024-04-03 18:57:46,381 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:27): Parsing error at 1:1:  expecting <model type>, here:
	# state naming convention: s <x> <y> <rock_0> <rock_1> .. <rock_{n-1}>
	^

2024-04-03 18:57:46,613 - sketch.py - assuming sketch in DRN format...
ERROR (DirectEncodingParser.cpp:124): Could not parse line '# state naming convention: s <x> <y> <rock_0> <rock_1> .. <rock_{n-1}>'.
2024-04-03 18:57:46,613 - sketch.py - assuming sketch in Cassandra format...
MADP: trying to parse as POMDP...
MADP: parsing success
2024-04-03 18:58:07,195 - sketch.py - applying discount factor transformation...
2024-04-03 18:58:07,298 - sketch.py - sketch parsing OK
2024-04-03 18:58:07,299 - sketch.py - constructed explicit quotient having 25346 states and 329486 actions
2024-04-03 18:58:07,299 - sketch.py - found the following specification optimality: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 
2024-04-03 18:58:07,451 - pomdp.py - constructed POMDP having 4 observations.
2024-04-03 18:58:13,656 - pomdp.py - unfolding 1-FSC template into POMDP ...
2024-04-03 18:58:13,760 - pomdp.py - constructed quotient MDP having 25346 states and 329486 actions.
2024-04-03 18:58:13,760 - pomdp.py - creating coloring ...
2024-04-03 18:58:14,017 - synthesizer_pomdp.py - Storm POMDP option enabled
2024-04-03 18:58:14,017 - synthesizer_pomdp.py - Storm settings: iterative - (900, 90, 5), get_storm_result - None, storm_options - cutoff, prune_storm - False, unfold_strategy - (True, False), use_storm_cutoffs - False, enhanced_saynt - None, saynt_overapprox - False
2024-04-03 18:58:14,017 - synthesizer.py - synthesis initiated, design space: 2197
2024-04-03 18:58:14,017 - synthesizer_pomdp.py - Timeout for PAYNT started
-----------PAYNT-----------                     
Value = 0.0 | Time elapsed = 0.1s | FSC size = 8

2024-04-03 18:58:14,102 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 18:58:14,102 - synthesizer.py - A(o0,0)=(a0), A(o1,0)=(a0), A(__no_obs__,0)=(a0)
2024-04-03 18:58:14,110 - synthesizer.py - double-checking specification satisfiability:  : 0.0
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 0.09 s
number of holes: 3, family size: 2197, quotient: 25346 states / 329486 actions
explored: 100 %
MDP stats: avg MDP size: 25346, iterations: 1

optimum: 0.0
--------------------
2024-04-03 18:58:21,673 - synthesizer_pomdp.py - Terminate: False
2024-04-03 18:58:21,673 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 18:58:21,684 - pomdp.py - unfolding 2-FSC template into POMDP ...
2024-04-03 18:58:22,158 - pomdp.py - constructed quotient MDP having 50691 states and 1317942 actions.
2024-04-03 18:58:22,164 - pomdp.py - creating coloring ...
2024-04-03 18:58:23,249 - synthesizer.py - synthesis initiated, design space: 1e8
2024-04-03 18:58:23,481 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 18:58:23,481 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 0.23 s
number of holes: 13, family size: 1e8, quotient: 50691 states / 1317942 actions
explored: 100 %
MDP stats: avg MDP size: 50691, iterations: 1

optimum: 0.0
--------------------
2024-04-03 18:58:23,481 - synthesizer_pomdp.py - Terminate: False
2024-04-03 18:58:23,481 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 18:58:23,536 - pomdp.py - unfolding 3-FSC template into POMDP ...
2024-04-03 18:58:24,787 - pomdp.py - constructed quotient MDP having 76036 states and 2965368 actions.
2024-04-03 18:58:24,788 - pomdp.py - creating coloring ...
2024-04-03 18:58:27,284 - synthesizer.py - synthesis initiated, design space: 1e14
2024-04-03 18:58:27,812 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 18:58:27,812 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 0.53 s
number of holes: 19, family size: 1e14, quotient: 76036 states / 2965368 actions
explored: 100 %
MDP stats: avg MDP size: 76036, iterations: 1

optimum: 0.0
--------------------
2024-04-03 18:58:27,812 - synthesizer_pomdp.py - Terminate: False
2024-04-03 18:58:27,812 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 18:58:27,948 - pomdp.py - unfolding 4-FSC template into POMDP ...
2024-04-03 18:58:30,237 - pomdp.py - constructed quotient MDP having 101381 states and 5271764 actions.
2024-04-03 18:58:30,237 - pomdp.py - creating coloring ...
2024-04-03 18:58:34,509 - synthesizer.py - synthesis initiated, design space: 1e21
2024-04-03 18:58:35,562 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 18:58:35,562 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 1.05 s
number of holes: 25, family size: 1e21, quotient: 101381 states / 5271764 actions
explored: 100 %
MDP stats: avg MDP size: 101381, iterations: 1

optimum: 0.0
--------------------
2024-04-03 18:58:35,562 - synthesizer_pomdp.py - Terminate: False
2024-04-03 18:58:35,562 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 18:58:35,815 - pomdp.py - unfolding 5-FSC template into POMDP ...
2024-04-03 18:58:39,295 - pomdp.py - constructed quotient MDP having 126726 states and 8237130 actions.
2024-04-03 18:58:39,295 - pomdp.py - creating coloring ...
2024-04-03 18:58:47,535 - synthesizer.py - synthesis initiated, design space: 1e27
2024-04-03 18:58:49,138 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 18:58:49,138 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 1.6 s
number of holes: 31, family size: 1e27, quotient: 126726 states / 8237130 actions
explored: 100 %
MDP stats: avg MDP size: 126726, iterations: 1

optimum: 0.0
--------------------
2024-04-03 18:58:49,138 - synthesizer_pomdp.py - Terminate: False
2024-04-03 18:58:49,138 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 18:58:49,643 - pomdp.py - unfolding 6-FSC template into POMDP ...
2024-04-03 18:58:55,490 - pomdp.py - constructed quotient MDP having 152071 states and 11861466 actions.
2024-04-03 18:58:55,490 - pomdp.py - creating coloring ...
2024-04-03 18:59:06,371 - synthesizer.py - synthesis initiated, design space: 1e34
2024-04-03 18:59:08,693 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 18:59:08,693 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 2.32 s
number of holes: 37, family size: 1e34, quotient: 152071 states / 11861466 actions
explored: 100 %
MDP stats: avg MDP size: 152071, iterations: 1

optimum: 0.0
--------------------
2024-04-03 18:59:08,693 - synthesizer_pomdp.py - Terminate: False
2024-04-03 18:59:08,693 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 18:59:09,313 - pomdp.py - unfolding 7-FSC template into POMDP ...
2024-04-03 18:59:16,019 - pomdp.py - constructed quotient MDP having 177416 states and 16144772 actions.
2024-04-03 18:59:16,096 - pomdp.py - creating coloring ...
2024-04-03 18:59:31,806 - synthesizer.py - synthesis initiated, design space: 1e41
2024-04-03 18:59:34,912 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 18:59:34,912 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 3.11 s
number of holes: 43, family size: 1e41, quotient: 177416 states / 16144772 actions
explored: 100 %
MDP stats: avg MDP size: 177416, iterations: 1

optimum: 0.0
--------------------
2024-04-03 18:59:34,912 - synthesizer_pomdp.py - Terminate: False
2024-04-03 18:59:34,912 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 18:59:35,707 - pomdp.py - unfolding 8-FSC template into POMDP ...
2024-04-03 18:59:44,804 - pomdp.py - constructed quotient MDP having 202761 states and 21087048 actions.
2024-04-03 18:59:44,908 - pomdp.py - creating coloring ...
2024-04-03 19:00:03,525 - synthesizer.py - synthesis initiated, design space: 1e49
2024-04-03 19:00:03,525 - synthesizer_ar_storm.py - Pausing synthesis
2024-04-03 19:00:03,625 - storm_pomdp_control.py - Interactive Storm started
2024-04-03 19:00:03,625 - storm_pomdp_control.py - starting Storm POMDP analysis
2024-04-03 19:00:09,106 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.0 | Time elapsed = 116.1s | FSC size = 12


------------------------------------

PAYNT results: 
0.0
controller size: 8

Storm results: 
0.0
controller size: 12

------------------------------------

2024-04-03 19:00:10,110 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-04-03 19:00:10,533 - synthesizer_ar_storm.py - Resuming synthesis
2024-04-03 19:00:10,533 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
2024-04-03 19:00:14,807 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 19:00:14,807 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 4.27 s
number of holes: 49, family size: 1e49, quotient: 202761 states / 21087048 actions
explored: 100 %
MDP stats: avg MDP size: 202761, iterations: 1

optimum: 0.0
--------------------
2024-04-03 19:00:14,808 - synthesizer_pomdp.py - Terminate: False
2024-04-03 19:00:14,808 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 19:00:15,859 - pomdp.py - unfolding 9-FSC template into POMDP ...
2024-04-03 19:00:35,453 - pomdp.py - constructed quotient MDP having 228106 states and 26688294 actions.
2024-04-03 19:00:35,597 - pomdp.py - creating coloring ...
2024-04-03 19:01:45,235 - synthesizer.py - synthesis initiated, design space: 1e56
2024-04-03 19:01:45,236 - synthesizer_ar_storm.py - Pausing synthesis
2024-04-03 19:01:45,336 - storm_pomdp_control.py - Interactive Storm resumed
2024-04-03 19:01:45,344 - storm_pomdp_control.py - Updating FSC values in Storm
2024-04-03 19:01:50,393 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.0 | Time elapsed = 242.4s | FSC size = 12


------------------------------------

PAYNT results: 
0.0
controller size: 8

Storm results: 
0.0
controller size: 12

------------------------------------

2024-04-03 19:02:16,495 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-04-03 19:02:16,773 - synthesizer_ar_storm.py - Resuming synthesis
2024-04-03 19:02:16,773 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
> progress 0.0%, elapsed 5 s, estimated 5058070 s (58 days), iters = {MDP: 1}, opt = 0.0
2024-04-03 19:02:39,806 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 19:02:39,813 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 23.03 s
number of holes: 55, family size: 1e56, quotient: 228106 states / 26688294 actions
explored: 100 %
MDP stats: avg MDP size: 228106, iterations: 1

optimum: 0.0
--------------------
2024-04-03 19:02:39,840 - synthesizer_pomdp.py - Terminate: False
2024-04-03 19:02:39,840 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 19:02:41,219 - pomdp.py - unfolding 10-FSC template into POMDP ...
2024-04-03 19:04:11,194 - pomdp.py - constructed quotient MDP having 253451 states and 32948510 actions.
2024-04-03 19:04:11,372 - pomdp.py - creating coloring ...
2024-04-03 19:04:52,554 - synthesizer.py - synthesis initiated, design space: 1e64
2024-04-03 19:04:52,554 - synthesizer_ar_storm.py - Pausing synthesis
2024-04-03 19:04:52,654 - storm_pomdp_control.py - Interactive Storm resumed
2024-04-03 19:04:52,655 - storm_pomdp_control.py - Updating FSC values in Storm
2024-04-03 19:04:57,672 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 0.0 | Time elapsed = 405.7s | FSC size = 12


------------------------------------

PAYNT results: 
0.0
controller size: 8

Storm results: 
0.0
controller size: 12

------------------------------------

2024-04-03 19:04:59,678 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-04-03 19:05:00,063 - synthesizer_ar_storm.py - Resuming synthesis
2024-04-03 19:05:00,063 - synthesizer_ar_storm.py - PAYNT's value is better. Prioritizing synthesis results
> progress 0.0%, elapsed 4 s, estimated 4285251 s (49 days), iters = {MDP: 1}, opt = 0.0
2024-04-03 19:05:06,889 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 19:05:06,889 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 6.83 s
number of holes: 61, family size: 1e64, quotient: 253451 states / 32948510 actions
explored: 100 %
MDP stats: avg MDP size: 253451, iterations: 1

optimum: 0.0
--------------------
2024-04-03 19:05:06,889 - synthesizer_pomdp.py - Terminate: False
2024-04-03 19:05:06,889 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 19:05:08,801 - pomdp.py - unfolding 11-FSC template into POMDP ...
2024-04-03 19:05:24,908 - pomdp.py - constructed quotient MDP having 278796 states and 39867696 actions.
2024-04-03 19:05:25,097 - pomdp.py - creating coloring ...
2024-04-03 19:06:14,025 - synthesizer.py - synthesis initiated, design space: 1e72
> progress 0.0%, elapsed 4 s, estimated 4923881 s (56 days), iters = {MDP: 1}, opt = 0.0
2024-04-03 19:06:21,764 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-03 19:06:21,764 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{9500000000000001/10000000000000000}] 

method: AR, synthesis time: 7.74 s
number of holes: 67, family size: 1e72, quotient: 278796 states / 39867696 actions
explored: 100 %
MDP stats: avg MDP size: 278796, iterations: 1

optimum: 0.0
--------------------
2024-04-03 19:06:21,765 - synthesizer_pomdp.py - Terminate: False
2024-04-03 19:06:21,765 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-03 19:06:23,923 - pomdp.py - unfolding 12-FSC template into POMDP ...
2024-04-03 19:06:47,904 - pomdp.py - constructed quotient MDP having 304141 states and 47445852 actions.
2024-04-03 19:06:48,113 - pomdp.py - creating coloring ...
