2024-01-17 00:27:38,885 - cli.py - This is Paynt version 0.1.0.
2024-01-17 00:27:38,885 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/avoid-8-2/sketch.templ ...
2024-01-17 00:27:38,885 - sketch.py - assuming sketch in PRISM format...
2024-01-17 00:27:38,888 - prism_parser.py - PRISM model type: MDP
2024-01-17 00:27:38,888 - prism_parser.py - processing hole definitions...
2024-01-17 00:27:38,888 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/avoid-8-2/sketch.props ...
2024-01-17 00:27:38,889 - prism_parser.py - found the following specification: constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-17 00:27:38,889 - jani.py - constructing JANI program...
2024-01-17 00:27:38,891 - jani.py - constructing the quotient...
2024-01-17 00:27:39,011 - jani.py - associating choices of the quotient with hole assignments...
2024-01-17 00:27:39,076 - sketch.py - sketch parsing OK
2024-01-17 00:27:39,077 - sketch.py - constructed explicit quotient having 21233 states and 93872 actions
2024-01-17 00:27:39,077 - sketch.py - found the following specification constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-17 00:27:39,104 - mdp_family.py - associating choices with action labels...
2024-01-17 00:27:39,261 - synthesizer.py - evaluation initiated, design space: 4096
> progress 25.0%, elapsed 3 s, estimated 12 s, iters = {game: 12, MDP: 3}
> progress 50.0%, elapsed 6 s, estimated 12 s, iters = {game: 26, MDP: 6}
> progress 75.0%, elapsed 9 s, estimated 12 s, iters = {game: 43, MDP: 7}
> progress 87.646%, elapsed 12 s, estimated 14 s, iters = {game: 57, MDP: 17}
> progress 88.183%, elapsed 15 s, estimated 17 s, iters = {game: 71, MDP: 32}
> progress 88.623%, elapsed 18 s, estimated 21 s, iters = {game: 85, MDP: 50}
> progress 89.062%, elapsed 21 s, estimated 24 s, iters = {game: 100, MDP: 68}
> progress 89.648%, elapsed 24 s, estimated 27 s, iters = {game: 117, MDP: 87}
> progress 90.234%, elapsed 27 s, estimated 30 s, iters = {game: 134, MDP: 107}
> progress 90.625%, elapsed 30 s, estimated 34 s, iters = {game: 149, MDP: 124}
> progress 91.162%, elapsed 33 s, estimated 37 s, iters = {game: 164, MDP: 142}
> progress 91.699%, elapsed 37 s, estimated 40 s, iters = {game: 180, MDP: 159}
> progress 92.187%, elapsed 40 s, estimated 43 s, iters = {game: 195, MDP: 178}
> progress 92.675%, elapsed 43 s, estimated 46 s, iters = {game: 210, MDP: 195}
> progress 93.164%, elapsed 46 s, estimated 49 s, iters = {game: 225, MDP: 213}
> progress 93.75%, elapsed 49 s, estimated 52 s, iters = {game: 240, MDP: 231}
> progress 94.238%, elapsed 52 s, estimated 55 s, iters = {game: 256, MDP: 248}
> progress 94.726%, elapsed 55 s, estimated 58 s, iters = {game: 271, MDP: 267}
> progress 95.312%, elapsed 58 s, estimated 61 s, iters = {game: 287, MDP: 286}
> progress 95.703%, elapsed 61 s, estimated 64 s, iters = {game: 303, MDP: 304}
> progress 96.24%, elapsed 64 s, estimated 67 s, iters = {game: 319, MDP: 323}
> progress 96.801%, elapsed 67 s, estimated 69 s, iters = {game: 334, MDP: 342}
> progress 97.265%, elapsed 70 s, estimated 72 s, iters = {game: 350, MDP: 359}
> progress 97.778%, elapsed 73 s, estimated 75 s, iters = {game: 365, MDP: 378}
> progress 98.339%, elapsed 76 s, estimated 78 s, iters = {game: 381, MDP: 394}
> progress 98.828%, elapsed 80 s, estimated 80 s, iters = {game: 397, MDP: 414}
> progress 99.365%, elapsed 83 s, estimated 83 s, iters = {game: 413, MDP: 433}
> progress 99.951%, elapsed 86 s, estimated 86 s, iters = {game: 429, MDP: 452}
--------------------
Policy tree summary:
found 168 satisfying policies for 3904/4096 family members (95.0%)
policy tree has 557 nodes, 296 of them are leaves:
	  solvable leaves: 168 (avg.size: 23.2)
	unsolvable leaves: 128 (avg.size: 1.5)
	 singleton leaves: 128
--------------------
2024-01-17 00:29:05,390 - policy_tree.py - post-processing the policy tree...
2024-01-17 00:29:05,390 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-17 00:29:06,737 - policy_tree.py - additional 166 MDPs were model checked
2024-01-17 00:29:06,737 - policy_tree.py - removed 19 nodes
2024-01-17 00:29:06,737 - policy_tree.py - merging all exclusively compatible policies...
2024-01-17 00:29:06,990 - policy_tree.py - removed 115 policies
2024-01-17 00:29:06,990 - policy_tree.py - reducing tree height...
2024-01-17 00:29:06,991 - policy_tree.py - removed 84 nodes
2024-01-17 00:29:06,991 - policy_tree.py - merging siblings that have the same solution...
2024-01-17 00:29:06,992 - policy_tree.py - removed 0 nodes
2024-01-17 00:29:06,992 - policy_tree.py - postprocessing took 1 s
--------------------
Policy tree summary:
found 34 satisfying policies for 3904/4096 family members (95.0%)
policy tree has 454 nodes, 277 of them are leaves:
	  solvable leaves: 149 (avg.size: 26.2)
	unsolvable leaves: 128 (avg.size: 1.5)
	 singleton leaves: 128
--------------------
2024-01-17 00:29:06,994 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>9/10 [F ((x = 8) & (y = 8))]

method: AR (policy tree), synthesis time: 87.73 s
number of holes: 6, family size: 4096, quotient: 21233 states / 93872 actions
explored: 100 %
Game stats: avg MDP size: 20125, iterations: 429
MDP stats: avg MDP size: 20119, iterations: 453

satisfied 3904/4096 members (95%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
21233 93872 4096 86970368 3904 95.31
synthesis info:	time	nodes	nodes (merged)	leaves	leaves (merged)	leaves (merged) / MDPs %	policies	policies (merged)	policies (merged) / SAT %	pp time	pp time %	game iters	MDP iters	iters/MDPs %
87 557 454 296 277 6.76 168 34 0.87 1 1.15 429 453 21.53

