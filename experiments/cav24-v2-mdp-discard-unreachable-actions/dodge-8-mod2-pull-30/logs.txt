2024-01-17 00:30:02,124 - cli.py - This is Paynt version 0.1.0.
2024-01-17 00:30:02,124 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dodge-8-mod2-pull-30/sketch.templ ...
2024-01-17 00:30:02,124 - sketch.py - assuming sketch in PRISM format...
2024-01-17 00:30:02,127 - prism_parser.py - PRISM model type: MDP
2024-01-17 00:30:02,127 - prism_parser.py - processing hole definitions...
2024-01-17 00:30:02,127 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dodge-8-mod2-pull-30/sketch.props ...
2024-01-17 00:30:02,128 - prism_parser.py - found the following specification: constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-17 00:30:02,128 - jani.py - constructing JANI program...
2024-01-17 00:30:02,132 - jani.py - constructing the quotient...
2024-01-17 00:30:03,292 - jani.py - associating choices of the quotient with hole assignments...
2024-01-17 00:30:03,816 - sketch.py - sketch parsing OK
2024-01-17 00:30:03,817 - sketch.py - constructed explicit quotient having 149659 states and 723570 actions
2024-01-17 00:30:03,817 - sketch.py - found the following specification constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-17 00:30:04,087 - mdp_family.py - associating choices with action labels...
2024-01-17 00:30:05,124 - synthesizer.py - evaluation initiated, design space: 30000
> progress 0.0%, elapsed 4 s, estimated 4891166 s (56 days), iters = {game: 2, MDP: 1}
> progress 4.0%, elapsed 8 s, estimated 206 s, iters = {game: 4, MDP: 2}
> progress 16.0%, elapsed 12 s, estimated 80 s, iters = {game: 7, MDP: 2}
> progress 16.8%, elapsed 16 s, estimated 96 s, iters = {game: 9, MDP: 3}
> progress 19.2%, elapsed 20 s, estimated 107 s, iters = {game: 12, MDP: 3}
> progress 20.0%, elapsed 24 s, estimated 121 s, iters = {game: 14, MDP: 4}
> progress 32.0%, elapsed 28 s, estimated 89 s, iters = {game: 17, MDP: 4}
> progress 36.0%, elapsed 32 s, estimated 89 s, iters = {game: 19, MDP: 5}
> progress 38.4%, elapsed 36 s, estimated 94 s, iters = {game: 22, MDP: 5}
> progress 40.0%, elapsed 39 s, estimated 99 s, iters = {game: 24, MDP: 5}
> progress 44.0%, elapsed 42 s, estimated 97 s, iters = {game: 26, MDP: 6}
> progress 56.0%, elapsed 47 s, estimated 84 s, iters = {game: 29, MDP: 6}
> progress 56.799%, elapsed 51 s, estimated 89 s, iters = {game: 31, MDP: 7}
> progress 59.2%, elapsed 55 s, estimated 93 s, iters = {game: 34, MDP: 7}
> progress 60.0%, elapsed 59 s, estimated 98 s, iters = {game: 36, MDP: 8}
> progress 72.0%, elapsed 63 s, estimated 88 s, iters = {game: 39, MDP: 8}
> progress 76.0%, elapsed 67 s, estimated 88 s, iters = {game: 41, MDP: 9}
> progress 78.4%, elapsed 71 s, estimated 91 s, iters = {game: 44, MDP: 9}
> progress 80.0%, elapsed 74 s, estimated 93 s, iters = {game: 46, MDP: 9}
> progress 80.0%, elapsed 78 s, estimated 98 s, iters = {game: 48, MDP: 11}
> progress 82.4%, elapsed 82 s, estimated 100 s, iters = {game: 51, MDP: 11}
> progress 84.0%, elapsed 86 s, estimated 102 s, iters = {game: 53, MDP: 12}
> progress 85.6%, elapsed 90 s, estimated 105 s, iters = {game: 56, MDP: 12}
> progress 88.0%, elapsed 94 s, estimated 107 s, iters = {game: 59, MDP: 12}
> progress 88.8%, elapsed 97 s, estimated 109 s, iters = {game: 61, MDP: 13}
> progress 91.2%, elapsed 101 s, estimated 111 s, iters = {game: 64, MDP: 13}
> progress 92.0%, elapsed 104 s, estimated 113 s, iters = {game: 66, MDP: 14}
> progress 94.4%, elapsed 108 s, estimated 115 s, iters = {game: 69, MDP: 14}
> progress 96.0%, elapsed 111 s, estimated 116 s, iters = {game: 71, MDP: 14}
> progress 96.8%, elapsed 115 s, estimated 119 s, iters = {game: 73, MDP: 15}
> progress 99.2%, elapsed 119 s, estimated 120 s, iters = {game: 76, MDP: 15}
--------------------
Policy tree summary:
found 61 satisfying policies for 30000/30000 family members (100.0%)
policy tree has 76 nodes, 61 of them are leaves:
	  solvable leaves: 61 (avg.size: 491.8)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 0
--------------------
2024-01-17 00:32:04,743 - policy_tree.py - post-processing the policy tree...
2024-01-17 00:32:04,743 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-17 00:32:17,634 - policy_tree.py - additional 131 MDPs were model checked
2024-01-17 00:32:17,634 - policy_tree.py - removed 32 nodes
2024-01-17 00:32:17,634 - policy_tree.py - merging all exclusively compatible policies...
2024-01-17 00:32:17,639 - policy_tree.py - removed 0 policies
2024-01-17 00:32:17,639 - policy_tree.py - reducing tree height...
2024-01-17 00:32:17,639 - policy_tree.py - removed 0 nodes
2024-01-17 00:32:17,639 - policy_tree.py - merging siblings that have the same solution...
2024-01-17 00:32:17,639 - policy_tree.py - removed 0 nodes
2024-01-17 00:32:17,639 - policy_tree.py - postprocessing took 12 s
--------------------
Policy tree summary:
found 29 satisfying policies for 30000/30000 family members (100.0%)
policy tree has 44 nodes, 29 of them are leaves:
	  solvable leaves: 29 (avg.size: 1034.5)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 0
--------------------
2024-01-17 00:32:17,647 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>9/10 [F ((x = 8) & (y = 8))]

method: AR (policy tree), synthesis time: 132.52 s
number of holes: 6, family size: 30000, quotient: 149659 states / 723570 actions
explored: 100 %
Game stats: avg MDP size: 149463, iterations: 76
MDP stats: avg MDP size: 149619, iterations: 15

satisfied 30000/30000 members (100%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
149659 723570 30000 4489770000 30000 100.0
synthesis info:	time	nodes	nodes (merged)	leaves	leaves (merged)	leaves (merged) / MDPs %	policies	policies (merged)	policies (merged) / SAT %	pp time	pp time %	game iters	MDP iters	iters/MDPs %
132 76 44 61 29 0.1 61 29 0.1 12 9.09 76 15 0.3

