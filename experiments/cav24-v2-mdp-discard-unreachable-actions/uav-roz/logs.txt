2024-01-17 09:00:14,674 - cli.py - This is Paynt version 0.1.0.
2024-01-17 09:00:14,674 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/uav-roz/sketch.templ ...
2024-01-17 09:00:14,674 - sketch.py - assuming sketch in PRISM format...
2024-01-17 09:00:14,682 - prism_parser.py - PRISM model type: MDP
2024-01-17 09:00:14,683 - prism_parser.py - processing hole definitions...
2024-01-17 09:00:14,683 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/uav-roz/sketch.props ...
2024-01-17 09:00:14,684 - prism_parser.py - found the following specification: constraints: P>=3/4 [F ((w1 & w2) & w6)]; 
2024-01-17 09:00:14,684 - jani.py - constructing JANI program...
2024-01-17 09:00:14,695 - jani.py - constructing the quotient...
2024-01-17 09:00:15,444 - jani.py - associating choices of the quotient with hole assignments...
2024-01-17 09:00:15,614 - sketch.py - sketch parsing OK
2024-01-17 09:00:15,614 - sketch.py - constructed explicit quotient having 17927 states and 191629 actions
2024-01-17 09:00:15,614 - sketch.py - found the following specification constraints: P>=3/4 [F ((w1 & w2) & w6)]; 
2024-01-17 09:00:15,715 - mdp_family.py - associating choices with action labels...
2024-01-17 09:00:15,986 - synthesizer.py - evaluation initiated, design space: 4500
> progress 3.333%, elapsed 3 s, estimated 95 s, iters = {game: 9, MDP: 2}
> progress 15.0%, elapsed 6 s, estimated 44 s, iters = {game: 88, MDP: 57}
> progress 25.555%, elapsed 9 s, estimated 37 s, iters = {game: 112, MDP: 69}
> progress 30.0%, elapsed 12 s, estimated 42 s, iters = {game: 177, MDP: 131}
> progress 40.0%, elapsed 16 s, estimated 40 s, iters = {game: 205, MDP: 142}
> progress 50.0%, elapsed 19 s, estimated 39 s, iters = {game: 234, MDP: 159}
> progress 65.0%, elapsed 22 s, estimated 35 s, iters = {game: 263, MDP: 171}
> progress 68.888%, elapsed 25 s, estimated 37 s, iters = {game: 272, MDP: 173}
> progress 80.0%, elapsed 28 s, estimated 36 s, iters = {game: 288, MDP: 177}
> progress 90.0%, elapsed 32 s, estimated 35 s, iters = {game: 304, MDP: 178}
--------------------
Policy tree summary:
found 202 satisfying policies for 4451/4500 family members (99.0%)
policy tree has 352 nodes, 227 of them are leaves:
	  solvable leaves: 202 (avg.size: 22.0)
	unsolvable leaves: 25 (avg.size: 2.0)
	 singleton leaves: 40
--------------------
2024-01-17 09:00:50,541 - policy_tree.py - post-processing the policy tree...
2024-01-17 09:00:50,541 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-17 09:00:50,657 - policy_tree.py - additional 0 MDPs were model checked
2024-01-17 09:00:50,657 - policy_tree.py - removed 115 nodes
2024-01-17 09:00:50,657 - policy_tree.py - merging all exclusively compatible policies...
2024-01-17 09:00:50,768 - policy_tree.py - removed 102 policies
2024-01-17 09:00:50,768 - policy_tree.py - reducing tree height...
2024-01-17 09:00:50,768 - policy_tree.py - removed 58 nodes
2024-01-17 09:00:50,768 - policy_tree.py - merging siblings that have the same solution...
2024-01-17 09:00:50,768 - policy_tree.py - removed 55 nodes
2024-01-17 09:00:50,768 - policy_tree.py - postprocessing took 0 s
--------------------
Policy tree summary:
found 1 satisfying policy for 4451/4500 family members (99.0%)
policy tree has 124 nodes, 73 of them are leaves:
	  solvable leaves: 49 (avg.size: 90.8)
	unsolvable leaves: 24 (avg.size: 2.0)
	 singleton leaves: 11
--------------------
2024-01-17 09:00:50,772 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>=3/4 [F ((w1 & w2) & w6)]

method: AR (policy tree), synthesis time: 34.79 s
number of holes: 4, family size: 4500, quotient: 17927 states / 191629 actions
explored: 100 %
Game stats: avg MDP size: 5096, iterations: 312
MDP stats: avg MDP size: 2755, iterations: 179

satisfied 4451/4500 members (99%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
17927 191629 4500 80671500 4451 98.91
synthesis info:	time	nodes	nodes (merged)	leaves	leaves (merged)	leaves (merged) / MDPs %	policies	policies (merged)	policies (merged) / SAT %	pp time	pp time %	game iters	MDP iters	iters/MDPs %
34 352 124 227 73 1.62 202 1 0.02 0 0.0 312 179 10.91

