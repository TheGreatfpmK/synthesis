2024-01-16 20:58:17,778 - cli.py - This is Paynt version 0.1.0.
2024-01-16 20:58:17,778 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/rocks-6-4/sketch.templ ...
2024-01-16 20:58:17,778 - sketch.py - assuming sketch in PRISM format...
2024-01-16 20:58:17,805 - prism_parser.py - PRISM model type: MDP
2024-01-16 20:58:17,805 - prism_parser.py - processing hole definitions...
2024-01-16 20:58:17,806 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/rocks-6-4/sketch.props ...
2024-01-16 20:58:17,812 - prism_parser.py - found the following specification: constraints: P>=1 [F (((visit1 & visit2) & visit3) & visit4)]; 
2024-01-16 20:58:17,812 - jani.py - constructing JANI program...
2024-01-16 20:58:17,819 - jani.py - constructing the quotient...
2024-01-16 20:58:17,905 - jani.py - associating choices of the quotient with hole assignments...
2024-01-16 20:58:17,912 - sketch.py - sketch parsing OK
2024-01-16 20:58:17,912 - sketch.py - constructed explicit quotient having 2736 states and 6660 actions
2024-01-16 20:58:17,912 - sketch.py - found the following specification constraints: P>=1 [F (((visit1 & visit2) & visit3) & visit4)]; 
2024-01-16 20:58:17,913 - mdp_family.py - associating choices with action labels...
2024-01-16 20:58:17,932 - synthesizer.py - evaluation initiated, design space: 6561
> progress 2.972%, elapsed 3 s, estimated 101 s, iters = {game: 103, MDP: 289}
> progress 5.761%, elapsed 6 s, estimated 104 s, iters = {game: 195, MDP: 552}
> progress 8.641%, elapsed 9 s, estimated 104 s, iters = {game: 289, MDP: 832}
> progress 11.842%, elapsed 12 s, estimated 101 s, iters = {game: 394, MDP: 1134}
> progress 14.54%, elapsed 15 s, estimated 103 s, iters = {game: 481, MDP: 1398}
> progress 17.283%, elapsed 18 s, estimated 104 s, iters = {game: 572, MDP: 1665}
> progress 20.301%, elapsed 21 s, estimated 103 s, iters = {game: 671, MDP: 1962}
> progress 23.456%, elapsed 24 s, estimated 102 s, iters = {game: 774, MDP: 2268}
> progress 26.428%, elapsed 27 s, estimated 102 s, iters = {game: 873, MDP: 2562}
> progress 29.629%, elapsed 30 s, estimated 101 s, iters = {game: 979, MDP: 2866}
> progress 33.196%, elapsed 33 s, estimated 99 s, iters = {game: 1093, MDP: 3206}
> progress 36.244%, elapsed 36 s, estimated 99 s, iters = {game: 1195, MDP: 3506}
> progress 39.094%, elapsed 39 s, estimated 100 s, iters = {game: 1288, MDP: 3776}
> progress 41.883%, elapsed 42 s, estimated 100 s, iters = {game: 1379, MDP: 4046}
> progress 44.581%, elapsed 45 s, estimated 101 s, iters = {game: 1470, MDP: 4314}
> progress 47.187%, elapsed 48 s, estimated 102 s, iters = {game: 1554, MDP: 4565}
> progress 49.839%, elapsed 51 s, estimated 102 s, iters = {game: 1644, MDP: 4825}
> progress 52.812%, elapsed 54 s, estimated 102 s, iters = {game: 1742, MDP: 5118}
> progress 55.692%, elapsed 57 s, estimated 102 s, iters = {game: 1838, MDP: 5403}
> progress 58.39%, elapsed 60 s, estimated 103 s, iters = {game: 1930, MDP: 5668}
> progress 61.042%, elapsed 63 s, estimated 103 s, iters = {game: 2024, MDP: 5932}
> progress 63.786%, elapsed 66 s, estimated 103 s, iters = {game: 2118, MDP: 6206}
> progress 66.666%, elapsed 69 s, estimated 103 s, iters = {game: 2215, MDP: 6494}
> progress 70.37%, elapsed 72 s, estimated 102 s, iters = {game: 2333, MDP: 6841}
> progress 73.921%, elapsed 75 s, estimated 101 s, iters = {game: 2448, MDP: 7179}
> progress 76.649%, elapsed 78 s, estimated 102 s, iters = {game: 2539, MDP: 7441}
> progress 79.286%, elapsed 81 s, estimated 102 s, iters = {game: 2630, MDP: 7703}
> progress 81.893%, elapsed 84 s, estimated 103 s, iters = {game: 2719, MDP: 7955}
> progress 84.499%, elapsed 87 s, estimated 103 s, iters = {game: 2802, MDP: 8209}
> progress 87.242%, elapsed 90 s, estimated 103 s, iters = {game: 2892, MDP: 8479}
> progress 90.367%, elapsed 93 s, estimated 103 s, iters = {game: 2995, MDP: 8789}
> progress 93.415%, elapsed 96 s, estimated 103 s, iters = {game: 3094, MDP: 9066}
> progress 95.93%, elapsed 99 s, estimated 103 s, iters = {game: 3177, MDP: 9314}
> progress 99.176%, elapsed 102 s, estimated 103 s, iters = {game: 3282, MDP: 9632}
--------------------
Policy tree summary:
found 6477 satisfying policies for 6561/6561 family members (100.0%)
policy tree has 9742 nodes, 6477 of them are leaves:
	  solvable leaves: 6477 (avg.size: 1.0)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 6435
--------------------
2024-01-16 21:00:01,479 - policy_tree.py - post-processing the policy tree...
2024-01-16 21:00:01,479 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-16 21:00:15,246 - policy_tree.py - additional 11528 MDPs were model checked
2024-01-16 21:00:15,246 - policy_tree.py - removed 5598 nodes
2024-01-16 21:00:15,246 - policy_tree.py - merging all exclusively compatible policies...
2024-01-16 21:00:17,121 - policy_tree.py - removed 55 policies
2024-01-16 21:00:17,121 - policy_tree.py - reducing tree height...
2024-01-16 21:00:17,137 - policy_tree.py - removed 0 nodes
2024-01-16 21:00:17,137 - policy_tree.py - merging siblings that have the same solution...
2024-01-16 21:00:17,152 - policy_tree.py - removed 0 nodes
2024-01-16 21:00:17,152 - policy_tree.py - postprocessing took 15 s
--------------------
Policy tree summary:
found 2564 satisfying policies for 6561/6561 family members (100.0%)
policy tree has 4144 nodes, 2619 of them are leaves:
	  solvable leaves: 2619 (avg.size: 2.5)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 442
--------------------
2024-01-16 21:00:17,286 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>=1 [F (((visit1 & visit2) & visit3) & visit4)]

method: AR (policy tree), synthesis time: 119.35 s
number of holes: 8, family size: 6561, quotient: 2736 states / 6660 actions
explored: 100 %
Game stats: avg MDP size: 2641, iterations: 3307
MDP stats: avg MDP size: 2630, iterations: 9700

satisfied 6561/6561 members (100%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
2736 6660 6561 17950896 6561 100.0
synthesis info:	time	nodes	nodes (merged)	leaves	leaves (merged)	leaves (merged) / MDPs %	policies	policies (merged)	policies (merged) / SAT %	pp time	pp time %	game iters	MDP iters	iters/MDPs %
119 9742 4144 6477 2619 39.92 6477 2564 39.08 15 12.61 3307 9700 198.25

