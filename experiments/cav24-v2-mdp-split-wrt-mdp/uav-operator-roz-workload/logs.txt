2024-01-17 19:44:31,133 - cli.py - This is Paynt version 0.1.0.
2024-01-17 19:44:31,133 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/uav-operator-roz-workload/sketch.templ ...
2024-01-17 19:44:31,134 - sketch.py - assuming sketch in PRISM format...
2024-01-17 19:44:31,146 - prism_parser.py - PRISM model type: MDP
2024-01-17 19:44:31,146 - prism_parser.py - processing hole definitions...
2024-01-17 19:44:31,146 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/uav-operator-roz-workload/sketch.props ...
2024-01-17 19:44:31,147 - prism_parser.py - found the following specification: constraints: P>=7/10 [F ((w1 & w2) & w6)]; 
2024-01-17 19:44:31,147 - jani.py - constructing JANI program...
2024-01-17 19:44:31,179 - jani.py - constructing the quotient...
2024-01-17 19:44:31,729 - jani.py - associating choices of the quotient with hole assignments...
2024-01-17 19:44:31,857 - sketch.py - sketch parsing OK
2024-01-17 19:44:31,857 - sketch.py - constructed explicit quotient having 9007 states and 139969 actions
2024-01-17 19:44:31,857 - sketch.py - found the following specification constraints: P>=7/10 [F ((w1 & w2) & w6)]; 
2024-01-17 19:44:31,927 - mdp_family.py - associating choices with action labels...
2024-01-17 19:44:32,062 - synthesizer.py - evaluation initiated, design space: 1620000
> progress 4.429%, elapsed 3 s, estimated 68 s, iters = {game: 71, MDP: 40}
> progress 5.525%, elapsed 6 s, estimated 109 s, iters = {game: 194, MDP: 120}
> progress 9.993%, elapsed 9 s, estimated 90 s, iters = {game: 277, MDP: 175}
> progress 15.486%, elapsed 12 s, estimated 77 s, iters = {game: 341, MDP: 209}
> progress 16.597%, elapsed 15 s, estimated 90 s, iters = {game: 449, MDP: 273}
> progress 16.666%, elapsed 18 s, estimated 108 s, iters = {game: 572, MDP: 359}
> progress 22.222%, elapsed 21 s, estimated 95 s, iters = {game: 625, MDP: 386}
> progress 26.663%, elapsed 24 s, estimated 90 s, iters = {game: 718, MDP: 441}
> progress 27.764%, elapsed 27 s, estimated 98 s, iters = {game: 850, MDP: 528}
> progress 33.287%, elapsed 30 s, estimated 90 s, iters = {game: 917, MDP: 568}
> progress 37.739%, elapsed 33 s, estimated 88 s, iters = {game: 989, MDP: 608}
> progress 38.842%, elapsed 36 s, estimated 93 s, iters = {game: 1103, MDP: 679}
> progress 43.209%, elapsed 39 s, estimated 90 s, iters = {game: 1205, MDP: 748}
> progress 44.444%, elapsed 42 s, estimated 95 s, iters = {game: 1261, MDP: 778}
> progress 48.819%, elapsed 45 s, estimated 92 s, iters = {game: 1370, MDP: 842}
> progress 48.868%, elapsed 48 s, estimated 98 s, iters = {game: 1473, MDP: 916}
> progress 49.876%, elapsed 51 s, estimated 102 s, iters = {game: 1610, MDP: 1006}
> progress 49.938%, elapsed 54 s, estimated 108 s, iters = {game: 1749, MDP: 1107}
> progress 49.99%, elapsed 57 s, estimated 114 s, iters = {game: 1885, MDP: 1216}
> progress 52.217%, elapsed 60 s, estimated 115 s, iters = {game: 1929, MDP: 1246}
> progress 53.325%, elapsed 63 s, estimated 119 s, iters = {game: 1969, MDP: 1267}
> progress 54.436%, elapsed 66 s, estimated 122 s, iters = {game: 2017, MDP: 1296}
> progress 55.493%, elapsed 69 s, estimated 125 s, iters = {game: 2092, MDP: 1338}
> progress 55.541%, elapsed 72 s, estimated 130 s, iters = {game: 2166, MDP: 1386}
> progress 59.954%, elapsed 75 s, estimated 126 s, iters = {game: 2228, MDP: 1425}
> progress 61.057%, elapsed 78 s, estimated 128 s, iters = {game: 2341, MDP: 1494}
> progress 65.308%, elapsed 81 s, estimated 125 s, iters = {game: 2451, MDP: 1568}
> progress 66.666%, elapsed 84 s, estimated 126 s, iters = {game: 2509, MDP: 1599}
> progress 71.104%, elapsed 87 s, estimated 123 s, iters = {game: 2599, MDP: 1653}
> progress 72.206%, elapsed 90 s, estimated 125 s, iters = {game: 2728, MDP: 1736}
> progress 77.716%, elapsed 93 s, estimated 120 s, iters = {game: 2799, MDP: 1780}
> progress 82.145%, elapsed 96 s, estimated 117 s, iters = {game: 2869, MDP: 1819}
> progress 82.21%, elapsed 99 s, estimated 121 s, iters = {game: 2971, MDP: 1883}
> progress 83.265%, elapsed 102 s, estimated 123 s, iters = {game: 3108, MDP: 1972}
> progress 83.317%, elapsed 105 s, estimated 126 s, iters = {game: 3242, MDP: 2068}
> progress 86.66%, elapsed 108 s, estimated 125 s, iters = {game: 3310, MDP: 2116}
> progress 88.881%, elapsed 111 s, estimated 125 s, iters = {game: 3374, MDP: 2149}
> progress 92.206%, elapsed 114 s, estimated 124 s, iters = {game: 3405, MDP: 2167}
> progress 93.163%, elapsed 117 s, estimated 126 s, iters = {game: 3468, MDP: 2204}
> progress 93.234%, elapsed 120 s, estimated 129 s, iters = {game: 3588, MDP: 2280}
> progress 93.283%, elapsed 123 s, estimated 132 s, iters = {game: 3696, MDP: 2355}
> progress 93.32%, elapsed 126 s, estimated 135 s, iters = {game: 3801, MDP: 2436}
> progress 94.259%, elapsed 129 s, estimated 137 s, iters = {game: 3955, MDP: 2536}
> progress 94.329%, elapsed 132 s, estimated 140 s, iters = {game: 4118, MDP: 2648}
> progress 94.379%, elapsed 135 s, estimated 144 s, iters = {game: 4260, MDP: 2756}
> progress 94.441%, elapsed 138 s, estimated 147 s, iters = {game: 4393, MDP: 2869}
> progress 95.548%, elapsed 141 s, estimated 148 s, iters = {game: 4422, MDP: 2889}
> progress 96.632%, elapsed 144 s, estimated 150 s, iters = {game: 4450, MDP: 2903}
> progress 96.663%, elapsed 148 s, estimated 153 s, iters = {game: 4477, MDP: 2919}
> progress 97.716%, elapsed 151 s, estimated 154 s, iters = {game: 4521, MDP: 2943}
> progress 97.762%, elapsed 154 s, estimated 157 s, iters = {game: 4558, MDP: 2964}
> progress 98.757%, elapsed 157 s, estimated 159 s, iters = {game: 4602, MDP: 2993}
> progress 98.834%, elapsed 160 s, estimated 162 s, iters = {game: 4656, MDP: 3024}
> progress 98.865%, elapsed 163 s, estimated 165 s, iters = {game: 4708, MDP: 3056}
> progress 98.888%, elapsed 166 s, estimated 168 s, iters = {game: 4758, MDP: 3091}
> progress 99.916%, elapsed 169 s, estimated 169 s, iters = {game: 4843, MDP: 3142}
> progress 99.958%, elapsed 172 s, estimated 172 s, iters = {game: 4919, MDP: 3191}
> progress 99.985%, elapsed 175 s, estimated 175 s, iters = {game: 4991, MDP: 3243}
--------------------
Policy tree summary:
found 1757 satisfying policies for 1612675/1620000 family members (100.0%)
policy tree has 5028 nodes, 2549 of them are leaves:
	  solvable leaves: 1757 (avg.size: 917.9)
	unsolvable leaves: 792 (avg.size: 9.2)
	 singleton leaves: 0
--------------------
2024-01-17 19:47:28,955 - policy_tree.py - post-processing the policy tree...
2024-01-17 19:47:28,955 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-17 19:47:29,014 - policy_tree.py - additional 3 MDPs were model checked
2024-01-17 19:47:29,014 - policy_tree.py - removed 34 nodes
2024-01-17 19:47:29,014 - policy_tree.py - merging all exclusively compatible policies...
2024-01-17 19:47:29,999 - policy_tree.py - removed 1719 policies
2024-01-17 19:47:29,999 - policy_tree.py - reducing tree height...
2024-01-17 19:47:30,010 - policy_tree.py - removed 1394 nodes
2024-01-17 19:47:30,010 - policy_tree.py - merging siblings that have the same solution...
2024-01-17 19:47:30,023 - policy_tree.py - removed 864 nodes
2024-01-17 19:47:30,023 - policy_tree.py - postprocessing took 1 s
--------------------
Policy tree summary:
found 6 satisfying policies for 1612675/1620000 family members (100.0%)
policy tree has 2736 nodes, 1653 of them are leaves:
	  solvable leaves: 1047 (avg.size: 1540.3)
	unsolvable leaves: 606 (avg.size: 12.1)
	 singleton leaves: 0
--------------------
2024-01-17 19:47:30,076 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>=7/10 [F ((w1 & w2) & w6)]

method: AR (policy tree), synthesis time: 178.01 s
number of holes: 8, family size: 1620000, quotient: 9007 states / 139969 actions
explored: 100 %
Game stats: avg MDP size: 1559, iterations: 5028
MDP stats: avg MDP size: 1478, iterations: 3271

satisfied 1612675/1620000 members (100%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
9007 139969 1620000 14591340000 1612675 99.55
synthesis info:	time	nodes	nodes (merged)	leaves	leaves (merged)	leaves (merged) / MDPs %	policies	policies (merged)	policies (merged) / SAT %	pp time	pp time %	game iters	MDP iters	iters/MDPs %
178 5028 2736 2549 1653 0.1 1757 6 0.0 1 0.56 5028 3271 0.51

