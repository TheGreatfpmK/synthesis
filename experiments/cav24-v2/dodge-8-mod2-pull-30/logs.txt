2024-01-16 15:00:30,772 - cli.py - This is Paynt version 0.1.0.
2024-01-16 15:00:30,772 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dodge-8-mod2-pull-30/sketch.templ ...
2024-01-16 15:00:30,772 - sketch.py - assuming sketch in PRISM format...
2024-01-16 15:00:30,780 - prism_parser.py - PRISM model type: MDP
2024-01-16 15:00:30,780 - prism_parser.py - processing hole definitions...
2024-01-16 15:00:30,780 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dodge-8-mod2-pull-30/sketch.props ...
2024-01-16 15:00:30,781 - prism_parser.py - found the following specification: constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-16 15:00:30,781 - jani.py - constructing JANI program...
2024-01-16 15:00:30,785 - jani.py - constructing the quotient...
2024-01-16 15:00:31,876 - jani.py - associating choices of the quotient with hole assignments...
2024-01-16 15:00:32,316 - sketch.py - sketch parsing OK
2024-01-16 15:00:32,316 - sketch.py - constructed explicit quotient having 149659 states and 723570 actions
2024-01-16 15:00:32,317 - sketch.py - found the following specification constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-16 15:00:32,563 - mdp_family.py - associating choices with action labels...
2024-01-16 15:00:33,409 - synthesizer.py - evaluation initiated, design space: 30000
> progress 0.0%, elapsed 4 s, estimated 4498679 s (52 days), iters = {game: 2, MDP: 1}
> progress 8.0%, elapsed 8 s, estimated 109 s, iters = {game: 5, MDP: 2}
> progress 16.0%, elapsed 11 s, estimated 74 s, iters = {game: 7, MDP: 3}
> progress 17.6%, elapsed 15 s, estimated 90 s, iters = {game: 10, MDP: 3}
> progress 20.0%, elapsed 20 s, estimated 101 s, iters = {game: 13, MDP: 3}
> progress 28.0%, elapsed 24 s, estimated 87 s, iters = {game: 16, MDP: 4}
> progress 36.0%, elapsed 27 s, estimated 76 s, iters = {game: 18, MDP: 5}
> progress 37.6%, elapsed 31 s, estimated 84 s, iters = {game: 21, MDP: 5}
> progress 40.0%, elapsed 36 s, estimated 90 s, iters = {game: 24, MDP: 5}
> progress 44.0%, elapsed 39 s, estimated 90 s, iters = {game: 26, MDP: 6}
> progress 56.0%, elapsed 43 s, estimated 78 s, iters = {game: 29, MDP: 6}
> progress 56.799%, elapsed 47 s, estimated 82 s, iters = {game: 31, MDP: 7}
> progress 59.2%, elapsed 51 s, estimated 86 s, iters = {game: 34, MDP: 7}
> progress 60.0%, elapsed 54 s, estimated 91 s, iters = {game: 36, MDP: 8}
> progress 72.0%, elapsed 58 s, estimated 81 s, iters = {game: 39, MDP: 8}
> progress 76.0%, elapsed 62 s, estimated 81 s, iters = {game: 41, MDP: 9}
> progress 78.4%, elapsed 66 s, estimated 84 s, iters = {game: 44, MDP: 9}
> progress 80.0%, elapsed 69 s, estimated 86 s, iters = {game: 46, MDP: 10}
> progress 80.0%, elapsed 72 s, estimated 90 s, iters = {game: 48, MDP: 11}
> progress 82.4%, elapsed 76 s, estimated 92 s, iters = {game: 51, MDP: 11}
> progress 84.0%, elapsed 79 s, estimated 94 s, iters = {game: 53, MDP: 12}
> progress 85.6%, elapsed 83 s, estimated 97 s, iters = {game: 56, MDP: 12}
> progress 88.0%, elapsed 87 s, estimated 99 s, iters = {game: 59, MDP: 12}
> progress 89.6%, elapsed 91 s, estimated 102 s, iters = {game: 62, MDP: 13}
> progress 92.0%, elapsed 95 s, estimated 103 s, iters = {game: 65, MDP: 13}
> progress 92.8%, elapsed 98 s, estimated 106 s, iters = {game: 67, MDP: 14}
> progress 95.2%, elapsed 102 s, estimated 107 s, iters = {game: 70, MDP: 14}
> progress 96.0%, elapsed 105 s, estimated 109 s, iters = {game: 72, MDP: 15}
> progress 98.4%, elapsed 109 s, estimated 111 s, iters = {game: 75, MDP: 15}
--------------------
Policy tree summary:
found 61 satisfying policies for 30000/30000 family members (100.0%)
policy tree has 76 nodes, 61 of them are leaves:
	  solvable leaves: 61 (avg.size: 491.8)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 0
--------------------
2024-01-16 15:02:24,342 - policy_tree.py - post-processing the policy tree...
2024-01-16 15:02:24,343 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-16 15:02:36,143 - policy_tree.py - additional 131 MDPs were model checked
2024-01-16 15:02:36,143 - policy_tree.py - removed 32 nodes
2024-01-16 15:02:36,143 - policy_tree.py - merging all exclusively compatible policies...
2024-01-16 15:02:36,147 - policy_tree.py - removed 0 policies
2024-01-16 15:02:36,148 - policy_tree.py - reducing tree height...
2024-01-16 15:02:36,148 - policy_tree.py - removed 0 nodes
2024-01-16 15:02:36,148 - policy_tree.py - merging siblings that have the same solution...
2024-01-16 15:02:36,148 - policy_tree.py - removed 0 nodes
2024-01-16 15:02:36,148 - policy_tree.py - postprocessing took 11 s
--------------------
Policy tree summary:
found 29 satisfying policies for 30000/30000 family members (100.0%)
policy tree has 44 nodes, 29 of them are leaves:
	  solvable leaves: 29 (avg.size: 1034.5)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 0
--------------------
2024-01-16 15:02:36,155 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>9/10 [F ((x = 8) & (y = 8))]

method: AR (policy tree), synthesis time: 122.75 s
number of holes: 6, family size: 30000, quotient: 149659 states / 723570 actions
explored: 100 %
Game stats: avg MDP size: 149463, iterations: 76
MDP stats: avg MDP size: 149619, iterations: 15

satisfied 30000/30000 members (100%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
149659 723570 30000 4489770000 30000 100.0
synthesis info:	time	nodes	nodes (merged)	leaves	leaves (merged)	leaves (merged) / MDPs %	policies	policies (merged)	policies (merged) / SAT %	pp time	pp time %	game iters	MDP iters	iters/MDPs %
122 76 44 61 29 0.1 61 29 0.1 11 9.02 76 15 0.3

