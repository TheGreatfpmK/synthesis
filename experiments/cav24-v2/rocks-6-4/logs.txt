2024-01-16 14:57:10,507 - cli.py - This is Paynt version 0.1.0.
2024-01-16 14:57:10,507 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/rocks-6-4/sketch.templ ...
2024-01-16 14:57:10,508 - sketch.py - assuming sketch in PRISM format...
2024-01-16 14:57:10,533 - prism_parser.py - PRISM model type: MDP
2024-01-16 14:57:10,533 - prism_parser.py - processing hole definitions...
2024-01-16 14:57:10,534 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/rocks-6-4/sketch.props ...
2024-01-16 14:57:10,539 - prism_parser.py - found the following specification: constraints: P>=1 [F (((visit1 & visit2) & visit3) & visit4)]; 
2024-01-16 14:57:10,539 - jani.py - constructing JANI program...
2024-01-16 14:57:10,547 - jani.py - constructing the quotient...
2024-01-16 14:57:10,633 - jani.py - associating choices of the quotient with hole assignments...
2024-01-16 14:57:10,636 - sketch.py - sketch parsing OK
2024-01-16 14:57:10,636 - sketch.py - constructed explicit quotient having 2736 states and 6660 actions
2024-01-16 14:57:10,637 - sketch.py - found the following specification constraints: P>=1 [F (((visit1 & visit2) & visit3) & visit4)]; 
2024-01-16 14:57:10,638 - mdp_family.py - associating choices with action labels...
2024-01-16 14:57:10,700 - synthesizer.py - evaluation initiated, design space: 6561
> progress 3.642%, elapsed 3 s, estimated 82 s, iters = {game: 123, MDP: 363}
> progress 7.544%, elapsed 6 s, estimated 79 s, iters = {game: 254, MDP: 748}
> progress 11.111%, elapsed 9 s, estimated 81 s, iters = {game: 368, MDP: 1096}
> progress 14.342%, elapsed 12 s, estimated 83 s, iters = {game: 474, MDP: 1416}
> progress 17.695%, elapsed 15 s, estimated 84 s, iters = {game: 584, MDP: 1745}
> progress 20.713%, elapsed 18 s, estimated 87 s, iters = {game: 683, MDP: 2041}
> progress 24.051%, elapsed 21 s, estimated 87 s, iters = {game: 794, MDP: 2371}
> progress 27.983%, elapsed 24 s, estimated 85 s, iters = {game: 923, MDP: 2758}
> progress 31.809%, elapsed 27 s, estimated 85 s, iters = {game: 1046, MDP: 3134}
> progress 35.101%, elapsed 30 s, estimated 85 s, iters = {game: 1156, MDP: 3460}
> progress 38.18%, elapsed 33 s, estimated 86 s, iters = {game: 1257, MDP: 3761}
> progress 41.258%, elapsed 36 s, estimated 87 s, iters = {game: 1358, MDP: 4066}
> progress 44.032%, elapsed 39 s, estimated 88 s, iters = {game: 1449, MDP: 4337}
> progress 47.005%, elapsed 42 s, estimated 89 s, iters = {game: 1547, MDP: 4630}
> progress 50.16%, elapsed 45 s, estimated 89 s, iters = {game: 1649, MDP: 4939}
> progress 53.04%, elapsed 48 s, estimated 90 s, iters = {game: 1743, MDP: 5222}
> progress 55.829%, elapsed 51 s, estimated 91 s, iters = {game: 1836, MDP: 5498}
> progress 59.03%, elapsed 54 s, estimated 91 s, iters = {game: 1940, MDP: 5812}
> progress 62.414%, elapsed 57 s, estimated 91 s, iters = {game: 2051, MDP: 6145}
> progress 65.34%, elapsed 60 s, estimated 92 s, iters = {game: 2146, MDP: 6432}
> progress 68.693%, elapsed 63 s, estimated 91 s, iters = {game: 2257, MDP: 6765}
> progress 72.702%, elapsed 66 s, estimated 91 s, iters = {game: 2388, MDP: 7157}
> progress 76.451%, elapsed 69 s, estimated 90 s, iters = {game: 2511, MDP: 7526}
> progress 79.835%, elapsed 72 s, estimated 90 s, iters = {game: 2624, MDP: 7861}
> progress 83.31%, elapsed 75 s, estimated 90 s, iters = {game: 2737, MDP: 8202}
> progress 86.556%, elapsed 78 s, estimated 90 s, iters = {game: 2843, MDP: 8521}
> progress 89.94%, elapsed 81 s, estimated 90 s, iters = {game: 2954, MDP: 8855}
> progress 93.964%, elapsed 84 s, estimated 89 s, iters = {game: 3086, MDP: 9250}
> progress 97.896%, elapsed 87 s, estimated 89 s, iters = {game: 3214, MDP: 9638}
--------------------
Policy tree summary:
found 6561 satisfying policies for 6561/6561 family members (100.0%)
policy tree has 9841 nodes, 6561 of them are leaves:
	  solvable leaves: 6561 (avg.size: 1.0)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 6561
--------------------
2024-01-16 14:58:39,927 - policy_tree.py - post-processing the policy tree...
2024-01-16 14:58:39,927 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-16 14:58:51,995 - policy_tree.py - additional 12120 MDPs were model checked
2024-01-16 14:58:51,995 - policy_tree.py - removed 6358 nodes
2024-01-16 14:58:51,995 - policy_tree.py - merging all exclusively compatible policies...
2024-01-16 14:58:53,402 - policy_tree.py - removed 49 policies
2024-01-16 14:58:53,402 - policy_tree.py - reducing tree height...
2024-01-16 14:58:53,413 - policy_tree.py - removed 0 nodes
2024-01-16 14:58:53,413 - policy_tree.py - merging siblings that have the same solution...
2024-01-16 14:58:53,424 - policy_tree.py - removed 0 nodes
2024-01-16 14:58:53,424 - policy_tree.py - postprocessing took 13 s
--------------------
Policy tree summary:
found 2238 satisfying policies for 6561/6561 family members (100.0%)
policy tree has 3483 nodes, 2287 of them are leaves:
	  solvable leaves: 2287 (avg.size: 2.9)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 103
--------------------
2024-01-16 14:58:53,534 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>=1 [F (((visit1 & visit2) & visit3) & visit4)]

method: AR (policy tree), synthesis time: 102.83 s
number of holes: 8, family size: 6561, quotient: 2736 states / 6660 actions
explored: 100 %
Game stats: avg MDP size: 2639, iterations: 3280
MDP stats: avg MDP size: 2629, iterations: 9841

satisfied 6561/6561 members (100%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
2736 6660 6561 17950896 6561 100.0
synthesis info:	time	nodes	nodes (merged)	leaves	leaves (merged)	leaves (merged) / MDPs %	policies	policies (merged)	policies (merged) / SAT %	pp time	pp time %	game iters	MDP iters	iters/MDPs %
102 9841 3483 6561 2287 34.86 6561 2238 34.11 13 12.75 3280 9841 199.98

