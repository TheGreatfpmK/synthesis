2024-01-09 22:21:31,103 - cli.py - This is Paynt version 0.1.0.
2024-01-09 22:21:31,103 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/avoid-8-2/sketch.templ ...
2024-01-09 22:21:31,103 - sketch.py - assuming sketch in PRISM format...
2024-01-09 22:21:31,105 - prism_parser.py - PRISM model type: MDP
2024-01-09 22:21:31,105 - prism_parser.py - processing hole definitions...
2024-01-09 22:21:31,105 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/avoid-8-2/sketch.props ...
2024-01-09 22:21:31,106 - prism_parser.py - found the following specification: constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-09 22:21:31,106 - jani.py - constructing JANI program...
2024-01-09 22:21:31,108 - jani.py - constructing the quotient...
2024-01-09 22:21:31,227 - jani.py - associating choices of the quotient with hole assignments...
2024-01-09 22:21:31,291 - sketch.py - sketch parsing OK
2024-01-09 22:21:31,291 - sketch.py - constructed explicit quotient having 21233 states and 93872 actions
2024-01-09 22:21:31,291 - sketch.py - found the following specification constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-09 22:21:31,317 - mdp_family.py - associating choices with action labels...
2024-01-09 22:21:31,495 - synthesizer.py - evaluation initiated, design space: 4096
> Progress 15.625%, elapsed 3 s, estimated 20 s, iters = {game: 14, MDP: 3}
> Progress 37.5%, elapsed 6 s, estimated 16 s, iters = {game: 30, MDP: 5}
> Progress 62.5%, elapsed 9 s, estimated 15 s, iters = {game: 47, MDP: 6}
> Progress 85.937%, elapsed 12 s, estimated 14 s, iters = {game: 64, MDP: 8}
> Progress 87.841%, elapsed 15 s, estimated 18 s, iters = {game: 78, MDP: 23}
> Progress 88.281%, elapsed 18 s, estimated 21 s, iters = {game: 93, MDP: 40}
> Progress 88.818%, elapsed 22 s, estimated 24 s, iters = {game: 107, MDP: 57}
> Progress 89.257%, elapsed 25 s, estimated 28 s, iters = {game: 122, MDP: 74}
> Progress 89.843%, elapsed 28 s, estimated 31 s, iters = {game: 137, MDP: 92}
> Progress 90.332%, elapsed 31 s, estimated 34 s, iters = {game: 152, MDP: 108}
> Progress 90.771%, elapsed 34 s, estimated 38 s, iters = {game: 167, MDP: 127}
> Progress 91.308%, elapsed 37 s, estimated 41 s, iters = {game: 182, MDP: 143}
> Progress 91.796%, elapsed 40 s, estimated 44 s, iters = {game: 197, MDP: 162}
> Progress 92.285%, elapsed 43 s, estimated 47 s, iters = {game: 212, MDP: 178}
> Progress 92.773%, elapsed 46 s, estimated 50 s, iters = {game: 227, MDP: 197}
> Progress 93.31%, elapsed 50 s, estimated 53 s, iters = {game: 242, MDP: 215}
> Progress 93.75%, elapsed 53 s, estimated 56 s, iters = {game: 257, MDP: 233}
> Progress 94.262%, elapsed 56 s, estimated 59 s, iters = {game: 271, MDP: 250}
> Progress 94.726%, elapsed 59 s, estimated 62 s, iters = {game: 286, MDP: 266}
> Progress 95.312%, elapsed 62 s, estimated 65 s, iters = {game: 301, MDP: 284}
> Progress 95.703%, elapsed 65 s, estimated 68 s, iters = {game: 316, MDP: 301}
> Progress 96.24%, elapsed 68 s, estimated 70 s, iters = {game: 331, MDP: 319}
> Progress 96.777%, elapsed 71 s, estimated 73 s, iters = {game: 346, MDP: 335}
> Progress 97.265%, elapsed 74 s, estimated 76 s, iters = {game: 361, MDP: 354}
> Progress 97.753%, elapsed 77 s, estimated 79 s, iters = {game: 377, MDP: 371}
> Progress 98.339%, elapsed 80 s, estimated 81 s, iters = {game: 392, MDP: 389}
> Progress 98.828%, elapsed 83 s, estimated 84 s, iters = {game: 408, MDP: 409}
> Progress 99.34%, elapsed 86 s, estimated 87 s, iters = {game: 424, MDP: 429}
> Progress 99.926%, elapsed 89 s, estimated 89 s, iters = {game: 440, MDP: 448}
--------------------
Policy tree summary:
found 184 satisfying policies for 3904/4096 family members (95.0%)
policy tree has 569 nodes, 312 of them are leaves:
	  solvable leaves: 184 (avg.size: 21.2)
	unsolvable leaves: 128 (avg.size: 1.5)
	 singleton leaves: 128
--------------------
2024-01-09 22:23:01,326 - policy_tree.py - post-processing the policy tree...
2024-01-09 22:23:01,326 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-09 22:23:03,683 - policy_tree.py - additional 311 MDPs were model checked
2024-01-09 22:23:03,683 - policy_tree.py - removed 29 nodes
2024-01-09 22:23:03,683 - policy_tree.py - merging all exclusively compatible policies...
2024-01-09 22:23:03,938 - policy_tree.py - removed 121 policies
2024-01-09 22:23:03,938 - policy_tree.py - reducing tree height...
2024-01-09 22:23:03,938 - policy_tree.py - removed 80 nodes
2024-01-09 22:23:03,939 - policy_tree.py - merging siblings that have the same solution...
2024-01-09 22:23:03,939 - policy_tree.py - removed 0 nodes
2024-01-09 22:23:03,939 - policy_tree.py - postprocessing took 2 s
--------------------
Policy tree summary:
found 34 satisfying policies for 3904/4096 family members (95.0%)
policy tree has 460 nodes, 283 of them are leaves:
	  solvable leaves: 155 (avg.size: 25.2)
	unsolvable leaves: 128 (avg.size: 1.5)
	 singleton leaves: 128
--------------------
2024-01-09 22:23:03,941 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>9/10 [F ((x = 8) & (y = 8))]

method: AR (policy tree), synthesis time: 92.45 s
number of holes: 6, family size: 4096, quotient: 21233 states / 93872 actions
explored: 100 %
Game stats: avg MDP size: 20117, iterations: 441
MDP stats: avg MDP size: 20116, iterations: 449

satisfied 3904/4096 members (95%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
21233 93872 4096 86970368 3904 95.3
synt info:	time	nodes	nodes (merged)	policies	policies (merged)	policies(merged) / SAT %	game iters	MDP iters	iters/MDPs
92 569 460 184 34 0.9 441 449 0.2

