2024-01-09 22:23:29,092 - cli.py - This is Paynt version 0.1.0.
2024-01-09 22:23:29,093 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dodge-8-mod2-pull-30/sketch.templ ...
2024-01-09 22:23:29,093 - sketch.py - assuming sketch in PRISM format...
2024-01-09 22:23:29,095 - prism_parser.py - PRISM model type: MDP
2024-01-09 22:23:29,095 - prism_parser.py - processing hole definitions...
2024-01-09 22:23:29,095 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dodge-8-mod2-pull-30/sketch.props ...
2024-01-09 22:23:29,096 - prism_parser.py - found the following specification: constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-09 22:23:29,096 - jani.py - constructing JANI program...
2024-01-09 22:23:29,101 - jani.py - constructing the quotient...
2024-01-09 22:23:30,267 - jani.py - associating choices of the quotient with hole assignments...
2024-01-09 22:23:30,737 - sketch.py - sketch parsing OK
2024-01-09 22:23:30,737 - sketch.py - constructed explicit quotient having 149659 states and 723570 actions
2024-01-09 22:23:30,737 - sketch.py - found the following specification constraints: P>9/10 [F ((x = 8) & (y = 8))]; 
2024-01-09 22:23:31,004 - mdp_family.py - associating choices with action labels...
2024-01-09 22:23:31,937 - synthesizer.py - evaluation initiated, design space: 30000
> Progress 0.0%, elapsed 4 s, estimated 4835767 s (55 days), iters = {game: 2, MDP: 1}
> Progress 4.0%, elapsed 8 s, estimated 201 s, iters = {game: 4, MDP: 2}
> Progress 16.0%, elapsed 12 s, estimated 78 s, iters = {game: 7, MDP: 2}
> Progress 16.8%, elapsed 15 s, estimated 93 s, iters = {game: 9, MDP: 3}
> Progress 19.2%, elapsed 20 s, estimated 104 s, iters = {game: 12, MDP: 3}
> Progress 20.0%, elapsed 23 s, estimated 118 s, iters = {game: 14, MDP: 4}
> Progress 32.0%, elapsed 27 s, estimated 87 s, iters = {game: 17, MDP: 4}
> Progress 36.0%, elapsed 31 s, estimated 87 s, iters = {game: 19, MDP: 5}
> Progress 38.4%, elapsed 35 s, estimated 92 s, iters = {game: 22, MDP: 5}
> Progress 40.0%, elapsed 38 s, estimated 96 s, iters = {game: 24, MDP: 5}
> Progress 44.0%, elapsed 42 s, estimated 95 s, iters = {game: 26, MDP: 6}
> Progress 56.0%, elapsed 46 s, estimated 83 s, iters = {game: 29, MDP: 6}
> Progress 56.799%, elapsed 49 s, estimated 87 s, iters = {game: 31, MDP: 7}
> Progress 59.2%, elapsed 54 s, estimated 91 s, iters = {game: 34, MDP: 7}
> Progress 60.0%, elapsed 57 s, estimated 96 s, iters = {game: 36, MDP: 8}
> Progress 72.0%, elapsed 62 s, estimated 86 s, iters = {game: 39, MDP: 8}
> Progress 76.0%, elapsed 65 s, estimated 86 s, iters = {game: 41, MDP: 9}
> Progress 78.4%, elapsed 70 s, estimated 89 s, iters = {game: 44, MDP: 9}
> Progress 80.0%, elapsed 73 s, estimated 91 s, iters = {game: 46, MDP: 9}
> Progress 80.0%, elapsed 77 s, estimated 96 s, iters = {game: 48, MDP: 11}
> Progress 82.4%, elapsed 80 s, estimated 98 s, iters = {game: 51, MDP: 11}
> Progress 84.0%, elapsed 84 s, estimated 100 s, iters = {game: 53, MDP: 12}
> Progress 85.6%, elapsed 88 s, estimated 103 s, iters = {game: 56, MDP: 12}
> Progress 88.0%, elapsed 92 s, estimated 105 s, iters = {game: 59, MDP: 12}
> Progress 88.8%, elapsed 95 s, estimated 107 s, iters = {game: 61, MDP: 13}
> Progress 91.2%, elapsed 99 s, estimated 109 s, iters = {game: 64, MDP: 13}
> Progress 92.0%, elapsed 102 s, estimated 111 s, iters = {game: 66, MDP: 14}
> Progress 94.4%, elapsed 106 s, estimated 113 s, iters = {game: 69, MDP: 14}
> Progress 96.0%, elapsed 110 s, estimated 114 s, iters = {game: 71, MDP: 15}
> Progress 96.8%, elapsed 113 s, estimated 117 s, iters = {game: 73, MDP: 15}
> Progress 99.2%, elapsed 117 s, estimated 118 s, iters = {game: 76, MDP: 15}
--------------------
Policy tree summary:
found 61 satisfying policies for 30000/30000 family members (100.0%)
policy tree has 76 nodes, 61 of them are leaves:
	  solvable leaves: 61 (avg.size: 491.8)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 0
--------------------
2024-01-09 22:25:29,622 - policy_tree.py - post-processing the policy tree...
2024-01-09 22:25:29,622 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-09 22:25:42,453 - policy_tree.py - additional 131 MDPs were model checked
2024-01-09 22:25:42,453 - policy_tree.py - removed 32 nodes
2024-01-09 22:25:42,453 - policy_tree.py - merging all exclusively compatible policies...
2024-01-09 22:25:42,458 - policy_tree.py - removed 0 policies
2024-01-09 22:25:42,458 - policy_tree.py - reducing tree height...
2024-01-09 22:25:42,458 - policy_tree.py - removed 0 nodes
2024-01-09 22:25:42,458 - policy_tree.py - merging siblings that have the same solution...
2024-01-09 22:25:42,458 - policy_tree.py - removed 0 nodes
2024-01-09 22:25:42,458 - policy_tree.py - postprocessing took 12 s
--------------------
Policy tree summary:
found 29 satisfying policies for 30000/30000 family members (100.0%)
policy tree has 44 nodes, 29 of them are leaves:
	  solvable leaves: 29 (avg.size: 1034.5)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 0
--------------------
2024-01-09 22:25:42,466 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>9/10 [F ((x = 8) & (y = 8))]

method: AR (policy tree), synthesis time: 130.53 s
number of holes: 6, family size: 30000, quotient: 149659 states / 723570 actions
explored: 100 %
Game stats: avg MDP size: 149463, iterations: 76
MDP stats: avg MDP size: 149619, iterations: 15

satisfied 30000/30000 members (100%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
149659 723570 30000 4489770000 30000 100.0
synt info:	time	nodes	nodes (merged)	policies	policies (merged)	policies(merged) / SAT %	game iters	MDP iters	iters/MDPs
130 76 44 61 29 0.1 76 15 0.0

