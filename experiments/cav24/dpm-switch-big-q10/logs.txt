2024-01-09 22:38:20,616 - cli.py - This is Paynt version 0.1.0.
2024-01-09 22:38:20,616 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dpm-switch-big-q10/sketch.templ ...
2024-01-09 22:38:20,616 - sketch.py - assuming sketch in PRISM format...
2024-01-09 22:38:20,618 - prism_parser.py - PRISM model type: MDP
2024-01-09 22:38:20,618 - prism_parser.py - processing hole definitions...
2024-01-09 22:38:20,619 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dpm-switch-big-q10/sketch.props ...
2024-01-09 22:38:20,619 - prism_parser.py - found the following specification: constraints: P>=9/10 [F ((bat = 0) & (lost = 0))]; 
2024-01-09 22:38:20,619 - jani.py - constructing JANI program...
2024-01-09 22:38:20,625 - jani.py - constructing the quotient...
2024-01-09 22:38:21,076 - jani.py - associating choices of the quotient with hole assignments...
2024-01-09 22:38:21,245 - sketch.py - sketch parsing OK
2024-01-09 22:38:21,246 - sketch.py - constructed explicit quotient having 8767 states and 117194 actions
2024-01-09 22:38:21,246 - sketch.py - found the following specification constraints: P>=9/10 [F ((bat = 0) & (lost = 0))]; 
2024-01-09 22:38:21,335 - mdp_family.py - associating choices with action labels...
2024-01-09 22:38:21,430 - synthesizer.py - evaluation initiated, design space: 131220
> Progress 13.333%, elapsed 3 s, estimated 23 s, iters = {game: 5, MDP: 3}
> Progress 22.222%, elapsed 6 s, estimated 27 s, iters = {game: 12, MDP: 10}
> Progress 26.666%, elapsed 9 s, estimated 34 s, iters = {game: 21, MDP: 17}
> Progress 31.851%, elapsed 12 s, estimated 38 s, iters = {game: 31, MDP: 24}
> Progress 36.296%, elapsed 15 s, estimated 42 s, iters = {game: 40, MDP: 32}
> Progress 40.74%, elapsed 18 s, estimated 45 s, iters = {game: 49, MDP: 39}
> Progress 43.703%, elapsed 21 s, estimated 49 s, iters = {game: 58, MDP: 47}
> Progress 45.925%, elapsed 24 s, estimated 53 s, iters = {game: 66, MDP: 54}
> Progress 48.888%, elapsed 27 s, estimated 56 s, iters = {game: 76, MDP: 61}
> Progress 51.111%, elapsed 30 s, estimated 60 s, iters = {game: 84, MDP: 69}
> Progress 54.074%, elapsed 34 s, estimated 62 s, iters = {game: 93, MDP: 77}
> Progress 57.037%, elapsed 37 s, estimated 65 s, iters = {game: 102, MDP: 84}
> Progress 59.506%, elapsed 40 s, estimated 67 s, iters = {game: 110, MDP: 92}
> Progress 80.74%, elapsed 43 s, estimated 53 s, iters = {game: 118, MDP: 98}
> Progress 80.905%, elapsed 46 s, estimated 57 s, iters = {game: 139, MDP: 112}
> Progress 81.234%, elapsed 49 s, estimated 60 s, iters = {game: 158, MDP: 123}
> Progress 81.399%, elapsed 52 s, estimated 64 s, iters = {game: 179, MDP: 136}
> Progress 82.962%, elapsed 55 s, estimated 66 s, iters = {game: 193, MDP: 147}
> Progress 82.983%, elapsed 58 s, estimated 70 s, iters = {game: 209, MDP: 185}
> Progress 83.008%, elapsed 61 s, estimated 74 s, iters = {game: 225, MDP: 226}
> Progress 83.026%, elapsed 64 s, estimated 78 s, iters = {game: 240, MDP: 265}
> Progress 83.049%, elapsed 67 s, estimated 81 s, iters = {game: 255, MDP: 302}
> Progress 83.072%, elapsed 70 s, estimated 85 s, iters = {game: 271, MDP: 344}
> Progress 83.102%, elapsed 74 s, estimated 89 s, iters = {game: 287, MDP: 382}
> Progress 83.456%, elapsed 77 s, estimated 92 s, iters = {game: 304, MDP: 418}
> Progress 83.488%, elapsed 80 s, estimated 96 s, iters = {game: 319, MDP: 449}
> Progress 83.511%, elapsed 83 s, estimated 99 s, iters = {game: 335, MDP: 487}
> Progress 83.543%, elapsed 86 s, estimated 103 s, iters = {game: 352, MDP: 521}
> Progress 84.444%, elapsed 89 s, estimated 106 s, iters = {game: 364, MDP: 550}
--------------------
Policy tree summary:
found 361 satisfying policies for 29160/131220 family members (22.0%)
policy tree has 639 nodes, 424 of them are leaves:
	  solvable leaves: 361 (avg.size: 80.8)
	unsolvable leaves: 63 (avg.size: 1620.0)
	 singleton leaves: 273
--------------------
2024-01-09 22:39:51,998 - policy_tree.py - post-processing the policy tree...
2024-01-09 22:39:51,998 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-09 22:39:53,605 - policy_tree.py - additional 319 MDPs were model checked
2024-01-09 22:39:53,605 - policy_tree.py - removed 514 nodes
2024-01-09 22:39:53,605 - policy_tree.py - merging all exclusively compatible policies...
2024-01-09 22:39:53,618 - policy_tree.py - removed 17 policies
2024-01-09 22:39:53,618 - policy_tree.py - reducing tree height...
2024-01-09 22:39:53,618 - policy_tree.py - removed 5 nodes
2024-01-09 22:39:53,618 - policy_tree.py - merging siblings that have the same solution...
2024-01-09 22:39:53,619 - policy_tree.py - removed 31 nodes
2024-01-09 22:39:53,619 - policy_tree.py - postprocessing took 1 s
--------------------
Policy tree summary:
found 5 satisfying policies for 29160/131220 family members (22.0%)
policy tree has 89 nodes, 54 of them are leaves:
	  solvable leaves: 22 (avg.size: 1325.5)
	unsolvable leaves: 32 (avg.size: 3189.4)
	 singleton leaves: 0
--------------------
2024-01-09 22:39:53,621 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>=9/10 [F ((bat = 0) & (lost = 0))]

method: AR (policy tree), synthesis time: 92.19 s
number of holes: 10, family size: 131220, quotient: 8767 states / 117194 actions
explored: 100 %
Game stats: avg MDP size: 8767, iterations: 366
MDP stats: avg MDP size: 8767, iterations: 551

satisfied 29160/131220 members (22%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
8767 117194 131220 1150405740 29160 22.2
synt info:	time	nodes	nodes (merged)	policies	policies (merged)	policies(merged) / SAT %	game iters	MDP iters	iters/MDPs
92 639 89 361 5 0.0 366 551 0.0

