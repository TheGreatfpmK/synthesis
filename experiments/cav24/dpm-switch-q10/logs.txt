2024-01-09 22:23:07,988 - cli.py - This is Paynt version 0.1.0.
2024-01-09 22:23:07,988 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dpm-switch-q10/sketch.templ ...
2024-01-09 22:23:07,988 - sketch.py - assuming sketch in PRISM format...
2024-01-09 22:23:07,990 - prism_parser.py - PRISM model type: MDP
2024-01-09 22:23:07,990 - prism_parser.py - processing hole definitions...
2024-01-09 22:23:07,990 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/cav24/dpm-switch-q10/sketch.props ...
2024-01-09 22:23:07,992 - prism_parser.py - found the following specification: constraints: P>=19/20 [F ((bat = 0) & (lost = 0))]; 
2024-01-09 22:23:07,992 - jani.py - constructing JANI program...
2024-01-09 22:23:07,997 - jani.py - constructing the quotient...
2024-01-09 22:23:08,045 - jani.py - associating choices of the quotient with hole assignments...
2024-01-09 22:23:08,059 - sketch.py - sketch parsing OK
2024-01-09 22:23:08,059 - sketch.py - constructed explicit quotient having 1594 states and 10508 actions
2024-01-09 22:23:08,059 - sketch.py - found the following specification constraints: P>=19/20 [F ((bat = 0) & (lost = 0))]; 
2024-01-09 22:23:08,062 - mdp_family.py - associating choices with action labels...
2024-01-09 22:23:08,090 - synthesizer.py - evaluation initiated, design space: 14580
> Progress 24.156%, elapsed 3 s, estimated 12 s, iters = {game: 140, MDP: 110}
> Progress 43.388%, elapsed 6 s, estimated 13 s, iters = {game: 347, MDP: 307}
> Progress 50.679%, elapsed 9 s, estimated 17 s, iters = {game: 549, MDP: 590}
> Progress 57.654%, elapsed 12 s, estimated 20 s, iters = {game: 756, MDP: 903}
> Progress 69.753%, elapsed 15 s, estimated 21 s, iters = {game: 968, MDP: 1192}
> Progress 83.209%, elapsed 18 s, estimated 21 s, iters = {game: 1157, MDP: 1464}
--------------------
Policy tree summary:
found 314 satisfying policies for 2638/14580 family members (18.0%)
policy tree has 1739 nodes, 1159 of them are leaves:
	  solvable leaves: 314 (avg.size: 8.4)
	unsolvable leaves: 845 (avg.size: 14.1)
	 singleton leaves: 444
--------------------
2024-01-09 22:23:28,883 - policy_tree.py - post-processing the policy tree...
2024-01-09 22:23:28,883 - policy_tree.py - merging SAT siblings solved by non-exclusively compatible policies...
2024-01-09 22:23:28,929 - policy_tree.py - additional 64 MDPs were model checked
2024-01-09 22:23:28,929 - policy_tree.py - removed 54 nodes
2024-01-09 22:23:28,929 - policy_tree.py - merging all exclusively compatible policies...
2024-01-09 22:23:28,964 - policy_tree.py - removed 77 policies
2024-01-09 22:23:28,964 - policy_tree.py - reducing tree height...
2024-01-09 22:23:28,965 - policy_tree.py - removed 6 nodes
2024-01-09 22:23:28,965 - policy_tree.py - merging siblings that have the same solution...
2024-01-09 22:23:28,968 - policy_tree.py - removed 404 nodes
2024-01-09 22:23:28,968 - policy_tree.py - postprocessing took 0 s
--------------------
Policy tree summary:
found 199 satisfying policies for 2638/14580 family members (18.0%)
policy tree has 1275 nodes, 719 of them are leaves:
	  solvable leaves: 276 (avg.size: 9.6)
	unsolvable leaves: 443 (avg.size: 27.0)
	 singleton leaves: 160
--------------------
2024-01-09 22:23:28,974 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>=19/20 [F ((bat = 0) & (lost = 0))]

method: AR (policy tree), synthesis time: 20.88 s
number of holes: 10, family size: 14580, quotient: 1594 states / 10508 actions
explored: 100 %
Game stats: avg MDP size: 1594, iterations: 1295
MDP stats: avg MDP size: 1594, iterations: 1615

satisfied 2638/14580 members (18%)
--------------------
model info:	states	choices	MDPs	states*MDPs	SAT MDPs	SAT %
1594 10508 14580 23240520 2638 18.1
synt info:	time	nodes	nodes (merged)	policies	policies (merged)	policies(merged) / SAT %	game iters	MDP iters	iters/MDPs
20 1739 1275 314 199 7.5 1295 1615 0.2

