2024-01-08 21:08:03,811 - cli.py - This is Paynt version 0.1.0.
2024-01-08 21:08:03,811 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/sketches/uav/int-holes/roz/sketch.templ ...
2024-01-08 21:08:03,811 - sketch.py - assuming sketch in PRISM format...
2024-01-08 21:08:03,818 - prism_parser.py - PRISM model type: MDP
2024-01-08 21:08:03,818 - prism_parser.py - processing hole definitions...
2024-01-08 21:08:03,818 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/sketches/uav/int-holes/roz/sketch.props ...
2024-01-08 21:08:03,819 - prism_parser.py - found the following specification: constraints: P>=3/4 [F ((w1 & w2) & w6)]; 
2024-01-08 21:08:03,819 - jani.py - constructing JANI program...
2024-01-08 21:08:03,829 - jani.py - constructing the quotient...
2024-01-08 21:08:04,553 - jani.py - associating choices of the quotient with hole assignments...
2024-01-08 21:08:04,713 - sketch.py - sketch parsing OK
2024-01-08 21:08:04,714 - sketch.py - constructed explicit quotient having 17927 states and 191629 actions
2024-01-08 21:08:04,714 - sketch.py - found the following specification constraints: P>=3/4 [F ((w1 & w2) & w6)]; 
2024-01-08 21:08:04,839 - mdp_family.py - associating choices with action labels...
2024-01-08 21:08:05,105 - synthesizer.py - evaluation initiated, design space: 4500
> Progress 3.333%, elapsed 3 s, estimated 97 s, iters = {game: 9, MDP: 8}
> Progress 13.333%, elapsed 6 s, estimated 46 s, iters = {game: 34, MDP: 36}
> Progress 24.777%, elapsed 9 s, estimated 37 s, iters = {game: 124, MDP: 147}
> Progress 30.0%, elapsed 12 s, estimated 41 s, iters = {game: 201, MDP: 237}
> Progress 35.0%, elapsed 15 s, estimated 44 s, iters = {game: 211, MDP: 246}
> Progress 42.222%, elapsed 18 s, estimated 43 s, iters = {game: 224, MDP: 260}
> Progress 55.0%, elapsed 21 s, estimated 39 s, iters = {game: 247, MDP: 282}
> Progress 65.0%, elapsed 24 s, estimated 37 s, iters = {game: 279, MDP: 319}
> Progress 70.0%, elapsed 27 s, estimated 39 s, iters = {game: 288, MDP: 327}
> Progress 75.0%, elapsed 30 s, estimated 40 s, iters = {game: 297, MDP: 337}
> Progress 81.666%, elapsed 33 s, estimated 41 s, iters = {game: 310, MDP: 349}
> Progress 92.222%, elapsed 36 s, estimated 39 s, iters = {game: 329, MDP: 368}
--------------------
Policy tree summary:
found 234 satisfying policies for 4451/4500 family members (99.0%)
policy tree has 381 nodes, 259 of them are leaves:
	  solvable leaves: 234 (avg.size: 19.0)
	unsolvable leaves: 25 (avg.size: 2.0)
	 singleton leaves: 40
2024-01-08 21:08:44,603 - policy_tree.py - post-processing the policy tree...
2024-01-08 21:08:44,603 - policy_tree.py - merging unsat siblings...
2024-01-08 21:08:44,603 - policy_tree.py - merged 0 pairs
2024-01-08 21:08:44,603 - policy_tree.py - merging compatible siblings...
2024-01-08 21:08:44,763 - policy_tree.py - merged 150 pairs
--------------------
Policy tree summary:
found 100 satisfying policies for 4451/4500 family members (99.0%)
policy tree has 231 nodes, 125 of them are leaves:
	  solvable leaves: 100 (avg.size: 44.5)
	unsolvable leaves: 25 (avg.size: 2.0)
	 singleton leaves: 40
2024-01-08 21:08:44,768 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>=3/4 [F ((w1 & w2) & w6)]

method: AR (policy tree), synthesis time: 39.66 s
number of holes: 4, family size: 4500, quotient: 17927 states / 191629 actions
explored: 100 %
Game stats: avg MDP size: 5263, iterations: 341
MDP stats: avg MDP size: 2287, iterations: 381

satisfied 4451/4500 members (99%)
--------------------
