2024-01-08 07:09:07,811 - cli.py - This is Paynt version 0.1.0.
2024-01-08 07:09:07,811 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/mdp/sketches/rocks/6-4/sketch.templ ...
2024-01-08 07:09:07,811 - sketch.py - assuming sketch in PRISM format...
2024-01-08 07:09:07,813 - prism_parser.py - PRISM model type: MDP
2024-01-08 07:09:07,813 - prism_parser.py - processing hole definitions...
2024-01-08 07:09:07,814 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/mdp/sketches/rocks/6-4/sketch.props ...
2024-01-08 07:09:07,814 - prism_parser.py - found the following specification: constraints: P>=1 [F (((visit1 & visit2) & visit3) & visit4)]; 
2024-01-08 07:09:07,814 - jani.py - constructing JANI program...
2024-01-08 07:09:07,817 - jani.py - constructing the quotient...
2024-01-08 07:09:07,836 - jani.py - associating choices of the quotient with hole assignments...
2024-01-08 07:09:07,839 - sketch.py - sketch parsing OK
2024-01-08 07:09:07,839 - sketch.py - constructed explicit quotient having 2736 states and 6660 actions
2024-01-08 07:09:07,840 - sketch.py - found the following specification constraints: P>=1 [F (((visit1 & visit2) & visit3) & visit4)]; 
2024-01-08 07:09:07,841 - mdp_family.py - associating choices with action labels...
2024-01-08 07:09:07,873 - synthesizer.py - evaluation initiated, design space: 6561
> Progress 3.612%, elapsed 3 s, estimated 83 s, iters = {game: 123, MDP: 359}
> Progress 7.468%, elapsed 6 s, estimated 80 s, iters = {game: 251, MDP: 742}
> Progress 10.973%, elapsed 9 s, estimated 82 s, iters = {game: 363, MDP: 1082}
> Progress 14.128%, elapsed 12 s, estimated 85 s, iters = {game: 468, MDP: 1394}
> Progress 17.451%, elapsed 15 s, estimated 86 s, iters = {game: 577, MDP: 1723}
> Progress 20.438%, elapsed 18 s, estimated 88 s, iters = {game: 675, MDP: 2015}
> Progress 23.639%, elapsed 21 s, estimated 88 s, iters = {game: 781, MDP: 2331}
> Progress 27.572%, elapsed 24 s, estimated 87 s, iters = {game: 910, MDP: 2718}
> Progress 31.367%, elapsed 27 s, estimated 86 s, iters = {game: 1033, MDP: 3090}
> Progress 34.567%, elapsed 30 s, estimated 86 s, iters = {game: 1141, MDP: 3408}
> Progress 37.585%, elapsed 33 s, estimated 88 s, iters = {game: 1239, MDP: 3704}
> Progress 40.74%, elapsed 36 s, estimated 88 s, iters = {game: 1342, MDP: 4014}
> Progress 43.484%, elapsed 39 s, estimated 89 s, iters = {game: 1431, MDP: 4283}
> Progress 46.395%, elapsed 42 s, estimated 90 s, iters = {game: 1526, MDP: 4571}
> Progress 49.382%, elapsed 45 s, estimated 91 s, iters = {game: 1625, MDP: 4864}
> Progress 52.4%, elapsed 48 s, estimated 91 s, iters = {game: 1723, MDP: 5160}
> Progress 55.098%, elapsed 51 s, estimated 92 s, iters = {game: 1810, MDP: 5424}
> Progress 58.07%, elapsed 54 s, estimated 93 s, iters = {game: 1910, MDP: 5719}
> Progress 61.408%, elapsed 57 s, estimated 93 s, iters = {game: 2018, MDP: 6046}
> Progress 64.517%, elapsed 60 s, estimated 93 s, iters = {game: 2120, MDP: 6352}
> Progress 67.626%, elapsed 63 s, estimated 93 s, iters = {game: 2224, MDP: 6660}
> Progress 71.559%, elapsed 66 s, estimated 92 s, iters = {game: 2351, MDP: 7045}
> Progress 75.354%, elapsed 69 s, estimated 91 s, iters = {game: 2477, MDP: 7420}
> Progress 78.768%, elapsed 72 s, estimated 91 s, iters = {game: 2588, MDP: 7757}
> Progress 82.03%, elapsed 75 s, estimated 91 s, iters = {game: 2695, MDP: 8076}
> Progress 85.55%, elapsed 78 s, estimated 91 s, iters = {game: 2810, MDP: 8422}
> Progress 88.614%, elapsed 81 s, estimated 91 s, iters = {game: 2910, MDP: 8723}
> Progress 92.409%, elapsed 84 s, estimated 91 s, iters = {game: 3034, MDP: 9096}
> Progress 96.433%, elapsed 87 s, estimated 90 s, iters = {game: 3167, MDP: 9493}
--------------------
Policy tree summary:
found 6561 satisfying policies for 6561/6561 family members (100.0%)
policy tree has 9841 nodes, 6561 of them are leaves:
	  solvable leaves: 6561 (avg.size: 1.0)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 6561
2024-01-08 07:10:38,393 - policy_tree.py - post-processing the policy tree...
2024-01-08 07:10:38,393 - policy_tree.py - merging unsat siblings...
2024-01-08 07:10:38,449 - policy_tree.py - merged 0 pairs
2024-01-08 07:10:38,449 - policy_tree.py - merging compatible siblings...
2024-01-08 07:10:49,943 - policy_tree.py - merged 6358 pairs
--------------------
Policy tree summary:
found 2287 satisfying policies for 6561/6561 family members (100.0%)
policy tree has 3483 nodes, 2287 of them are leaves:
	  solvable leaves: 2287 (avg.size: 2.9)
	unsolvable leaves: 0 (avg.size: NA)
	 singleton leaves: 103
2024-01-08 07:10:50,025 - synthesizer.py - evaluation finished
--------------------
Synthesis summary:
constraint 1: P>=1 [F (((visit1 & visit2) & visit3) & visit4)]

method: AR (policy tree), synthesis time: 102.15 s
number of holes: 8, family size: 6561, quotient: 2736 states / 6660 actions
explored: 100 %
Game stats: avg MDP size: 2639, iterations: 3280
MDP stats: avg MDP size: 2629, iterations: 9841

satisfied 6561/6561 members (100%)
--------------------
