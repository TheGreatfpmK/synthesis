2024-02-04 00:06:57,786 - cli.py - This is Paynt version 0.1.0.
2024-02-04 00:06:57,787 - sketch.py - loading sketch from /home/fpmk/research/synthesis/experiments/../models/tac24/grid-10-sl-4fsc/sketch.templ ...
2024-02-04 00:06:57,787 - sketch.py - assuming sketch in PRISM format...
2024-02-04 00:06:57,788 - prism_parser.py - PRISM model type: DTMC
2024-02-04 00:06:57,788 - prism_parser.py - processing hole definitions...
2024-02-04 00:06:57,789 - prism_parser.py - loading properties from /home/fpmk/research/synthesis/experiments/../models/tac24/grid-10-sl-4fsc/sketch.props ...
2024-02-04 00:06:57,789 - prism_parser.py - found the following specification: optimality: R[exp]{"steps"}min=? [F "goal"] 
2024-02-04 00:06:57,789 - jani.py - constructing JANI program...
2024-02-04 00:06:57,791 - jani.py - constructing the quotient...
2024-02-04 00:06:57,816 - jani.py - associating choices of the quotient with hole assignments...
2024-02-04 00:06:57,823 - sketch.py - sketch parsing OK
2024-02-04 00:06:57,824 - sketch.py - converting state rewards 'steps' to state-action rewards
2024-02-04 00:06:57,825 - sketch.py - constructed explicit quotient having 2405 states and 9605 actions
2024-02-04 00:06:57,825 - sketch.py - found the following specification optimality: R[exp]{"steps"}min=? [F "goal"] 
2024-02-04 00:06:57,837 - synthesizer.py - synthesis initiated, design space: 65536
> progress 3.125%, elapsed 3 s, estimated 96 s, iters = {MDP: 262}, opt = 1160.364
> progress 12.701%, elapsed 6 s, estimated 47 s, iters = {MDP: 526}, opt = 1160.364
> progress 15.087%, elapsed 9 s, estimated 59 s, iters = {MDP: 977}, opt = 1160.364
> progress 17.358%, elapsed 12 s, estimated 69 s, iters = {MDP: 1410}, opt = 1160.364
> progress 50.781%, elapsed 15 s, estimated 29 s, iters = {MDP: 1841}, opt = 1160.364
> progress 52.343%, elapsed 18 s, estimated 34 s, iters = {MDP: 2096}, opt = 1160.364
> progress 57.739%, elapsed 21 s, estimated 36 s, iters = {MDP: 2448}, opt = 1160.364
> progress 59.906%, elapsed 24 s, estimated 40 s, iters = {MDP: 2700}, opt = 1160.364
> progress 62.304%, elapsed 27 s, estimated 43 s, iters = {MDP: 2977}, opt = 1160.364
> progress 64.648%, elapsed 30 s, estimated 46 s, iters = {MDP: 3341}, opt = 1160.364
> progress 69.073%, elapsed 33 s, estimated 47 s, iters = {MDP: 3693}, opt = 1160.364
> progress 72.131%, elapsed 36 s, estimated 50 s, iters = {MDP: 3952}, opt = 1160.364
> progress 73.983%, elapsed 39 s, estimated 52 s, iters = {MDP: 4218}, opt = 1160.364
> progress 76.647%, elapsed 42 s, estimated 54 s, iters = {MDP: 4633}, opt = 1160.364
> progress 78.564%, elapsed 45 s, estimated 57 s, iters = {MDP: 4894}, opt = 1160.364
> progress 84.838%, elapsed 48 s, estimated 56 s, iters = {MDP: 5307}, opt = 1160.364
> progress 86.596%, elapsed 51 s, estimated 59 s, iters = {MDP: 5553}, opt = 1160.364
> progress 89.575%, elapsed 54 s, estimated 60 s, iters = {MDP: 5942}, opt = 1160.364
> progress 93.829%, elapsed 57 s, estimated 60 s, iters = {MDP: 6261}, opt = 1160.364
> progress 97.106%, elapsed 60 s, estimated 61 s, iters = {MDP: 6565}, opt = 1160.364
> progress 98.851%, elapsed 63 s, estimated 63 s, iters = {MDP: 6836}, opt = 1160.364
2024-02-04 00:08:01,781 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-02-04 00:08:01,781 - synthesizer.py - M_0_1=1, M_1_1=3, M_2_1=0, M_3_1=2, P_0_1=2, P_1_1=1, P_2_1=3, P_3_1=4
2024-02-04 00:08:01,806 - synthesizer.py - double-checking specification satisfiability:  : 1160.3642313506098
--------------------
Synthesis summary:
optimality objective: R[exp]{"steps"}min=? [F "goal"] 

method: AR, synthesis time: 63.94 s
number of holes: 8, family size: 65536, quotient: 2405 states / 9605 actions
explored: 100 %
MDP stats: avg MDP size: 895, iterations: 6886

optimum: 1160.364231
--------------------
