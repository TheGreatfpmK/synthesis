2024-04-10 21:25:53,151 - cli.py - This is Paynt version 0.1.0.
2024-04-10 21:25:53,151 - sketch.py - loading sketch from ../sarsop/models/08/ejs1.pomdp ...
2024-04-10 21:25:53,151 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 1:1:  expecting <model type>, here:
	discount: 0.8
	^

2024-04-10 21:25:53,152 - sketch.py - assuming sketch in DRN format...
ERROR (DirectEncodingParser.cpp:124): Could not parse line 'discount: 0.8'.
2024-04-10 21:25:53,153 - sketch.py - assuming sketch in Cassandra format...
MADP: trying to parse as POMDP...
MADP: parsing success
2024-04-10 21:25:53,155 - sketch.py - applying discount factor transformation...
2024-04-10 21:25:53,156 - sketch.py - sketch parsing OK
2024-04-10 21:25:53,156 - sketch.py - constructed explicit quotient having 9 states and 33 actions
2024-04-10 21:25:53,156 - sketch.py - found the following specification optimality: R[exp]{"reward"}max=? [C{4/5}] 
2024-04-10 21:25:53,156 - pomdp.py - constructed POMDP having 4 observations.
2024-04-10 21:25:53,157 - pomdp.py - unfolding 1-FSC template into POMDP ...
2024-04-10 21:25:53,157 - pomdp.py - constructed quotient MDP having 9 states and 33 actions.
2024-04-10 21:25:53,157 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,161 - synthesizer_pomdp.py - Storm POMDP option enabled
2024-04-10 21:25:53,161 - synthesizer_pomdp.py - Storm settings: iterative - (900, 90, 10), get_storm_result - None, storm_options - cutoff, prune_storm - False, unfold_strategy - (True, False), use_storm_cutoffs - False, enhanced_saynt - None, saynt_overapprox - False
2024-04-10 21:25:53,162 - synthesizer.py - synthesis initiated, design space: 64
-----------PAYNT-----------                     
Value = 2.24532584529214 | Time elapsed = 0.0s | FSC size = 8

2024-04-10 21:25:53,163 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,163 - synthesizer.py - A(good,0)=(Manufacture), A(defective,0)=(Manufacture), A(__no_obs__,0)=(Manufacture)
2024-04-10 21:25:53,163 - synthesizer.py - double-checking specification satisfiability:  : 2.24532584529214
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 3, family size: 64, quotient: 9 states / 33 actions
explored: 100 %
MDP stats: avg MDP size: 9, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,164 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,164 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-04-10 21:25:53,164 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,164 - pomdp.py - unfolding 2-FSC template into POMDP ...
2024-04-10 21:25:53,164 - pomdp.py - constructed quotient MDP having 17 states and 130 actions.
2024-04-10 21:25:53,164 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,164 - synthesizer.py - synthesis initiated, design space: 524288
2024-04-10 21:25:53,165 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,165 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 13, family size: 524288, quotient: 17 states / 130 actions
explored: 100 %
MDP stats: avg MDP size: 17, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,165 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,165 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,165 - pomdp.py - unfolding 3-FSC template into POMDP ...
2024-04-10 21:25:53,165 - pomdp.py - constructed quotient MDP having 25 states and 291 actions.
2024-04-10 21:25:53,165 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,165 - synthesizer.py - synthesis initiated, design space: 1e10
2024-04-10 21:25:53,165 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,166 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 19, family size: 1e10, quotient: 25 states / 291 actions
explored: 100 %
MDP stats: avg MDP size: 25, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,166 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,166 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,166 - pomdp.py - unfolding 4-FSC template into POMDP ...
2024-04-10 21:25:53,166 - pomdp.py - constructed quotient MDP having 33 states and 516 actions.
2024-04-10 21:25:53,166 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,167 - synthesizer.py - synthesis initiated, design space: 1e15
2024-04-10 21:25:53,168 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,168 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 25, family size: 1e15, quotient: 33 states / 516 actions
explored: 100 %
MDP stats: avg MDP size: 33, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,168 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,168 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,168 - pomdp.py - unfolding 5-FSC template into POMDP ...
2024-04-10 21:25:53,168 - pomdp.py - constructed quotient MDP having 41 states and 805 actions.
2024-04-10 21:25:53,168 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,169 - synthesizer.py - synthesis initiated, design space: 1e20
2024-04-10 21:25:53,169 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,169 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 31, family size: 1e20, quotient: 41 states / 805 actions
explored: 100 %
MDP stats: avg MDP size: 41, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,169 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,169 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,169 - pomdp.py - unfolding 6-FSC template into POMDP ...
2024-04-10 21:25:53,170 - pomdp.py - constructed quotient MDP having 49 states and 1158 actions.
2024-04-10 21:25:53,170 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,170 - synthesizer.py - synthesis initiated, design space: 1e25
2024-04-10 21:25:53,171 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,171 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 37, family size: 1e25, quotient: 49 states / 1158 actions
explored: 100 %
MDP stats: avg MDP size: 49, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,171 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,171 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,172 - pomdp.py - unfolding 7-FSC template into POMDP ...
2024-04-10 21:25:53,172 - pomdp.py - constructed quotient MDP having 57 states and 1575 actions.
2024-04-10 21:25:53,173 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,175 - synthesizer.py - synthesis initiated, design space: 1e31
2024-04-10 21:25:53,176 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,176 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 43, family size: 1e31, quotient: 57 states / 1575 actions
explored: 100 %
MDP stats: avg MDP size: 57, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,176 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,177 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,177 - pomdp.py - unfolding 8-FSC template into POMDP ...
2024-04-10 21:25:53,177 - pomdp.py - constructed quotient MDP having 65 states and 2056 actions.
2024-04-10 21:25:53,177 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,180 - synthesizer.py - synthesis initiated, design space: 1e37
2024-04-10 21:25:53,181 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,182 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 49, family size: 1e37, quotient: 65 states / 2056 actions
explored: 100 %
MDP stats: avg MDP size: 65, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,182 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,182 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,182 - pomdp.py - unfolding 9-FSC template into POMDP ...
2024-04-10 21:25:53,182 - pomdp.py - constructed quotient MDP having 73 states and 2601 actions.
2024-04-10 21:25:53,182 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,184 - synthesizer.py - synthesis initiated, design space: 1e42
2024-04-10 21:25:53,186 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,186 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 55, family size: 1e42, quotient: 73 states / 2601 actions
explored: 100 %
MDP stats: avg MDP size: 73, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,186 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,186 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,186 - pomdp.py - unfolding 10-FSC template into POMDP ...
2024-04-10 21:25:53,187 - pomdp.py - constructed quotient MDP having 81 states and 3210 actions.
2024-04-10 21:25:53,187 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,202 - synthesizer.py - synthesis initiated, design space: 1e49
2024-04-10 21:25:53,204 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,204 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 61, family size: 1e49, quotient: 81 states / 3210 actions
explored: 100 %
MDP stats: avg MDP size: 81, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,204 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,204 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,205 - pomdp.py - unfolding 11-FSC template into POMDP ...
2024-04-10 21:25:53,205 - pomdp.py - constructed quotient MDP having 89 states and 3883 actions.
2024-04-10 21:25:53,205 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,209 - synthesizer.py - synthesis initiated, design space: 1e55
2024-04-10 21:25:53,212 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,212 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 67, family size: 1e55, quotient: 89 states / 3883 actions
explored: 100 %
MDP stats: avg MDP size: 89, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,212 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,212 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,212 - pomdp.py - unfolding 12-FSC template into POMDP ...
2024-04-10 21:25:53,213 - pomdp.py - constructed quotient MDP having 97 states and 4620 actions.
2024-04-10 21:25:53,213 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,218 - synthesizer.py - synthesis initiated, design space: 1e61
2024-04-10 21:25:53,220 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,220 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 73, family size: 1e61, quotient: 97 states / 4620 actions
explored: 100 %
MDP stats: avg MDP size: 97, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,220 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,220 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,221 - pomdp.py - unfolding 13-FSC template into POMDP ...
2024-04-10 21:25:53,222 - pomdp.py - constructed quotient MDP having 105 states and 5421 actions.
2024-04-10 21:25:53,222 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,226 - synthesizer.py - synthesis initiated, design space: 1e68
2024-04-10 21:25:53,229 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,229 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 79, family size: 1e68, quotient: 105 states / 5421 actions
explored: 100 %
MDP stats: avg MDP size: 105, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,230 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,230 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,230 - pomdp.py - unfolding 14-FSC template into POMDP ...
2024-04-10 21:25:53,231 - pomdp.py - constructed quotient MDP having 113 states and 6286 actions.
2024-04-10 21:25:53,231 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,237 - synthesizer.py - synthesis initiated, design space: 1e74
2024-04-10 21:25:53,241 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,241 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 85, family size: 1e74, quotient: 113 states / 6286 actions
explored: 100 %
MDP stats: avg MDP size: 113, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,241 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,241 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,242 - pomdp.py - unfolding 15-FSC template into POMDP ...
2024-04-10 21:25:53,243 - pomdp.py - constructed quotient MDP having 121 states and 7215 actions.
2024-04-10 21:25:53,243 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,266 - synthesizer.py - synthesis initiated, design space: 1e81
2024-04-10 21:25:53,270 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,270 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 91, family size: 1e81, quotient: 121 states / 7215 actions
explored: 100 %
MDP stats: avg MDP size: 121, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,270 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,270 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,271 - pomdp.py - unfolding 16-FSC template into POMDP ...
2024-04-10 21:25:53,272 - pomdp.py - constructed quotient MDP having 129 states and 8208 actions.
2024-04-10 21:25:53,272 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,278 - synthesizer.py - synthesis initiated, design space: 1e87
2024-04-10 21:25:53,282 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,282 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.0 s
number of holes: 97, family size: 1e87, quotient: 129 states / 8208 actions
explored: 100 %
MDP stats: avg MDP size: 129, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,282 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,283 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,283 - pomdp.py - unfolding 17-FSC template into POMDP ...
2024-04-10 21:25:53,285 - pomdp.py - constructed quotient MDP having 137 states and 9265 actions.
2024-04-10 21:25:53,285 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,292 - synthesizer.py - synthesis initiated, design space: 1e94
2024-04-10 21:25:53,298 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,298 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 103, family size: 1e94, quotient: 137 states / 9265 actions
explored: 100 %
MDP stats: avg MDP size: 137, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,298 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,298 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,299 - pomdp.py - unfolding 18-FSC template into POMDP ...
2024-04-10 21:25:53,302 - pomdp.py - constructed quotient MDP having 145 states and 10386 actions.
2024-04-10 21:25:53,302 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,327 - synthesizer.py - synthesis initiated, design space: 1e101
2024-04-10 21:25:53,333 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,333 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 109, family size: 1e101, quotient: 145 states / 10386 actions
explored: 100 %
MDP stats: avg MDP size: 145, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,333 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,333 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,334 - pomdp.py - unfolding 19-FSC template into POMDP ...
2024-04-10 21:25:53,337 - pomdp.py - constructed quotient MDP having 153 states and 11571 actions.
2024-04-10 21:25:53,337 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,345 - synthesizer.py - synthesis initiated, design space: 1e108
2024-04-10 21:25:53,351 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,351 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 115, family size: 1e108, quotient: 153 states / 11571 actions
explored: 100 %
MDP stats: avg MDP size: 153, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,351 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,351 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,352 - pomdp.py - unfolding 20-FSC template into POMDP ...
2024-04-10 21:25:53,355 - pomdp.py - constructed quotient MDP having 161 states and 12820 actions.
2024-04-10 21:25:53,355 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,383 - synthesizer.py - synthesis initiated, design space: 1e115
2024-04-10 21:25:53,388 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,388 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 121, family size: 1e115, quotient: 161 states / 12820 actions
explored: 100 %
MDP stats: avg MDP size: 161, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,388 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,388 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,389 - pomdp.py - unfolding 21-FSC template into POMDP ...
2024-04-10 21:25:53,393 - pomdp.py - constructed quotient MDP having 169 states and 14133 actions.
2024-04-10 21:25:53,393 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,407 - synthesizer.py - synthesis initiated, design space: 1e122
2024-04-10 21:25:53,414 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,415 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 127, family size: 1e122, quotient: 169 states / 14133 actions
explored: 100 %
MDP stats: avg MDP size: 169, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,415 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,415 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,416 - pomdp.py - unfolding 22-FSC template into POMDP ...
2024-04-10 21:25:53,437 - pomdp.py - constructed quotient MDP having 177 states and 15510 actions.
2024-04-10 21:25:53,438 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,450 - synthesizer.py - synthesis initiated, design space: 1e129
2024-04-10 21:25:53,457 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,457 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 133, family size: 1e129, quotient: 177 states / 15510 actions
explored: 100 %
MDP stats: avg MDP size: 177, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,457 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,458 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,458 - pomdp.py - unfolding 23-FSC template into POMDP ...
2024-04-10 21:25:53,462 - pomdp.py - constructed quotient MDP having 185 states and 16951 actions.
2024-04-10 21:25:53,462 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,494 - synthesizer.py - synthesis initiated, design space: 1e136
2024-04-10 21:25:53,501 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,501 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 139, family size: 1e136, quotient: 185 states / 16951 actions
explored: 100 %
MDP stats: avg MDP size: 185, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,501 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,501 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,502 - pomdp.py - unfolding 24-FSC template into POMDP ...
2024-04-10 21:25:53,507 - pomdp.py - constructed quotient MDP having 193 states and 18456 actions.
2024-04-10 21:25:53,507 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,543 - synthesizer.py - synthesis initiated, design space: 1e144
2024-04-10 21:25:53,551 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,551 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 145, family size: 1e144, quotient: 193 states / 18456 actions
explored: 100 %
MDP stats: avg MDP size: 193, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,551 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,551 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,552 - pomdp.py - unfolding 25-FSC template into POMDP ...
2024-04-10 21:25:53,557 - pomdp.py - constructed quotient MDP having 201 states and 20025 actions.
2024-04-10 21:25:53,558 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,579 - synthesizer.py - synthesis initiated, design space: 1e151
2024-04-10 21:25:53,590 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,590 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 151, family size: 1e151, quotient: 201 states / 20025 actions
explored: 100 %
MDP stats: avg MDP size: 201, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,590 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,590 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,592 - pomdp.py - unfolding 26-FSC template into POMDP ...
2024-04-10 21:25:53,617 - pomdp.py - constructed quotient MDP having 209 states and 21658 actions.
2024-04-10 21:25:53,617 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,634 - synthesizer.py - synthesis initiated, design space: 1e158
2024-04-10 21:25:53,643 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,643 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 157, family size: 1e158, quotient: 209 states / 21658 actions
explored: 100 %
MDP stats: avg MDP size: 209, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,643 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,643 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,645 - pomdp.py - unfolding 27-FSC template into POMDP ...
2024-04-10 21:25:53,682 - pomdp.py - constructed quotient MDP having 217 states and 23355 actions.
2024-04-10 21:25:53,683 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,699 - synthesizer.py - synthesis initiated, design space: 1e166
2024-04-10 21:25:53,708 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,708 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 163, family size: 1e166, quotient: 217 states / 23355 actions
explored: 100 %
MDP stats: avg MDP size: 217, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,708 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,708 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,709 - pomdp.py - unfolding 28-FSC template into POMDP ...
2024-04-10 21:25:53,736 - pomdp.py - constructed quotient MDP having 225 states and 25116 actions.
2024-04-10 21:25:53,737 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,781 - synthesizer.py - synthesis initiated, design space: 1e173
2024-04-10 21:25:53,794 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,795 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 169, family size: 1e173, quotient: 225 states / 25116 actions
explored: 100 %
MDP stats: avg MDP size: 225, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,795 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,795 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,796 - pomdp.py - unfolding 29-FSC template into POMDP ...
2024-04-10 21:25:53,803 - pomdp.py - constructed quotient MDP having 233 states and 26941 actions.
2024-04-10 21:25:53,804 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,853 - synthesizer.py - synthesis initiated, design space: 1e181
2024-04-10 21:25:53,869 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,869 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 175, family size: 1e181, quotient: 233 states / 26941 actions
explored: 100 %
MDP stats: avg MDP size: 233, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,869 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,869 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,871 - pomdp.py - unfolding 30-FSC template into POMDP ...
2024-04-10 21:25:53,878 - pomdp.py - constructed quotient MDP having 241 states and 28830 actions.
2024-04-10 21:25:53,878 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,927 - synthesizer.py - synthesis initiated, design space: 1e188
2024-04-10 21:25:53,941 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:53,941 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 181, family size: 1e188, quotient: 241 states / 28830 actions
explored: 100 %
MDP stats: avg MDP size: 241, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:53,941 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:53,941 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:53,943 - pomdp.py - unfolding 31-FSC template into POMDP ...
2024-04-10 21:25:53,950 - pomdp.py - constructed quotient MDP having 249 states and 30783 actions.
2024-04-10 21:25:53,950 - pomdp.py - creating coloring ...
2024-04-10 21:25:53,994 - synthesizer.py - synthesis initiated, design space: 1e196
2024-04-10 21:25:54,005 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,006 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 187, family size: 1e196, quotient: 249 states / 30783 actions
explored: 100 %
MDP stats: avg MDP size: 249, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,006 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,006 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,007 - pomdp.py - unfolding 32-FSC template into POMDP ...
2024-04-10 21:25:54,042 - pomdp.py - constructed quotient MDP having 257 states and 32800 actions.
2024-04-10 21:25:54,042 - pomdp.py - creating coloring ...
2024-04-10 21:25:54,101 - synthesizer.py - synthesis initiated, design space: 1e203
2024-04-10 21:25:54,115 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,115 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 193, family size: 1e203, quotient: 257 states / 32800 actions
explored: 100 %
MDP stats: avg MDP size: 257, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,115 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,115 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,117 - pomdp.py - unfolding 33-FSC template into POMDP ...
2024-04-10 21:25:54,125 - pomdp.py - constructed quotient MDP having 265 states and 34881 actions.
2024-04-10 21:25:54,125 - pomdp.py - creating coloring ...
2024-04-10 21:25:54,182 - synthesizer.py - synthesis initiated, design space: 1e211
2024-04-10 21:25:54,196 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,197 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 199, family size: 1e211, quotient: 265 states / 34881 actions
explored: 100 %
MDP stats: avg MDP size: 265, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,197 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,197 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,200 - pomdp.py - unfolding 34-FSC template into POMDP ...
2024-04-10 21:25:54,229 - pomdp.py - constructed quotient MDP having 273 states and 37026 actions.
2024-04-10 21:25:54,229 - pomdp.py - creating coloring ...
2024-04-10 21:25:54,287 - synthesizer.py - synthesis initiated, design space: 1e219
2024-04-10 21:25:54,302 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,302 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 205, family size: 1e219, quotient: 273 states / 37026 actions
explored: 100 %
MDP stats: avg MDP size: 273, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,302 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,302 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,304 - pomdp.py - unfolding 35-FSC template into POMDP ...
2024-04-10 21:25:54,312 - pomdp.py - constructed quotient MDP having 281 states and 39235 actions.
2024-04-10 21:25:54,313 - pomdp.py - creating coloring ...
2024-04-10 21:25:54,389 - synthesizer.py - synthesis initiated, design space: 1e226
2024-04-10 21:25:54,404 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,405 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.01 s
number of holes: 211, family size: 1e226, quotient: 281 states / 39235 actions
explored: 100 %
MDP stats: avg MDP size: 281, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,405 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,405 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,407 - pomdp.py - unfolding 36-FSC template into POMDP ...
2024-04-10 21:25:54,418 - pomdp.py - constructed quotient MDP having 289 states and 41508 actions.
2024-04-10 21:25:54,418 - pomdp.py - creating coloring ...
2024-04-10 21:25:54,474 - synthesizer.py - synthesis initiated, design space: 1e234
2024-04-10 21:25:54,490 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,490 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 217, family size: 1e234, quotient: 289 states / 41508 actions
explored: 100 %
MDP stats: avg MDP size: 289, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,490 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,491 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,493 - pomdp.py - unfolding 37-FSC template into POMDP ...
2024-04-10 21:25:54,527 - pomdp.py - constructed quotient MDP having 297 states and 43845 actions.
2024-04-10 21:25:54,527 - pomdp.py - creating coloring ...
2024-04-10 21:25:54,589 - synthesizer.py - synthesis initiated, design space: 1e242
2024-04-10 21:25:54,605 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,605 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 223, family size: 1e242, quotient: 297 states / 43845 actions
explored: 100 %
MDP stats: avg MDP size: 297, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,606 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,606 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,608 - pomdp.py - unfolding 38-FSC template into POMDP ...
2024-04-10 21:25:54,642 - pomdp.py - constructed quotient MDP having 305 states and 46246 actions.
2024-04-10 21:25:54,642 - pomdp.py - creating coloring ...
2024-04-10 21:25:54,710 - synthesizer.py - synthesis initiated, design space: 1e250
2024-04-10 21:25:54,728 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,728 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 229, family size: 1e250, quotient: 305 states / 46246 actions
explored: 100 %
MDP stats: avg MDP size: 305, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,728 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,728 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,731 - pomdp.py - unfolding 39-FSC template into POMDP ...
2024-04-10 21:25:54,765 - pomdp.py - constructed quotient MDP having 313 states and 48711 actions.
2024-04-10 21:25:54,765 - pomdp.py - creating coloring ...
2024-04-10 21:25:54,828 - synthesizer.py - synthesis initiated, design space: 1e258
2024-04-10 21:25:54,846 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,846 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 235, family size: 1e258, quotient: 313 states / 48711 actions
explored: 100 %
MDP stats: avg MDP size: 313, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,847 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,847 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,849 - pomdp.py - unfolding 40-FSC template into POMDP ...
2024-04-10 21:25:54,879 - pomdp.py - constructed quotient MDP having 321 states and 51240 actions.
2024-04-10 21:25:54,879 - pomdp.py - creating coloring ...
2024-04-10 21:25:54,977 - synthesizer.py - synthesis initiated, design space: 1e266
2024-04-10 21:25:54,996 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:54,996 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 241, family size: 1e266, quotient: 321 states / 51240 actions
explored: 100 %
MDP stats: avg MDP size: 321, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:54,996 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:54,997 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:54,999 - pomdp.py - unfolding 41-FSC template into POMDP ...
2024-04-10 21:25:55,012 - pomdp.py - constructed quotient MDP having 329 states and 53833 actions.
2024-04-10 21:25:55,012 - pomdp.py - creating coloring ...
2024-04-10 21:25:55,106 - synthesizer.py - synthesis initiated, design space: 1e274
2024-04-10 21:25:55,126 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:55,126 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 247, family size: 1e274, quotient: 329 states / 53833 actions
explored: 100 %
MDP stats: avg MDP size: 329, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:55,126 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:55,126 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:55,130 - pomdp.py - unfolding 42-FSC template into POMDP ...
2024-04-10 21:25:55,176 - pomdp.py - constructed quotient MDP having 337 states and 56490 actions.
2024-04-10 21:25:55,176 - pomdp.py - creating coloring ...
2024-04-10 21:25:55,245 - synthesizer.py - synthesis initiated, design space: 1e282
2024-04-10 21:25:55,267 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:55,267 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 253, family size: 1e282, quotient: 337 states / 56490 actions
explored: 100 %
MDP stats: avg MDP size: 337, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:55,267 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:55,267 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:55,270 - pomdp.py - unfolding 43-FSC template into POMDP ...
2024-04-10 21:25:55,310 - pomdp.py - constructed quotient MDP having 345 states and 59211 actions.
2024-04-10 21:25:55,310 - pomdp.py - creating coloring ...
2024-04-10 21:25:55,416 - synthesizer.py - synthesis initiated, design space: 1e290
2024-04-10 21:25:55,439 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:55,439 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 259, family size: 1e290, quotient: 345 states / 59211 actions
explored: 100 %
MDP stats: avg MDP size: 345, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:55,439 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:55,439 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:55,442 - pomdp.py - unfolding 44-FSC template into POMDP ...
2024-04-10 21:25:55,488 - pomdp.py - constructed quotient MDP having 353 states and 61996 actions.
2024-04-10 21:25:55,489 - pomdp.py - creating coloring ...
2024-04-10 21:25:55,611 - synthesizer.py - synthesis initiated, design space: 1e298
2024-04-10 21:25:55,633 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:55,634 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.02 s
number of holes: 265, family size: 1e298, quotient: 353 states / 61996 actions
explored: 100 %
MDP stats: avg MDP size: 353, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:55,634 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:55,634 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:55,638 - pomdp.py - unfolding 45-FSC template into POMDP ...
2024-04-10 21:25:55,653 - pomdp.py - constructed quotient MDP having 361 states and 64845 actions.
2024-04-10 21:25:55,653 - pomdp.py - creating coloring ...
2024-04-10 21:25:55,757 - synthesizer.py - synthesis initiated, design space: 1e306
2024-04-10 21:25:55,782 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:55,783 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 271, family size: 1e306, quotient: 361 states / 64845 actions
explored: 100 %
MDP stats: avg MDP size: 361, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:55,783 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:55,783 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:55,786 - pomdp.py - unfolding 46-FSC template into POMDP ...
2024-04-10 21:25:55,827 - pomdp.py - constructed quotient MDP having 369 states and 67758 actions.
2024-04-10 21:25:55,827 - pomdp.py - creating coloring ...
2024-04-10 21:25:55,938 - synthesizer.py - synthesis initiated, design space: 1e314
2024-04-10 21:25:55,965 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:55,965 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 277, family size: 1e314, quotient: 369 states / 67758 actions
explored: 100 %
MDP stats: avg MDP size: 369, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:55,965 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:55,965 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:55,970 - pomdp.py - unfolding 47-FSC template into POMDP ...
2024-04-10 21:25:56,014 - pomdp.py - constructed quotient MDP having 377 states and 70735 actions.
2024-04-10 21:25:56,014 - pomdp.py - creating coloring ...
2024-04-10 21:25:56,122 - synthesizer.py - synthesis initiated, design space: 1e322
2024-04-10 21:25:56,149 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:56,149 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 283, family size: 1e322, quotient: 377 states / 70735 actions
explored: 100 %
MDP stats: avg MDP size: 377, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:56,149 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:56,149 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:56,154 - pomdp.py - unfolding 48-FSC template into POMDP ...
2024-04-10 21:25:56,201 - pomdp.py - constructed quotient MDP having 385 states and 73776 actions.
2024-04-10 21:25:56,202 - pomdp.py - creating coloring ...
2024-04-10 21:25:56,325 - synthesizer.py - synthesis initiated, design space: 1e330
2024-04-10 21:25:56,354 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:56,354 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 289, family size: 1e330, quotient: 385 states / 73776 actions
explored: 100 %
MDP stats: avg MDP size: 385, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:56,354 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:56,354 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:56,359 - pomdp.py - unfolding 49-FSC template into POMDP ...
2024-04-10 21:25:56,404 - pomdp.py - constructed quotient MDP having 393 states and 76881 actions.
2024-04-10 21:25:56,404 - pomdp.py - creating coloring ...
2024-04-10 21:25:56,571 - synthesizer.py - synthesis initiated, design space: 1e338
2024-04-10 21:25:56,605 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:56,605 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 295, family size: 1e338, quotient: 393 states / 76881 actions
explored: 100 %
MDP stats: avg MDP size: 393, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:56,605 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:56,606 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:56,610 - pomdp.py - unfolding 50-FSC template into POMDP ...
2024-04-10 21:25:56,633 - pomdp.py - constructed quotient MDP having 401 states and 80050 actions.
2024-04-10 21:25:56,634 - pomdp.py - creating coloring ...
2024-04-10 21:25:56,821 - synthesizer.py - synthesis initiated, design space: 1e346
2024-04-10 21:25:56,855 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:56,855 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.03 s
number of holes: 301, family size: 1e346, quotient: 401 states / 80050 actions
explored: 100 %
MDP stats: avg MDP size: 401, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:56,856 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:56,856 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:56,860 - pomdp.py - unfolding 51-FSC template into POMDP ...
2024-04-10 21:25:56,883 - pomdp.py - constructed quotient MDP having 409 states and 83283 actions.
2024-04-10 21:25:56,883 - pomdp.py - creating coloring ...
2024-04-10 21:25:57,142 - synthesizer.py - synthesis initiated, design space: 1e355
2024-04-10 21:25:57,201 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:57,201 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 307, family size: 1e355, quotient: 409 states / 83283 actions
explored: 100 %
MDP stats: avg MDP size: 409, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:57,202 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:57,202 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:57,212 - pomdp.py - unfolding 52-FSC template into POMDP ...
2024-04-10 21:25:57,300 - pomdp.py - constructed quotient MDP having 417 states and 86580 actions.
2024-04-10 21:25:57,300 - pomdp.py - creating coloring ...
2024-04-10 21:25:57,464 - synthesizer.py - synthesis initiated, design space: 1e363
2024-04-10 21:25:57,501 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:57,501 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 313, family size: 1e363, quotient: 417 states / 86580 actions
explored: 100 %
MDP stats: avg MDP size: 417, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:57,501 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:57,501 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:57,506 - pomdp.py - unfolding 53-FSC template into POMDP ...
2024-04-10 21:25:57,577 - pomdp.py - constructed quotient MDP having 425 states and 89941 actions.
2024-04-10 21:25:57,578 - pomdp.py - creating coloring ...
2024-04-10 21:25:57,741 - synthesizer.py - synthesis initiated, design space: 1e371
2024-04-10 21:25:57,778 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:57,778 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 319, family size: 1e371, quotient: 425 states / 89941 actions
explored: 100 %
MDP stats: avg MDP size: 425, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:57,778 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:57,778 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:57,784 - pomdp.py - unfolding 54-FSC template into POMDP ...
2024-04-10 21:25:57,839 - pomdp.py - constructed quotient MDP having 433 states and 93366 actions.
2024-04-10 21:25:57,839 - pomdp.py - creating coloring ...
2024-04-10 21:25:58,042 - synthesizer.py - synthesis initiated, design space: 1e379
2024-04-10 21:25:58,088 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:58,088 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 325, family size: 1e379, quotient: 433 states / 93366 actions
explored: 100 %
MDP stats: avg MDP size: 433, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:58,088 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:58,088 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:58,096 - pomdp.py - unfolding 55-FSC template into POMDP ...
2024-04-10 21:25:58,157 - pomdp.py - constructed quotient MDP having 441 states and 96855 actions.
2024-04-10 21:25:58,157 - pomdp.py - creating coloring ...
2024-04-10 21:25:58,319 - synthesizer.py - synthesis initiated, design space: 1e388
2024-04-10 21:25:58,356 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:58,356 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 331, family size: 1e388, quotient: 441 states / 96855 actions
explored: 100 %
MDP stats: avg MDP size: 441, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:58,356 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:58,356 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:58,362 - pomdp.py - unfolding 56-FSC template into POMDP ...
2024-04-10 21:25:58,415 - pomdp.py - constructed quotient MDP having 449 states and 100408 actions.
2024-04-10 21:25:58,415 - pomdp.py - creating coloring ...
2024-04-10 21:25:58,614 - synthesizer.py - synthesis initiated, design space: 1e396
2024-04-10 21:25:58,652 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:58,652 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 337, family size: 1e396, quotient: 449 states / 100408 actions
explored: 100 %
MDP stats: avg MDP size: 449, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:58,652 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:58,652 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:58,658 - pomdp.py - unfolding 57-FSC template into POMDP ...
2024-04-10 21:25:58,721 - pomdp.py - constructed quotient MDP having 457 states and 104025 actions.
2024-04-10 21:25:58,721 - pomdp.py - creating coloring ...
2024-04-10 21:25:58,917 - synthesizer.py - synthesis initiated, design space: 1e404
2024-04-10 21:25:58,958 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:58,958 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 343, family size: 1e404, quotient: 457 states / 104025 actions
explored: 100 %
MDP stats: avg MDP size: 457, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:58,958 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:58,958 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:58,966 - pomdp.py - unfolding 58-FSC template into POMDP ...
2024-04-10 21:25:59,024 - pomdp.py - constructed quotient MDP having 465 states and 107706 actions.
2024-04-10 21:25:59,024 - pomdp.py - creating coloring ...
2024-04-10 21:25:59,228 - synthesizer.py - synthesis initiated, design space: 1e413
2024-04-10 21:25:59,270 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:59,270 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 349, family size: 1e413, quotient: 465 states / 107706 actions
explored: 100 %
MDP stats: avg MDP size: 465, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:59,270 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:59,270 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:59,277 - pomdp.py - unfolding 59-FSC template into POMDP ...
2024-04-10 21:25:59,341 - pomdp.py - constructed quotient MDP having 473 states and 111451 actions.
2024-04-10 21:25:59,341 - pomdp.py - creating coloring ...
2024-04-10 21:25:59,514 - synthesizer.py - synthesis initiated, design space: 1e421
2024-04-10 21:25:59,555 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:59,556 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 355, family size: 1e421, quotient: 473 states / 111451 actions
explored: 100 %
MDP stats: avg MDP size: 473, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:59,556 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:59,556 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:59,562 - pomdp.py - unfolding 60-FSC template into POMDP ...
2024-04-10 21:25:59,623 - pomdp.py - constructed quotient MDP having 481 states and 115260 actions.
2024-04-10 21:25:59,623 - pomdp.py - creating coloring ...
2024-04-10 21:25:59,832 - synthesizer.py - synthesis initiated, design space: 1e430
2024-04-10 21:25:59,876 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:25:59,876 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.04 s
number of holes: 361, family size: 1e430, quotient: 481 states / 115260 actions
explored: 100 %
MDP stats: avg MDP size: 481, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:25:59,876 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:25:59,876 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:25:59,883 - pomdp.py - unfolding 61-FSC template into POMDP ...
2024-04-10 21:25:59,946 - pomdp.py - constructed quotient MDP having 489 states and 119133 actions.
2024-04-10 21:25:59,946 - pomdp.py - creating coloring ...
2024-04-10 21:26:00,162 - synthesizer.py - synthesis initiated, design space: 1e438
2024-04-10 21:26:00,215 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:00,215 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 367, family size: 1e438, quotient: 489 states / 119133 actions
explored: 100 %
MDP stats: avg MDP size: 489, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:00,215 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:00,215 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:00,223 - pomdp.py - unfolding 62-FSC template into POMDP ...
2024-04-10 21:26:00,292 - pomdp.py - constructed quotient MDP having 497 states and 123070 actions.
2024-04-10 21:26:00,293 - pomdp.py - creating coloring ...
2024-04-10 21:26:00,522 - synthesizer.py - synthesis initiated, design space: 1e447
2024-04-10 21:26:00,569 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:00,569 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 373, family size: 1e447, quotient: 497 states / 123070 actions
explored: 100 %
MDP stats: avg MDP size: 497, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:00,569 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:00,569 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:00,576 - pomdp.py - unfolding 63-FSC template into POMDP ...
2024-04-10 21:26:00,642 - pomdp.py - constructed quotient MDP having 505 states and 127071 actions.
2024-04-10 21:26:00,642 - pomdp.py - creating coloring ...
2024-04-10 21:26:00,857 - synthesizer.py - synthesis initiated, design space: 1e455
2024-04-10 21:26:00,905 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:00,905 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 379, family size: 1e455, quotient: 505 states / 127071 actions
explored: 100 %
MDP stats: avg MDP size: 505, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:00,905 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:00,905 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:00,912 - pomdp.py - unfolding 64-FSC template into POMDP ...
2024-04-10 21:26:00,982 - pomdp.py - constructed quotient MDP having 513 states and 131136 actions.
2024-04-10 21:26:00,982 - pomdp.py - creating coloring ...
2024-04-10 21:26:01,212 - synthesizer.py - synthesis initiated, design space: 1e464
2024-04-10 21:26:01,263 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:01,264 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 385, family size: 1e464, quotient: 513 states / 131136 actions
explored: 100 %
MDP stats: avg MDP size: 513, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:01,264 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:01,264 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:01,272 - pomdp.py - unfolding 65-FSC template into POMDP ...
2024-04-10 21:26:01,384 - pomdp.py - constructed quotient MDP having 521 states and 135265 actions.
2024-04-10 21:26:01,384 - pomdp.py - creating coloring ...
2024-04-10 21:26:01,590 - synthesizer.py - synthesis initiated, design space: 1e472
2024-04-10 21:26:01,643 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:01,643 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 391, family size: 1e472, quotient: 521 states / 135265 actions
explored: 100 %
MDP stats: avg MDP size: 521, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:01,643 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:01,643 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:01,651 - pomdp.py - unfolding 66-FSC template into POMDP ...
2024-04-10 21:26:01,723 - pomdp.py - constructed quotient MDP having 529 states and 139458 actions.
2024-04-10 21:26:01,724 - pomdp.py - creating coloring ...
2024-04-10 21:26:01,956 - synthesizer.py - synthesis initiated, design space: 1e481
2024-04-10 21:26:02,023 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:02,023 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 397, family size: 1e481, quotient: 529 states / 139458 actions
explored: 100 %
MDP stats: avg MDP size: 529, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:02,023 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:02,024 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:02,037 - pomdp.py - unfolding 67-FSC template into POMDP ...
2024-04-10 21:26:02,158 - pomdp.py - constructed quotient MDP having 537 states and 143715 actions.
2024-04-10 21:26:02,159 - pomdp.py - creating coloring ...
2024-04-10 21:26:02,381 - synthesizer.py - synthesis initiated, design space: 1e489
2024-04-10 21:26:02,435 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:02,435 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.05 s
number of holes: 403, family size: 1e489, quotient: 537 states / 143715 actions
explored: 100 %
MDP stats: avg MDP size: 537, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:02,436 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:02,436 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:02,443 - pomdp.py - unfolding 68-FSC template into POMDP ...
2024-04-10 21:26:02,525 - pomdp.py - constructed quotient MDP having 545 states and 148036 actions.
2024-04-10 21:26:02,525 - pomdp.py - creating coloring ...
2024-04-10 21:26:02,797 - synthesizer.py - synthesis initiated, design space: 1e498
2024-04-10 21:26:02,862 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:02,862 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 409, family size: 1e498, quotient: 545 states / 148036 actions
explored: 100 %
MDP stats: avg MDP size: 545, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:02,862 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:02,862 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:02,873 - pomdp.py - unfolding 69-FSC template into POMDP ...
2024-04-10 21:26:03,069 - pomdp.py - constructed quotient MDP having 553 states and 152421 actions.
2024-04-10 21:26:03,069 - pomdp.py - creating coloring ...
2024-04-10 21:26:03,333 - synthesizer.py - synthesis initiated, design space: 1e507
2024-04-10 21:26:03,405 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:03,405 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 415, family size: 1e507, quotient: 553 states / 152421 actions
explored: 100 %
MDP stats: avg MDP size: 553, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:03,405 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:03,405 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:03,415 - pomdp.py - unfolding 70-FSC template into POMDP ...
2024-04-10 21:26:03,551 - pomdp.py - constructed quotient MDP having 561 states and 156870 actions.
2024-04-10 21:26:03,552 - pomdp.py - creating coloring ...
2024-04-10 21:26:03,793 - synthesizer.py - synthesis initiated, design space: 1e515
2024-04-10 21:26:03,853 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:03,854 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 421, family size: 1e515, quotient: 561 states / 156870 actions
explored: 100 %
MDP stats: avg MDP size: 561, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:03,854 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:03,854 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:03,866 - pomdp.py - unfolding 71-FSC template into POMDP ...
2024-04-10 21:26:03,955 - pomdp.py - constructed quotient MDP having 569 states and 161383 actions.
2024-04-10 21:26:03,955 - pomdp.py - creating coloring ...
2024-04-10 21:26:04,238 - synthesizer.py - synthesis initiated, design space: 1e524
2024-04-10 21:26:04,304 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:04,304 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 427, family size: 1e524, quotient: 569 states / 161383 actions
explored: 100 %
MDP stats: avg MDP size: 569, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:04,304 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:04,304 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:04,320 - pomdp.py - unfolding 72-FSC template into POMDP ...
2024-04-10 21:26:04,458 - pomdp.py - constructed quotient MDP having 577 states and 165960 actions.
2024-04-10 21:26:04,458 - pomdp.py - creating coloring ...
2024-04-10 21:26:04,822 - synthesizer.py - synthesis initiated, design space: 1e533
2024-04-10 21:26:04,885 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:04,885 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 433, family size: 1e533, quotient: 577 states / 165960 actions
explored: 100 %
MDP stats: avg MDP size: 577, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:04,885 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:04,885 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:04,896 - pomdp.py - unfolding 73-FSC template into POMDP ...
2024-04-10 21:26:05,030 - pomdp.py - constructed quotient MDP having 585 states and 170601 actions.
2024-04-10 21:26:05,030 - pomdp.py - creating coloring ...
2024-04-10 21:26:05,342 - synthesizer.py - synthesis initiated, design space: 1e541
2024-04-10 21:26:05,414 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:05,414 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 439, family size: 1e541, quotient: 585 states / 170601 actions
explored: 100 %
MDP stats: avg MDP size: 585, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:05,415 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:05,415 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:05,425 - pomdp.py - unfolding 74-FSC template into POMDP ...
2024-04-10 21:26:05,513 - pomdp.py - constructed quotient MDP having 593 states and 175306 actions.
2024-04-10 21:26:05,513 - pomdp.py - creating coloring ...
2024-04-10 21:26:05,781 - synthesizer.py - synthesis initiated, design space: 1e550
2024-04-10 21:26:05,843 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:05,843 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.06 s
number of holes: 445, family size: 1e550, quotient: 593 states / 175306 actions
explored: 100 %
MDP stats: avg MDP size: 593, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:05,843 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:05,843 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:05,855 - pomdp.py - unfolding 75-FSC template into POMDP ...
2024-04-10 21:26:05,994 - pomdp.py - constructed quotient MDP having 601 states and 180075 actions.
2024-04-10 21:26:05,994 - pomdp.py - creating coloring ...
2024-04-10 21:26:06,299 - synthesizer.py - synthesis initiated, design space: 1e559
2024-04-10 21:26:06,371 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:06,371 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 451, family size: 1e559, quotient: 601 states / 180075 actions
explored: 100 %
MDP stats: avg MDP size: 601, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:06,371 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:06,372 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:06,383 - pomdp.py - unfolding 76-FSC template into POMDP ...
2024-04-10 21:26:06,527 - pomdp.py - constructed quotient MDP having 609 states and 184908 actions.
2024-04-10 21:26:06,528 - pomdp.py - creating coloring ...
2024-04-10 21:26:06,808 - synthesizer.py - synthesis initiated, design space: 1e567
2024-04-10 21:26:06,881 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:06,881 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 457, family size: 1e567, quotient: 609 states / 184908 actions
explored: 100 %
MDP stats: avg MDP size: 609, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:06,881 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:06,881 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:06,893 - pomdp.py - unfolding 77-FSC template into POMDP ...
2024-04-10 21:26:07,062 - pomdp.py - constructed quotient MDP having 617 states and 189805 actions.
2024-04-10 21:26:07,062 - pomdp.py - creating coloring ...
2024-04-10 21:26:07,391 - synthesizer.py - synthesis initiated, design space: 1e576
2024-04-10 21:26:07,463 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:07,464 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.07 s
number of holes: 463, family size: 1e576, quotient: 617 states / 189805 actions
explored: 100 %
MDP stats: avg MDP size: 617, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:07,464 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:07,464 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:07,475 - pomdp.py - unfolding 78-FSC template into POMDP ...
2024-04-10 21:26:07,619 - pomdp.py - constructed quotient MDP having 625 states and 194766 actions.
2024-04-10 21:26:07,619 - pomdp.py - creating coloring ...
2024-04-10 21:26:07,885 - synthesizer.py - synthesis initiated, design space: 1e585
2024-04-10 21:26:07,966 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:07,966 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.08 s
number of holes: 469, family size: 1e585, quotient: 625 states / 194766 actions
explored: 100 %
MDP stats: avg MDP size: 625, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:07,967 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:07,967 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:07,979 - pomdp.py - unfolding 79-FSC template into POMDP ...
2024-04-10 21:26:08,125 - pomdp.py - constructed quotient MDP having 633 states and 199791 actions.
2024-04-10 21:26:08,126 - pomdp.py - creating coloring ...
2024-04-10 21:26:08,463 - synthesizer.py - synthesis initiated, design space: 1e594
2024-04-10 21:26:08,543 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:08,543 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.08 s
number of holes: 475, family size: 1e594, quotient: 633 states / 199791 actions
explored: 100 %
MDP stats: avg MDP size: 633, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:08,544 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:08,544 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:08,557 - pomdp.py - unfolding 80-FSC template into POMDP ...
2024-04-10 21:26:08,710 - pomdp.py - constructed quotient MDP having 641 states and 204880 actions.
2024-04-10 21:26:08,710 - pomdp.py - creating coloring ...
2024-04-10 21:26:09,053 - synthesizer.py - synthesis initiated, design space: 1e603
2024-04-10 21:26:09,153 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:09,153 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 481, family size: 1e603, quotient: 641 states / 204880 actions
explored: 100 %
MDP stats: avg MDP size: 641, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:09,153 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:09,153 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:09,167 - pomdp.py - unfolding 81-FSC template into POMDP ...
2024-04-10 21:26:09,322 - pomdp.py - constructed quotient MDP having 649 states and 210033 actions.
2024-04-10 21:26:09,322 - pomdp.py - creating coloring ...
2024-04-10 21:26:09,599 - synthesizer.py - synthesis initiated, design space: 1e611
2024-04-10 21:26:09,687 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:09,687 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.09 s
number of holes: 487, family size: 1e611, quotient: 649 states / 210033 actions
explored: 100 %
MDP stats: avg MDP size: 649, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:09,687 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:09,688 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:09,701 - pomdp.py - unfolding 82-FSC template into POMDP ...
2024-04-10 21:26:09,854 - pomdp.py - constructed quotient MDP having 657 states and 215250 actions.
2024-04-10 21:26:09,854 - pomdp.py - creating coloring ...
2024-04-10 21:26:10,195 - synthesizer.py - synthesis initiated, design space: 1e620
2024-04-10 21:26:10,283 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:10,283 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.09 s
number of holes: 493, family size: 1e620, quotient: 657 states / 215250 actions
explored: 100 %
MDP stats: avg MDP size: 657, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:10,283 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:10,283 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:10,297 - pomdp.py - unfolding 83-FSC template into POMDP ...
2024-04-10 21:26:10,460 - pomdp.py - constructed quotient MDP having 665 states and 220531 actions.
2024-04-10 21:26:10,461 - pomdp.py - creating coloring ...
2024-04-10 21:26:10,830 - synthesizer.py - synthesis initiated, design space: 1e629
2024-04-10 21:26:10,925 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:10,925 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.09 s
number of holes: 499, family size: 1e629, quotient: 665 states / 220531 actions
explored: 100 %
MDP stats: avg MDP size: 665, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:10,925 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:10,926 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:10,940 - pomdp.py - unfolding 84-FSC template into POMDP ...
2024-04-10 21:26:11,110 - pomdp.py - constructed quotient MDP having 673 states and 225876 actions.
2024-04-10 21:26:11,110 - pomdp.py - creating coloring ...
2024-04-10 21:26:11,425 - synthesizer.py - synthesis initiated, design space: 1e638
2024-04-10 21:26:11,523 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:11,523 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 505, family size: 1e638, quotient: 673 states / 225876 actions
explored: 100 %
MDP stats: avg MDP size: 673, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:11,524 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:11,524 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:11,539 - pomdp.py - unfolding 85-FSC template into POMDP ...
2024-04-10 21:26:11,749 - pomdp.py - constructed quotient MDP having 681 states and 231285 actions.
2024-04-10 21:26:11,749 - pomdp.py - creating coloring ...
2024-04-10 21:26:12,092 - synthesizer.py - synthesis initiated, design space: 1e647
2024-04-10 21:26:12,195 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:12,195 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.1 s
number of holes: 511, family size: 1e647, quotient: 681 states / 231285 actions
explored: 100 %
MDP stats: avg MDP size: 681, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:12,195 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:12,195 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:12,211 - pomdp.py - unfolding 86-FSC template into POMDP ...
2024-04-10 21:26:12,481 - pomdp.py - constructed quotient MDP having 689 states and 236758 actions.
2024-04-10 21:26:12,481 - pomdp.py - creating coloring ...
2024-04-10 21:26:12,837 - synthesizer.py - synthesis initiated, design space: 1e656
2024-04-10 21:26:12,944 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:12,945 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 517, family size: 1e656, quotient: 689 states / 236758 actions
explored: 100 %
MDP stats: avg MDP size: 689, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:12,945 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:12,945 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:12,962 - pomdp.py - unfolding 87-FSC template into POMDP ...
2024-04-10 21:26:13,195 - pomdp.py - constructed quotient MDP having 697 states and 242295 actions.
2024-04-10 21:26:13,196 - pomdp.py - creating coloring ...
2024-04-10 21:26:13,643 - synthesizer.py - synthesis initiated, design space: 1e665
2024-04-10 21:26:13,753 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:13,753 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 523, family size: 1e665, quotient: 697 states / 242295 actions
explored: 100 %
MDP stats: avg MDP size: 697, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:13,753 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:13,753 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:13,768 - pomdp.py - unfolding 88-FSC template into POMDP ...
2024-04-10 21:26:13,963 - pomdp.py - constructed quotient MDP having 705 states and 247896 actions.
2024-04-10 21:26:13,964 - pomdp.py - creating coloring ...
2024-04-10 21:26:14,318 - synthesizer.py - synthesis initiated, design space: 1e674
2024-04-10 21:26:14,432 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:14,432 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 529, family size: 1e674, quotient: 705 states / 247896 actions
explored: 100 %
MDP stats: avg MDP size: 705, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:14,432 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:14,432 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:14,450 - pomdp.py - unfolding 89-FSC template into POMDP ...
2024-04-10 21:26:14,640 - pomdp.py - constructed quotient MDP having 713 states and 253561 actions.
2024-04-10 21:26:14,640 - pomdp.py - creating coloring ...
2024-04-10 21:26:15,092 - synthesizer.py - synthesis initiated, design space: 1e683
2024-04-10 21:26:15,228 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:15,228 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 535, family size: 1e683, quotient: 713 states / 253561 actions
explored: 100 %
MDP stats: avg MDP size: 713, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:15,228 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:15,228 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:15,244 - pomdp.py - unfolding 90-FSC template into POMDP ...
2024-04-10 21:26:15,430 - pomdp.py - constructed quotient MDP having 721 states and 259290 actions.
2024-04-10 21:26:15,430 - pomdp.py - creating coloring ...
2024-04-10 21:26:15,833 - synthesizer.py - synthesis initiated, design space: 1e692
2024-04-10 21:26:15,945 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:15,945 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.11 s
number of holes: 541, family size: 1e692, quotient: 721 states / 259290 actions
explored: 100 %
MDP stats: avg MDP size: 721, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:15,945 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:15,946 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:15,963 - pomdp.py - unfolding 91-FSC template into POMDP ...
2024-04-10 21:26:16,223 - pomdp.py - constructed quotient MDP having 729 states and 265083 actions.
2024-04-10 21:26:16,223 - pomdp.py - creating coloring ...
2024-04-10 21:26:16,593 - synthesizer.py - synthesis initiated, design space: 1e701
2024-04-10 21:26:16,711 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:16,711 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.12 s
number of holes: 547, family size: 1e701, quotient: 729 states / 265083 actions
explored: 100 %
MDP stats: avg MDP size: 729, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:16,712 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:16,712 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:16,727 - pomdp.py - unfolding 92-FSC template into POMDP ...
2024-04-10 21:26:16,923 - pomdp.py - constructed quotient MDP having 737 states and 270940 actions.
2024-04-10 21:26:16,923 - pomdp.py - creating coloring ...
2024-04-10 21:26:17,292 - synthesizer.py - synthesis initiated, design space: 1e710
2024-04-10 21:26:17,418 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:17,418 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.13 s
number of holes: 553, family size: 1e710, quotient: 737 states / 270940 actions
explored: 100 %
MDP stats: avg MDP size: 737, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:17,419 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:17,419 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:17,436 - pomdp.py - unfolding 93-FSC template into POMDP ...
2024-04-10 21:26:17,687 - pomdp.py - constructed quotient MDP having 745 states and 276861 actions.
2024-04-10 21:26:17,687 - pomdp.py - creating coloring ...
2024-04-10 21:26:18,071 - synthesizer.py - synthesis initiated, design space: 1e719
2024-04-10 21:26:18,198 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:18,198 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.13 s
number of holes: 559, family size: 1e719, quotient: 745 states / 276861 actions
explored: 100 %
MDP stats: avg MDP size: 745, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:18,198 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:18,198 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:18,216 - pomdp.py - unfolding 94-FSC template into POMDP ...
2024-04-10 21:26:18,471 - pomdp.py - constructed quotient MDP having 753 states and 282846 actions.
2024-04-10 21:26:18,471 - pomdp.py - creating coloring ...
2024-04-10 21:26:18,938 - synthesizer.py - synthesis initiated, design space: 1e728
2024-04-10 21:26:19,081 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:19,081 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 565, family size: 1e728, quotient: 753 states / 282846 actions
explored: 100 %
MDP stats: avg MDP size: 753, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:19,082 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:19,082 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:19,100 - pomdp.py - unfolding 95-FSC template into POMDP ...
2024-04-10 21:26:19,315 - pomdp.py - constructed quotient MDP having 761 states and 288895 actions.
2024-04-10 21:26:19,315 - pomdp.py - creating coloring ...
2024-04-10 21:26:19,780 - synthesizer.py - synthesis initiated, design space: 1e737
2024-04-10 21:26:19,927 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:19,927 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 571, family size: 1e737, quotient: 761 states / 288895 actions
explored: 100 %
MDP stats: avg MDP size: 761, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:19,927 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:19,927 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:19,948 - pomdp.py - unfolding 96-FSC template into POMDP ...
2024-04-10 21:26:20,181 - pomdp.py - constructed quotient MDP having 769 states and 295008 actions.
2024-04-10 21:26:20,181 - pomdp.py - creating coloring ...
2024-04-10 21:26:20,699 - synthesizer.py - synthesis initiated, design space: 1e746
2024-04-10 21:26:20,844 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:20,844 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 577, family size: 1e746, quotient: 769 states / 295008 actions
explored: 100 %
MDP stats: avg MDP size: 769, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:20,845 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:20,845 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:20,864 - pomdp.py - unfolding 97-FSC template into POMDP ...
2024-04-10 21:26:21,106 - pomdp.py - constructed quotient MDP having 777 states and 301185 actions.
2024-04-10 21:26:21,106 - pomdp.py - creating coloring ...
2024-04-10 21:26:21,648 - synthesizer.py - synthesis initiated, design space: 1e755
2024-04-10 21:26:21,799 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:21,799 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 583, family size: 1e755, quotient: 777 states / 301185 actions
explored: 100 %
MDP stats: avg MDP size: 777, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:21,799 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:21,799 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:21,822 - pomdp.py - unfolding 98-FSC template into POMDP ...
2024-04-10 21:26:22,050 - pomdp.py - constructed quotient MDP having 785 states and 307426 actions.
2024-04-10 21:26:22,050 - pomdp.py - creating coloring ...
2024-04-10 21:26:22,500 - synthesizer.py - synthesis initiated, design space: 1e764
2024-04-10 21:26:22,642 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:22,642 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 589, family size: 1e764, quotient: 785 states / 307426 actions
explored: 100 %
MDP stats: avg MDP size: 785, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:22,642 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:22,642 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:22,665 - pomdp.py - unfolding 99-FSC template into POMDP ...
2024-04-10 21:26:22,895 - pomdp.py - constructed quotient MDP having 793 states and 313731 actions.
2024-04-10 21:26:22,895 - pomdp.py - creating coloring ...
2024-04-10 21:26:23,362 - synthesizer.py - synthesis initiated, design space: 1e773
2024-04-10 21:26:23,510 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:23,510 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 595, family size: 1e773, quotient: 793 states / 313731 actions
explored: 100 %
MDP stats: avg MDP size: 793, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:23,511 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:23,511 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:23,535 - pomdp.py - unfolding 100-FSC template into POMDP ...
2024-04-10 21:26:23,871 - pomdp.py - constructed quotient MDP having 801 states and 320100 actions.
2024-04-10 21:26:23,871 - pomdp.py - creating coloring ...
2024-04-10 21:26:24,323 - synthesizer.py - synthesis initiated, design space: 1e782
2024-04-10 21:26:24,475 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:24,475 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.15 s
number of holes: 601, family size: 1e782, quotient: 801 states / 320100 actions
explored: 100 %
MDP stats: avg MDP size: 801, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:24,476 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:24,476 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:24,500 - pomdp.py - unfolding 101-FSC template into POMDP ...
2024-04-10 21:26:24,803 - pomdp.py - constructed quotient MDP having 809 states and 326533 actions.
2024-04-10 21:26:24,803 - pomdp.py - creating coloring ...
2024-04-10 21:26:25,370 - synthesizer.py - synthesis initiated, design space: 1e791
2024-04-10 21:26:25,513 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:25,513 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.14 s
number of holes: 607, family size: 1e791, quotient: 809 states / 326533 actions
explored: 100 %
MDP stats: avg MDP size: 809, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:25,513 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:25,513 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:25,536 - pomdp.py - unfolding 102-FSC template into POMDP ...
2024-04-10 21:26:25,784 - pomdp.py - constructed quotient MDP having 817 states and 333030 actions.
2024-04-10 21:26:25,784 - pomdp.py - creating coloring ...
2024-04-10 21:26:26,357 - synthesizer.py - synthesis initiated, design space: 1e800
2024-04-10 21:26:26,516 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:26,516 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 613, family size: 1e800, quotient: 817 states / 333030 actions
explored: 100 %
MDP stats: avg MDP size: 817, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:26,516 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:26,516 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:26,538 - pomdp.py - unfolding 103-FSC template into POMDP ...
2024-04-10 21:26:26,807 - pomdp.py - constructed quotient MDP having 825 states and 339591 actions.
2024-04-10 21:26:26,807 - pomdp.py - creating coloring ...
2024-04-10 21:26:27,332 - synthesizer.py - synthesis initiated, design space: 1e810
2024-04-10 21:26:27,488 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:27,488 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 619, family size: 1e810, quotient: 825 states / 339591 actions
explored: 100 %
MDP stats: avg MDP size: 825, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:27,489 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:27,489 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:27,515 - pomdp.py - unfolding 104-FSC template into POMDP ...
2024-04-10 21:26:27,778 - pomdp.py - constructed quotient MDP having 833 states and 346216 actions.
2024-04-10 21:26:27,778 - pomdp.py - creating coloring ...
2024-04-10 21:26:28,455 - synthesizer.py - synthesis initiated, design space: 1e819
2024-04-10 21:26:28,616 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:28,616 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 625, family size: 1e819, quotient: 833 states / 346216 actions
explored: 100 %
MDP stats: avg MDP size: 833, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:28,616 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:28,616 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:28,646 - pomdp.py - unfolding 105-FSC template into POMDP ...
2024-04-10 21:26:28,897 - pomdp.py - constructed quotient MDP having 841 states and 352905 actions.
2024-04-10 21:26:28,898 - pomdp.py - creating coloring ...
2024-04-10 21:26:29,417 - synthesizer.py - synthesis initiated, design space: 1e828
2024-04-10 21:26:29,573 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:29,573 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 631, family size: 1e828, quotient: 841 states / 352905 actions
explored: 100 %
MDP stats: avg MDP size: 841, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:29,574 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:29,574 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:29,599 - pomdp.py - unfolding 106-FSC template into POMDP ...
2024-04-10 21:26:29,908 - pomdp.py - constructed quotient MDP having 849 states and 359658 actions.
2024-04-10 21:26:29,909 - pomdp.py - creating coloring ...
2024-04-10 21:26:30,495 - synthesizer.py - synthesis initiated, design space: 1e837
2024-04-10 21:26:30,664 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:30,665 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.17 s
number of holes: 637, family size: 1e837, quotient: 849 states / 359658 actions
explored: 100 %
MDP stats: avg MDP size: 849, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:30,665 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:30,665 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:30,692 - pomdp.py - unfolding 107-FSC template into POMDP ...
2024-04-10 21:26:30,947 - pomdp.py - constructed quotient MDP having 857 states and 366475 actions.
2024-04-10 21:26:30,947 - pomdp.py - creating coloring ...
2024-04-10 21:26:31,414 - synthesizer.py - synthesis initiated, design space: 1e846
2024-04-10 21:26:31,575 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:31,575 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 643, family size: 1e846, quotient: 857 states / 366475 actions
explored: 100 %
MDP stats: avg MDP size: 857, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:31,575 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:31,575 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:31,601 - pomdp.py - unfolding 108-FSC template into POMDP ...
2024-04-10 21:26:31,901 - pomdp.py - constructed quotient MDP having 865 states and 373356 actions.
2024-04-10 21:26:31,901 - pomdp.py - creating coloring ...
2024-04-10 21:26:32,485 - synthesizer.py - synthesis initiated, design space: 1e855
2024-04-10 21:26:32,648 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:32,648 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 649, family size: 1e855, quotient: 865 states / 373356 actions
explored: 100 %
MDP stats: avg MDP size: 865, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:32,648 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:32,649 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:32,674 - pomdp.py - unfolding 109-FSC template into POMDP ...
2024-04-10 21:26:33,009 - pomdp.py - constructed quotient MDP having 873 states and 380301 actions.
2024-04-10 21:26:33,009 - pomdp.py - creating coloring ...
2024-04-10 21:26:33,530 - synthesizer.py - synthesis initiated, design space: 1e865
2024-04-10 21:26:33,704 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:33,704 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.17 s
number of holes: 655, family size: 1e865, quotient: 873 states / 380301 actions
explored: 100 %
MDP stats: avg MDP size: 873, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:33,704 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:33,704 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:33,729 - pomdp.py - unfolding 110-FSC template into POMDP ...
2024-04-10 21:26:34,071 - pomdp.py - constructed quotient MDP having 881 states and 387310 actions.
2024-04-10 21:26:34,071 - pomdp.py - creating coloring ...
2024-04-10 21:26:34,573 - synthesizer.py - synthesis initiated, design space: 1e874
2024-04-10 21:26:34,747 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:34,747 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.17 s
number of holes: 661, family size: 1e874, quotient: 881 states / 387310 actions
explored: 100 %
MDP stats: avg MDP size: 881, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:34,748 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:34,748 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:34,775 - pomdp.py - unfolding 111-FSC template into POMDP ...
2024-04-10 21:26:35,124 - pomdp.py - constructed quotient MDP having 889 states and 394383 actions.
2024-04-10 21:26:35,125 - pomdp.py - creating coloring ...
2024-04-10 21:26:35,673 - synthesizer.py - synthesis initiated, design space: 1e883
2024-04-10 21:26:35,837 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:35,837 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.16 s
number of holes: 667, family size: 1e883, quotient: 889 states / 394383 actions
explored: 100 %
MDP stats: avg MDP size: 889, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:35,837 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:35,837 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:35,865 - pomdp.py - unfolding 112-FSC template into POMDP ...
2024-04-10 21:26:36,144 - pomdp.py - constructed quotient MDP having 897 states and 401520 actions.
2024-04-10 21:26:36,144 - pomdp.py - creating coloring ...
2024-04-10 21:26:36,735 - synthesizer.py - synthesis initiated, design space: 1e892
2024-04-10 21:26:36,915 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:36,915 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.18 s
number of holes: 673, family size: 1e892, quotient: 897 states / 401520 actions
explored: 100 %
MDP stats: avg MDP size: 897, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:36,915 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:36,915 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:36,946 - pomdp.py - unfolding 113-FSC template into POMDP ...
2024-04-10 21:26:37,333 - pomdp.py - constructed quotient MDP having 905 states and 408721 actions.
2024-04-10 21:26:37,333 - pomdp.py - creating coloring ...
2024-04-10 21:26:37,888 - synthesizer.py - synthesis initiated, design space: 1e902
2024-04-10 21:26:38,079 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:38,079 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.19 s
number of holes: 679, family size: 1e902, quotient: 905 states / 408721 actions
explored: 100 %
MDP stats: avg MDP size: 905, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:38,079 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:38,079 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:38,114 - pomdp.py - unfolding 114-FSC template into POMDP ...
2024-04-10 21:26:38,401 - pomdp.py - constructed quotient MDP having 913 states and 415986 actions.
2024-04-10 21:26:38,401 - pomdp.py - creating coloring ...
2024-04-10 21:26:38,989 - synthesizer.py - synthesis initiated, design space: 1e911
2024-04-10 21:26:39,186 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:39,186 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.2 s
number of holes: 685, family size: 1e911, quotient: 913 states / 415986 actions
explored: 100 %
MDP stats: avg MDP size: 913, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:39,186 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:39,186 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:39,214 - pomdp.py - unfolding 115-FSC template into POMDP ...
2024-04-10 21:26:39,549 - pomdp.py - constructed quotient MDP having 921 states and 423315 actions.
2024-04-10 21:26:39,549 - pomdp.py - creating coloring ...
2024-04-10 21:26:40,168 - synthesizer.py - synthesis initiated, design space: 1e920
2024-04-10 21:26:40,359 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:40,359 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.19 s
number of holes: 691, family size: 1e920, quotient: 921 states / 423315 actions
explored: 100 %
MDP stats: avg MDP size: 921, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:40,360 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:40,360 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:40,390 - pomdp.py - unfolding 116-FSC template into POMDP ...
2024-04-10 21:26:40,754 - pomdp.py - constructed quotient MDP having 929 states and 430708 actions.
2024-04-10 21:26:40,755 - pomdp.py - creating coloring ...
2024-04-10 21:26:41,314 - synthesizer.py - synthesis initiated, design space: 1e930
2024-04-10 21:26:41,510 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:41,511 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.2 s
number of holes: 697, family size: 1e930, quotient: 929 states / 430708 actions
explored: 100 %
MDP stats: avg MDP size: 929, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:41,511 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:41,511 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:41,540 - pomdp.py - unfolding 117-FSC template into POMDP ...
2024-04-10 21:26:41,897 - pomdp.py - constructed quotient MDP having 937 states and 438165 actions.
2024-04-10 21:26:41,897 - pomdp.py - creating coloring ...
2024-04-10 21:26:42,630 - synthesizer.py - synthesis initiated, design space: 1e939
2024-04-10 21:26:42,832 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:42,832 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.2 s
number of holes: 703, family size: 1e939, quotient: 937 states / 438165 actions
explored: 100 %
MDP stats: avg MDP size: 937, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:42,833 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:42,833 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:42,862 - pomdp.py - unfolding 118-FSC template into POMDP ...
2024-04-10 21:26:43,175 - pomdp.py - constructed quotient MDP having 945 states and 445686 actions.
2024-04-10 21:26:43,175 - pomdp.py - creating coloring ...
2024-04-10 21:26:43,764 - synthesizer.py - synthesis initiated, design space: 1e948
2024-04-10 21:26:43,968 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:43,968 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.2 s
number of holes: 709, family size: 1e948, quotient: 945 states / 445686 actions
explored: 100 %
MDP stats: avg MDP size: 945, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:43,968 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:43,969 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:44,000 - pomdp.py - unfolding 119-FSC template into POMDP ...
2024-04-10 21:26:44,285 - pomdp.py - constructed quotient MDP having 953 states and 453271 actions.
2024-04-10 21:26:44,285 - pomdp.py - creating coloring ...
2024-04-10 21:26:44,932 - synthesizer.py - synthesis initiated, design space: 1e957
2024-04-10 21:26:45,141 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:45,142 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.21 s
number of holes: 715, family size: 1e957, quotient: 953 states / 453271 actions
explored: 100 %
MDP stats: avg MDP size: 953, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:45,142 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:45,143 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:45,185 - pomdp.py - unfolding 120-FSC template into POMDP ...
2024-04-10 21:26:45,572 - pomdp.py - constructed quotient MDP having 961 states and 460920 actions.
2024-04-10 21:26:45,572 - pomdp.py - creating coloring ...
2024-04-10 21:26:46,145 - synthesizer.py - synthesis initiated, design space: 1e967
2024-04-10 21:26:46,345 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:46,345 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.2 s
number of holes: 721, family size: 1e967, quotient: 961 states / 460920 actions
explored: 100 %
MDP stats: avg MDP size: 961, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:46,346 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:46,346 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:46,380 - pomdp.py - unfolding 121-FSC template into POMDP ...
2024-04-10 21:26:46,733 - pomdp.py - constructed quotient MDP having 969 states and 468633 actions.
2024-04-10 21:26:46,733 - pomdp.py - creating coloring ...
2024-04-10 21:26:47,469 - synthesizer.py - synthesis initiated, design space: 1e976
2024-04-10 21:26:47,679 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:47,679 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.21 s
number of holes: 727, family size: 1e976, quotient: 969 states / 468633 actions
explored: 100 %
MDP stats: avg MDP size: 969, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:47,680 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:47,680 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:47,715 - pomdp.py - unfolding 122-FSC template into POMDP ...
2024-04-10 21:26:48,136 - pomdp.py - constructed quotient MDP having 977 states and 476410 actions.
2024-04-10 21:26:48,136 - pomdp.py - creating coloring ...
2024-04-10 21:26:48,769 - synthesizer.py - synthesis initiated, design space: 1e986
2024-04-10 21:26:48,993 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:48,993 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.22 s
number of holes: 733, family size: 1e986, quotient: 977 states / 476410 actions
explored: 100 %
MDP stats: avg MDP size: 977, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:48,993 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:48,993 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:49,029 - pomdp.py - unfolding 123-FSC template into POMDP ...
2024-04-10 21:26:49,444 - pomdp.py - constructed quotient MDP having 985 states and 484251 actions.
2024-04-10 21:26:49,445 - pomdp.py - creating coloring ...
2024-04-10 21:26:50,068 - synthesizer.py - synthesis initiated, design space: 1e995
2024-04-10 21:26:50,292 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:50,292 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.22 s
number of holes: 739, family size: 1e995, quotient: 985 states / 484251 actions
explored: 100 %
MDP stats: avg MDP size: 985, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:50,292 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:50,292 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:50,328 - pomdp.py - unfolding 124-FSC template into POMDP ...
2024-04-10 21:26:50,745 - pomdp.py - constructed quotient MDP having 993 states and 492156 actions.
2024-04-10 21:26:50,745 - pomdp.py - creating coloring ...
2024-04-10 21:26:51,572 - synthesizer.py - synthesis initiated, design space: 1e1004
2024-04-10 21:26:51,799 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:51,800 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.23 s
number of holes: 745, family size: 1e1004, quotient: 993 states / 492156 actions
explored: 100 %
MDP stats: avg MDP size: 993, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:51,800 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:51,800 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:51,846 - pomdp.py - unfolding 125-FSC template into POMDP ...
2024-04-10 21:26:52,208 - pomdp.py - constructed quotient MDP having 1001 states and 500125 actions.
2024-04-10 21:26:52,208 - pomdp.py - creating coloring ...
2024-04-10 21:26:52,872 - synthesizer.py - synthesis initiated, design space: 1e1014
2024-04-10 21:26:53,143 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:53,143 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.27 s
number of holes: 751, family size: 1e1014, quotient: 1001 states / 500125 actions
explored: 100 %
MDP stats: avg MDP size: 1001, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:53,144 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:53,144 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:53,202 - pomdp.py - unfolding 126-FSC template into POMDP ...
2024-04-10 21:26:53,681 - pomdp.py - constructed quotient MDP having 1009 states and 508158 actions.
2024-04-10 21:26:53,681 - pomdp.py - creating coloring ...
2024-04-10 21:26:54,401 - synthesizer.py - synthesis initiated, design space: 1e1023
2024-04-10 21:26:54,651 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:54,651 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.25 s
number of holes: 757, family size: 1e1023, quotient: 1009 states / 508158 actions
explored: 100 %
MDP stats: avg MDP size: 1009, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:54,652 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:54,652 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:54,691 - pomdp.py - unfolding 127-FSC template into POMDP ...
2024-04-10 21:26:55,169 - pomdp.py - constructed quotient MDP having 1017 states and 516255 actions.
2024-04-10 21:26:55,169 - pomdp.py - creating coloring ...
2024-04-10 21:26:55,916 - synthesizer.py - synthesis initiated, design space: 1e1033
2024-04-10 21:26:56,173 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:56,173 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.26 s
number of holes: 763, family size: 1e1033, quotient: 1017 states / 516255 actions
explored: 100 %
MDP stats: avg MDP size: 1017, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:56,174 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:56,174 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:56,215 - pomdp.py - unfolding 128-FSC template into POMDP ...
2024-04-10 21:26:56,578 - pomdp.py - constructed quotient MDP having 1025 states and 524416 actions.
2024-04-10 21:26:56,578 - pomdp.py - creating coloring ...
2024-04-10 21:26:57,603 - synthesizer.py - synthesis initiated, design space: 1e1042
2024-04-10 21:26:57,850 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:57,850 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.25 s
number of holes: 769, family size: 1e1042, quotient: 1025 states / 524416 actions
explored: 100 %
MDP stats: avg MDP size: 1025, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:57,851 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:57,851 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:57,890 - pomdp.py - unfolding 129-FSC template into POMDP ...
2024-04-10 21:26:58,259 - pomdp.py - constructed quotient MDP having 1033 states and 532641 actions.
2024-04-10 21:26:58,259 - pomdp.py - creating coloring ...
2024-04-10 21:26:58,947 - synthesizer.py - synthesis initiated, design space: 1e1051
2024-04-10 21:26:59,205 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:26:59,205 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.26 s
number of holes: 775, family size: 1e1051, quotient: 1033 states / 532641 actions
explored: 100 %
MDP stats: avg MDP size: 1033, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:26:59,205 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:26:59,205 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:26:59,244 - pomdp.py - unfolding 130-FSC template into POMDP ...
2024-04-10 21:26:59,706 - pomdp.py - constructed quotient MDP having 1041 states and 540930 actions.
2024-04-10 21:26:59,706 - pomdp.py - creating coloring ...
2024-04-10 21:27:00,406 - synthesizer.py - synthesis initiated, design space: 1e1061
2024-04-10 21:27:00,715 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:00,715 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.31 s
number of holes: 781, family size: 1e1061, quotient: 1041 states / 540930 actions
explored: 100 %
MDP stats: avg MDP size: 1041, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:00,716 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:00,716 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:00,769 - pomdp.py - unfolding 131-FSC template into POMDP ...
2024-04-10 21:27:01,233 - pomdp.py - constructed quotient MDP having 1049 states and 549283 actions.
2024-04-10 21:27:01,233 - pomdp.py - creating coloring ...
2024-04-10 21:27:01,972 - synthesizer.py - synthesis initiated, design space: 1e1070
2024-04-10 21:27:02,237 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:02,237 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.26 s
number of holes: 787, family size: 1e1070, quotient: 1049 states / 549283 actions
explored: 100 %
MDP stats: avg MDP size: 1049, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:02,237 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:02,237 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:02,278 - pomdp.py - unfolding 132-FSC template into POMDP ...
2024-04-10 21:27:02,618 - pomdp.py - constructed quotient MDP having 1057 states and 557700 actions.
2024-04-10 21:27:02,618 - pomdp.py - creating coloring ...
2024-04-10 21:27:03,582 - synthesizer.py - synthesis initiated, design space: 1e1080
2024-04-10 21:27:03,843 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:03,843 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.26 s
number of holes: 793, family size: 1e1080, quotient: 1057 states / 557700 actions
explored: 100 %
MDP stats: avg MDP size: 1057, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:03,844 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:03,844 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:03,883 - pomdp.py - unfolding 133-FSC template into POMDP ...
2024-04-10 21:27:04,259 - pomdp.py - constructed quotient MDP having 1065 states and 566181 actions.
2024-04-10 21:27:04,259 - pomdp.py - creating coloring ...
2024-04-10 21:27:04,953 - synthesizer.py - synthesis initiated, design space: 1e1089
2024-04-10 21:27:05,202 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:05,202 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.25 s
number of holes: 799, family size: 1e1089, quotient: 1065 states / 566181 actions
explored: 100 %
MDP stats: avg MDP size: 1065, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:05,202 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:05,202 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:05,243 - pomdp.py - unfolding 134-FSC template into POMDP ...
2024-04-10 21:27:05,680 - pomdp.py - constructed quotient MDP having 1073 states and 574726 actions.
2024-04-10 21:27:05,680 - pomdp.py - creating coloring ...
2024-04-10 21:27:06,517 - synthesizer.py - synthesis initiated, design space: 1e1099
2024-04-10 21:27:06,771 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:06,771 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.25 s
number of holes: 805, family size: 1e1099, quotient: 1073 states / 574726 actions
explored: 100 %
MDP stats: avg MDP size: 1073, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:06,772 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:06,772 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:06,813 - pomdp.py - unfolding 135-FSC template into POMDP ...
2024-04-10 21:27:07,311 - pomdp.py - constructed quotient MDP having 1081 states and 583335 actions.
2024-04-10 21:27:07,311 - pomdp.py - creating coloring ...
2024-04-10 21:27:08,235 - synthesizer.py - synthesis initiated, design space: 1e1108
2024-04-10 21:27:08,516 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:08,516 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.28 s
number of holes: 811, family size: 1e1108, quotient: 1081 states / 583335 actions
explored: 100 %
MDP stats: avg MDP size: 1081, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:08,516 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:08,516 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:08,557 - pomdp.py - unfolding 136-FSC template into POMDP ...
2024-04-10 21:27:08,958 - pomdp.py - constructed quotient MDP having 1089 states and 592008 actions.
2024-04-10 21:27:08,958 - pomdp.py - creating coloring ...
2024-04-10 21:27:09,715 - synthesizer.py - synthesis initiated, design space: 1e1118
2024-04-10 21:27:09,987 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:09,987 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.27 s
number of holes: 817, family size: 1e1118, quotient: 1089 states / 592008 actions
explored: 100 %
MDP stats: avg MDP size: 1089, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:09,988 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:09,988 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:10,029 - pomdp.py - unfolding 137-FSC template into POMDP ...
2024-04-10 21:27:10,499 - pomdp.py - constructed quotient MDP having 1097 states and 600745 actions.
2024-04-10 21:27:10,499 - pomdp.py - creating coloring ...
2024-04-10 21:27:11,351 - synthesizer.py - synthesis initiated, design space: 1e1127
2024-04-10 21:27:11,633 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:11,633 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.28 s
number of holes: 823, family size: 1e1127, quotient: 1097 states / 600745 actions
explored: 100 %
MDP stats: avg MDP size: 1097, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:11,633 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:11,633 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:11,676 - pomdp.py - unfolding 138-FSC template into POMDP ...
2024-04-10 21:27:12,201 - pomdp.py - constructed quotient MDP having 1105 states and 609546 actions.
2024-04-10 21:27:12,201 - pomdp.py - creating coloring ...
2024-04-10 21:27:13,187 - synthesizer.py - synthesis initiated, design space: 1e1137
2024-04-10 21:27:13,476 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:13,477 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.29 s
number of holes: 829, family size: 1e1137, quotient: 1105 states / 609546 actions
explored: 100 %
MDP stats: avg MDP size: 1105, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:13,477 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:13,477 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:13,520 - pomdp.py - unfolding 139-FSC template into POMDP ...
2024-04-10 21:27:13,928 - pomdp.py - constructed quotient MDP having 1113 states and 618411 actions.
2024-04-10 21:27:13,929 - pomdp.py - creating coloring ...
2024-04-10 21:27:14,946 - synthesizer.py - synthesis initiated, design space: 1e1146
2024-04-10 21:27:15,271 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:15,271 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.32 s
number of holes: 835, family size: 1e1146, quotient: 1113 states / 618411 actions
explored: 100 %
MDP stats: avg MDP size: 1113, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:15,271 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:15,272 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:15,317 - pomdp.py - unfolding 140-FSC template into POMDP ...
2024-04-10 21:27:15,730 - pomdp.py - constructed quotient MDP having 1121 states and 627340 actions.
2024-04-10 21:27:15,730 - pomdp.py - creating coloring ...
2024-04-10 21:27:16,674 - synthesizer.py - synthesis initiated, design space: 1e1156
2024-04-10 21:27:16,972 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:16,972 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.3 s
number of holes: 841, family size: 1e1156, quotient: 1121 states / 627340 actions
explored: 100 %
MDP stats: avg MDP size: 1121, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:16,972 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:16,972 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:17,022 - pomdp.py - unfolding 141-FSC template into POMDP ...
2024-04-10 21:27:17,566 - pomdp.py - constructed quotient MDP having 1129 states and 636333 actions.
2024-04-10 21:27:17,567 - pomdp.py - creating coloring ...
2024-04-10 21:27:18,449 - synthesizer.py - synthesis initiated, design space: 1e1165
2024-04-10 21:27:18,758 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:18,758 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.31 s
number of holes: 847, family size: 1e1165, quotient: 1129 states / 636333 actions
explored: 100 %
MDP stats: avg MDP size: 1129, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:18,759 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:18,759 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:18,812 - pomdp.py - unfolding 142-FSC template into POMDP ...
2024-04-10 21:27:19,322 - pomdp.py - constructed quotient MDP having 1137 states and 645390 actions.
2024-04-10 21:27:19,322 - pomdp.py - creating coloring ...
2024-04-10 21:27:20,402 - synthesizer.py - synthesis initiated, design space: 1e1175
2024-04-10 21:27:20,697 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:20,697 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.29 s
number of holes: 853, family size: 1e1175, quotient: 1137 states / 645390 actions
explored: 100 %
MDP stats: avg MDP size: 1137, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:20,698 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:20,698 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:20,747 - pomdp.py - unfolding 143-FSC template into POMDP ...
2024-04-10 21:27:21,202 - pomdp.py - constructed quotient MDP having 1145 states and 654511 actions.
2024-04-10 21:27:21,203 - pomdp.py - creating coloring ...
2024-04-10 21:27:22,089 - synthesizer.py - synthesis initiated, design space: 1e1185
2024-04-10 21:27:22,413 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:27:22,413 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 0.32 s
number of holes: 859, family size: 1e1185, quotient: 1145 states / 654511 actions
explored: 100 %
MDP stats: avg MDP size: 1145, iterations: 1

optimum: 2.245326
--------------------
2024-04-10 21:27:22,413 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:27:22,413 - synthesizer_pomdp.py - Increase memory in all imperfect observation
2024-04-10 21:27:22,464 - pomdp.py - unfolding 144-FSC template into POMDP ...
2024-04-10 21:27:23,035 - pomdp.py - constructed quotient MDP having 1153 states and 663696 actions.
2024-04-10 21:27:23,036 - pomdp.py - creating coloring ...
2024-04-10 21:27:24,120 - synthesizer.py - synthesis initiated, design space: 1e1194
2024-04-10 21:27:24,120 - synthesizer_ar_storm.py - Pausing synthesis
2024-04-10 21:27:24,172 - storm_pomdp_control.py - Interactive Storm started
2024-04-10 21:27:24,173 - storm_pomdp_control.py - starting Storm POMDP analysis
2024-04-10 21:27:34,193 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 2.245332291795019 | Time elapsed = 113.0s | FSC size = 31


------------------------------------

PAYNT results: 
2.24532584529214
controller size: 8

Storm results: 
2.245332291795019
controller size: 31

------------------------------------

2024-04-10 21:27:46,207 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-04-10 21:27:46,647 - synthesizer_ar_storm.py - Resuming synthesis
2024-04-10 21:27:46,648 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-04-10 21:27:46,649 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 4580103908483131652178819006442224294848820954294948052136815657230956902966163662974764310415664869090185937855746841373575797607881075966797188250649237894965443104383027164340660806860632214805058612455509580152763497239415547862532406391483365480173882591475225840788072113482787159345889902522183379286533289615562336461751961209842228752754057817665221645068686783448565772508902749125565916100334776598269318683565562682498956379302062892513167047258222541007476077633476228634906731679145340014235326772357197597570600624816472813361872258939444198901421941889579118131920266745349477048442613762311279529416280213711010106441972347868719172471841039401876646027181040156194485312679895794751035159403781248399249501300505869023318776921258407380051139466605502070464473358205300045742506511150540157614820087799659374820271476269509610198897165675653790388088276985310468441224995330050477632800263797258720515626393643141884484011124568239892351249018328900607852862596575947387500334526934097100368957921388265407547345313238260880006123309377423453006565065800223776234114289868717946864259258958760506806189448653566756922278949692763957832482307848140635884884016478049455250079744 to 37235661813363050280693073081211745486849094864936768356464778639336279127723065298969177471683738970439752873340902637181886563411085954166978424049860352116609500853482033835203441124398087772586268620438409995151616979979903780114289091080424684566973057735534432912563106796026582161740185125900352135922771435624113668964326444942653569891330580817049454544944808482338203629970990402881500363620667863834023543996756140813632518794748392836839810000627487630974494578917829509282818593978487673398734658993801422928324903723534393267143266300355611861770567433156390097985513507331375030908702764985657295199411817384351360432166685142560332400558828157617449648493009331197428794306483474466801332561744705954410729170197293784135286500142746168413020460402089143333152137721987143139558274321460364118039016434100913271730220154087611282227057018401813829269746334179405165975797464763591801343438988733136858420718837992259584
2024-04-10 21:27:46,761 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 1, Subfamilies - 288
2024-04-10 21:27:46,833 - synthesizer_ar_storm.py - Main family synthesis done
2024-04-10 21:27:46,833 - synthesizer_ar_storm.py - Subfamilies buffer contains: 288 families
> progress 0.0%, elapsed 3 s, estimated 680312864070943911390087143311238032555581037266575280423127522780544702208024168647666141175471573667237088871401738215653925455369592757770742755870123539562496 s (21572579403568746534062675087711843912987139075764423980066497515390273896866820611183621589747523089311123772586201603640274088322157054676614185870163968 years), iters = {MDP: 22}, opt = 2.245
> progress 0.0%, elapsed 6 s, estimated 79022904177102443236128274540561785498551813904713794955749909391496486097454251094102322087974475541777273335203735885648025874000670016738559520669696 s (2505799853408880238042054509593302754071406368387150927432627864859082343720507470622582607019888486458163517737436712275125976917198563595780096 years), iters = {MDP: 39}, opt = 2.245
> progress 0.0%, elapsed 9 s, estimated 27705653881355011527164334982142245365072111670724203480787685230700079304289744162122244668976070347564509267636756733997586831449244227862528 s (878540521351947369635682169927916119146091911109523656248706955995333361304533734565262458436920113302281692020022728343871071442698240 years), iters = {MDP: 55}, opt = 2.245
> progress 0.0%, elapsed 12 s, estimated 34803122769393117077304614429823098411813936980923903574164997747144326430781358128258769040773118853878682245378523038935388914712576 s (1103599783402876638515380456146407326236028816050087421799528420698209400016941050703340645378187793112674713089656226043658240 years), iters = {MDP: 70}, opt = 2.245
> progress 0.0%, elapsed 15 s, estimated 10159844011244988622798872020044910145818973772005899874583804386174354561863776230568603067205104402690748247169082377371648 s (322166540184074983902442470641491834476429206881571270890954476354156897500578316644351479296406078090365175299309568 years), iters = {MDP: 86}, opt = 2.245
> progress 0.0%, elapsed 18 s, estimated 2851234688174900241836880318934372747596770425157115729475722736612390489084440610219463343400713937488916644888576 s (90412058858919983785161381174390620565151947098368091847887293094562133255807876378195859676421157134794752 years), iters = {MDP: 102}, opt = 2.245
> progress 0.0%, elapsed 21 s, estimated 3087655710025688604058300072880898652795082589964213018977513554179151147671474892405758896053146596933632 s (97908920282397528115168518456545553591110012564714262301179685822748016920174140868939207803928576 years), iters = {MDP: 117}, opt = 2.245
> progress 0.0%, elapsed 24 s, estimated 52788304751629180235812547090647208265256523441681275137886854755577816657632622135892128500285440 s (1673906162849733144786073626792540661519154096173290789817852886987300669394440815707684864 years), iters = {MDP: 130}, opt = 2.245
> progress 0.0%, elapsed 27 s, estimated 221387710766023385076411457812226374918631741165699377869911288613283165405600307824558080 s (7020158256152441630535851037973141288966315282485650300732043131669493885205217280 years), iters = {MDP: 144}, opt = 2.245
> progress 0.0%, elapsed 31 s, estimated 919436685844209429913831943707379478720739948923090267828110636702916011003740160 s (29155146050361788899021038448811231276737600908010140084244777642961666048 years), iters = {MDP: 158}, opt = 2.245
> progress 0.0%, elapsed 34 s, estimated 15116707454449235274837038879871938092397986074859769623830616125380493312 s (479347648860008793586400091537225695729774887979542296371902021632 years), iters = {MDP: 171}, opt = 2.245
> progress 0.0%, elapsed 37 s, estimated 3935688056955476150604142550102232894084576583606999537407250923520 s (124799849599044784331909668952407663822898122960237244710912 years), iters = {MDP: 182}, opt = 2.245
> progress 0.0%, elapsed 40 s, estimated 1014156649939592460374522611613780639648602699994782890983424 s (32158696408536033729725495579225408109949631940526080 years), iters = {MDP: 193}, opt = 2.245
> progress 0.0%, elapsed 43 s, estimated 260753134840642623724097053928505686430571241840574464 s (8268427664911294943513104734260306482619744256 years), iters = {MDP: 204}, opt = 2.245
> progress 0.0%, elapsed 46 s, estimated 66491599478696857913753068454991296489859317760 s (2108434788137267428480850080980583579648 years), iters = {MDP: 215}, opt = 2.245
> progress 0.0%, elapsed 49 s, estimated 16901475223000058003689711966105693585408 s (535942263540083049708462373076992 years), iters = {MDP: 226}, opt = 2.245
> progress 0.0%, elapsed 52 s, estimated 17117304829388842625445811716096000 s (542786175462609141507293184 years), iters = {MDP: 236}, opt = 2.245
> progress 0.0%, elapsed 56 s, estimated 4334282759019710291248152576 s (137439204687332278272 years), iters = {MDP: 247}, opt = 2.245
> progress 0.0%, elapsed 59 s, estimated 1093302645116970729472 s (34668399451958 years), iters = {MDP: 258}, opt = 2.245
> progress 0.0%, elapsed 62 s, estimated 1095863399323936 s (34749600 years), iters = {MDP: 268}, opt = 2.245
> progress 0.0%, elapsed 65 s, estimated 4396372901 s (139 years), iters = {MDP: 277}, opt = 2.245
> progress 0.39%, elapsed 68 s, estimated 17591 s (4 hours), iters = {MDP: 286}, opt = 2.245
2024-04-10 21:28:56,720 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:28:56,720 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 69.96 s
number of holes: 865, family size: 1e1194, quotient: 1153 states / 663696 actions
explored: 100 %
MDP stats: avg MDP size: 1153, iterations: 289

optimum: 2.245326
--------------------
2024-04-10 21:28:56,720 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:28:56,720 - synthesizer_pomdp.py - Added memory nodes for observation based on Storm data
2024-04-10 21:28:56,776 - pomdp.py - unfolding 145-FSC template into POMDP ...
2024-04-10 21:28:59,700 - pomdp.py - constructed quotient MDP having 1160 states and 671930 actions.
2024-04-10 21:28:59,700 - pomdp.py - creating coloring ...
2024-04-10 21:29:00,543 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 4471829234185960285282268262723891918137574868448716829107978708474505813321863619368106302313732364244101677697501364780863037914106332192309328402469950861970798989912558235972748022995574119924362313329108844743052302866427166798802962231419811482225245897425636441082506084754062882501494692109445079743421006590654811490237549728079225063576838498170024756384080751468923194158680996466253481712951356232246345301618572025576645152229196040476473381436390051409405273909413928353253599350643912943070878521379057218138181781781235547293219503141640704991373547658178585611849297401087568418427274619785046676327432680973671002407656977865414668095513030126857915823047366321038762221552948829983479560508207873472084114264977560440003694484707822428588389601116160000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 to 2272212655793286545047605853617001832617804704218672355077519622671149736102868190953947824471080750829554075596242576425938835078866975154198980118321747921224270588534496489026392933542193030544754089278584502293849910995554129884260030022379693404348002042302678478436065887307302292111020500431685629446138598801859675397382707069500019700705006020356290910348656667078173235383592331275332297380681619682802534459750874947198829879558664410332531905692623926528784342408584526021809308257633422019960047586943223555810073335957247666557308991237004147021456112734175328655864513291405860594691684858499776136379052537761997715109420487269929130012174803114922957768646965812058743237570308195167798647779270752053072936353552540439427216459015038859343788501635664319622899916005411130751202744285157925755769219514436828718815878111174989152788368508769705709984770111250281588659366949803399536068904129848533557378686964511871337890625
2024-04-10 21:29:00,638 - synthesizer.py - synthesis initiated, design space: 1e1203
2024-04-10 21:29:00,714 - synthesizer_ar_storm.py - Main family synthesis done
2024-04-10 21:29:00,714 - synthesizer_ar_storm.py - Subfamilies buffer contains: 290 families
> progress 0.0%, elapsed 3 s, estimated 10974436270097719682235036498222017526450516716138644751082179324540470912642341713932335643802051970961962830836842258163780648956790447722870810048334372777492480 s (347997091263880035691804331589052100382805202769004711609090950790800465487604766112528452712046132551000827786982535997201702646989310795812034132173651968 years), iters = {MDP: 22}, opt = 2.245
> progress 0.0%, elapsed 6 s, estimated 20284104517001791811736960176884336138030651077703464588596996650862630590504946359166596263026020690511056691539680943318238277319746703450331265630208 s (643204734811066510401882114852271707650358062406618812657375979277796877701340787285855921724286173637495270863371810776917634788682671969009664 years), iters = {MDP: 42}, opt = 2.245
> progress 0.0%, elapsed 9 s, estimated 442810670951396595412652238991665092474412053074198518287657811621245863840221129089722570072848198356625739918523499367855340958295905009664 s (14041434264060012570294447775945428265650325883774565515525297476240708549848390927547327060677349621291109758958715053861098091446272 years), iters = {MDP: 60}, opt = 2.245
> progress 0.0%, elapsed 12 s, estimated 138868947646495858028799421238669276066429925653617244770890114955463256689775823088668123104287845959437448151099658947791467577344 s (4403505442874678043114829249834293600873042711890106588597962048541614109623136189945828620787251954078980150939982082605056 years), iters = {MDP: 76}, opt = 2.245
> progress 0.0%, elapsed 15 s, estimated 162252704869484519057361570364802005699463305219671562380101287408439472353276406605697445389936050539807582915506833719296 s (5144999520214501956768512218445847572963342959099118712355571650459773113316689198387302470667138341857486845247488 years), iters = {MDP: 91}, opt = 2.245
2024-04-10 21:29:16,483 - synthesizer_ar_storm.py - Pausing synthesis
2024-04-10 21:29:16,582 - storm_pomdp_control.py - Interactive Storm resumed
2024-04-10 21:29:16,583 - storm_pomdp_control.py - Updating FSC values in Storm
2024-04-10 21:29:26,603 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 2.2453323915885606 | Time elapsed = 230.5s | FSC size = 33


------------------------------------

PAYNT results: 
2.24532584529214
controller size: 8

Storm results: 
2.2453323915885606
controller size: 33

------------------------------------

2024-04-10 21:29:43,622 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-04-10 21:29:44,016 - synthesizer_ar_storm.py - Resuming synthesis
2024-04-10 21:29:44,016 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-04-10 21:29:44,099 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 0, Subfamilies - 200
> progress 0.0%, elapsed 18 s, estimated 180385058797504976794570092490030911531051894313437990654208362810994421083983972699346272156938004591387183415296 s (5719972691448026289874933881898309064473319897111161653392140597218173961396253989893479670309236357726208 years), iters = {MDP: 106}, opt = 2.245
> progress 0.0%, elapsed 21 s, estimated 195836460609579020433711403939420084701581528089327147062282204826150258713224390029076479648828911255552 s (6209933428766457579595720194144159018512199679335413527703415206472401906416616970265574626033664 years), iters = {MDP: 121}, opt = 2.245
> progress 0.0%, elapsed 24 s, estimated 3328992552396276885482230876199880331420178125471938743951267406147408317640914675797259622285312 s (105561661351987460197129409410112466908834595823601443608123697744572966394875361674395648 years), iters = {MDP: 134}, opt = 2.245
> progress 0.0%, elapsed 28 s, estimated 55783794703974952745298048039385657658565206065468543301733959627372352315687228770615296 s (1768892526128074259158803958666523527717305665357171695810666608931787559669858304 years), iters = {MDP: 147}, opt = 2.245
> progress 0.0%, elapsed 31 s, estimated 924785071771781399763563904338133157327545515805626955937256169273764778625466368 s (29324742255573985595966157312986618671338211285817394276522310230054273024 years), iters = {MDP: 160}, opt = 2.245
> progress 0.0%, elapsed 34 s, estimated 60539115026043225176784710196456298878224041902669716833794743798937419776 s (1919682744357027824196004718337019979770816009210513815424951386112 years), iters = {MDP: 172}, opt = 2.245
> progress 0.0%, elapsed 37 s, estimated 3952428166263127341047284060277514505243404065816885119841338392576 s (125330674982975883897875892723567235386655629852322488647680 years), iters = {MDP: 184}, opt = 2.245
> progress 0.0%, elapsed 40 s, estimated 255487438663017986806037400263907419122193901540103071727616 s (8101453534469113217955390666112671887911327184715776 years), iters = {MDP: 196}, opt = 2.245
> progress 0.0%, elapsed 43 s, estimated 65491679909962484918920095702417731858358516146241536 s (2076727546612204651686937080056451974033309696 years), iters = {MDP: 207}, opt = 2.245
> progress 0.0%, elapsed 46 s, estimated 16742368966916978612030953311883129534287970304 s (530897037256372941789874104866005057536 years), iters = {MDP: 218}, opt = 2.245
> progress 0.0%, elapsed 50 s, estimated 4270101577169542814808131169201109860352 s (135404032761591299262548442873856 years), iters = {MDP: 229}, opt = 2.245
> progress 0.0%, elapsed 53 s, estimated 17270845889313462601769187855564800 s (547654930533785597126901760 years), iters = {MDP: 238}, opt = 2.245
> progress 0.0%, elapsed 56 s, estimated 17490050394198189141254995968 s (554605859785584410624 years), iters = {MDP: 248}, opt = 2.245
> progress 0.0%, elapsed 59 s, estimated 282041179175388176187392 s (8943467122507236 years), iters = {MDP: 256}, opt = 2.245
> progress 0.0%, elapsed 62 s, estimated 283569768850087936 s (8991938383 years), iters = {MDP: 266}, opt = 2.245
> progress 0.0%, elapsed 66 s, estimated 284166096728 s (9010 years), iters = {MDP: 276}, opt = 2.245
> progress 0.001%, elapsed 69 s, estimated 4583505 s (53 days), iters = {MDP: 284}, opt = 2.245
> progress 0.39%, elapsed 73 s, estimated 18704 s (5 hours), iters = {MDP: 288}, opt = 2.245
2024-04-10 21:30:42,647 - synthesizer.py - synthesis finished, printing synthesized assignment below:
2024-04-10 21:30:43,006 - synthesizer.py - None
--------------------
Synthesis summary:
optimality objective: R[exp]{"reward"}max=? [C{4/5}] 

method: AR, synthesis time: 74.39 s
number of holes: 870, family size: 1e1203, quotient: 1160 states / 671930 actions
explored: 100 %
MDP stats: avg MDP size: 1160, iterations: 291

optimum: 2.245326
--------------------
2024-04-10 21:30:44,729 - synthesizer_pomdp.py - Terminate: False
2024-04-10 21:30:44,967 - synthesizer_pomdp.py - Added memory nodes for observation based on Storm data
2024-04-10 21:30:45,167 - pomdp.py - unfolding 146-FSC template into POMDP ...
2024-04-10 21:30:51,356 - pomdp.py - constructed quotient MDP having 1169 states and 681382 actions.
2024-04-10 21:30:51,356 - pomdp.py - creating coloring ...
2024-04-10 21:30:54,244 - storm_pomdp_control.py - Main family based on data from Storm: reduced design space from 2602991533189594297479612624131506538739430662758119675068399825833457058705415054527936934039915241113897461373651416198205771049977208017205566979074670685980624871853089004101534355712388228890920906888206367802219544575917567349009236681839758348006929204514278671001756083596107303156542271029555992923365469434050076049784533748613495389294135777162891828075498978183971508636490078642625498245092408560243747901735904834090170172813710564647694351105924732479761158756305864880507604913418097055085313896124434978719368886540175265367362039984536959239467884232854527354277385662923175431151395320463671350193961498747001580609324421107604036788056172324185872244683866851273066348658707126070113904593431930087821530062024187709174146813952711869486822266013976619340768476579708524736333459653497312012958710803146000729019033186378785094219676462411442417962829915706666853034185511400409823481838776621078309908876096143478285800601571610358465856021972994824751937976389137506123492058852515337098884110563099629884223087097106237944154046512982658210635907325357427927390311973895037882914685383186127470137578551395115610008218141182347963882126457423825509221971253956605939501756203880467473297833984 to 20666005714943865969831907433034121954244050653846739600888106286202983777600578565447371301297679600242272127665468064988220763325138445611282548683196921289867559918478728310300345618967757552111843196575924738461101020493282953652569737740220311524844729773425791691354125577279690514919438897167532963916043790040091335076473966727539562558359382373191294612741659055054897807151106426338566464627490162522452923822628550243261631305685720328471456119829981605473078850736965384614173223291390286018668187526451789494629692677245336024151318481331267251828566875169833808355561382610248317310055770445626503348753007582128296521720073437314773089310769825553037834814032497800503422587879248538090305299937560164427530848085297702687719186977508563212577544831461309375273459092103016657772676141057650620606890007296298596194355068423673285636339087958529266120471384167051860001043359253923598924518392804646683667522980411913906926815135374770176
2024-04-10 21:30:54,418 - synthesizer.py - synthesis initiated, design space: 1e1215
2024-04-10 21:30:54,500 - synthesizer_ar_storm.py - Main family synthesis done
2024-04-10 21:30:54,500 - synthesizer_ar_storm.py - Subfamilies buffer contains: 437 families
> progress 0.0%, elapsed 3 s, estimated 84905268788760720512130366911066658378634343846769876462997251890488000208250665584859721178629128411889680078338842514394709368548934976898573263738683542494803847746698941306093695141352516307132728406739808495481462469483009136927273358721024 s (2692328411617221801901202772959551242056675173070094076195366746416496234421351999721412467208242795246464801354164514226148666251014129596342853472841071074308736336015757701402801862791955012000732152920198548627866896649873887776997376 years), iters = {MDP: 33}, opt = 2.245
> progress 0.0%, elapsed 6 s, estimated 594326860597210472078786928260587351872311168949062948024195428007523719826125099907047888588916455703793993527240655657410700113753907852709853977755994950613431423855830462589519783390599768719852299019901407487511455400133132288 s (18845981119901397709487822134109886049947655783224627545469401987009072713620285310114788492797336524803928741533398025051954187535504231345403845249772909023323838014202350290250018337247520540478886409703248421472127942656 years), iters = {MDP: 57}, opt = 2.245
> progress 0.0%, elapsed 9 s, estimated 3146308076592097197659146045536358491113859822001124427098295574483074939144418597865486222112923804555974926099657180463098877953050132542897213870893279734439327275143067435457704970305841562661990065321002227728384 s (99768774625573859170879840742672727221266659604695007742289487325658026552908170174659324656598151657742184552878306052292811940992643215331784365805932474423321654795049919252778223011911594675865467656077312 years), iters = {MDP: 81}, opt = 2.245
> progress 0.0%, elapsed 12 s, estimated 955814500549498182086494083603964843165985548511078321207273533596380136777721402385179169568438103070372345170502806110912170337236584427273319897050646070554858472774920235625175184810218277093347688448 s (30308678987490427737722489907015347783556812819917820715778983836594389938544388034270290572051533871148000122004378757409501031324094739547104234751224272786035079577468941304943301749081458606080 years), iters = {MDP: 102}, opt = 2.245
> progress 0.0%, elapsed 15 s, estimated 17382384890016510431296231917731786106735493135500197236459860059265045765870591008311072691480549828380563004086313894418883889536917240159177548542032452531410904463061822045529820455967391744 s (551191809044156178667668839886808578608655211500693564873694219415448798711327261408887926498339191679329669659448841404120726452791666367079324365435734284412439809524178614810855866368 years), iters = {MDP: 120}, opt = 2.245
> progress 0.0%, elapsed 18 s, estimated 304047347951426671523267010389772522638595224683306646430521731514538524825728260239966972349878030574728309477204696838592554689190294489825732600070143452785673752925305881487212544 s (9641278156755032720624808621364010564832684263223830673513791960269861124203627456038422864567159112203813282974534097601253769969115283040944871405470345105728476098733277184 years), iters = {MDP: 138}, opt = 2.245
2024-04-10 21:31:13,766 - synthesizer_ar_storm.py - Pausing synthesis
2024-04-10 21:31:13,866 - storm_pomdp_control.py - Interactive Storm resumed
2024-04-10 21:31:13,866 - storm_pomdp_control.py - Updating FSC values in Storm
2024-04-10 21:31:23,890 - storm_pomdp_control.py - Pausing Storm
Finished exploring under-approximation MDP.
Start analysis...
-----------Storm-----------               
Value = 2.2453323915885606 | Time elapsed = 350.8s | FSC size = 33


------------------------------------

PAYNT results: 
2.24532584529214
controller size: 8

Storm results: 
2.2453323915885606
controller size: 33

------------------------------------

2024-04-10 21:31:43,920 - synthesizer_pomdp.py - Timeout for PAYNT started
2024-04-10 21:31:44,303 - synthesizer_ar_storm.py - Resuming synthesis
2024-04-10 21:31:44,303 - synthesizer_ar_storm.py - Applying family split according to Storm results
2024-04-10 21:31:44,416 - synthesizer_ar_storm.py - State after Storm splitting: Main families - 0, Subfamilies - 295
> progress 0.0%, elapsed 21 s, estimated 5159922503796893148388538057817053177577974429737940528206614876141689869503509857309341704482904826315717083184499455131813483112592506462195631174307449731896372138868736 s (163620069247745230307488861128248110350364387980635285803427177733483751283079815170739759333876123504508739876358414989603412437340746256022180340951159724251807744 years), iters = {MDP: 156}, opt = 2.245
> progress 0.0%, elapsed 24 s, estimated 343266893725779306094554294233022011680989680939788475241575038781423251055540595902210850090015863504659751773034623884525788009032407791840381846729412352933888 s (10884921794957486745141500146062896040947907521956582609019633562992148769031249487121014691686070062436470007414491275607504249624391987228507208832516096 years), iters = {MDP: 173}, opt = 2.245
> progress 0.0%, elapsed 27 s, estimated 22447221883845086064299375890329590119515706158503646693586236192380314240092243019725564514737493278357549043815306159344678275578664542916949481357312 s (711796736550135891586796255449976301342038398249880622469244700427665950592551801132551591108563350645847587640531240273160467037193203716456448 years), iters = {MDP: 190}, opt = 2.245
> progress 0.0%, elapsed 30 s, estimated 1454961196421969892704175366662796832257921370737320439673037740999839229320478520089800396222337079626127854671361774188168163636093523066880 s (46136516882989916163833392254221767579905619078131931622121624088548328720656256174428986401634742310475221768470413398397370463420416 years), iters = {MDP: 207}, opt = 2.245
> progress 0.0%, elapsed 33 s, estimated 1495185995037330755825460239952511135269726217011848199610762276655098249397341493799708960128301575892873788965469392628294000574464 s (47412036879671828414198631276235767128252231558065187150408705432847895045286883168347537499139988649460243245964808998092800 years), iters = {MDP: 222}, opt = 2.245
> progress 0.0%, elapsed 36 s, estimated 25045034667719043657604303950245274155233049142001159050242658957601959251815873488845878469027634525478286049551915750141198336 s (794172839539543559219120922261893801861020278873840340744456818542450975700236190941552008546595983853887451789634043904 years), iters = {MDP: 230}, opt = 2.245
