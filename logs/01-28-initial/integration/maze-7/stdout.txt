2025-01-28 12:23:41,761 - cli.py - This is Paynt version 0.1.0.
2025-01-28 12:23:41,761 - sketch.py - loading sketch from /home/fpmk/synthesis-playground/models/dts-backup/maze/7/model-random.drn ...
2025-01-28 12:23:41,761 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-28 12:23:41,788 - sketch.py - assuming sketch in DRN format...
2025-01-28 12:23:41,806 - prism_parser.py - loading properties from /home/fpmk/synthesis-playground/models/dts-backup/maze/7/discounted.props ...
2025-01-28 12:23:41,806 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-28 12:23:41,811 - sketch.py - found state valuations in /home/fpmk/synthesis-playground/models/dts-backup/maze/7/state-valuations.json, adding to the model...
2025-01-28 12:23:41,813 - sketch.py - sketch parsing OK
2025-01-28 12:23:41,820 - sketch.py - tree helper loaded
2025-01-28 12:23:41,823 - sketch.py - constructed explicit quotient having 2039 states and 10195 choices
2025-01-28 12:23:41,823 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-28 12:23:41,829 - mdp.py - MDP has 2039/2039 relevant states
2025-01-28 12:23:41,846 - mdp.py - MDP has 5 actions
2025-01-28 12:23:41,861 - mdp.py - found the following 9 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked5:[0..1]', 'picked6:[0..1]', 'x:[0..14]', 'y:[0..6]']
2025-01-28 12:23:41,871 - decision_tree.py - the optimal scheduler has value: 5.179578174110294
2025-01-28 12:23:41,882 - decision_tree.py - the random scheduler has value: 1.2183016282364878
2025-01-28 12:23:41,884 - decision_tree.py - initial external tree has depth 14 and 280 nodes
2025-01-28 12:23:41,884 - decision_tree.py - starting iteration with subtree depth 7
2025-01-28 12:23:41,901 - decision_tree.py - starting iteration 0 with 13 nodes in node queue
2025-01-28 12:23:41,901 - decision_tree.py - current tree size: 561 nodes
2025-01-28 12:23:41,979 - decision_tree.py - subtree quotient has 2039 states and 2375 choices
2025-01-28 12:23:41,984 - mdp.py - MDP has 84/2039 relevant states
2025-01-28 12:23:41,986 - mdp.py - MDP has 5 actions
2025-01-28 12:23:41,999 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'x:[6..8]', 'y:[2..4]']

2025-01-28 12:23:41,999 - mdp.py - building tree of depth 0
2025-01-28 12:23:42,009 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.12 s
number of holes: 1, family size: 5, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:23:42,126 - decision_tree.py - families considered: 4
2025-01-28 12:23:42,126 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:23:42,126 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:23:42,126 - decision_tree.py - families model checked: 4
2025-01-28 12:23:42,126 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:23:42,126 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:23:42,126 - mdp.py - building tree of depth 1
2025-01-28 12:23:42,144 - statistic.py - synthesis initiated, design space: 300
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.8 s
number of holes: 9, family size: 300, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 25

optimum: 5.127782
--------------------
2025-01-28 12:23:42,949 - decision_tree.py - families considered: 25
2025-01-28 12:23:42,949 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:23:42,949 - decision_tree.py - families with schedulers preserved: 3
2025-01-28 12:23:42,949 - decision_tree.py - families model checked: 22
2025-01-28 12:23:42,949 - decision_tree.py - harmonizations attempted: 5
2025-01-28 12:23:42,949 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:23:42,949 - mdp.py - building tree of depth 2
2025-01-28 12:23:42,967 - statistic.py - synthesis initiated, design space: 1e6
> progress 8.333%, elapsed 3 s, estimated 37 s, iters = {MDP: 85}, opt = 5.1278
2025-01-28 12:23:47,975 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.01 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2375 actions
explored: 8 %
MDP stats: avg MDP size: 2039, iterations: 124

optimum: 5.127782
--------------------
2025-01-28 12:23:47,976 - decision_tree.py - families considered: 124
2025-01-28 12:23:47,976 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:23:47,976 - decision_tree.py - families with schedulers preserved: 19
2025-01-28 12:23:47,976 - decision_tree.py - families model checked: 105
2025-01-28 12:23:47,976 - decision_tree.py - harmonizations attempted: 27
2025-01-28 12:23:47,976 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:23:47,976 - mdp.py - building tree of depth 3
2025-01-28 12:23:48,014 - statistic.py - synthesis initiated, design space: 1e13
2025-01-28 12:23:48,686 - synthesizer_ar.py - value 5.1774 achieved after 6.93 seconds
2025-01-28 12:23:48,792 - synthesizer_ar.py - value 5.1789 achieved after 7.03 seconds
2025-01-28 12:23:49,767 - synthesizer_ar.py - value 5.1796 achieved after 8.01 seconds
> progress 1.604%, elapsed 3 s, estimated 187 s, iters = {MDP: 66}, opt = 5.1796
2025-01-28 12:23:53,091 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.08 s
number of holes: 57, family size: 1e13, quotient: 2039 states / 2375 actions
explored: 4 %
MDP stats: avg MDP size: 2039, iterations: 123

optimum: 5.179554
--------------------
2025-01-28 12:23:53,091 - decision_tree.py - families considered: 123
2025-01-28 12:23:53,091 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:23:53,091 - decision_tree.py - families with schedulers preserved: 39
2025-01-28 12:23:53,091 - decision_tree.py - families model checked: 84
2025-01-28 12:23:53,091 - decision_tree.py - harmonizations attempted: 6
2025-01-28 12:23:53,091 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:23:53,091 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:23:53,091 - decision_tree.py - V_0=y, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, x_0=6, y_0=2, V_1=picked3, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, x_1=6, y_1=2, V_2=picked4, picked1_2=0, picked2_2=0, picked3_2=0, picked4_2=0, x_2=6, y_2=2, A_3=r, A_4=u, V_5=picked1, picked1_5=0, picked2_5=0, picked3_5=0, picked4_5=0, x_5=6, y_5=2, A_6=r, A_7=l, V_8=picked2, picked1_8=0, picked2_8=0, picked3_8=0, picked4_8=0, x_8=6, y_8=2, V_9=x, picked1_9=0, picked2_9=0, picked3_9=0, picked4_9=0, x_9=6, y_9=2, A_10=r, A_11=l, V_12=picked2, picked1_12=0, picked2_12=0, picked3_12=0, picked4_12=0, x_12=6, y_12=2, A_13=d, A_14=r
2025-01-28 12:23:53,097 - decision_tree.py - double-checking specification satisfiability:  : 5.17955375559106
2025-01-28 12:23:53,097 - decision_tree.py - admissible subtree found from node 146
2025-01-28 12:23:53,105 - decision_tree.py - new tree has depth 14 and 267 nodes
2025-01-28 12:23:54,825 - decision_tree.py - new dtcontrol tree has depth 16 and 267 nodes
2025-01-28 12:23:54,826 - decision_tree.py - New DtControl tree is smaller
2025-01-28 12:23:54,853 - decision_tree.py - starting iteration 1 with 16 nodes in node queue
2025-01-28 12:23:54,853 - decision_tree.py - current tree size: 535 nodes
2025-01-28 12:23:54,935 - decision_tree.py - subtree quotient has 2039 states and 2343 choices
2025-01-28 12:23:54,941 - mdp.py - MDP has 76/2039 relevant states
2025-01-28 12:23:54,944 - mdp.py - MDP has 5 actions
2025-01-28 12:23:54,957 - mdp.py - found the following 8 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked5:[0..1]', 'picked6:[0..1]', 'x:[2..3]', 'y:[4..6]']

2025-01-28 12:23:54,957 - mdp.py - building tree of depth 0
2025-01-28 12:23:54,962 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 1, family size: 5, quotient: 2039 states / 2343 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:23:55,058 - decision_tree.py - families considered: 4
2025-01-28 12:23:55,058 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:23:55,059 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:23:55,059 - decision_tree.py - families model checked: 4
2025-01-28 12:23:55,059 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:23:55,059 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:23:55,059 - mdp.py - building tree of depth 1
2025-01-28 12:23:55,072 - statistic.py - synthesis initiated, design space: 400
2025-01-28 12:23:55,937 - synthesizer_ar.py - value 5.1302 achieved after 14.18 seconds
2025-01-28 12:23:56,392 - synthesizer_ar.py - value 5.1596 achieved after 14.63 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.44 s
number of holes: 11, family size: 400, quotient: 2039 states / 2343 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 44

optimum: 5.159615
--------------------
2025-01-28 12:23:56,512 - decision_tree.py - families considered: 44
2025-01-28 12:23:56,512 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:23:56,512 - decision_tree.py - families with schedulers preserved: 7
2025-01-28 12:23:56,512 - decision_tree.py - families model checked: 37
2025-01-28 12:23:56,512 - decision_tree.py - harmonizations attempted: 8
2025-01-28 12:23:56,512 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:23:56,512 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:23:56,512 - decision_tree.py - V_0=y, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked5_0=0, picked6_0=0, x_0=2, y_0=5, A_1=u, A_2=r
2025-01-28 12:23:56,516 - decision_tree.py - double-checking specification satisfiability:  : 5.159614709517799

2025-01-28 12:23:56,516 - mdp.py - building tree of depth 2
2025-01-28 12:23:56,535 - statistic.py - synthesis initiated, design space: 1e6
2025-01-28 12:23:56,810 - synthesizer_ar.py - value 5.165 achieved after 15.05 seconds
2025-01-28 12:23:57,344 - synthesizer_ar.py - value 5.167 achieved after 15.58 seconds
> progress 31.25%, elapsed 3 s, estimated 9 s, iters = {MDP: 93}, opt = 5.167
2025-01-28 12:24:00,863 - synthesizer_ar.py - value 5.1796 achieved after 19.1 seconds
2025-01-28 12:24:01,587 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.05 s
number of holes: 31, family size: 1e6, quotient: 2039 states / 2343 actions
explored: 46 %
MDP stats: avg MDP size: 2039, iterations: 157

optimum: 5.17955
--------------------
2025-01-28 12:24:01,587 - decision_tree.py - families considered: 157
2025-01-28 12:24:01,587 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:01,587 - decision_tree.py - families with schedulers preserved: 47
2025-01-28 12:24:01,587 - decision_tree.py - families model checked: 110
2025-01-28 12:24:01,587 - decision_tree.py - harmonizations attempted: 7
2025-01-28 12:24:01,587 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:24:01,587 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:01,587 - decision_tree.py - V_0=y, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked5_0=0, picked6_0=0, x_0=2, y_0=4, V_1=x, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked5_1=0, picked6_1=0, x_1=2, y_1=4, A_2=r, A_3=d, V_4=y, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked5_4=0, picked6_4=0, x_4=2, y_4=5, A_5=d, A_6=r
2025-01-28 12:24:01,592 - decision_tree.py - double-checking specification satisfiability:  : 5.179550166740631
2025-01-28 12:24:01,592 - decision_tree.py - admissible subtree found from node 19
2025-01-28 12:24:01,594 - decision_tree.py - new tree has depth 16 and 261 nodes
2025-01-28 12:24:03,403 - decision_tree.py - new dtcontrol tree has depth 14 and 263 nodes
2025-01-28 12:24:03,404 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:24:03,407 - decision_tree.py - starting iteration 2 with 15 nodes in node queue
2025-01-28 12:24:03,407 - decision_tree.py - current tree size: 523 nodes
2025-01-28 12:24:03,491 - decision_tree.py - subtree quotient has 2039 states and 2431 choices
2025-01-28 12:24:03,498 - mdp.py - MDP has 98/2039 relevant states
2025-01-28 12:24:03,501 - mdp.py - MDP has 5 actions
2025-01-28 12:24:03,514 - mdp.py - found the following 5 variables: ['picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[0..6]']

2025-01-28 12:24:03,514 - mdp.py - building tree of depth 0
2025-01-28 12:24:03,519 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:24:03,603 - synthesizer_ar.py - value 5.1793 achieved after 21.84 seconds
2025-01-28 12:24:03,607 - synthesizer_ar.py - value 5.1796 achieved after 21.85 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.11 s
number of holes: 1, family size: 5, quotient: 2039 states / 2431 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.17955
--------------------
2025-01-28 12:24:03,628 - decision_tree.py - families considered: 4
2025-01-28 12:24:03,628 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:03,629 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:24:03,629 - decision_tree.py - families model checked: 4
2025-01-28 12:24:03,629 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:24:03,629 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:24:03,629 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:03,629 - decision_tree.py - A_0=r
2025-01-28 12:24:03,633 - decision_tree.py - double-checking specification satisfiability:  : 5.179550166734296
2025-01-28 12:24:03,633 - decision_tree.py - admissible subtree found from node 254
2025-01-28 12:24:03,635 - decision_tree.py - new tree has depth 16 and 251 nodes
2025-01-28 12:24:05,354 - decision_tree.py - new dtcontrol tree has depth 13 and 240 nodes
2025-01-28 12:24:05,355 - decision_tree.py - New DtControl tree is smaller
2025-01-28 12:24:05,378 - decision_tree.py - starting iteration 3 with 14 nodes in node queue
2025-01-28 12:24:05,379 - decision_tree.py - current tree size: 481 nodes
2025-01-28 12:24:05,461 - decision_tree.py - subtree quotient has 2039 states and 2207 choices
2025-01-28 12:24:05,467 - mdp.py - MDP has 42/2039 relevant states
2025-01-28 12:24:05,469 - mdp.py - MDP has 5 actions
2025-01-28 12:24:05,482 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'x:[2..3]', 'y:[3..4]']

2025-01-28 12:24:05,482 - mdp.py - building tree of depth 0
2025-01-28 12:24:05,485 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:24:05,567 - synthesizer_ar.py - value 5.1795 achieved after 23.81 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 1, family size: 5, quotient: 2039 states / 2207 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.179545
--------------------
2025-01-28 12:24:05,588 - decision_tree.py - families considered: 4
2025-01-28 12:24:05,588 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:05,588 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:24:05,588 - decision_tree.py - families model checked: 4
2025-01-28 12:24:05,588 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:24:05,588 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:24:05,588 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:05,588 - decision_tree.py - A_0=d
2025-01-28 12:24:05,597 - decision_tree.py - double-checking specification satisfiability:  : 5.179545033917149
2025-01-28 12:24:05,598 - decision_tree.py - admissible subtree found from node 65
2025-01-28 12:24:05,601 - decision_tree.py - new tree has depth 13 and 227 nodes
2025-01-28 12:24:05,444 - decision_tree.py - new dtcontrol tree has depth 16 and 227 nodes
2025-01-28 12:24:05,445 - decision_tree.py - New DtControl tree is smaller
2025-01-28 12:24:05,469 - decision_tree.py - starting iteration 4 with 15 nodes in node queue
2025-01-28 12:24:05,469 - decision_tree.py - current tree size: 455 nodes
2025-01-28 12:24:05,556 - decision_tree.py - subtree quotient has 2039 states and 2291 choices
2025-01-28 12:24:05,562 - mdp.py - MDP has 63/2039 relevant states
2025-01-28 12:24:05,565 - mdp.py - MDP has 5 actions
2025-01-28 12:24:05,577 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[6..8]']

2025-01-28 12:24:05,578 - mdp.py - building tree of depth 0
2025-01-28 12:24:05,581 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:24:05,677 - synthesizer_ar.py - value 5.1621 achieved after 26.4 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 1, family size: 5, quotient: 2039 states / 2291 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.162055
--------------------
2025-01-28 12:24:05,710 - decision_tree.py - families considered: 4
2025-01-28 12:24:05,710 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:05,710 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:24:05,710 - decision_tree.py - families model checked: 4
2025-01-28 12:24:05,710 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:24:05,710 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:24:05,711 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:05,711 - decision_tree.py - A_0=r
2025-01-28 12:24:05,717 - decision_tree.py - double-checking specification satisfiability:  : 5.1620547382500135

2025-01-28 12:24:05,718 - mdp.py - building tree of depth 1
2025-01-28 12:24:05,733 - statistic.py - synthesis initiated, design space: 300
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.99 s
number of holes: 9, family size: 300, quotient: 2039 states / 2291 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 66

optimum: 5.162055
--------------------
2025-01-28 12:24:07,723 - decision_tree.py - families considered: 66
2025-01-28 12:24:07,723 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:07,723 - decision_tree.py - families with schedulers preserved: 12
2025-01-28 12:24:07,723 - decision_tree.py - families model checked: 54
2025-01-28 12:24:07,723 - decision_tree.py - harmonizations attempted: 10
2025-01-28 12:24:07,723 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:24:07,724 - mdp.py - building tree of depth 2
2025-01-28 12:24:07,738 - statistic.py - synthesis initiated, design space: 1e6
2025-01-28 12:24:09,398 - synthesizer_ar.py - value 5.1667 achieved after 30.12 seconds
2025-01-28 12:24:09,535 - synthesizer_ar.py - value 5.1795 achieved after 30.26 seconds
> progress 38.888%, elapsed 3 s, estimated 7 s, iters = {MDP: 80}, opt = 5.1795
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 3.98 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2291 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 115

optimum: 5.179545
--------------------
2025-01-28 12:24:11,720 - decision_tree.py - families considered: 115
2025-01-28 12:24:11,721 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:11,721 - decision_tree.py - families with schedulers preserved: 30
2025-01-28 12:24:11,721 - decision_tree.py - families model checked: 85
2025-01-28 12:24:11,721 - decision_tree.py - harmonizations attempted: 8
2025-01-28 12:24:11,721 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:24:11,721 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:11,721 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=x, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=7, A_2=r, A_3=u, V_4=picked6, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=7, A_5=d, A_6=r
2025-01-28 12:24:11,725 - decision_tree.py - double-checking specification satisfiability:  : 5.179545033917149
2025-01-28 12:24:11,725 - decision_tree.py - admissible subtree found from node 170
2025-01-28 12:24:11,732 - decision_tree.py - new tree has depth 15 and 218 nodes
2025-01-28 12:24:13,461 - decision_tree.py - new dtcontrol tree has depth 15 and 218 nodes
2025-01-28 12:24:13,461 - decision_tree.py - New DtControl tree is smaller
2025-01-28 12:24:13,486 - decision_tree.py - starting iteration 5 with 15 nodes in node queue
2025-01-28 12:24:13,486 - decision_tree.py - current tree size: 437 nodes
2025-01-28 12:24:13,579 - decision_tree.py - subtree quotient has 2039 states and 2379 choices
2025-01-28 12:24:13,585 - mdp.py - MDP has 85/2039 relevant states
2025-01-28 12:24:13,588 - mdp.py - MDP has 5 actions
2025-01-28 12:24:13,602 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[3..9]']

2025-01-28 12:24:13,602 - mdp.py - building tree of depth 0
2025-01-28 12:24:13,607 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.11 s
number of holes: 1, family size: 5, quotient: 2039 states / 2379 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:24:13,714 - decision_tree.py - families considered: 4
2025-01-28 12:24:13,714 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:13,714 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:24:13,714 - decision_tree.py - families model checked: 4
2025-01-28 12:24:13,714 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:24:13,714 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:24:13,714 - mdp.py - building tree of depth 1
2025-01-28 12:24:13,727 - statistic.py - synthesis initiated, design space: 175
2025-01-28 12:24:14,012 - synthesizer_ar.py - value 5.1407 achieved after 34.74 seconds
2025-01-28 12:24:14,362 - synthesizer_ar.py - value 5.1417 achieved after 35.09 seconds
2025-01-28 12:24:14,655 - synthesizer_ar.py - value 5.1567 achieved after 35.38 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.04 s
number of holes: 10, family size: 175, quotient: 2039 states / 2379 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 28

optimum: 5.156729
--------------------
2025-01-28 12:24:14,768 - decision_tree.py - families considered: 28
2025-01-28 12:24:14,769 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:14,769 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:24:14,769 - decision_tree.py - families model checked: 27
2025-01-28 12:24:14,769 - decision_tree.py - harmonizations attempted: 8
2025-01-28 12:24:14,769 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:24:14,769 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:14,769 - decision_tree.py - V_0=picked1, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, A_1=d, A_2=u
2025-01-28 12:24:14,773 - decision_tree.py - double-checking specification satisfiability:  : 5.156728781136663

2025-01-28 12:24:14,773 - mdp.py - building tree of depth 2
2025-01-28 12:24:14,793 - statistic.py - synthesis initiated, design space: 214375
2025-01-28 12:24:15,341 - synthesizer_ar.py - value 5.1653 achieved after 36.07 seconds
2025-01-28 12:24:15,451 - synthesizer_ar.py - value 5.1697 achieved after 36.18 seconds
> progress 2.145%, elapsed 3 s, estimated 142 s, iters = {MDP: 80}, opt = 5.1697
2025-01-28 12:24:19,798 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:24:19,798 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.01 s
number of holes: 28, family size: 214375, quotient: 2039 states / 2379 actions
explored: 2 %
MDP stats: avg MDP size: 2039, iterations: 132

optimum: 5.169668
--------------------
2025-01-28 12:24:19,799 - decision_tree.py - families considered: 132
2025-01-28 12:24:19,799 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:19,799 - decision_tree.py - families with schedulers preserved: 21
2025-01-28 12:24:19,799 - decision_tree.py - families model checked: 111
2025-01-28 12:24:19,799 - decision_tree.py - harmonizations attempted: 24
2025-01-28 12:24:19,799 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:24:19,799 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:19,799 - decision_tree.py - V_0=picked1, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=picked2, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, A_2=d, A_3=d, V_4=picked4, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=3, A_5=u, A_6=__random__
2025-01-28 12:24:19,805 - decision_tree.py - double-checking specification satisfiability:  : 5.169667856479398

2025-01-28 12:24:19,805 - mdp.py - building tree of depth 3
2025-01-28 12:24:19,849 - statistic.py - synthesis initiated, design space: 1e11
2025-01-28 12:24:21,444 - synthesizer_ar.py - value 5.17 achieved after 42.17 seconds
2025-01-28 12:24:21,945 - synthesizer_ar.py - value 5.1777 achieved after 42.67 seconds
> progress 0.058%, elapsed 3 s, estimated 5237 s, iters = {MDP: 59}, opt = 5.1777
2025-01-28 12:24:24,938 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:24:24,938 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.09 s
number of holes: 64, family size: 1e11, quotient: 2039 states / 2379 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 106

optimum: 5.177655
--------------------
2025-01-28 12:24:24,938 - decision_tree.py - families considered: 106
2025-01-28 12:24:24,938 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:24,938 - decision_tree.py - families with schedulers preserved: 15
2025-01-28 12:24:24,938 - decision_tree.py - families model checked: 91
2025-01-28 12:24:24,938 - decision_tree.py - harmonizations attempted: 25
2025-01-28 12:24:24,938 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:24:24,938 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:24,938 - decision_tree.py - V_0=picked1, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=picked2, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, V_2=picked2, picked0_2=0, picked1_2=0, picked2_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=3, A_3=d, A_4=d, V_5=picked0, picked0_5=0, picked1_5=0, picked2_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=3, A_6=d, A_7=u, V_8=picked4, picked0_8=0, picked1_8=0, picked2_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=3, V_9=picked3, picked0_9=0, picked1_9=0, picked2_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=3, A_10=u, A_11=u, V_12=picked2, picked0_12=0, picked1_12=0, picked2_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=3, A_13=u, A_14=d
2025-01-28 12:24:24,944 - decision_tree.py - double-checking specification satisfiability:  : 5.177655401590699
2025-01-28 12:24:24,944 - decision_tree.py - admissible subtree found from node 98
2025-01-28 12:24:24,946 - decision_tree.py - new tree has depth 15 and 209 nodes
2025-01-28 12:24:26,773 - decision_tree.py - new dtcontrol tree has depth 13 and 253 nodes
2025-01-28 12:24:26,774 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:24:26,778 - decision_tree.py - starting iteration 6 with 14 nodes in node queue
2025-01-28 12:24:26,778 - decision_tree.py - current tree size: 419 nodes
2025-01-28 12:24:26,886 - decision_tree.py - subtree quotient has 2039 states and 2375 choices
2025-01-28 12:24:26,892 - mdp.py - MDP has 84/2039 relevant states
2025-01-28 12:24:26,896 - mdp.py - MDP has 5 actions
2025-01-28 12:24:26,912 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[6..9]']

2025-01-28 12:24:26,912 - mdp.py - building tree of depth 0
2025-01-28 12:24:26,916 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.14 s
number of holes: 1, family size: 5, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:24:27,056 - decision_tree.py - families considered: 4
2025-01-28 12:24:27,056 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:27,056 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:24:27,056 - decision_tree.py - families model checked: 4
2025-01-28 12:24:27,056 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:24:27,056 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:24:27,056 - mdp.py - building tree of depth 1
2025-01-28 12:24:27,068 - statistic.py - synthesis initiated, design space: 450
2025-01-28 12:24:27,325 - synthesizer_ar.py - value 5.1391 achieved after 48.05 seconds
2025-01-28 12:24:28,596 - synthesizer_ar.py - value 5.1394 achieved after 49.32 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.88 s
number of holes: 9, family size: 450, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 52

optimum: 5.139364
--------------------
2025-01-28 12:24:28,945 - decision_tree.py - families considered: 52
2025-01-28 12:24:28,945 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:28,945 - decision_tree.py - families with schedulers preserved: 7
2025-01-28 12:24:28,945 - decision_tree.py - families model checked: 45
2025-01-28 12:24:28,945 - decision_tree.py - harmonizations attempted: 11
2025-01-28 12:24:28,945 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:24:28,945 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:28,945 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, A_1=r, A_2=__random__
2025-01-28 12:24:28,951 - decision_tree.py - double-checking specification satisfiability:  : 5.139364189365034

2025-01-28 12:24:28,952 - mdp.py - building tree of depth 2
2025-01-28 12:24:28,969 - statistic.py - synthesis initiated, design space: 1e6
2025-01-28 12:24:29,361 - synthesizer_ar.py - value 5.1424 achieved after 50.09 seconds
2025-01-28 12:24:29,779 - synthesizer_ar.py - value 5.1437 achieved after 50.5 seconds
2025-01-28 12:24:30,508 - synthesizer_ar.py - value 5.1445 achieved after 51.23 seconds
> progress 0.074%, elapsed 3 s, estimated 4058 s, iters = {MDP: 69}, opt = 5.1445
2025-01-28 12:24:33,671 - synthesizer_ar.py - value 5.1478 achieved after 54.4 seconds
2025-01-28 12:24:33,681 - synthesizer_ar.py - value 5.1511 achieved after 54.41 seconds
2025-01-28 12:24:34,070 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:24:34,070 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.1 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 112

optimum: 5.151135
--------------------
2025-01-28 12:24:34,070 - decision_tree.py - families considered: 112
2025-01-28 12:24:34,070 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:34,071 - decision_tree.py - families with schedulers preserved: 13
2025-01-28 12:24:34,071 - decision_tree.py - families model checked: 99
2025-01-28 12:24:34,071 - decision_tree.py - harmonizations attempted: 30
2025-01-28 12:24:34,071 - decision_tree.py - harmonizations succeeded: 5

2025-01-28 12:24:34,071 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:34,071 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked6, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, A_2=r, A_3=r, V_4=x, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=7, A_5=r, A_6=u
2025-01-28 12:24:34,089 - decision_tree.py - double-checking specification satisfiability:  : 5.151134748619029

2025-01-28 12:24:34,089 - mdp.py - building tree of depth 3
2025-01-28 12:24:34,184 - statistic.py - synthesis initiated, design space: 1e14
2025-01-28 12:24:34,652 - synthesizer_ar.py - value 5.1551 achieved after 57.86 seconds
2025-01-28 12:24:34,661 - synthesizer_ar.py - value 5.1568 achieved after 57.87 seconds
> progress 0.0%, elapsed 3 s, estimated 1712415 s (19 days), iters = {MDP: 57}, opt = 5.1568
2025-01-28 12:24:36,727 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:24:36,728 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.02 s
number of holes: 57, family size: 1e14, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 98

optimum: 5.156808
--------------------
2025-01-28 12:24:36,728 - decision_tree.py - families considered: 98
2025-01-28 12:24:36,728 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:36,728 - decision_tree.py - families with schedulers preserved: 19
2025-01-28 12:24:36,728 - decision_tree.py - families model checked: 79
2025-01-28 12:24:36,728 - decision_tree.py - harmonizations attempted: 19
2025-01-28 12:24:36,728 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:24:36,728 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:36,728 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked6, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=picked4, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=6, A_3=r, A_4=r, V_5=picked6, picked0_5=0, picked1_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=6, A_6=d, A_7=r, V_8=x, picked0_8=0, picked1_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=7, V_9=picked4, picked0_9=0, picked1_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=6, A_10=r, A_11=r, V_12=picked6, picked0_12=0, picked1_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=6, A_13=u, A_14=d
2025-01-28 12:24:36,736 - decision_tree.py - double-checking specification satisfiability:  : 5.156807563165011

2025-01-28 12:24:36,736 - mdp.py - building tree of depth 4
2025-01-28 12:24:36,798 - statistic.py - synthesis initiated, design space: 1e30
2025-01-28 12:24:38,128 - synthesizer_ar.py - value 5.1587 achieved after 61.34 seconds
> progress 0.0%, elapsed 3 s, estimated 11165506229 s (354 years), iters = {MDP: 44}, opt = 5.1587
2025-01-28 12:24:40,537 - synthesizer_ar.py - value 5.164 achieved after 63.74 seconds
2025-01-28 12:24:41,214 - synthesizer_ar.py - value 5.1664 achieved after 64.42 seconds
2025-01-28 12:24:41,841 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:24:41,841 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.04 s
number of holes: 121, family size: 1e30, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 85

optimum: 5.166397
--------------------
2025-01-28 12:24:41,842 - decision_tree.py - families considered: 85
2025-01-28 12:24:41,842 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:41,842 - decision_tree.py - families with schedulers preserved: 25
2025-01-28 12:24:41,842 - decision_tree.py - families model checked: 60
2025-01-28 12:24:41,842 - decision_tree.py - harmonizations attempted: 10
2025-01-28 12:24:41,842 - decision_tree.py - harmonizations succeeded: 3

2025-01-28 12:24:41,842 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:41,842 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked6, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=picked4, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=6, V_3=picked6, picked0_3=0, picked1_3=0, picked3_3=0, picked4_3=0, picked6_3=0, x_3=6, A_4=r, A_5=l, V_6=picked3, picked0_6=0, picked1_6=0, picked3_6=0, picked4_6=0, picked6_6=0, x_6=6, A_7=l, A_8=l, V_9=picked6, picked0_9=0, picked1_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=6, V_10=picked3, picked0_10=0, picked1_10=0, picked3_10=0, picked4_10=0, picked6_10=0, x_10=6, A_11=l, A_12=l, V_13=picked6, picked0_13=0, picked1_13=0, picked3_13=0, picked4_13=0, picked6_13=0, x_13=6, A_14=r, A_15=r, V_16=x, picked0_16=0, picked1_16=0, picked3_16=0, picked4_16=0, picked6_16=0, x_16=7, V_17=picked4, picked0_17=0, picked1_17=0, picked3_17=0, picked4_17=0, picked6_17=0, x_17=6, V_18=picked3, picked0_18=0, picked1_18=0, picked3_18=0, picked4_18=0, picked6_18=0, x_18=6, A_19=l, A_20=l, V_21=x, picked0_21=0, picked1_21=0, picked3_21=0, picked4_21=0, picked6_21=0, x_21=7, A_22=r, A_23=l, V_24=picked6, picked0_24=0, picked1_24=0, picked3_24=0, picked4_24=0, picked6_24=0, x_24=6, V_25=x, picked0_25=0, picked1_25=0, picked3_25=0, picked4_25=0, picked6_25=0, x_25=8, A_26=u, A_27=l, V_28=picked4, picked0_28=0, picked1_28=0, picked3_28=0, picked4_28=0, picked6_28=0, x_28=6, A_29=u, A_30=d
2025-01-28 12:24:41,851 - decision_tree.py - double-checking specification satisfiability:  : 5.166396877886078

2025-01-28 12:24:41,851 - mdp.py - building tree of depth 5
2025-01-28 12:24:41,961 - statistic.py - synthesis initiated, design space: 1e61
> progress 0.0%, elapsed 3 s, estimated 20045508214904508 s (635638895 years), iters = {MDP: 41}, opt = 5.1664
2025-01-28 12:24:45,828 - synthesizer_ar.py - value 5.168 achieved after 69.04 seconds
2025-01-28 12:24:46,058 - synthesizer_ar.py - value 5.1703 achieved after 69.27 seconds
2025-01-28 12:24:46,989 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:24:46,989 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.03 s
number of holes: 249, family size: 1e61, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 74

optimum: 5.170306
--------------------
2025-01-28 12:24:46,989 - decision_tree.py - families considered: 74
2025-01-28 12:24:46,989 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:24:46,989 - decision_tree.py - families with schedulers preserved: 17
2025-01-28 12:24:46,989 - decision_tree.py - families model checked: 57
2025-01-28 12:24:46,989 - decision_tree.py - harmonizations attempted: 11
2025-01-28 12:24:46,989 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:24:46,989 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:24:46,989 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked6, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=picked4, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=6, V_3=picked6, picked0_3=0, picked1_3=0, picked3_3=0, picked4_3=0, picked6_3=0, x_3=6, V_4=picked4, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=6, A_5=r, A_6=__random__, V_7=picked3, picked0_7=0, picked1_7=0, picked3_7=0, picked4_7=0, picked6_7=0, x_7=6, A_8=__random__, A_9=l, V_10=picked3, picked0_10=0, picked1_10=0, picked3_10=0, picked4_10=0, picked6_10=0, x_10=6, V_11=picked3, picked0_11=0, picked1_11=0, picked3_11=0, picked4_11=0, picked6_11=0, x_11=6, A_12=__random__, A_13=__random__, V_14=picked0, picked0_14=0, picked1_14=0, picked3_14=0, picked4_14=0, picked6_14=0, x_14=6, A_15=__random__, A_16=__random__, V_17=picked6, picked0_17=0, picked1_17=0, picked3_17=0, picked4_17=0, picked6_17=0, x_17=6, V_18=picked3, picked0_18=0, picked1_18=0, picked3_18=0, picked4_18=0, picked6_18=0, x_18=6, V_19=picked0, picked0_19=0, picked1_19=0, picked3_19=0, picked4_19=0, picked6_19=0, x_19=6, A_20=__random__, A_21=__random__, V_22=picked0, picked0_22=0, picked1_22=0, picked3_22=0, picked4_22=0, picked6_22=0, x_22=6, A_23=__random__, A_24=r, V_25=picked6, picked0_25=0, picked1_25=0, picked3_25=0, picked4_25=0, picked6_25=0, x_25=6, V_26=picked0, picked0_26=0, picked1_26=0, picked3_26=0, picked4_26=0, picked6_26=0, x_26=6, A_27=__random__, A_28=__random__, V_29=picked6, picked0_29=0, picked1_29=0, picked3_29=0, picked4_29=0, picked6_29=0, x_29=6, A_30=r, A_31=r, V_32=x, picked0_32=0, picked1_32=0, picked3_32=0, picked4_32=0, picked6_32=0, x_32=7, V_33=picked4, picked0_33=0, picked1_33=0, picked3_33=0, picked4_33=0, picked6_33=0, x_33=6, V_34=picked3, picked0_34=0, picked1_34=0, picked3_34=0, picked4_34=0, picked6_34=0, x_34=6, V_35=picked0, picked0_35=0, picked1_35=0, picked3_35=0, picked4_35=0, picked6_35=0, x_35=6, A_36=__random__, A_37=__random__, V_38=picked0, picked0_38=0, picked1_38=0, picked3_38=0, picked4_38=0, picked6_38=0, x_38=6, A_39=__random__, A_40=__random__, V_41=x, picked0_41=0, picked1_41=0, picked3_41=0, picked4_41=0, picked6_41=0, x_41=7, V_42=x, picked0_42=0, picked1_42=0, picked3_42=0, picked4_42=0, picked6_42=0, x_42=7, A_43=r, A_44=l, V_45=picked0, picked0_45=0, picked1_45=0, picked3_45=0, picked4_45=0, picked6_45=0, x_45=6, A_46=__random__, A_47=__random__, V_48=picked6, picked0_48=0, picked1_48=0, picked3_48=0, picked4_48=0, picked6_48=0, x_48=6, V_49=x, picked0_49=0, picked1_49=0, picked3_49=0, picked4_49=0, picked6_49=0, x_49=8, V_50=picked1, picked0_50=0, picked1_50=0, picked3_50=0, picked4_50=0, picked6_50=0, x_50=6, A_51=u, A_52=u, V_53=picked0, picked0_53=0, picked1_53=0, picked3_53=0, picked4_53=0, picked6_53=0, x_53=6, A_54=__random__, A_55=l, V_56=picked4, picked0_56=0, picked1_56=0, picked3_56=0, picked4_56=0, picked6_56=0, x_56=6, V_57=picked0, picked0_57=0, picked1_57=0, picked3_57=0, picked4_57=0, picked6_57=0, x_57=6, A_58=__random__, A_59=__random__, V_60=x, picked0_60=0, picked1_60=0, picked3_60=0, picked4_60=0, picked6_60=0, x_60=8, A_61=r, A_62=d
2025-01-28 12:24:47,000 - decision_tree.py - double-checking specification satisfiability:  : 5.17030615365279

2025-01-28 12:24:47,000 - mdp.py - building tree of depth 6
2025-01-28 12:24:47,230 - statistic.py - synthesis initiated, design space: 1e123
2025-01-28 12:24:49,478 - synthesizer_ar.py - value 5.1761 achieved after 72.69 seconds
> progress 0.0%, elapsed 3 s, estimated 81195853341618103776786251776 s (2574703619406966554624 years), iters = {MDP: 33}, opt = 5.1761
> progress 0.0%, elapsed 6 s, estimated 11804812425078981447926153216 s (374328146406614106112 years), iters = {MDP: 77}, opt = 5.1761
> progress 0.0%, elapsed 9 s, estimated 9061994631461720256365461504 s (287353964721642569728 years), iters = {MDP: 118}, opt = 5.1761
> progress 0.0%, elapsed 12 s, estimated 11830348130068036389697486848 s (375137878299975811072 years), iters = {MDP: 152}, opt = 5.1761
> progress 0.0%, elapsed 15 s, estimated 12959594345537328840808857600 s (410946040890960445440 years), iters = {MDP: 192}, opt = 5.1761
> progress 0.0%, elapsed 18 s, estimated 14994456199840312638570496000 s (475471087006605574144 years), iters = {MDP: 222}, opt = 5.1761
> progress 0.0%, elapsed 21 s, estimated 17380976092728778609347526656 s (551147136375214964736 years), iters = {MDP: 249}, opt = 5.1761
> progress 0.0%, elapsed 24 s, estimated 17983556800310262754231451648 s (570254845266053496832 years), iters = {MDP: 285}, opt = 5.1761
2025-01-28 12:25:13,107 - synthesizer_ar.py - value 5.1778 achieved after 98.79 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 28.36 s
number of holes: 505, family size: 1e123, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 318

optimum: 5.177802
--------------------
2025-01-28 12:25:13,107 - decision_tree.py - families considered: 318
2025-01-28 12:25:13,107 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:13,107 - decision_tree.py - families with schedulers preserved: 62
2025-01-28 12:25:13,107 - decision_tree.py - families model checked: 256
2025-01-28 12:25:13,107 - decision_tree.py - harmonizations attempted: 52
2025-01-28 12:25:13,107 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:13,107 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:13,107 - decision_tree.py - V_0=picked1, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked3, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=picked4, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=6, V_3=picked6, picked0_3=0, picked1_3=0, picked3_3=0, picked4_3=0, picked6_3=0, x_3=6, V_4=x, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=8, V_5=x, picked0_5=0, picked1_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=7, A_6=r, A_7=u, V_8=picked4, picked0_8=0, picked1_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=6, A_9=l, A_10=d, V_11=x, picked0_11=0, picked1_11=0, picked3_11=0, picked4_11=0, picked6_11=0, x_11=8, V_12=x, picked0_12=0, picked1_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=8, A_13=r, A_14=__random__, V_15=x, picked0_15=0, picked1_15=0, picked3_15=0, picked4_15=0, picked6_15=0, x_15=8, A_16=__random__, A_17=r, V_18=x, picked0_18=0, picked1_18=0, picked3_18=0, picked4_18=0, picked6_18=0, x_18=8, V_19=x, picked0_19=0, picked1_19=0, picked3_19=0, picked4_19=0, picked6_19=0, x_19=8, V_20=x, picked0_20=0, picked1_20=0, picked3_20=0, picked4_20=0, picked6_20=0, x_20=8, A_21=__random__, A_22=__random__, V_23=x, picked0_23=0, picked1_23=0, picked3_23=0, picked4_23=0, picked6_23=0, x_23=8, A_24=__random__, A_25=d, V_26=x, picked0_26=0, picked1_26=0, picked3_26=0, picked4_26=0, picked6_26=0, x_26=8, V_27=x, picked0_27=0, picked1_27=0, picked3_27=0, picked4_27=0, picked6_27=0, x_27=8, A_28=__random__, A_29=__random__, V_30=x, picked0_30=0, picked1_30=0, picked3_30=0, picked4_30=0, picked6_30=0, x_30=8, A_31=__random__, A_32=l, V_33=x, picked0_33=0, picked1_33=0, picked3_33=0, picked4_33=0, picked6_33=0, x_33=8, V_34=picked3, picked0_34=0, picked1_34=0, picked3_34=0, picked4_34=0, picked6_34=0, x_34=6, V_35=picked6, picked0_35=0, picked1_35=0, picked3_35=0, picked4_35=0, picked6_35=0, x_35=6, V_36=picked6, picked0_36=0, picked1_36=0, picked3_36=0, picked4_36=0, picked6_36=0, x_36=6, A_37=__random__, A_38=__random__, V_39=picked4, picked0_39=0, picked1_39=0, picked3_39=0, picked4_39=0, picked6_39=0, x_39=6, A_40=r, A_41=__random__, V_42=picked6, picked0_42=0, picked1_42=0, picked3_42=0, picked4_42=0, picked6_42=0, x_42=6, V_43=x, picked0_43=0, picked1_43=0, picked3_43=0, picked4_43=0, picked6_43=0, x_43=7, A_44=r, A_45=u, V_46=picked3, picked0_46=0, picked1_46=0, picked3_46=0, picked4_46=0, picked6_46=0, x_46=6, A_47=__random__, A_48=r, V_49=picked6, picked0_49=0, picked1_49=0, picked3_49=0, picked4_49=0, picked6_49=0, x_49=6, V_50=picked4, picked0_50=0, picked1_50=0, picked3_50=0, picked4_50=0, picked6_50=0, x_50=8, V_51=picked3, picked0_51=0, picked1_51=0, picked3_51=0, picked4_51=0, picked6_51=0, x_51=8, A_52=__random__, A_53=l, V_54=picked1, picked0_54=0, picked1_54=0, picked3_54=0, picked4_54=0, picked6_54=0, x_54=6, A_55=l, A_56=__random__, V_57=picked4, picked0_57=0, picked1_57=0, picked3_57=0, picked4_57=0, picked6_57=0, x_57=8, V_58=picked0, picked0_58=0, picked1_58=0, picked3_58=0, picked4_58=0, picked6_58=0, x_58=8, A_59=d, A_60=r, V_61=picked1, picked0_61=0, picked1_61=0, picked3_61=0, picked4_61=0, picked6_61=0, x_61=6, A_62=d, A_63=r, V_64=picked6, picked0_64=0, picked1_64=0, picked3_64=0, picked4_64=0, picked6_64=0, x_64=6, V_65=picked6, picked0_65=0, picked1_65=0, picked3_65=0, picked4_65=0, picked6_65=0, x_65=6, V_66=x, picked0_66=0, picked1_66=0, picked3_66=0, picked4_66=0, picked6_66=0, x_66=7, V_67=picked4, picked0_67=0, picked1_67=0, picked3_67=0, picked4_67=0, picked6_67=0, x_67=6, V_68=x, picked0_68=0, picked1_68=0, picked3_68=0, picked4_68=0, picked6_68=0, x_68=7, A_69=r, A_70=d, V_71=picked4, picked0_71=0, picked1_71=0, picked3_71=0, picked4_71=0, picked6_71=0, x_71=6, A_72=l, A_73=r, V_74=x, picked0_74=0, picked1_74=0, picked3_74=0, picked4_74=0, picked6_74=0, x_74=8, V_75=picked4, picked0_75=0, picked1_75=0, picked3_75=0, picked4_75=0, picked6_75=0, x_75=6, A_76=u, A_77=u, V_78=picked3, picked0_78=0, picked1_78=0, picked3_78=0, picked4_78=0, picked6_78=0, x_78=8, A_79=r, A_80=l, V_81=picked3, picked0_81=0, picked1_81=0, picked3_81=0, picked4_81=0, picked6_81=0, x_81=6, V_82=picked0, picked0_82=0, picked1_82=0, picked3_82=0, picked4_82=0, picked6_82=0, x_82=6, V_83=picked0, picked0_83=0, picked1_83=0, picked3_83=0, picked4_83=0, picked6_83=0, x_83=6, A_84=l, A_85=__random__, V_86=picked0, picked0_86=0, picked1_86=0, picked3_86=0, picked4_86=0, picked6_86=0, x_86=6, A_87=u, A_88=r, V_89=picked0, picked0_89=0, picked1_89=0, picked3_89=0, picked4_89=0, picked6_89=0, x_89=6, V_90=picked0, picked0_90=0, picked1_90=0, picked3_90=0, picked4_90=0, picked6_90=0, x_90=6, A_91=d, A_92=r, V_93=picked0, picked0_93=0, picked1_93=0, picked3_93=0, picked4_93=0, picked6_93=0, x_93=6, A_94=l, A_95=u, V_96=picked4, picked0_96=0, picked1_96=0, picked3_96=0, picked4_96=0, picked6_96=0, x_96=6, V_97=picked4, picked0_97=0, picked1_97=0, picked3_97=0, picked4_97=0, picked6_97=0, x_97=6, V_98=picked4, picked0_98=0, picked1_98=0, picked3_98=0, picked4_98=0, picked6_98=0, x_98=6, V_99=x, picked0_99=0, picked1_99=0, picked3_99=0, picked4_99=0, picked6_99=0, x_99=8, A_100=r, A_101=r, V_102=x, picked0_102=0, picked1_102=0, picked3_102=0, picked4_102=0, picked6_102=0, x_102=8, A_103=__random__, A_104=__random__, V_105=x, picked0_105=0, picked1_105=0, picked3_105=0, picked4_105=0, picked6_105=0, x_105=8, V_106=x, picked0_106=0, picked1_106=0, picked3_106=0, picked4_106=0, picked6_106=0, x_106=8, A_107=__random__, A_108=__random__, V_109=picked0, picked0_109=0, picked1_109=0, picked3_109=0, picked4_109=0, picked6_109=0, x_109=6, A_110=__random__, A_111=__random__, V_112=picked3, picked0_112=0, picked1_112=0, picked3_112=0, picked4_112=0, picked6_112=0, x_112=6, V_113=picked0, picked0_113=0, picked1_113=0, picked3_113=0, picked4_113=0, picked6_113=0, x_113=6, V_114=picked3, picked0_114=0, picked1_114=0, picked3_114=0, picked4_114=0, picked6_114=0, x_114=6, A_115=r, A_116=__random__, V_117=picked0, picked0_117=0, picked1_117=0, picked3_117=0, picked4_117=0, picked6_117=0, x_117=6, A_118=__random__, A_119=r, V_120=picked0, picked0_120=0, picked1_120=0, picked3_120=0, picked4_120=0, picked6_120=0, x_120=6, V_121=x, picked0_121=0, picked1_121=0, picked3_121=0, picked4_121=0, picked6_121=0, x_121=8, A_122=r, A_123=d, V_124=picked4, picked0_124=0, picked1_124=0, picked3_124=0, picked4_124=0, picked6_124=0, x_124=6, A_125=__random__, A_126=u
2025-01-28 12:25:13,125 - decision_tree.py - double-checking specification satisfiability:  : 5.1778024187318445
2025-01-28 12:25:13,125 - decision_tree.py - admissible subtree found from node 151
2025-01-28 12:25:13,126 - decision_tree.py - new tree has depth 15 and 218 nodes
2025-01-28 12:25:15,476 - decision_tree.py - new dtcontrol tree has depth 13 and 248 nodes
2025-01-28 12:25:15,477 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:25:15,478 - decision_tree.py - starting iteration 7 with 13 nodes in node queue
2025-01-28 12:25:15,478 - decision_tree.py - current tree size: 419 nodes
2025-01-28 12:25:15,593 - decision_tree.py - subtree quotient has 2039 states and 2615 choices
2025-01-28 12:25:15,602 - mdp.py - MDP has 144/2039 relevant states
2025-01-28 12:25:15,608 - mdp.py - MDP has 5 actions
2025-01-28 12:25:15,625 - mdp.py - found the following 5 variables: ['picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[0..8]']

2025-01-28 12:25:15,625 - mdp.py - building tree of depth 0
2025-01-28 12:25:15,631 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:25:15,770 - synthesizer_ar.py - value 5.1777 achieved after 101.46 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.18 s
number of holes: 1, family size: 5, quotient: 2039 states / 2615 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.177655
--------------------
2025-01-28 12:25:15,812 - decision_tree.py - families considered: 4
2025-01-28 12:25:15,812 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:15,812 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:25:15,812 - decision_tree.py - families model checked: 4
2025-01-28 12:25:15,812 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:25:15,812 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:15,812 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:15,812 - decision_tree.py - A_0=r
2025-01-28 12:25:15,818 - decision_tree.py - double-checking specification satisfiability:  : 5.177655385644633
2025-01-28 12:25:15,818 - decision_tree.py - admissible subtree found from node 50
2025-01-28 12:25:15,820 - decision_tree.py - new tree has depth 15 and 193 nodes
2025-01-28 12:25:17,750 - decision_tree.py - new dtcontrol tree has depth 14 and 236 nodes
2025-01-28 12:25:17,751 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:25:17,754 - decision_tree.py - starting iteration 8 with 12 nodes in node queue
2025-01-28 12:25:17,754 - decision_tree.py - current tree size: 387 nodes
2025-01-28 12:25:17,853 - decision_tree.py - subtree quotient has 2039 states and 2351 choices
2025-01-28 12:25:17,860 - mdp.py - MDP has 78/2039 relevant states
2025-01-28 12:25:17,863 - mdp.py - MDP has 5 actions
2025-01-28 12:25:17,877 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'x:[10..12]', 'y:[2..3]']

2025-01-28 12:25:17,877 - mdp.py - building tree of depth 0
2025-01-28 12:25:17,880 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:25:17,984 - synthesizer_ar.py - value 5.1469 achieved after 103.67 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 1, family size: 5, quotient: 2039 states / 2351 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.14689
--------------------
2025-01-28 12:25:18,011 - decision_tree.py - families considered: 4
2025-01-28 12:25:18,011 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:18,011 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:25:18,011 - decision_tree.py - families model checked: 4
2025-01-28 12:25:18,011 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:25:18,011 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:18,011 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:18,011 - decision_tree.py - A_0=l
2025-01-28 12:25:18,016 - decision_tree.py - double-checking specification satisfiability:  : 5.146889563672286

2025-01-28 12:25:18,017 - mdp.py - building tree of depth 1
2025-01-28 12:25:18,028 - statistic.py - synthesis initiated, design space: 350
2025-01-28 12:25:19,275 - synthesizer_ar.py - value 5.1655 achieved after 104.96 seconds
2025-01-28 12:25:19,281 - synthesizer_ar.py - value 5.1669 achieved after 104.97 seconds
2025-01-28 12:25:19,450 - synthesizer_ar.py - value 5.1724 achieved after 105.14 seconds
> progress 128.571%, elapsed 3 s, estimated 2 s, iters = {MDP: 78}, opt = 5.1724
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 3.8 s
number of holes: 10, family size: 350, quotient: 2039 states / 2351 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 103

optimum: 5.172356
--------------------
2025-01-28 12:25:21,832 - decision_tree.py - families considered: 103
2025-01-28 12:25:21,832 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:21,832 - decision_tree.py - families with schedulers preserved: 17
2025-01-28 12:25:21,832 - decision_tree.py - families model checked: 86
2025-01-28 12:25:21,832 - decision_tree.py - harmonizations attempted: 17
2025-01-28 12:25:21,832 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:25:21,832 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:21,832 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=11, y_0=2, A_1=r, A_2=u
2025-01-28 12:25:21,838 - decision_tree.py - double-checking specification satisfiability:  : 5.172355830426039

2025-01-28 12:25:21,838 - mdp.py - building tree of depth 2
2025-01-28 12:25:21,864 - statistic.py - synthesis initiated, design space: 1e6
> progress 0.151%, elapsed 3 s, estimated 1983 s, iters = {MDP: 58}, opt = 5.1724
2025-01-28 12:25:25,624 - synthesizer_ar.py - value 5.1756 achieved after 111.31 seconds
2025-01-28 12:25:26,903 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:25:26,903 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.04 s
number of holes: 28, family size: 1e6, quotient: 2039 states / 2351 actions
explored: 3 %
MDP stats: avg MDP size: 2039, iterations: 108

optimum: 5.175607
--------------------
2025-01-28 12:25:26,903 - decision_tree.py - families considered: 108
2025-01-28 12:25:26,903 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:26,904 - decision_tree.py - families with schedulers preserved: 24
2025-01-28 12:25:26,904 - decision_tree.py - families model checked: 84
2025-01-28 12:25:26,904 - decision_tree.py - harmonizations attempted: 16
2025-01-28 12:25:26,904 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:26,904 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:26,904 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=11, y_0=2, V_1=picked6, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, x_1=10, y_1=2, A_2=l, A_3=r, V_4=x, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked6_4=0, x_4=10, y_4=2, A_5=l, A_6=u
2025-01-28 12:25:26,911 - decision_tree.py - double-checking specification satisfiability:  : 5.175606721050167
2025-01-28 12:25:26,912 - decision_tree.py - admissible subtree found from node 245
2025-01-28 12:25:26,920 - decision_tree.py - new tree has depth 15 and 179 nodes
2025-01-28 12:25:29,428 - decision_tree.py - new dtcontrol tree has depth 14 and 222 nodes
2025-01-28 12:25:29,429 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:25:29,432 - decision_tree.py - starting iteration 9 with 11 nodes in node queue
2025-01-28 12:25:29,432 - decision_tree.py - current tree size: 359 nodes
2025-01-28 12:25:29,549 - decision_tree.py - subtree quotient has 2039 states and 2255 choices
2025-01-28 12:25:29,566 - mdp.py - MDP has 54/2039 relevant states
2025-01-28 12:25:29,571 - mdp.py - MDP has 5 actions
2025-01-28 12:25:29,597 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'y:[2..4]']

2025-01-28 12:25:29,597 - mdp.py - building tree of depth 0
2025-01-28 12:25:29,604 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.3 s
number of holes: 1, family size: 5, quotient: 2039 states / 2255 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:25:29,900 - decision_tree.py - families considered: 4
2025-01-28 12:25:29,900 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:29,900 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:25:29,900 - decision_tree.py - families model checked: 4
2025-01-28 12:25:29,900 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:25:29,900 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:25:29,901 - mdp.py - building tree of depth 1
2025-01-28 12:25:29,918 - statistic.py - synthesis initiated, design space: 300
2025-01-28 12:25:30,571 - synthesizer_ar.py - value 5.1413 achieved after 116.26 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.93 s
number of holes: 9, family size: 300, quotient: 2039 states / 2255 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 47

optimum: 5.141263
--------------------
2025-01-28 12:25:31,850 - decision_tree.py - families considered: 47
2025-01-28 12:25:31,850 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:31,850 - decision_tree.py - families with schedulers preserved: 9
2025-01-28 12:25:31,850 - decision_tree.py - families model checked: 38
2025-01-28 12:25:31,850 - decision_tree.py - harmonizations attempted: 7
2025-01-28 12:25:31,850 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:31,850 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:31,851 - decision_tree.py - V_0=y, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, y_0=2, A_1=l, A_2=d
2025-01-28 12:25:31,857 - decision_tree.py - double-checking specification satisfiability:  : 5.14126325755367

2025-01-28 12:25:31,857 - mdp.py - building tree of depth 2
2025-01-28 12:25:31,872 - statistic.py - synthesis initiated, design space: 1e6
2025-01-28 12:25:32,236 - synthesizer_ar.py - value 5.1429 achieved after 117.92 seconds
2025-01-28 12:25:32,388 - synthesizer_ar.py - value 5.1431 achieved after 118.08 seconds
2025-01-28 12:25:34,438 - synthesizer_ar.py - value 5.1435 achieved after 120.13 seconds
> progress 4.248%, elapsed 3 s, estimated 70 s, iters = {MDP: 67}, opt = 5.1435
2025-01-28 12:25:36,154 - synthesizer_ar.py - value 5.1625 achieved after 121.84 seconds
2025-01-28 12:25:34,430 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:25:34,430 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.03 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2255 actions
explored: 5 %
MDP stats: avg MDP size: 2039, iterations: 106

optimum: 5.162473
--------------------
2025-01-28 12:25:34,431 - decision_tree.py - families considered: 106
2025-01-28 12:25:34,431 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:34,431 - decision_tree.py - families with schedulers preserved: 26
2025-01-28 12:25:34,431 - decision_tree.py - families model checked: 80
2025-01-28 12:25:34,431 - decision_tree.py - harmonizations attempted: 13
2025-01-28 12:25:34,431 - decision_tree.py - harmonizations succeeded: 3

2025-01-28 12:25:34,431 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:34,431 - decision_tree.py - V_0=y, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, y_0=2, V_1=y, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, y_1=2, A_2=l, A_3=__random__, V_4=picked3, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked6_4=0, y_4=2, A_5=u, A_6=d
2025-01-28 12:25:34,437 - decision_tree.py - double-checking specification satisfiability:  : 5.162473019010135

2025-01-28 12:25:34,438 - mdp.py - building tree of depth 3
2025-01-28 12:25:34,477 - statistic.py - synthesis initiated, design space: 1e13
2025-01-28 12:25:34,949 - synthesizer_ar.py - value 5.1739 achieved after 123.11 seconds
2025-01-28 12:25:35,915 - synthesizer_ar.py - value 5.1742 achieved after 124.08 seconds
2025-01-28 12:25:36,869 - synthesizer_ar.py - value 5.1752 achieved after 125.03 seconds
> progress 0.115%, elapsed 3 s, estimated 2712 s, iters = {MDP: 59}, opt = 5.1752
2025-01-28 12:25:39,538 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.06 s
number of holes: 57, family size: 1e13, quotient: 2039 states / 2255 actions
explored: 3 %
MDP stats: avg MDP size: 2039, iterations: 98

optimum: 5.175179
--------------------
2025-01-28 12:25:39,539 - decision_tree.py - families considered: 98
2025-01-28 12:25:39,539 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:39,539 - decision_tree.py - families with schedulers preserved: 26
2025-01-28 12:25:39,539 - decision_tree.py - families model checked: 72
2025-01-28 12:25:39,539 - decision_tree.py - harmonizations attempted: 10
2025-01-28 12:25:39,539 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:25:39,539 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:39,539 - decision_tree.py - V_0=y, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, y_0=2, V_1=y, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, y_1=2, V_2=picked3, picked0_2=0, picked1_2=0, picked2_2=0, picked3_2=0, picked6_2=0, y_2=2, A_3=u, A_4=l, V_5=picked1, picked0_5=0, picked1_5=0, picked2_5=0, picked3_5=0, picked6_5=0, y_5=2, A_6=u, A_7=l, V_8=picked3, picked0_8=0, picked1_8=0, picked2_8=0, picked3_8=0, picked6_8=0, y_8=2, V_9=y, picked0_9=0, picked1_9=0, picked2_9=0, picked3_9=0, picked6_9=0, y_9=3, A_10=u, A_11=l, V_12=picked6, picked0_12=0, picked1_12=0, picked2_12=0, picked3_12=0, picked6_12=0, y_12=2, A_13=l, A_14=d
2025-01-28 12:25:39,546 - decision_tree.py - double-checking specification satisfiability:  : 5.175179248113052
2025-01-28 12:25:39,546 - decision_tree.py - admissible subtree found from node 314
2025-01-28 12:25:39,549 - decision_tree.py - new tree has depth 15 and 173 nodes
2025-01-28 12:25:41,957 - decision_tree.py - new dtcontrol tree has depth 14 and 214 nodes
2025-01-28 12:25:41,958 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:25:41,961 - decision_tree.py - starting iteration 10 with 10 nodes in node queue
2025-01-28 12:25:41,961 - decision_tree.py - current tree size: 347 nodes
2025-01-28 12:25:42,089 - decision_tree.py - subtree quotient has 2039 states and 2183 choices
2025-01-28 12:25:42,100 - mdp.py - MDP has 36/2039 relevant states
2025-01-28 12:25:42,104 - mdp.py - MDP has 5 actions
2025-01-28 12:25:42,125 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'y:[2..4]']

2025-01-28 12:25:42,125 - mdp.py - building tree of depth 0
2025-01-28 12:25:42,131 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:25:42,259 - synthesizer_ar.py - value 5.1752 achieved after 130.42 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.16 s
number of holes: 1, family size: 5, quotient: 2039 states / 2183 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.175179
--------------------
2025-01-28 12:25:42,291 - decision_tree.py - families considered: 4
2025-01-28 12:25:42,291 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:42,291 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:25:42,292 - decision_tree.py - families model checked: 4
2025-01-28 12:25:42,292 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:25:42,292 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:42,292 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:42,292 - decision_tree.py - A_0=l
2025-01-28 12:25:42,299 - decision_tree.py - double-checking specification satisfiability:  : 5.175179248113052
2025-01-28 12:25:42,299 - decision_tree.py - admissible subtree found from node 281
2025-01-28 12:25:42,301 - decision_tree.py - new tree has depth 15 and 166 nodes
2025-01-28 12:25:44,215 - decision_tree.py - new dtcontrol tree has depth 14 and 207 nodes
2025-01-28 12:25:44,216 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:25:44,218 - decision_tree.py - starting iteration 11 with 9 nodes in node queue
2025-01-28 12:25:44,218 - decision_tree.py - current tree size: 333 nodes
2025-01-28 12:25:44,306 - decision_tree.py - subtree quotient has 2039 states and 2323 choices
2025-01-28 12:25:44,313 - mdp.py - MDP has 71/2039 relevant states
2025-01-28 12:25:44,316 - mdp.py - MDP has 5 actions
2025-01-28 12:25:44,330 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[8..9]']

2025-01-28 12:25:44,330 - mdp.py - building tree of depth 0
2025-01-28 12:25:44,334 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:25:44,428 - synthesizer_ar.py - value 5.131 achieved after 132.59 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.12 s
number of holes: 1, family size: 5, quotient: 2039 states / 2323 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.131047
--------------------
2025-01-28 12:25:44,455 - decision_tree.py - families considered: 4
2025-01-28 12:25:44,455 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:44,455 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:25:44,455 - decision_tree.py - families model checked: 4
2025-01-28 12:25:44,455 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:25:44,456 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:44,456 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:44,456 - decision_tree.py - A_0=d
2025-01-28 12:25:44,462 - decision_tree.py - double-checking specification satisfiability:  : 5.131046870427037

2025-01-28 12:25:44,462 - mdp.py - building tree of depth 1
2025-01-28 12:25:44,482 - statistic.py - synthesis initiated, design space: 175
2025-01-28 12:25:45,224 - synthesizer_ar.py - value 5.1746 achieved after 133.39 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.8 s
number of holes: 10, family size: 175, quotient: 2039 states / 2323 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 50

optimum: 5.174601
--------------------
2025-01-28 12:25:46,280 - decision_tree.py - families considered: 50
2025-01-28 12:25:46,280 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:46,280 - decision_tree.py - families with schedulers preserved: 12
2025-01-28 12:25:46,280 - decision_tree.py - families model checked: 38
2025-01-28 12:25:46,280 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:25:46,280 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:46,280 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:46,280 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=8, A_1=d, A_2=l
2025-01-28 12:25:46,285 - decision_tree.py - double-checking specification satisfiability:  : 5.1746005304780365
2025-01-28 12:25:46,286 - decision_tree.py - admissible subtree found from node 215
2025-01-28 12:25:46,287 - decision_tree.py - new tree has depth 15 and 154 nodes
2025-01-28 12:25:48,167 - decision_tree.py - new dtcontrol tree has depth 14 and 181 nodes
2025-01-28 12:25:48,168 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:25:48,170 - decision_tree.py - starting iteration 12 with 8 nodes in node queue
2025-01-28 12:25:48,170 - decision_tree.py - current tree size: 309 nodes
2025-01-28 12:25:48,261 - decision_tree.py - subtree quotient has 2039 states and 2279 choices
2025-01-28 12:25:48,268 - mdp.py - MDP has 60/2039 relevant states
2025-01-28 12:25:48,271 - mdp.py - MDP has 5 actions
2025-01-28 12:25:48,324 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[4..7]']

2025-01-28 12:25:48,324 - mdp.py - building tree of depth 0
2025-01-28 12:25:48,328 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:25:48,429 - synthesizer_ar.py - value 5.1739 achieved after 136.59 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.12 s
number of holes: 1, family size: 5, quotient: 2039 states / 2279 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.173894
--------------------
2025-01-28 12:25:48,450 - decision_tree.py - families considered: 4
2025-01-28 12:25:48,450 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:48,450 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:25:48,450 - decision_tree.py - families model checked: 4
2025-01-28 12:25:48,450 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:25:48,450 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:48,450 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:48,450 - decision_tree.py - A_0=r
2025-01-28 12:25:48,457 - decision_tree.py - double-checking specification satisfiability:  : 5.173893944031337

2025-01-28 12:25:48,457 - mdp.py - building tree of depth 1
2025-01-28 12:25:48,469 - statistic.py - synthesis initiated, design space: 450
2025-01-28 12:25:49,165 - synthesizer_ar.py - value 5.174 achieved after 137.33 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.08 s
number of holes: 9, family size: 450, quotient: 2039 states / 2279 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 57

optimum: 5.174036
--------------------
2025-01-28 12:25:50,547 - decision_tree.py - families considered: 57
2025-01-28 12:25:50,547 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:50,547 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 12:25:50,547 - decision_tree.py - families model checked: 51
2025-01-28 12:25:50,547 - decision_tree.py - harmonizations attempted: 13
2025-01-28 12:25:50,547 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:50,547 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:50,547 - decision_tree.py - V_0=picked4, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=4, A_1=r, A_2=l
2025-01-28 12:25:50,552 - decision_tree.py - double-checking specification satisfiability:  : 5.174036070855322

2025-01-28 12:25:50,553 - mdp.py - building tree of depth 2
2025-01-28 12:25:50,567 - statistic.py - synthesis initiated, design space: 1e6
2025-01-28 12:25:53,390 - synthesizer_ar.py - value 5.1746 achieved after 141.55 seconds
> progress 0.092%, elapsed 3 s, estimated 3311 s, iters = {MDP: 67}, opt = 5.1746
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 3.15 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2279 actions
explored: 116 %
MDP stats: avg MDP size: 2039, iterations: 76

optimum: 5.17455
--------------------
2025-01-28 12:25:53,713 - decision_tree.py - families considered: 76
2025-01-28 12:25:53,713 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:53,713 - decision_tree.py - families with schedulers preserved: 10
2025-01-28 12:25:53,713 - decision_tree.py - families model checked: 66
2025-01-28 12:25:53,713 - decision_tree.py - harmonizations attempted: 15
2025-01-28 12:25:53,713 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:53,713 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:53,713 - decision_tree.py - V_0=picked4, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=4, V_1=picked6, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=4, A_2=r, A_3=r, V_4=x, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=4, A_5=d, A_6=l
2025-01-28 12:25:53,723 - decision_tree.py - double-checking specification satisfiability:  : 5.174550296294327
2025-01-28 12:25:53,724 - decision_tree.py - admissible subtree found from node 181
2025-01-28 12:25:53,731 - decision_tree.py - new tree has depth 15 and 146 nodes
2025-01-28 12:25:55,918 - decision_tree.py - new dtcontrol tree has depth 14 and 187 nodes
2025-01-28 12:25:55,919 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:25:55,923 - decision_tree.py - starting iteration 13 with 7 nodes in node queue
2025-01-28 12:25:55,923 - decision_tree.py - current tree size: 293 nodes
2025-01-28 12:25:56,052 - decision_tree.py - subtree quotient has 2039 states and 2215 choices
2025-01-28 12:25:56,060 - mdp.py - MDP has 44/2039 relevant states
2025-01-28 12:25:56,064 - mdp.py - MDP has 5 actions
2025-01-28 12:25:56,084 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[2..8]']

2025-01-28 12:25:56,084 - mdp.py - building tree of depth 0
2025-01-28 12:25:56,089 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:25:56,233 - synthesizer_ar.py - value 5.1681 achieved after 144.4 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.18 s
number of holes: 1, family size: 5, quotient: 2039 states / 2215 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.168133
--------------------
2025-01-28 12:25:56,268 - decision_tree.py - families considered: 4
2025-01-28 12:25:56,269 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:56,269 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:25:56,269 - decision_tree.py - families model checked: 4
2025-01-28 12:25:56,269 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:25:56,269 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:25:56,269 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:25:56,269 - decision_tree.py - A_0=d
2025-01-28 12:25:56,275 - decision_tree.py - double-checking specification satisfiability:  : 5.168133293469946

2025-01-28 12:25:56,276 - mdp.py - building tree of depth 1
2025-01-28 12:25:56,288 - statistic.py - synthesis initiated, design space: 300
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.99 s
number of holes: 9, family size: 300, quotient: 2039 states / 2215 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 26

optimum: 5.168133
--------------------
2025-01-28 12:25:57,283 - decision_tree.py - families considered: 26
2025-01-28 12:25:57,283 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:25:57,283 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:25:57,283 - decision_tree.py - families model checked: 21
2025-01-28 12:25:57,283 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:25:57,283 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:25:57,283 - mdp.py - building tree of depth 2
2025-01-28 12:25:57,298 - statistic.py - synthesis initiated, design space: 1e6
2025-01-28 12:25:58,404 - synthesizer_ar.py - value 5.1751 achieved after 146.57 seconds
> progress 20.12%, elapsed 3 s, estimated 15 s, iters = {MDP: 46}, opt = 5.1751
2025-01-28 12:26:02,378 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:26:02,378 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.08 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2215 actions
explored: 20 %
MDP stats: avg MDP size: 2039, iterations: 81

optimum: 5.175104
--------------------
2025-01-28 12:26:02,379 - decision_tree.py - families considered: 81
2025-01-28 12:26:02,379 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:02,379 - decision_tree.py - families with schedulers preserved: 34
2025-01-28 12:26:02,379 - decision_tree.py - families model checked: 47
2025-01-28 12:26:02,379 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:26:02,379 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:26:02,379 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:26:02,379 - decision_tree.py - V_0=x, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=2, V_1=x, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=4, A_2=d, A_3=d, V_4=picked6, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=2, A_5=u, A_6=d
2025-01-28 12:26:02,386 - decision_tree.py - double-checking specification satisfiability:  : 5.175103799012402
2025-01-28 12:26:02,386 - decision_tree.py - admissible subtree found from node 141
2025-01-28 12:26:02,388 - decision_tree.py - new tree has depth 15 and 141 nodes
2025-01-28 12:26:04,594 - decision_tree.py - new dtcontrol tree has depth 14 and 189 nodes
2025-01-28 12:26:04,595 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:26:04,597 - decision_tree.py - starting iteration 14 with 6 nodes in node queue
2025-01-28 12:26:04,598 - decision_tree.py - current tree size: 283 nodes
2025-01-28 12:26:04,725 - decision_tree.py - subtree quotient has 2039 states and 2423 choices
2025-01-28 12:26:04,743 - mdp.py - MDP has 96/2039 relevant states
2025-01-28 12:26:04,748 - mdp.py - MDP has 5 actions
2025-01-28 12:26:04,768 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'x:[10..14]']

2025-01-28 12:26:04,768 - mdp.py - building tree of depth 0
2025-01-28 12:26:04,773 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:26:04,931 - synthesizer_ar.py - value 5.1609 achieved after 153.09 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.19 s
number of holes: 1, family size: 5, quotient: 2039 states / 2423 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.1609
--------------------
2025-01-28 12:26:04,964 - decision_tree.py - families considered: 4
2025-01-28 12:26:04,964 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:04,964 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:26:04,964 - decision_tree.py - families model checked: 4
2025-01-28 12:26:04,964 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:26:04,964 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:26:04,964 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:26:04,964 - decision_tree.py - A_0=r
2025-01-28 12:26:04,973 - decision_tree.py - double-checking specification satisfiability:  : 5.16090040928949

2025-01-28 12:26:04,974 - mdp.py - building tree of depth 1
2025-01-28 12:26:04,994 - statistic.py - synthesis initiated, design space: 600
2025-01-28 12:26:06,235 - synthesizer_ar.py - value 5.1706 achieved after 154.4 seconds
> progress 120.0%, elapsed 3 s, estimated 2 s, iters = {MDP: 64}, opt = 5.1706
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 3.37 s
number of holes: 9, family size: 600, quotient: 2039 states / 2423 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 73

optimum: 5.170553
--------------------
2025-01-28 12:26:05,878 - decision_tree.py - families considered: 73
2025-01-28 12:26:05,878 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:05,878 - decision_tree.py - families with schedulers preserved: 8
2025-01-28 12:26:05,878 - decision_tree.py - families model checked: 65
2025-01-28 12:26:05,878 - decision_tree.py - harmonizations attempted: 17
2025-01-28 12:26:05,878 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:26:05,878 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:26:05,878 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=13, A_1=r, A_2=l
2025-01-28 12:26:05,883 - decision_tree.py - double-checking specification satisfiability:  : 5.170553478672818

2025-01-28 12:26:05,884 - mdp.py - building tree of depth 2
2025-01-28 12:26:05,902 - statistic.py - synthesis initiated, design space: 1e6
2025-01-28 12:26:07,251 - synthesizer_ar.py - value 5.1739 achieved after 157.9 seconds
2025-01-28 12:26:07,363 - synthesizer_ar.py - value 5.1745 achieved after 158.01 seconds
2025-01-28 12:26:08,909 - synthesizer_ar.py - value 5.1748 achieved after 159.56 seconds
> progress 4.546%, elapsed 3 s, estimated 66 s, iters = {MDP: 64}, opt = 5.1748
2025-01-28 12:26:09,192 - synthesizer_ar.py - value 5.175 achieved after 159.84 seconds
2025-01-28 12:26:10,909 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.01 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2423 actions
explored: 27 %
MDP stats: avg MDP size: 2039, iterations: 122

optimum: 5.174955
--------------------
2025-01-28 12:26:10,909 - decision_tree.py - families considered: 122
2025-01-28 12:26:10,909 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:10,909 - decision_tree.py - families with schedulers preserved: 30
2025-01-28 12:26:10,909 - decision_tree.py - families model checked: 92
2025-01-28 12:26:10,909 - decision_tree.py - harmonizations attempted: 14
2025-01-28 12:26:10,909 - decision_tree.py - harmonizations succeeded: 4

2025-01-28 12:26:10,909 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:26:10,909 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=10, V_1=picked6, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, x_1=10, A_2=l, A_3=r, V_4=x, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked6_4=0, x_4=13, A_5=r, A_6=l
2025-01-28 12:26:10,915 - decision_tree.py - double-checking specification satisfiability:  : 5.174955020365119
2025-01-28 12:26:10,916 - decision_tree.py - admissible subtree found from node 200
2025-01-28 12:26:10,920 - decision_tree.py - new tree has depth 15 and 130 nodes
2025-01-28 12:26:13,277 - decision_tree.py - new dtcontrol tree has depth 14 and 178 nodes
2025-01-28 12:26:13,277 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:26:13,280 - decision_tree.py - starting iteration 15 with 5 nodes in node queue
2025-01-28 12:26:13,280 - decision_tree.py - current tree size: 261 nodes
2025-01-28 12:26:13,423 - decision_tree.py - subtree quotient has 2039 states and 2435 choices
2025-01-28 12:26:13,433 - mdp.py - MDP has 99/2039 relevant states
2025-01-28 12:26:13,438 - mdp.py - MDP has 5 actions
2025-01-28 12:26:13,459 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[3..9]']

2025-01-28 12:26:13,459 - mdp.py - building tree of depth 0
2025-01-28 12:26:13,464 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.38 s
number of holes: 1, family size: 5, quotient: 2039 states / 2435 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 7

optimum: 5.127782
--------------------
2025-01-28 12:26:13,843 - decision_tree.py - families considered: 7
2025-01-28 12:26:13,843 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:13,843 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:26:13,843 - decision_tree.py - families model checked: 7
2025-01-28 12:26:13,843 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:26:13,843 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:26:13,844 - mdp.py - building tree of depth 1
2025-01-28 12:26:13,867 - statistic.py - synthesis initiated, design space: 900
2025-01-28 12:26:14,604 - synthesizer_ar.py - value 5.1694 achieved after 165.25 seconds
2025-01-28 12:26:15,643 - synthesizer_ar.py - value 5.171 achieved after 166.29 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.81 s
number of holes: 9, family size: 900, quotient: 2039 states / 2435 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 39

optimum: 5.170989
--------------------
2025-01-28 12:26:15,682 - decision_tree.py - families considered: 39
2025-01-28 12:26:15,682 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:15,682 - decision_tree.py - families with schedulers preserved: 4
2025-01-28 12:26:15,682 - decision_tree.py - families model checked: 35
2025-01-28 12:26:15,682 - decision_tree.py - harmonizations attempted: 9
2025-01-28 12:26:15,682 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:26:15,682 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:26:15,682 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, A_1=r, A_2=l
2025-01-28 12:26:15,687 - decision_tree.py - double-checking specification satisfiability:  : 5.1709885298563885

2025-01-28 12:26:15,687 - mdp.py - building tree of depth 2
2025-01-28 12:26:15,709 - statistic.py - synthesis initiated, design space: 1e7
2025-01-28 12:26:16,397 - synthesizer_ar.py - value 5.1716 achieved after 167.05 seconds
2025-01-28 12:26:16,557 - synthesizer_ar.py - value 5.1718 achieved after 167.21 seconds
2025-01-28 12:26:18,569 - synthesizer_ar.py - value 5.1724 achieved after 169.22 seconds
> progress 0.092%, elapsed 3 s, estimated 3308 s, iters = {MDP: 64}, opt = 5.1724
2025-01-28 12:26:20,717 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:26:20,717 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.01 s
number of holes: 25, family size: 1e7, quotient: 2039 states / 2435 actions
explored: 2 %
MDP stats: avg MDP size: 2039, iterations: 118

optimum: 5.172435
--------------------
2025-01-28 12:26:20,717 - decision_tree.py - families considered: 118
2025-01-28 12:26:20,717 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:20,717 - decision_tree.py - families with schedulers preserved: 18
2025-01-28 12:26:20,717 - decision_tree.py - families model checked: 100
2025-01-28 12:26:20,717 - decision_tree.py - harmonizations attempted: 24
2025-01-28 12:26:20,717 - decision_tree.py - harmonizations succeeded: 3

2025-01-28 12:26:20,717 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:26:20,717 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=x, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, A_2=r, A_3=r, V_4=x, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=3, A_5=r, A_6=l
2025-01-28 12:26:20,722 - decision_tree.py - double-checking specification satisfiability:  : 5.172435101235843

2025-01-28 12:26:20,723 - mdp.py - building tree of depth 3
2025-01-28 12:26:20,759 - statistic.py - synthesis initiated, design space: 1e16
2025-01-28 12:26:22,570 - synthesizer_ar.py - value 5.1731 achieved after 173.22 seconds
> progress 0.0%, elapsed 3 s, estimated 3111028 s (36 days), iters = {MDP: 61}, opt = 5.1731
2025-01-28 12:26:25,815 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:26:25,815 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.06 s
number of holes: 57, family size: 1e16, quotient: 2039 states / 2435 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 108

optimum: 5.173101
--------------------
2025-01-28 12:26:25,815 - decision_tree.py - families considered: 108
2025-01-28 12:26:25,816 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:25,816 - decision_tree.py - families with schedulers preserved: 21
2025-01-28 12:26:25,816 - decision_tree.py - families model checked: 87
2025-01-28 12:26:25,816 - decision_tree.py - harmonizations attempted: 17
2025-01-28 12:26:25,816 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:26:25,816 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:26:25,816 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=x, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, V_2=picked2, picked1_2=0, picked2_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=3, A_3=r, A_4=r, V_5=picked6, picked1_5=0, picked2_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=3, A_6=u, A_7=r, V_8=x, picked1_8=0, picked2_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=3, V_9=x, picked1_9=0, picked2_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=3, A_10=r, A_11=__random__, V_12=picked3, picked1_12=0, picked2_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=3, A_13=u, A_14=l
2025-01-28 12:26:25,825 - decision_tree.py - double-checking specification satisfiability:  : 5.173101244997851

2025-01-28 12:26:25,825 - mdp.py - building tree of depth 4
2025-01-28 12:26:25,903 - statistic.py - synthesis initiated, design space: 1e34
> progress 0.0%, elapsed 3 s, estimated 816258856796 s (25883 years), iters = {MDP: 50}, opt = 5.1731
2025-01-28 12:26:30,906 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:26:30,906 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.0 s
number of holes: 121, family size: 1e34, quotient: 2039 states / 2435 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 88

optimum: 5.173101
--------------------
2025-01-28 12:26:30,906 - decision_tree.py - families considered: 88
2025-01-28 12:26:30,907 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:30,907 - decision_tree.py - families with schedulers preserved: 15
2025-01-28 12:26:30,907 - decision_tree.py - families model checked: 73
2025-01-28 12:26:30,907 - decision_tree.py - harmonizations attempted: 19
2025-01-28 12:26:30,907 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:26:30,907 - mdp.py - building tree of depth 5
2025-01-28 12:26:31,050 - statistic.py - synthesis initiated, design space: 1e70
> progress 0.0%, elapsed 3 s, estimated 3293562 s (38 days), iters = {MDP: 15}, opt = 5.1731
2025-01-28 12:26:36,057 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:26:36,059 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.01 s
number of holes: 249, family size: 1e70, quotient: 2039 states / 2435 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 29

optimum: 5.173101
--------------------
2025-01-28 12:26:36,060 - decision_tree.py - families considered: 29
2025-01-28 12:26:36,060 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:26:36,060 - decision_tree.py - families with schedulers preserved: 15
2025-01-28 12:26:36,060 - decision_tree.py - families model checked: 14
2025-01-28 12:26:36,060 - decision_tree.py - harmonizations attempted: 7
2025-01-28 12:26:36,060 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:26:36,060 - mdp.py - building tree of depth 6
2025-01-28 12:26:33,939 - statistic.py - synthesis initiated, design space: 1e142
> progress 0.0%, elapsed 3 s, estimated 3637868 s (42 days), iters = {MDP: 8}, opt = 5.1731
2025-01-28 12:26:39,631 - synthesizer_ar.py - value 5.1744 achieved after 192.76 seconds
> progress 0.0%, elapsed 6 s, estimated 21593450622665264 s (684723827 years), iters = {MDP: 21}, opt = 5.1744
2025-01-28 12:26:43,276 - synthesizer_ar.py - value 5.175 achieved after 196.41 seconds
> progress 0.0%, elapsed 9 s, estimated 4982675463823588 s (157999602 years), iters = {MDP: 43}, opt = 5.175
> progress 0.0%, elapsed 13 s, estimated 460175878024898 s (14592081 years), iters = {MDP: 69}, opt = 5.175
> progress 0.0%, elapsed 16 s, estimated 441573101786183 s (14002191 years), iters = {MDP: 98}, opt = 5.175
> progress 0.0%, elapsed 19 s, estimated 449806000956545 s (14263254 years), iters = {MDP: 137}, opt = 5.175
> progress 0.0%, elapsed 22 s, estimated 420887434148556 s (13346252 years), iters = {MDP: 170}, opt = 5.175
> progress 0.0%, elapsed 25 s, estimated 416780406490022 s (13216019 years), iters = {MDP: 203}, opt = 5.175
> progress 0.0%, elapsed 28 s, estimated 302286427347378 s (9585439 years), iters = {MDP: 242}, opt = 5.175
2025-01-28 12:27:03,942 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:27:03,943 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.0 s
number of holes: 505, family size: 1e142, quotient: 2039 states / 2435 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 251

optimum: 5.174952
--------------------
2025-01-28 12:27:03,943 - decision_tree.py - families considered: 251
2025-01-28 12:27:03,944 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:03,944 - decision_tree.py - families with schedulers preserved: 86
2025-01-28 12:27:03,944 - decision_tree.py - families model checked: 165
2025-01-28 12:27:03,944 - decision_tree.py - harmonizations attempted: 7
2025-01-28 12:27:03,944 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:27:03,944 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:03,944 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=x, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, V_2=picked2, picked1_2=0, picked2_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=3, V_3=picked4, picked1_3=0, picked2_3=0, picked3_3=0, picked4_3=0, picked6_3=0, x_3=3, V_4=picked4, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=3, V_5=picked4, picked1_5=0, picked2_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=3, A_6=r, A_7=l, V_8=picked4, picked1_8=0, picked2_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=3, A_9=__random__, A_10=__random__, V_11=picked4, picked1_11=0, picked2_11=0, picked3_11=0, picked4_11=0, picked6_11=0, x_11=3, V_12=picked4, picked1_12=0, picked2_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=3, A_13=__random__, A_14=d, V_15=picked4, picked1_15=0, picked2_15=0, picked3_15=0, picked4_15=0, picked6_15=0, x_15=3, A_16=__random__, A_17=r, V_18=picked6, picked1_18=0, picked2_18=0, picked3_18=0, picked4_18=0, picked6_18=0, x_18=3, V_19=picked4, picked1_19=0, picked2_19=0, picked3_19=0, picked4_19=0, picked6_19=0, x_19=3, V_20=picked4, picked1_20=0, picked2_20=0, picked3_20=0, picked4_20=0, picked6_20=0, x_20=3, A_21=d, A_22=l, V_23=picked1, picked1_23=0, picked2_23=0, picked3_23=0, picked4_23=0, picked6_23=0, x_23=3, A_24=__random__, A_25=__random__, V_26=picked3, picked1_26=0, picked2_26=0, picked3_26=0, picked4_26=0, picked6_26=0, x_26=3, V_27=picked3, picked1_27=0, picked2_27=0, picked3_27=0, picked4_27=0, picked6_27=0, x_27=3, A_28=r, A_29=__random__, V_30=picked3, picked1_30=0, picked2_30=0, picked3_30=0, picked4_30=0, picked6_30=0, x_30=3, A_31=r, A_32=r, V_33=picked6, picked1_33=0, picked2_33=0, picked3_33=0, picked4_33=0, picked6_33=0, x_33=3, V_34=picked1, picked1_34=0, picked2_34=0, picked3_34=0, picked4_34=0, picked6_34=0, x_34=3, V_35=picked2, picked1_35=0, picked2_35=0, picked3_35=0, picked4_35=0, picked6_35=0, x_35=3, V_36=x, picked1_36=0, picked2_36=0, picked3_36=0, picked4_36=0, picked6_36=0, x_36=3, A_37=l, A_38=l, V_39=picked1, picked1_39=0, picked2_39=0, picked3_39=0, picked4_39=0, picked6_39=0, x_39=3, A_40=__random__, A_41=__random__, V_42=picked1, picked1_42=0, picked2_42=0, picked3_42=0, picked4_42=0, picked6_42=0, x_42=3, V_43=picked1, picked1_43=0, picked2_43=0, picked3_43=0, picked4_43=0, picked6_43=0, x_43=3, A_44=d, A_45=d, V_46=picked6, picked1_46=0, picked2_46=0, picked3_46=0, picked4_46=0, picked6_46=0, x_46=3, A_47=u, A_48=__random__, V_49=picked6, picked1_49=0, picked2_49=0, picked3_49=0, picked4_49=0, picked6_49=0, x_49=3, V_50=picked1, picked1_50=0, picked2_50=0, picked3_50=0, picked4_50=0, picked6_50=0, x_50=3, V_51=picked1, picked1_51=0, picked2_51=0, picked3_51=0, picked4_51=0, picked6_51=0, x_51=3, A_52=__random__, A_53=__random__, V_54=picked1, picked1_54=0, picked2_54=0, picked3_54=0, picked4_54=0, picked6_54=0, x_54=3, A_55=__random__, A_56=__random__, V_57=x, picked1_57=0, picked2_57=0, picked3_57=0, picked4_57=0, picked6_57=0, x_57=8, V_58=picked6, picked1_58=0, picked2_58=0, picked3_58=0, picked4_58=0, picked6_58=0, x_58=3, A_59=__random__, A_60=r, V_61=picked4, picked1_61=0, picked2_61=0, picked3_61=0, picked4_61=0, picked6_61=0, x_61=3, A_62=r, A_63=r, V_64=x, picked1_64=0, picked2_64=0, picked3_64=0, picked4_64=0, picked6_64=0, x_64=3, V_65=x, picked1_65=0, picked2_65=0, picked3_65=0, picked4_65=0, picked6_65=0, x_65=3, V_66=picked2, picked1_66=0, picked2_66=0, picked3_66=0, picked4_66=0, picked6_66=0, x_66=3, V_67=picked2, picked1_67=0, picked2_67=0, picked3_67=0, picked4_67=0, picked6_67=0, x_67=3, V_68=picked4, picked1_68=0, picked2_68=0, picked3_68=0, picked4_68=0, picked6_68=0, x_68=3, A_69=r, A_70=r, V_71=picked4, picked1_71=0, picked2_71=0, picked3_71=0, picked4_71=0, picked6_71=0, x_71=3, A_72=d, A_73=__random__, V_74=picked4, picked1_74=0, picked2_74=0, picked3_74=0, picked4_74=0, picked6_74=0, x_74=3, V_75=x, picked1_75=0, picked2_75=0, picked3_75=0, picked4_75=0, picked6_75=0, x_75=3, A_76=r, A_77=__random__, V_78=picked3, picked1_78=0, picked2_78=0, picked3_78=0, picked4_78=0, picked6_78=0, x_78=3, A_79=r, A_80=u, V_81=picked2, picked1_81=0, picked2_81=0, picked3_81=0, picked4_81=0, picked6_81=0, x_81=3, V_82=picked1, picked1_82=0, picked2_82=0, picked3_82=0, picked4_82=0, picked6_82=0, x_82=3, V_83=picked1, picked1_83=0, picked2_83=0, picked3_83=0, picked4_83=0, picked6_83=0, x_83=3, A_84=__random__, A_85=__random__, V_86=picked1, picked1_86=0, picked2_86=0, picked3_86=0, picked4_86=0, picked6_86=0, x_86=3, A_87=__random__, A_88=__random__, V_89=picked1, picked1_89=0, picked2_89=0, picked3_89=0, picked4_89=0, picked6_89=0, x_89=3, V_90=picked1, picked1_90=0, picked2_90=0, picked3_90=0, picked4_90=0, picked6_90=0, x_90=3, A_91=__random__, A_92=__random__, V_93=picked1, picked1_93=0, picked2_93=0, picked3_93=0, picked4_93=0, picked6_93=0, x_93=3, A_94=__random__, A_95=__random__, V_96=picked3, picked1_96=0, picked2_96=0, picked3_96=0, picked4_96=0, picked6_96=0, x_96=3, V_97=picked3, picked1_97=0, picked2_97=0, picked3_97=0, picked4_97=0, picked6_97=0, x_97=3, V_98=picked3, picked1_98=0, picked2_98=0, picked3_98=0, picked4_98=0, picked6_98=0, x_98=3, V_99=x, picked1_99=0, picked2_99=0, picked3_99=0, picked4_99=0, picked6_99=0, x_99=8, A_100=r, A_101=u, V_102=picked3, picked1_102=0, picked2_102=0, picked3_102=0, picked4_102=0, picked6_102=0, x_102=3, A_103=__random__, A_104=__random__, V_105=picked1, picked1_105=0, picked2_105=0, picked3_105=0, picked4_105=0, picked6_105=0, x_105=3, V_106=picked1, picked1_106=0, picked2_106=0, picked3_106=0, picked4_106=0, picked6_106=0, x_106=3, A_107=__random__, A_108=__random__, V_109=picked1, picked1_109=0, picked2_109=0, picked3_109=0, picked4_109=0, picked6_109=0, x_109=3, A_110=__random__, A_111=__random__, V_112=picked2, picked1_112=0, picked2_112=0, picked3_112=0, picked4_112=0, picked6_112=0, x_112=3, V_113=x, picked1_113=0, picked2_113=0, picked3_113=0, picked4_113=0, picked6_113=0, x_113=8, V_114=picked1, picked1_114=0, picked2_114=0, picked3_114=0, picked4_114=0, picked6_114=0, x_114=3, A_115=__random__, A_116=l, V_117=picked4, picked1_117=0, picked2_117=0, picked3_117=0, picked4_117=0, picked6_117=0, x_117=3, A_118=u, A_119=u, V_120=picked4, picked1_120=0, picked2_120=0, picked3_120=0, picked4_120=0, picked6_120=0, x_120=3, V_121=picked4, picked1_121=0, picked2_121=0, picked3_121=0, picked4_121=0, picked6_121=0, x_121=3, A_122=l, A_123=__random__, V_124=picked4, picked1_124=0, picked2_124=0, picked3_124=0, picked4_124=0, picked6_124=0, x_124=3, A_125=__random__, A_126=l
2025-01-28 12:27:03,959 - decision_tree.py - double-checking specification satisfiability:  : 5.174952058142328
2025-01-28 12:27:03,959 - decision_tree.py - admissible subtree found from node 20
2025-01-28 12:27:03,960 - decision_tree.py - new tree has depth 15 and 126 nodes
2025-01-28 12:27:05,812 - decision_tree.py - new dtcontrol tree has depth 13 and 139 nodes
2025-01-28 12:27:05,813 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:27:05,814 - decision_tree.py - starting iteration 16 with 4 nodes in node queue
2025-01-28 12:27:05,815 - decision_tree.py - current tree size: 253 nodes
2025-01-28 12:27:05,906 - decision_tree.py - subtree quotient has 2039 states and 2375 choices
2025-01-28 12:27:05,913 - mdp.py - MDP has 84/2039 relevant states
2025-01-28 12:27:05,916 - mdp.py - MDP has 5 actions
2025-01-28 12:27:05,932 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[2..8]']

2025-01-28 12:27:05,932 - mdp.py - building tree of depth 0
2025-01-28 12:27:05,938 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:27:03,547 - synthesizer_ar.py - value 5.1463 achieved after 219.17 seconds
2025-01-28 12:27:03,551 - synthesizer_ar.py - value 5.1567 achieved after 219.17 seconds
2025-01-28 12:27:03,694 - synthesizer_ar.py - value 5.1643 achieved after 219.31 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.27 s
number of holes: 1, family size: 5, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 7

optimum: 5.164293
--------------------
2025-01-28 12:27:03,718 - decision_tree.py - families considered: 7
2025-01-28 12:27:03,718 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:03,718 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:27:03,718 - decision_tree.py - families model checked: 7
2025-01-28 12:27:03,718 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:27:03,718 - decision_tree.py - harmonizations succeeded: 3

2025-01-28 12:27:03,718 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:03,718 - decision_tree.py - A_0=__random__
2025-01-28 12:27:03,724 - decision_tree.py - double-checking specification satisfiability:  : 5.164292888407555

2025-01-28 12:27:03,724 - mdp.py - building tree of depth 1
2025-01-28 12:27:03,739 - statistic.py - synthesis initiated, design space: 300
2025-01-28 12:27:04,123 - synthesizer_ar.py - value 5.1647 achieved after 219.74 seconds
2025-01-28 12:27:04,878 - synthesizer_ar.py - value 5.1748 achieved after 220.5 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.25 s
number of holes: 9, family size: 300, quotient: 2039 states / 2375 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 65

optimum: 5.174801
--------------------
2025-01-28 12:27:05,986 - decision_tree.py - families considered: 65
2025-01-28 12:27:05,986 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:05,986 - decision_tree.py - families with schedulers preserved: 10
2025-01-28 12:27:05,986 - decision_tree.py - families model checked: 55
2025-01-28 12:27:05,986 - decision_tree.py - harmonizations attempted: 11
2025-01-28 12:27:05,986 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:27:05,986 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:05,987 - decision_tree.py - V_0=picked6, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=2, A_1=u, A_2=d
2025-01-28 12:27:05,991 - decision_tree.py - double-checking specification satisfiability:  : 5.174800972383377
2025-01-28 12:27:05,991 - decision_tree.py - admissible subtree found from node 138
2025-01-28 12:27:05,998 - decision_tree.py - new tree has depth 15 and 117 nodes
2025-01-28 12:27:07,671 - decision_tree.py - new dtcontrol tree has depth 14 and 129 nodes
2025-01-28 12:27:07,672 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:27:07,673 - decision_tree.py - starting iteration 17 with 3 nodes in node queue
2025-01-28 12:27:07,673 - decision_tree.py - current tree size: 235 nodes
2025-01-28 12:27:07,762 - decision_tree.py - subtree quotient has 2039 states and 2375 choices
2025-01-28 12:27:07,768 - mdp.py - MDP has 84/2039 relevant states
2025-01-28 12:27:07,772 - mdp.py - MDP has 5 actions
2025-01-28 12:27:07,786 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[6..9]']

2025-01-28 12:27:07,786 - mdp.py - building tree of depth 0
2025-01-28 12:27:07,792 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:27:07,879 - synthesizer_ar.py - value 5.1472 achieved after 223.5 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.12 s
number of holes: 1, family size: 5, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.147182
--------------------
2025-01-28 12:27:07,910 - decision_tree.py - families considered: 4
2025-01-28 12:27:07,910 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:07,910 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:27:07,910 - decision_tree.py - families model checked: 4
2025-01-28 12:27:07,910 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:27:07,910 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:27:07,910 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:07,910 - decision_tree.py - A_0=l
2025-01-28 12:27:07,915 - decision_tree.py - double-checking specification satisfiability:  : 5.147182228592187

2025-01-28 12:27:07,915 - mdp.py - building tree of depth 1
2025-01-28 12:27:07,927 - statistic.py - synthesis initiated, design space: 450
2025-01-28 12:27:08,704 - synthesizer_ar.py - value 5.1679 achieved after 224.32 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.45 s
number of holes: 9, family size: 450, quotient: 2039 states / 2375 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 44

optimum: 5.167886
--------------------
2025-01-28 12:27:09,380 - decision_tree.py - families considered: 44
2025-01-28 12:27:09,381 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:09,381 - decision_tree.py - families with schedulers preserved: 8
2025-01-28 12:27:09,381 - decision_tree.py - families model checked: 36
2025-01-28 12:27:09,381 - decision_tree.py - harmonizations attempted: 6
2025-01-28 12:27:09,381 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:27:09,381 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:09,381 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, A_1=r, A_2=l
2025-01-28 12:27:09,386 - decision_tree.py - double-checking specification satisfiability:  : 5.167885590533488

2025-01-28 12:27:09,386 - mdp.py - building tree of depth 2
2025-01-28 12:27:09,405 - statistic.py - synthesis initiated, design space: 1e6
> progress 11.52%, elapsed 3 s, estimated 26 s, iters = {MDP: 74}, opt = 5.1679
2025-01-28 12:27:12,924 - synthesizer_ar.py - value 5.1704 achieved after 228.54 seconds
2025-01-28 12:27:14,532 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.13 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2375 actions
explored: 11 %
MDP stats: avg MDP size: 2039, iterations: 121

optimum: 5.170405
--------------------
2025-01-28 12:27:14,532 - decision_tree.py - families considered: 121
2025-01-28 12:27:14,533 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:14,533 - decision_tree.py - families with schedulers preserved: 24
2025-01-28 12:27:14,533 - decision_tree.py - families model checked: 97
2025-01-28 12:27:14,533 - decision_tree.py - harmonizations attempted: 22
2025-01-28 12:27:14,533 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:27:14,533 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:14,533 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked3, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, A_2=r, A_3=l, V_4=x, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=6, A_5=r, A_6=l
2025-01-28 12:27:14,542 - decision_tree.py - double-checking specification satisfiability:  : 5.170405086043344

2025-01-28 12:27:14,542 - mdp.py - building tree of depth 3
2025-01-28 12:27:14,583 - statistic.py - synthesis initiated, design space: 1e14
2025-01-28 12:27:15,430 - synthesizer_ar.py - value 5.1706 achieved after 231.05 seconds
2025-01-28 12:27:15,436 - synthesizer_ar.py - value 5.1708 achieved after 231.05 seconds
2025-01-28 12:27:17,692 - synthesizer_ar.py - value 5.1718 achieved after 233.31 seconds
> progress 0.001%, elapsed 3 s, estimated 292529 s (3 days), iters = {MDP: 57}, opt = 5.1718
2025-01-28 12:27:19,063 - synthesizer_ar.py - value 5.1719 achieved after 234.68 seconds
2025-01-28 12:27:19,672 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:27:19,673 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.09 s
number of holes: 57, family size: 1e14, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 97

optimum: 5.171924
--------------------
2025-01-28 12:27:19,673 - decision_tree.py - families considered: 97
2025-01-28 12:27:19,673 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:19,673 - decision_tree.py - families with schedulers preserved: 25
2025-01-28 12:27:19,673 - decision_tree.py - families model checked: 72
2025-01-28 12:27:19,673 - decision_tree.py - harmonizations attempted: 14
2025-01-28 12:27:19,673 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:27:19,673 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:19,673 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked3, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=x, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=8, A_3=l, A_4=r, V_5=x, picked0_5=0, picked1_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=6, A_6=r, A_7=l, V_8=x, picked0_8=0, picked1_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=6, V_9=x, picked0_9=0, picked1_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=6, A_10=r, A_11=d, V_12=picked6, picked0_12=0, picked1_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=6, A_13=r, A_14=l
2025-01-28 12:27:19,679 - decision_tree.py - double-checking specification satisfiability:  : 5.171923543361112

2025-01-28 12:27:19,679 - mdp.py - building tree of depth 4
2025-01-28 12:27:19,734 - statistic.py - synthesis initiated, design space: 1e30
> progress 0.0%, elapsed 3 s, estimated 9949105163 s (315 years), iters = {MDP: 57}, opt = 5.1719
2025-01-28 12:27:24,787 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:27:24,788 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.05 s
number of holes: 121, family size: 1e30, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 103

optimum: 5.171924
--------------------
2025-01-28 12:27:24,788 - decision_tree.py - families considered: 103
2025-01-28 12:27:24,788 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:24,788 - decision_tree.py - families with schedulers preserved: 19
2025-01-28 12:27:24,788 - decision_tree.py - families model checked: 84
2025-01-28 12:27:24,788 - decision_tree.py - harmonizations attempted: 20
2025-01-28 12:27:24,788 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:27:24,788 - mdp.py - building tree of depth 5
2025-01-28 12:27:24,899 - statistic.py - synthesis initiated, design space: 1e61
2025-01-28 12:27:25,692 - synthesizer_ar.py - value 5.1722 achieved after 241.31 seconds
> progress 0.0%, elapsed 3 s, estimated 57161105416 s (1812 years), iters = {MDP: 28}, opt = 5.1722
2025-01-28 12:27:29,958 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:27:29,958 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.06 s
number of holes: 249, family size: 1e61, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 54

optimum: 5.172195
--------------------
2025-01-28 12:27:29,959 - decision_tree.py - families considered: 54
2025-01-28 12:27:29,959 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:29,959 - decision_tree.py - families with schedulers preserved: 21
2025-01-28 12:27:29,959 - decision_tree.py - families model checked: 33
2025-01-28 12:27:29,959 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:27:29,959 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:27:29,959 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:29,959 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked3, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=x, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=8, V_3=x, picked0_3=0, picked1_3=0, picked3_3=0, picked4_3=0, picked6_3=0, x_3=7, V_4=x, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=6, A_5=r, A_6=l, V_7=picked1, picked0_7=0, picked1_7=0, picked3_7=0, picked4_7=0, picked6_7=0, x_7=6, A_8=u, A_9=l, V_10=picked3, picked0_10=0, picked1_10=0, picked3_10=0, picked4_10=0, picked6_10=0, x_10=6, V_11=x, picked0_11=0, picked1_11=0, picked3_11=0, picked4_11=0, picked6_11=0, x_11=6, A_12=u, A_13=r, V_14=picked6, picked0_14=0, picked1_14=0, picked3_14=0, picked4_14=0, picked6_14=0, x_14=6, A_15=u, A_16=__random__, V_17=x, picked0_17=0, picked1_17=0, picked3_17=0, picked4_17=0, picked6_17=0, x_17=6, V_18=picked1, picked0_18=0, picked1_18=0, picked3_18=0, picked4_18=0, picked6_18=0, x_18=6, V_19=picked4, picked0_19=0, picked1_19=0, picked3_19=0, picked4_19=0, picked6_19=0, x_19=6, A_20=r, A_21=u, V_22=picked3, picked0_22=0, picked1_22=0, picked3_22=0, picked4_22=0, picked6_22=0, x_22=6, A_23=u, A_24=r, V_25=picked0, picked0_25=0, picked1_25=0, picked3_25=0, picked4_25=0, picked6_25=0, x_25=8, V_26=picked6, picked0_26=0, picked1_26=0, picked3_26=0, picked4_26=0, picked6_26=0, x_26=8, A_27=u, A_28=__random__, V_29=picked1, picked0_29=0, picked1_29=0, picked3_29=0, picked4_29=0, picked6_29=0, x_29=8, A_30=d, A_31=l, V_32=x, picked0_32=0, picked1_32=0, picked3_32=0, picked4_32=0, picked6_32=0, x_32=6, V_33=x, picked0_33=0, picked1_33=0, picked3_33=0, picked4_33=0, picked6_33=0, x_33=6, V_34=picked3, picked0_34=0, picked1_34=0, picked3_34=0, picked4_34=0, picked6_34=0, x_34=6, V_35=picked3, picked0_35=0, picked1_35=0, picked3_35=0, picked4_35=0, picked6_35=0, x_35=6, A_36=r, A_37=l, V_38=x, picked0_38=0, picked1_38=0, picked3_38=0, picked4_38=0, picked6_38=0, x_38=6, A_39=r, A_40=__random__, V_41=picked0, picked0_41=0, picked1_41=0, picked3_41=0, picked4_41=0, picked6_41=0, x_41=6, V_42=picked4, picked0_42=0, picked1_42=0, picked3_42=0, picked4_42=0, picked6_42=0, x_42=6, A_43=__random__, A_44=l, V_45=picked0, picked0_45=0, picked1_45=0, picked3_45=0, picked4_45=0, picked6_45=0, x_45=6, A_46=__random__, A_47=d, V_48=picked6, picked0_48=0, picked1_48=0, picked3_48=0, picked4_48=0, picked6_48=0, x_48=6, V_49=picked0, picked0_49=0, picked1_49=0, picked3_49=0, picked4_49=0, picked6_49=0, x_49=6, V_50=picked0, picked0_50=0, picked1_50=0, picked3_50=0, picked4_50=0, picked6_50=0, x_50=6, A_51=r, A_52=__random__, V_53=picked6, picked0_53=0, picked1_53=0, picked3_53=0, picked4_53=0, picked6_53=0, x_53=6, A_54=l, A_55=l, V_56=picked6, picked0_56=0, picked1_56=0, picked3_56=0, picked4_56=0, picked6_56=0, x_56=6, V_57=picked1, picked0_57=0, picked1_57=0, picked3_57=0, picked4_57=0, picked6_57=0, x_57=6, A_58=d, A_59=r, V_60=picked6, picked0_60=0, picked1_60=0, picked3_60=0, picked4_60=0, picked6_60=0, x_60=6, A_61=d, A_62=l
2025-01-28 12:27:29,970 - decision_tree.py - double-checking specification satisfiability:  : 5.172194605801465

2025-01-28 12:27:29,971 - mdp.py - building tree of depth 6
2025-01-28 12:27:30,228 - statistic.py - synthesis initiated, design space: 1e123
2025-01-28 12:27:32,695 - synthesizer_ar.py - value 5.1749 achieved after 248.31 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.47 s
number of holes: 505, family size: 1e123, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 23

optimum: 5.17493
--------------------
2025-01-28 12:27:32,696 - decision_tree.py - families considered: 23
2025-01-28 12:27:32,696 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:32,696 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 12:27:32,696 - decision_tree.py - families model checked: 17
2025-01-28 12:27:32,696 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:27:32,696 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:27:32,696 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:32,696 - decision_tree.py - V_0=picked3, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked4, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=x, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=7, V_3=picked3, picked0_3=0, picked1_3=0, picked3_3=0, picked4_3=0, picked6_3=0, x_3=8, V_4=x, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=7, V_5=x, picked0_5=0, picked1_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=6, A_6=r, A_7=l, V_8=x, picked0_8=0, picked1_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=7, A_9=l, A_10=__random__, V_11=x, picked0_11=0, picked1_11=0, picked3_11=0, picked4_11=0, picked6_11=0, x_11=8, V_12=picked4, picked0_12=0, picked1_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=6, A_13=__random__, A_14=__random__, V_15=x, picked0_15=0, picked1_15=0, picked3_15=0, picked4_15=0, picked6_15=0, x_15=6, A_16=__random__, A_17=__random__, V_18=x, picked0_18=0, picked1_18=0, picked3_18=0, picked4_18=0, picked6_18=0, x_18=8, V_19=picked6, picked0_19=0, picked1_19=0, picked3_19=0, picked4_19=0, picked6_19=0, x_19=7, V_20=picked1, picked0_20=0, picked1_20=0, picked3_20=0, picked4_20=0, picked6_20=0, x_20=6, A_21=u, A_22=l, V_23=picked1, picked0_23=0, picked1_23=0, picked3_23=0, picked4_23=0, picked6_23=0, x_23=8, A_24=l, A_25=l, V_26=picked0, picked0_26=0, picked1_26=0, picked3_26=0, picked4_26=0, picked6_26=0, x_26=7, V_27=picked1, picked0_27=0, picked1_27=0, picked3_27=0, picked4_27=0, picked6_27=0, x_27=6, A_28=r, A_29=l, V_30=picked4, picked0_30=0, picked1_30=0, picked3_30=0, picked4_30=0, picked6_30=0, x_30=8, A_31=r, A_32=__random__, V_33=picked0, picked0_33=0, picked1_33=0, picked3_33=0, picked4_33=0, picked6_33=0, x_33=8, V_34=x, picked0_34=0, picked1_34=0, picked3_34=0, picked4_34=0, picked6_34=0, x_34=6, V_35=picked4, picked0_35=0, picked1_35=0, picked3_35=0, picked4_35=0, picked6_35=0, x_35=6, V_36=x, picked0_36=0, picked1_36=0, picked3_36=0, picked4_36=0, picked6_36=0, x_36=6, A_37=r, A_38=__random__, V_39=x, picked0_39=0, picked1_39=0, picked3_39=0, picked4_39=0, picked6_39=0, x_39=7, A_40=r, A_41=d, V_42=x, picked0_42=0, picked1_42=0, picked3_42=0, picked4_42=0, picked6_42=0, x_42=8, V_43=x, picked0_43=0, picked1_43=0, picked3_43=0, picked4_43=0, picked6_43=0, x_43=8, A_44=l, A_45=__random__, V_46=picked3, picked0_46=0, picked1_46=0, picked3_46=0, picked4_46=0, picked6_46=0, x_46=7, A_47=r, A_48=__random__, V_49=picked3, picked0_49=0, picked1_49=0, picked3_49=0, picked4_49=0, picked6_49=0, x_49=6, V_50=x, picked0_50=0, picked1_50=0, picked3_50=0, picked4_50=0, picked6_50=0, x_50=7, V_51=x, picked0_51=0, picked1_51=0, picked3_51=0, picked4_51=0, picked6_51=0, x_51=6, A_52=r, A_53=l, V_54=picked1, picked0_54=0, picked1_54=0, picked3_54=0, picked4_54=0, picked6_54=0, x_54=7, A_55=__random__, A_56=r, V_57=picked1, picked0_57=0, picked1_57=0, picked3_57=0, picked4_57=0, picked6_57=0, x_57=6, V_58=x, picked0_58=0, picked1_58=0, picked3_58=0, picked4_58=0, picked6_58=0, x_58=6, A_59=__random__, A_60=__random__, V_61=picked1, picked0_61=0, picked1_61=0, picked3_61=0, picked4_61=0, picked6_61=0, x_61=6, A_62=r, A_63=u, V_64=picked1, picked0_64=0, picked1_64=0, picked3_64=0, picked4_64=0, picked6_64=0, x_64=6, V_65=picked0, picked0_65=0, picked1_65=0, picked3_65=0, picked4_65=0, picked6_65=0, x_65=6, V_66=picked3, picked0_66=0, picked1_66=0, picked3_66=0, picked4_66=0, picked6_66=0, x_66=7, V_67=x, picked0_67=0, picked1_67=0, picked3_67=0, picked4_67=0, picked6_67=0, x_67=6, V_68=picked3, picked0_68=0, picked1_68=0, picked3_68=0, picked4_68=0, picked6_68=0, x_68=6, A_69=r, A_70=r, V_71=x, picked0_71=0, picked1_71=0, picked3_71=0, picked4_71=0, picked6_71=0, x_71=6, A_72=__random__, A_73=l, V_74=x, picked0_74=0, picked1_74=0, picked3_74=0, picked4_74=0, picked6_74=0, x_74=8, V_75=x, picked0_75=0, picked1_75=0, picked3_75=0, picked4_75=0, picked6_75=0, x_75=6, A_76=r, A_77=l, V_78=picked3, picked0_78=0, picked1_78=0, picked3_78=0, picked4_78=0, picked6_78=0, x_78=8, A_79=__random__, A_80=l, V_81=x, picked0_81=0, picked1_81=0, picked3_81=0, picked4_81=0, picked6_81=0, x_81=7, V_82=x, picked0_82=0, picked1_82=0, picked3_82=0, picked4_82=0, picked6_82=0, x_82=6, V_83=x, picked0_83=0, picked1_83=0, picked3_83=0, picked4_83=0, picked6_83=0, x_83=6, A_84=r, A_85=l, V_86=picked4, picked0_86=0, picked1_86=0, picked3_86=0, picked4_86=0, picked6_86=0, x_86=7, A_87=l, A_88=r, V_89=picked6, picked0_89=0, picked1_89=0, picked3_89=0, picked4_89=0, picked6_89=0, x_89=7, V_90=x, picked0_90=0, picked1_90=0, picked3_90=0, picked4_90=0, picked6_90=0, x_90=8, A_91=u, A_92=d, V_93=x, picked0_93=0, picked1_93=0, picked3_93=0, picked4_93=0, picked6_93=0, x_93=8, A_94=r, A_95=d, V_96=picked4, picked0_96=0, picked1_96=0, picked3_96=0, picked4_96=0, picked6_96=0, x_96=6, V_97=picked1, picked0_97=0, picked1_97=0, picked3_97=0, picked4_97=0, picked6_97=0, x_97=6, V_98=picked6, picked0_98=0, picked1_98=0, picked3_98=0, picked4_98=0, picked6_98=0, x_98=7, V_99=picked6, picked0_99=0, picked1_99=0, picked3_99=0, picked4_99=0, picked6_99=0, x_99=8, A_100=__random__, A_101=__random__, V_102=picked6, picked0_102=0, picked1_102=0, picked3_102=0, picked4_102=0, picked6_102=0, x_102=8, A_103=__random__, A_104=d, V_105=picked0, picked0_105=0, picked1_105=0, picked3_105=0, picked4_105=0, picked6_105=0, x_105=8, V_106=x, picked0_106=0, picked1_106=0, picked3_106=0, picked4_106=0, picked6_106=0, x_106=6, A_107=r, A_108=l, V_109=x, picked0_109=0, picked1_109=0, picked3_109=0, picked4_109=0, picked6_109=0, x_109=6, A_110=r, A_111=l, V_112=picked0, picked0_112=0, picked1_112=0, picked3_112=0, picked4_112=0, picked6_112=0, x_112=8, V_113=picked3, picked0_113=0, picked1_113=0, picked3_113=0, picked4_113=0, picked6_113=0, x_113=8, V_114=picked6, picked0_114=0, picked1_114=0, picked3_114=0, picked4_114=0, picked6_114=0, x_114=8, A_115=__random__, A_116=__random__, V_117=x, picked0_117=0, picked1_117=0, picked3_117=0, picked4_117=0, picked6_117=0, x_117=6, A_118=r, A_119=l, V_120=picked6, picked0_120=0, picked1_120=0, picked3_120=0, picked4_120=0, picked6_120=0, x_120=8, V_121=x, picked0_121=0, picked1_121=0, picked3_121=0, picked4_121=0, picked6_121=0, x_121=6, A_122=r, A_123=l, V_124=x, picked0_124=0, picked1_124=0, picked3_124=0, picked4_124=0, picked6_124=0, x_124=6, A_125=u, A_126=l
2025-01-28 12:27:32,712 - decision_tree.py - double-checking specification satisfiability:  : 5.174930352015529
2025-01-28 12:27:32,712 - decision_tree.py - admissible subtree found from node 94
2025-01-28 12:27:32,713 - decision_tree.py - new tree has depth 15 and 142 nodes
2025-01-28 12:27:34,520 - decision_tree.py - new dtcontrol tree has depth 15 and 149 nodes
2025-01-28 12:27:34,521 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:27:34,522 - decision_tree.py - starting iteration 18 with 2 nodes in node queue
2025-01-28 12:27:34,523 - decision_tree.py - current tree size: 235 nodes
2025-01-28 12:27:34,651 - decision_tree.py - subtree quotient has 2039 states and 2487 choices
2025-01-28 12:27:34,659 - mdp.py - MDP has 112/2039 relevant states
2025-01-28 12:27:34,663 - mdp.py - MDP has 5 actions
2025-01-28 12:27:34,680 - mdp.py - found the following 7 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[1..3]', 'y:[0..1]']

2025-01-28 12:27:34,680 - mdp.py - building tree of depth 0
2025-01-28 12:27:34,686 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:27:34,786 - synthesizer_ar.py - value 5.1638 achieved after 250.41 seconds
2025-01-28 12:27:34,793 - synthesizer_ar.py - value 5.1747 achieved after 250.41 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 1, family size: 5, quotient: 2039 states / 2487 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.174677
--------------------
2025-01-28 12:27:34,813 - decision_tree.py - families considered: 4
2025-01-28 12:27:34,813 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:34,813 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:27:34,813 - decision_tree.py - families model checked: 4
2025-01-28 12:27:34,813 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:27:34,813 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:27:34,813 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:34,813 - decision_tree.py - A_0=u
2025-01-28 12:27:34,819 - decision_tree.py - double-checking specification satisfiability:  : 5.174676931240249
2025-01-28 12:27:34,819 - decision_tree.py - admissible subtree found from node 6
2025-01-28 12:27:34,819 - decision_tree.py - new tree has depth 15 and 111 nodes
2025-01-28 12:27:34,235 - decision_tree.py - new dtcontrol tree has depth 15 and 120 nodes
2025-01-28 12:27:34,236 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:27:34,238 - decision_tree.py - starting iteration 19 with 1 nodes in node queue
2025-01-28 12:27:34,238 - decision_tree.py - current tree size: 223 nodes
2025-01-28 12:27:34,325 - decision_tree.py - subtree quotient has 2039 states and 2935 choices
2025-01-28 12:27:34,334 - mdp.py - MDP has 224/2039 relevant states
2025-01-28 12:27:34,339 - mdp.py - MDP has 5 actions
2025-01-28 12:27:34,361 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[0..7]']

2025-01-28 12:27:34,361 - mdp.py - building tree of depth 0
2025-01-28 12:27:34,368 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:27:34,470 - synthesizer_ar.py - value 5.1747 achieved after 252.57 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.14 s
number of holes: 1, family size: 5, quotient: 2039 states / 2935 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.174677
--------------------
2025-01-28 12:27:34,505 - decision_tree.py - families considered: 4
2025-01-28 12:27:34,505 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:34,505 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:27:34,505 - decision_tree.py - families model checked: 4
2025-01-28 12:27:34,505 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:27:34,505 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:27:34,505 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:34,505 - decision_tree.py - A_0=r
2025-01-28 12:27:34,510 - decision_tree.py - double-checking specification satisfiability:  : 5.174676931240249
2025-01-28 12:27:34,510 - decision_tree.py - admissible subtree found from node 138
2025-01-28 12:27:34,511 - decision_tree.py - new tree has depth 15 and 105 nodes
2025-01-28 12:27:36,247 - decision_tree.py - new dtcontrol tree has depth 15 and 114 nodes
2025-01-28 12:27:36,247 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:27:36,248 - decision_tree.py - starting iteration with subtree depth 6
2025-01-28 12:27:36,257 - decision_tree.py - starting iteration 20 with 5 nodes in node queue
2025-01-28 12:27:36,257 - decision_tree.py - current tree size: 211 nodes
2025-01-28 12:27:36,341 - decision_tree.py - subtree quotient has 2039 states and 3159 choices
2025-01-28 12:27:36,347 - mdp.py - MDP has 280/2039 relevant states
2025-01-28 12:27:36,352 - mdp.py - MDP has 5 actions
2025-01-28 12:27:36,365 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[0..9]']

2025-01-28 12:27:36,365 - mdp.py - building tree of depth 0
2025-01-28 12:27:36,370 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 1, family size: 5, quotient: 2039 states / 3159 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:27:36,502 - decision_tree.py - families considered: 4
2025-01-28 12:27:36,502 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:36,502 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:27:36,502 - decision_tree.py - families model checked: 4
2025-01-28 12:27:36,502 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:27:36,502 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:27:36,502 - mdp.py - building tree of depth 1
2025-01-28 12:27:36,522 - statistic.py - synthesis initiated, design space: 1350
2025-01-28 12:27:37,274 - synthesizer_ar.py - value 5.1362 achieved after 255.37 seconds
2025-01-28 12:27:37,575 - synthesizer_ar.py - value 5.1596 achieved after 255.67 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.32 s
number of holes: 9, family size: 1350, quotient: 2039 states / 3159 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 33

optimum: 5.15958
--------------------
2025-01-28 12:27:37,846 - decision_tree.py - families considered: 33
2025-01-28 12:27:37,846 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:37,846 - decision_tree.py - families with schedulers preserved: 3
2025-01-28 12:27:37,846 - decision_tree.py - families model checked: 30
2025-01-28 12:27:37,846 - decision_tree.py - harmonizations attempted: 8
2025-01-28 12:27:37,846 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:27:37,846 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:37,846 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=0, A_1=r, A_2=u
2025-01-28 12:27:37,856 - decision_tree.py - double-checking specification satisfiability:  : 5.159579836738542

2025-01-28 12:27:37,857 - mdp.py - building tree of depth 2
2025-01-28 12:27:37,899 - statistic.py - synthesis initiated, design space: 1e7
2025-01-28 12:27:38,429 - synthesizer_ar.py - value 5.1609 achieved after 256.53 seconds
2025-01-28 12:27:40,366 - synthesizer_ar.py - value 5.1747 achieved after 258.47 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.91 s
number of holes: 25, family size: 1e7, quotient: 2039 states / 3159 actions
explored: 116 %
MDP stats: avg MDP size: 2039, iterations: 60

optimum: 5.174663
--------------------
2025-01-28 12:27:40,809 - decision_tree.py - families considered: 60
2025-01-28 12:27:40,809 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:40,809 - decision_tree.py - families with schedulers preserved: 16
2025-01-28 12:27:40,809 - decision_tree.py - families model checked: 44
2025-01-28 12:27:40,809 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:27:40,809 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:27:40,809 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:40,809 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=0, V_1=picked6, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=0, A_2=r, A_3=r, V_4=x, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=8, A_5=r, A_6=u
2025-01-28 12:27:40,815 - decision_tree.py - double-checking specification satisfiability:  : 5.174663193608655
2025-01-28 12:27:40,815 - decision_tree.py - admissible subtree found from node 27
2025-01-28 12:27:40,816 - decision_tree.py - new tree has depth 15 and 100 nodes
2025-01-28 12:27:42,533 - decision_tree.py - new dtcontrol tree has depth 15 and 114 nodes
2025-01-28 12:27:42,533 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:27:42,534 - decision_tree.py - starting iteration 21 with 4 nodes in node queue
2025-01-28 12:27:42,535 - decision_tree.py - current tree size: 201 nodes
2025-01-28 12:27:42,617 - decision_tree.py - subtree quotient has 2039 states and 2399 choices
2025-01-28 12:27:42,623 - mdp.py - MDP has 90/2039 relevant states
2025-01-28 12:27:42,626 - mdp.py - MDP has 5 actions
2025-01-28 12:27:42,640 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'x:[12..14]', 'y:[2..4]']

2025-01-28 12:27:42,640 - mdp.py - building tree of depth 0
2025-01-28 12:27:42,644 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.11 s
number of holes: 1, family size: 5, quotient: 2039 states / 2399 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:27:42,757 - decision_tree.py - families considered: 4
2025-01-28 12:27:42,757 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:42,757 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:27:42,757 - decision_tree.py - families model checked: 4
2025-01-28 12:27:42,757 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:27:42,757 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:27:42,757 - mdp.py - building tree of depth 1
2025-01-28 12:27:42,768 - statistic.py - synthesis initiated, design space: 700
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.16 s
number of holes: 10, family size: 700, quotient: 2039 states / 2399 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 37

optimum: 5.127782
--------------------
2025-01-28 12:27:43,929 - decision_tree.py - families considered: 37
2025-01-28 12:27:43,929 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:43,929 - decision_tree.py - families with schedulers preserved: 9
2025-01-28 12:27:43,929 - decision_tree.py - families model checked: 28
2025-01-28 12:27:43,929 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:27:43,929 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:27:43,930 - mdp.py - building tree of depth 2
2025-01-28 12:27:43,949 - statistic.py - synthesis initiated, design space: 1e7
> progress 24.897%, elapsed 3 s, estimated 12 s, iters = {MDP: 87}, opt = 5.1278
2025-01-28 12:27:48,403 - synthesizer_ar.py - value 5.14 achieved after 266.5 seconds
2025-01-28 12:27:50,055 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.11 s
number of holes: 28, family size: 1e7, quotient: 2039 states / 2399 actions
explored: 30 %
MDP stats: avg MDP size: 2039, iterations: 161

optimum: 5.140029
--------------------
2025-01-28 12:27:50,055 - decision_tree.py - families considered: 161
2025-01-28 12:27:50,055 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:50,055 - decision_tree.py - families with schedulers preserved: 36
2025-01-28 12:27:50,055 - decision_tree.py - families model checked: 125
2025-01-28 12:27:50,055 - decision_tree.py - harmonizations attempted: 22
2025-01-28 12:27:50,055 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:27:50,056 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:50,056 - decision_tree.py - V_0=y, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=12, y_0=2, V_1=picked6, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, x_1=12, y_1=2, A_2=l, A_3=l, V_4=x, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked6_4=0, x_4=12, y_4=2, A_5=d, A_6=l
2025-01-28 12:27:50,062 - decision_tree.py - double-checking specification satisfiability:  : 5.140028858542158

2025-01-28 12:27:50,063 - mdp.py - building tree of depth 3
2025-01-28 12:27:50,100 - statistic.py - synthesis initiated, design space: 1e15
2025-01-28 12:27:51,150 - synthesizer_ar.py - value 5.1426 achieved after 269.25 seconds
> progress 0.031%, elapsed 3 s, estimated 9966 s (2 hours), iters = {MDP: 70}, opt = 5.1426
2025-01-28 12:27:53,565 - synthesizer_ar.py - value 5.1558 achieved after 271.66 seconds
2025-01-28 12:27:54,012 - synthesizer_ar.py - value 5.156 achieved after 272.11 seconds
2025-01-28 12:27:56,058 - synthesizer_ar.py - value 5.1727 achieved after 274.16 seconds
2025-01-28 12:27:56,330 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:27:56,330 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.23 s
number of holes: 64, family size: 1e15, quotient: 2039 states / 2399 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 126

optimum: 5.172722
--------------------
2025-01-28 12:27:56,331 - decision_tree.py - families considered: 126
2025-01-28 12:27:56,331 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:27:56,331 - decision_tree.py - families with schedulers preserved: 29
2025-01-28 12:27:56,331 - decision_tree.py - families model checked: 97
2025-01-28 12:27:56,331 - decision_tree.py - harmonizations attempted: 17
2025-01-28 12:27:56,331 - decision_tree.py - harmonizations succeeded: 4

2025-01-28 12:27:56,331 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:27:56,331 - decision_tree.py - V_0=y, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=12, y_0=2, V_1=picked6, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, x_1=12, y_1=2, V_2=x, picked0_2=0, picked1_2=0, picked2_2=0, picked3_2=0, picked6_2=0, x_2=12, y_2=2, A_3=u, A_4=u, V_5=picked3, picked0_5=0, picked1_5=0, picked2_5=0, picked3_5=0, picked6_5=0, x_5=12, y_5=2, A_6=u, A_7=l, V_8=x, picked0_8=0, picked1_8=0, picked2_8=0, picked3_8=0, picked6_8=0, x_8=12, y_8=2, V_9=picked1, picked0_9=0, picked1_9=0, picked2_9=0, picked3_9=0, picked6_9=0, x_9=12, y_9=2, A_10=d, A_11=l, V_12=picked1, picked0_12=0, picked1_12=0, picked2_12=0, picked3_12=0, picked6_12=0, x_12=12, y_12=2, A_13=l, A_14=l
2025-01-28 12:27:56,354 - decision_tree.py - double-checking specification satisfiability:  : 5.1727220731449775

2025-01-28 12:27:56,355 - mdp.py - building tree of depth 4
2025-01-28 12:27:56,484 - statistic.py - synthesis initiated, design space: 1e32
2025-01-28 12:27:58,917 - synthesizer_ar.py - value 5.1747 achieved after 277.02 seconds
> progress 0.0%, elapsed 3 s, estimated 12317933948 s (390 years), iters = {MDP: 31}, opt = 5.1747
2025-01-28 12:28:02,513 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:28:02,514 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.03 s
number of holes: 136, family size: 1e32, quotient: 2039 states / 2399 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 83

optimum: 5.174674
--------------------
2025-01-28 12:28:02,514 - decision_tree.py - families considered: 83
2025-01-28 12:28:02,514 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:02,514 - decision_tree.py - families with schedulers preserved: 23
2025-01-28 12:28:02,514 - decision_tree.py - families model checked: 60
2025-01-28 12:28:02,514 - decision_tree.py - harmonizations attempted: 6
2025-01-28 12:28:02,514 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:28:02,514 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:28:02,514 - decision_tree.py - V_0=y, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=12, y_0=2, V_1=picked6, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, x_1=12, y_1=2, V_2=x, picked0_2=0, picked1_2=0, picked2_2=0, picked3_2=0, picked6_2=0, x_2=12, y_2=2, V_3=picked1, picked0_3=0, picked1_3=0, picked2_3=0, picked3_3=0, picked6_3=0, x_3=12, y_3=2, A_4=l, A_5=u, V_6=picked0, picked0_6=0, picked1_6=0, picked2_6=0, picked3_6=0, picked6_6=0, x_6=12, y_6=2, A_7=__random__, A_8=d, V_9=picked3, picked0_9=0, picked1_9=0, picked2_9=0, picked3_9=0, picked6_9=0, x_9=12, y_9=2, V_10=picked1, picked0_10=0, picked1_10=0, picked2_10=0, picked3_10=0, picked6_10=0, x_10=12, y_10=2, A_11=__random__, A_12=u, V_13=y, picked0_13=0, picked1_13=0, picked2_13=0, picked3_13=0, picked6_13=0, x_13=12, y_13=2, A_14=l, A_15=__random__, V_16=x, picked0_16=0, picked1_16=0, picked2_16=0, picked3_16=0, picked6_16=0, x_16=12, y_16=2, V_17=picked1, picked0_17=0, picked1_17=0, picked2_17=0, picked3_17=0, picked6_17=0, x_17=12, y_17=2, V_18=picked6, picked0_18=0, picked1_18=0, picked2_18=0, picked3_18=0, picked6_18=0, x_18=12, y_18=2, A_19=d, A_20=d, V_21=y, picked0_21=0, picked1_21=0, picked2_21=0, picked3_21=0, picked6_21=0, x_21=12, y_21=3, A_22=u, A_23=l, V_24=picked1, picked0_24=0, picked1_24=0, picked2_24=0, picked3_24=0, picked6_24=0, x_24=12, y_24=2, V_25=picked6, picked0_25=0, picked1_25=0, picked2_25=0, picked3_25=0, picked6_25=0, x_25=12, y_25=2, A_26=l, A_27=l, V_28=x, picked0_28=0, picked1_28=0, picked2_28=0, picked3_28=0, picked6_28=0, x_28=13, y_28=2, A_29=l, A_30=l
2025-01-28 12:28:02,523 - decision_tree.py - double-checking specification satisfiability:  : 5.17467446869925
2025-01-28 12:28:02,523 - decision_tree.py - admissible subtree found from node 167
2025-01-28 12:28:02,527 - decision_tree.py - new tree has depth 15 and 96 nodes
2025-01-28 12:28:04,379 - decision_tree.py - new dtcontrol tree has depth 15 and 117 nodes
2025-01-28 12:28:04,379 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:28:04,381 - decision_tree.py - starting iteration 22 with 3 nodes in node queue
2025-01-28 12:28:04,381 - decision_tree.py - current tree size: 193 nodes
2025-01-28 12:28:04,478 - decision_tree.py - subtree quotient has 2039 states and 2375 choices
2025-01-28 12:28:04,486 - mdp.py - MDP has 84/2039 relevant states
2025-01-28 12:28:04,490 - mdp.py - MDP has 5 actions
2025-01-28 12:28:04,512 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[6..9]']

2025-01-28 12:28:04,512 - mdp.py - building tree of depth 0
2025-01-28 12:28:04,519 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.23 s
number of holes: 1, family size: 5, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:28:04,750 - decision_tree.py - families considered: 4
2025-01-28 12:28:04,750 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:04,750 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:28:04,750 - decision_tree.py - families model checked: 4
2025-01-28 12:28:04,750 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:28:04,750 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:28:04,750 - mdp.py - building tree of depth 1
2025-01-28 12:28:04,769 - statistic.py - synthesis initiated, design space: 450
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.94 s
number of holes: 9, family size: 450, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 47

optimum: 5.127782
--------------------
2025-01-28 12:28:04,230 - decision_tree.py - families considered: 47
2025-01-28 12:28:04,230 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:04,230 - decision_tree.py - families with schedulers preserved: 7
2025-01-28 12:28:04,230 - decision_tree.py - families model checked: 40
2025-01-28 12:28:04,231 - decision_tree.py - harmonizations attempted: 9
2025-01-28 12:28:04,231 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:28:04,231 - mdp.py - building tree of depth 2
2025-01-28 12:28:04,250 - statistic.py - synthesis initiated, design space: 1e6
> progress 0.379%, elapsed 3 s, estimated 791 s, iters = {MDP: 54}, opt = 5.1278
2025-01-28 12:28:10,297 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.05 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2375 actions
explored: 3 %
MDP stats: avg MDP size: 2039, iterations: 120

optimum: 5.127782
--------------------
2025-01-28 12:28:10,297 - decision_tree.py - families considered: 120
2025-01-28 12:28:10,297 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:10,297 - decision_tree.py - families with schedulers preserved: 19
2025-01-28 12:28:10,297 - decision_tree.py - families model checked: 101
2025-01-28 12:28:10,297 - decision_tree.py - harmonizations attempted: 24
2025-01-28 12:28:10,297 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:28:10,298 - mdp.py - building tree of depth 3
2025-01-28 12:28:10,329 - statistic.py - synthesis initiated, design space: 1e14
2025-01-28 12:28:10,870 - synthesizer_ar.py - value 5.1525 achieved after 291.45 seconds
2025-01-28 12:28:11,563 - synthesizer_ar.py - value 5.1543 achieved after 292.14 seconds
> progress 2.802%, elapsed 3 s, estimated 110 s, iters = {MDP: 62}, opt = 5.1543
2025-01-28 12:28:13,585 - synthesizer_ar.py - value 5.1743 achieved after 294.17 seconds
2025-01-28 12:28:16,383 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.05 s
number of holes: 57, family size: 1e14, quotient: 2039 states / 2375 actions
explored: 5 %
MDP stats: avg MDP size: 2039, iterations: 137

optimum: 5.174322
--------------------
2025-01-28 12:28:16,384 - decision_tree.py - families considered: 137
2025-01-28 12:28:16,384 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:16,384 - decision_tree.py - families with schedulers preserved: 38
2025-01-28 12:28:16,384 - decision_tree.py - families model checked: 99
2025-01-28 12:28:16,384 - decision_tree.py - harmonizations attempted: 12
2025-01-28 12:28:16,384 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:28:16,384 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:28:16,384 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=x, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=8, V_2=x, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=7, A_3=r, A_4=u, V_5=picked3, picked0_5=0, picked1_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=8, A_6=r, A_7=l, V_8=picked4, picked0_8=0, picked1_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=6, V_9=picked6, picked0_9=0, picked1_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=6, A_10=d, A_11=r, V_12=x, picked0_12=0, picked1_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=8, A_13=r, A_14=d
2025-01-28 12:28:16,392 - decision_tree.py - double-checking specification satisfiability:  : 5.174321878333321

2025-01-28 12:28:16,392 - mdp.py - building tree of depth 4
2025-01-28 12:28:16,457 - statistic.py - synthesis initiated, design space: 1e30
> progress 0.154%, elapsed 3 s, estimated 1988 s, iters = {MDP: 58}, opt = 5.1743
2025-01-28 12:28:22,516 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.06 s
number of holes: 121, family size: 1e30, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 113

optimum: 5.174322
--------------------
2025-01-28 12:28:22,517 - decision_tree.py - families considered: 113
2025-01-28 12:28:22,517 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:22,517 - decision_tree.py - families with schedulers preserved: 32
2025-01-28 12:28:22,517 - decision_tree.py - families model checked: 81
2025-01-28 12:28:22,517 - decision_tree.py - harmonizations attempted: 10
2025-01-28 12:28:22,517 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:28:22,517 - mdp.py - building tree of depth 5
2025-01-28 12:28:22,644 - statistic.py - synthesis initiated, design space: 1e61
> progress 0.0%, elapsed 3 s, estimated 68216598 s (2 years), iters = {MDP: 54}, opt = 5.1743
> progress 0.0%, elapsed 6 s, estimated 72492816 s (2 years), iters = {MDP: 105}, opt = 5.1743
> progress 0.0%, elapsed 9 s, estimated 97030162 s (3 years), iters = {MDP: 148}, opt = 5.1743
> progress 0.0%, elapsed 12 s, estimated 118597926 s (3 years), iters = {MDP: 191}, opt = 5.1743
> progress 0.0%, elapsed 15 s, estimated 135985143 s (4 years), iters = {MDP: 240}, opt = 5.1743
2025-01-28 12:28:38,172 - synthesizer_ar.py - value 5.1748 achieved after 321.23 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 18.01 s
number of holes: 249, family size: 1e61, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 285

optimum: 5.174822
--------------------
2025-01-28 12:28:38,172 - decision_tree.py - families considered: 285
2025-01-28 12:28:38,172 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:38,172 - decision_tree.py - families with schedulers preserved: 95
2025-01-28 12:28:38,172 - decision_tree.py - families model checked: 190
2025-01-28 12:28:38,172 - decision_tree.py - harmonizations attempted: 5
2025-01-28 12:28:38,172 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:28:38,172 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:28:38,173 - decision_tree.py - V_0=picked1, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=8, V_1=picked6, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=picked3, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=6, V_3=x, picked0_3=0, picked1_3=0, picked3_3=0, picked4_3=0, picked6_3=0, x_3=7, V_4=picked0, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=6, A_5=l, A_6=r, V_7=x, picked0_7=0, picked1_7=0, picked3_7=0, picked4_7=0, picked6_7=0, x_7=8, A_8=u, A_9=r, V_10=x, picked0_10=0, picked1_10=0, picked3_10=0, picked4_10=0, picked6_10=0, x_10=7, V_11=picked4, picked0_11=0, picked1_11=0, picked3_11=0, picked4_11=0, picked6_11=0, x_11=6, A_12=r, A_13=r, V_14=x, picked0_14=0, picked1_14=0, picked3_14=0, picked4_14=0, picked6_14=0, x_14=8, A_15=u, A_16=l, V_17=x, picked0_17=0, picked1_17=0, picked3_17=0, picked4_17=0, picked6_17=0, x_17=8, V_18=picked1, picked0_18=0, picked1_18=0, picked3_18=0, picked4_18=0, picked6_18=0, x_18=8, V_19=picked1, picked0_19=0, picked1_19=0, picked3_19=0, picked4_19=0, picked6_19=0, x_19=6, A_20=r, A_21=l, V_22=picked1, picked0_22=0, picked1_22=0, picked3_22=0, picked4_22=0, picked6_22=0, x_22=8, A_23=u, A_24=__random__, V_25=picked0, picked0_25=0, picked1_25=0, picked3_25=0, picked4_25=0, picked6_25=0, x_25=8, V_26=picked3, picked0_26=0, picked1_26=0, picked3_26=0, picked4_26=0, picked6_26=0, x_26=7, A_27=r, A_28=d, V_29=picked4, picked0_29=0, picked1_29=0, picked3_29=0, picked4_29=0, picked6_29=0, x_29=8, A_30=r, A_31=d, V_32=picked0, picked0_32=0, picked1_32=0, picked3_32=0, picked4_32=0, picked6_32=0, x_32=6, V_33=picked4, picked0_33=0, picked1_33=0, picked3_33=0, picked4_33=0, picked6_33=0, x_33=7, V_34=x, picked0_34=0, picked1_34=0, picked3_34=0, picked4_34=0, picked6_34=0, x_34=8, V_35=picked1, picked0_35=0, picked1_35=0, picked3_35=0, picked4_35=0, picked6_35=0, x_35=8, A_36=l, A_37=r, V_38=picked1, picked0_38=0, picked1_38=0, picked3_38=0, picked4_38=0, picked6_38=0, x_38=8, A_39=__random__, A_40=r, V_41=picked3, picked0_41=0, picked1_41=0, picked3_41=0, picked4_41=0, picked6_41=0, x_41=8, V_42=picked1, picked0_42=0, picked1_42=0, picked3_42=0, picked4_42=0, picked6_42=0, x_42=7, A_43=__random__, A_44=r, V_45=x, picked0_45=0, picked1_45=0, picked3_45=0, picked4_45=0, picked6_45=0, x_45=8, A_46=r, A_47=d, V_48=picked6, picked0_48=0, picked1_48=0, picked3_48=0, picked4_48=0, picked6_48=0, x_48=8, V_49=x, picked0_49=0, picked1_49=0, picked3_49=0, picked4_49=0, picked6_49=0, x_49=8, V_50=x, picked0_50=0, picked1_50=0, picked3_50=0, picked4_50=0, picked6_50=0, x_50=7, A_51=r, A_52=u, V_53=picked3, picked0_53=0, picked1_53=0, picked3_53=0, picked4_53=0, picked6_53=0, x_53=8, A_54=r, A_55=l, V_56=picked4, picked0_56=0, picked1_56=0, picked3_56=0, picked4_56=0, picked6_56=0, x_56=8, V_57=picked0, picked0_57=0, picked1_57=0, picked3_57=0, picked4_57=0, picked6_57=0, x_57=8, A_58=__random__, A_59=r, V_60=picked3, picked0_60=0, picked1_60=0, picked3_60=0, picked4_60=0, picked6_60=0, x_60=6, A_61=r, A_62=u
2025-01-28 12:28:38,184 - decision_tree.py - double-checking specification satisfiability:  : 5.174821849355178
2025-01-28 12:28:38,184 - decision_tree.py - admissible subtree found from node 89
2025-01-28 12:28:38,192 - decision_tree.py - new tree has depth 15 and 107 nodes
2025-01-28 12:28:40,024 - decision_tree.py - new dtcontrol tree has depth 15 and 127 nodes
2025-01-28 12:28:40,024 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:28:40,026 - decision_tree.py - starting iteration 23 with 2 nodes in node queue
2025-01-28 12:28:40,026 - decision_tree.py - current tree size: 193 nodes
2025-01-28 12:28:40,131 - decision_tree.py - subtree quotient has 2039 states and 2327 choices
2025-01-28 12:28:40,139 - mdp.py - MDP has 72/2039 relevant states
2025-01-28 12:28:40,143 - mdp.py - MDP has 5 actions
2025-01-28 12:28:40,160 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'x:[10..11]', 'y:[2..4]']

2025-01-28 12:28:40,160 - mdp.py - building tree of depth 0
2025-01-28 12:28:40,165 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:28:40,267 - synthesizer_ar.py - value 5.1744 achieved after 323.33 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.15 s
number of holes: 1, family size: 5, quotient: 2039 states / 2327 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.174412
--------------------
2025-01-28 12:28:40,311 - decision_tree.py - families considered: 4
2025-01-28 12:28:40,311 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:40,311 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:28:40,311 - decision_tree.py - families model checked: 4
2025-01-28 12:28:40,311 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:28:40,311 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:28:40,311 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:28:40,312 - decision_tree.py - A_0=l
2025-01-28 12:28:40,318 - decision_tree.py - double-checking specification satisfiability:  : 5.1744120574572205
2025-01-28 12:28:40,319 - decision_tree.py - admissible subtree found from node 148
2025-01-28 12:28:40,319 - decision_tree.py - new tree has depth 15 and 87 nodes
2025-01-28 12:28:42,170 - decision_tree.py - new dtcontrol tree has depth 15 and 99 nodes
2025-01-28 12:28:42,170 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:28:42,172 - decision_tree.py - starting iteration 24 with 1 nodes in node queue
2025-01-28 12:28:42,172 - decision_tree.py - current tree size: 175 nodes
2025-01-28 12:28:42,286 - decision_tree.py - subtree quotient has 2039 states and 2375 choices
2025-01-28 12:28:42,294 - mdp.py - MDP has 84/2039 relevant states
2025-01-28 12:28:42,297 - mdp.py - MDP has 5 actions
2025-01-28 12:28:42,313 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[6..9]']

2025-01-28 12:28:42,313 - mdp.py - building tree of depth 0
2025-01-28 12:28:42,318 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:28:42,421 - synthesizer_ar.py - value 5.1465 achieved after 325.48 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.14 s
number of holes: 1, family size: 5, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.146506
--------------------
2025-01-28 12:28:42,460 - decision_tree.py - families considered: 4
2025-01-28 12:28:42,460 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:42,460 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:28:42,460 - decision_tree.py - families model checked: 4
2025-01-28 12:28:42,460 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:28:42,460 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:28:42,460 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:28:42,460 - decision_tree.py - A_0=l
2025-01-28 12:28:42,467 - decision_tree.py - double-checking specification satisfiability:  : 5.1465064300250765

2025-01-28 12:28:42,467 - mdp.py - building tree of depth 1
2025-01-28 12:28:42,481 - statistic.py - synthesis initiated, design space: 450
2025-01-28 12:28:43,441 - synthesizer_ar.py - value 5.1672 achieved after 326.5 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.75 s
number of holes: 9, family size: 450, quotient: 2039 states / 2375 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 44

optimum: 5.167204
--------------------
2025-01-28 12:28:44,227 - decision_tree.py - families considered: 44
2025-01-28 12:28:44,227 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:44,227 - decision_tree.py - families with schedulers preserved: 8
2025-01-28 12:28:44,228 - decision_tree.py - families model checked: 36
2025-01-28 12:28:44,228 - decision_tree.py - harmonizations attempted: 6
2025-01-28 12:28:44,228 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:28:44,228 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:28:44,228 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, A_1=r, A_2=l
2025-01-28 12:28:44,235 - decision_tree.py - double-checking specification satisfiability:  : 5.167204427727532

2025-01-28 12:28:44,236 - mdp.py - building tree of depth 2
2025-01-28 12:28:44,258 - statistic.py - synthesis initiated, design space: 1e6
> progress 13.37%, elapsed 3 s, estimated 22 s, iters = {MDP: 65}, opt = 5.1672
2025-01-28 12:28:48,430 - synthesizer_ar.py - value 5.1699 achieved after 331.49 seconds
2025-01-28 12:28:50,277 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.02 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2375 actions
explored: 27 %
MDP stats: avg MDP size: 2039, iterations: 141

optimum: 5.169856
--------------------
2025-01-28 12:28:50,277 - decision_tree.py - families considered: 141
2025-01-28 12:28:50,278 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:50,278 - decision_tree.py - families with schedulers preserved: 26
2025-01-28 12:28:50,278 - decision_tree.py - families model checked: 115
2025-01-28 12:28:50,278 - decision_tree.py - harmonizations attempted: 24
2025-01-28 12:28:50,278 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:28:50,278 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:28:50,278 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked3, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, A_2=r, A_3=l, V_4=x, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=6, A_5=r, A_6=l
2025-01-28 12:28:50,283 - decision_tree.py - double-checking specification satisfiability:  : 5.169855792288361

2025-01-28 12:28:50,284 - mdp.py - building tree of depth 3
2025-01-28 12:28:50,315 - statistic.py - synthesis initiated, design space: 1e14
2025-01-28 12:28:51,471 - synthesizer_ar.py - value 5.1701 achieved after 334.53 seconds
2025-01-28 12:28:52,475 - synthesizer_ar.py - value 5.1712 achieved after 335.53 seconds
> progress 0.001%, elapsed 3 s, estimated 295755 s (3 days), iters = {MDP: 63}, opt = 5.1712
2025-01-28 12:28:55,026 - synthesizer_ar.py - value 5.1714 achieved after 338.08 seconds
2025-01-28 12:28:56,332 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:28:56,332 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.02 s
number of holes: 57, family size: 1e14, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 136

optimum: 5.171359
--------------------
2025-01-28 12:28:56,332 - decision_tree.py - families considered: 136
2025-01-28 12:28:56,332 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:28:56,332 - decision_tree.py - families with schedulers preserved: 38
2025-01-28 12:28:56,332 - decision_tree.py - families model checked: 98
2025-01-28 12:28:56,332 - decision_tree.py - harmonizations attempted: 12
2025-01-28 12:28:56,332 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:28:56,332 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:28:56,332 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked3, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=x, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=8, A_3=l, A_4=r, V_5=x, picked0_5=0, picked1_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=6, A_6=r, A_7=l, V_8=x, picked0_8=0, picked1_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=6, V_9=x, picked0_9=0, picked1_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=6, A_10=r, A_11=__random__, V_12=picked6, picked0_12=0, picked1_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=6, A_13=r, A_14=l
2025-01-28 12:28:56,339 - decision_tree.py - double-checking specification satisfiability:  : 5.171359082432742

2025-01-28 12:28:56,340 - mdp.py - building tree of depth 4
2025-01-28 12:28:56,400 - statistic.py - synthesis initiated, design space: 1e30
2025-01-28 12:28:58,576 - synthesizer_ar.py - value 5.1716 achieved after 341.64 seconds
> progress 0.0%, elapsed 3 s, estimated 330442001 s (10 years), iters = {MDP: 51}, opt = 5.1716
2025-01-28 12:29:02,482 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.08 s
number of holes: 121, family size: 1e30, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 99

optimum: 5.171563
--------------------
2025-01-28 12:29:02,482 - decision_tree.py - families considered: 99
2025-01-28 12:29:02,483 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:29:02,483 - decision_tree.py - families with schedulers preserved: 25
2025-01-28 12:29:02,483 - decision_tree.py - families model checked: 74
2025-01-28 12:29:02,483 - decision_tree.py - harmonizations attempted: 12
2025-01-28 12:29:02,483 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:29:02,483 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:29:02,483 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, V_1=picked3, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, V_2=x, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=8, V_3=x, picked0_3=0, picked1_3=0, picked3_3=0, picked4_3=0, picked6_3=0, x_3=6, A_4=r, A_5=l, V_6=picked1, picked0_6=0, picked1_6=0, picked3_6=0, picked4_6=0, picked6_6=0, x_6=6, A_7=r, A_8=r, V_9=x, picked0_9=0, picked1_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=6, V_10=picked1, picked0_10=0, picked1_10=0, picked3_10=0, picked4_10=0, picked6_10=0, x_10=6, A_11=r, A_12=r, V_13=picked3, picked0_13=0, picked1_13=0, picked3_13=0, picked4_13=0, picked6_13=0, x_13=6, A_14=__random__, A_15=l, V_16=x, picked0_16=0, picked1_16=0, picked3_16=0, picked4_16=0, picked6_16=0, x_16=6, V_17=x, picked0_17=0, picked1_17=0, picked3_17=0, picked4_17=0, picked6_17=0, x_17=6, V_18=x, picked0_18=0, picked1_18=0, picked3_18=0, picked4_18=0, picked6_18=0, x_18=6, A_19=r, A_20=d, V_21=picked0, picked0_21=0, picked1_21=0, picked3_21=0, picked4_21=0, picked6_21=0, x_21=6, A_22=__random__, A_23=__random__, V_24=picked6, picked0_24=0, picked1_24=0, picked3_24=0, picked4_24=0, picked6_24=0, x_24=6, V_25=picked0, picked0_25=0, picked1_25=0, picked3_25=0, picked4_25=0, picked6_25=0, x_25=6, A_26=__random__, A_27=__random__, V_28=x, picked0_28=0, picked1_28=0, picked3_28=0, picked4_28=0, picked6_28=0, x_28=6, A_29=l, A_30=l
2025-01-28 12:29:02,494 - decision_tree.py - double-checking specification satisfiability:  : 5.171562522903766

2025-01-28 12:29:02,494 - mdp.py - building tree of depth 5
2025-01-28 12:29:02,671 - statistic.py - synthesis initiated, design space: 1e61
> progress 0.0%, elapsed 3 s, estimated 14957391632120700 s (474295777 years), iters = {MDP: 36}, opt = 5.1716
> progress 0.0%, elapsed 6 s, estimated 27896599258652084 s (884595359 years), iters = {MDP: 82}, opt = 5.1716
> progress 0.0%, elapsed 9 s, estimated 12820783458980702 s (406544376 years), iters = {MDP: 134}, opt = 5.1716
> progress 0.0%, elapsed 12 s, estimated 16641235459398808 s (527690114 years), iters = {MDP: 178}, opt = 5.1716
> progress 0.0%, elapsed 15 s, estimated 20649744449766968 s (654799101 years), iters = {MDP: 227}, opt = 5.1716
> progress 0.0%, elapsed 18 s, estimated 24414475693873296 s (774177945 years), iters = {MDP: 283}, opt = 5.1716
> progress 0.0%, elapsed 21 s, estimated 22562888681117284 s (715464506 years), iters = {MDP: 326}, opt = 5.1716
> progress 0.0%, elapsed 25 s, estimated 26567458597557720 s (842448585 years), iters = {MDP: 329}, opt = 5.1716
> progress 0.0%, elapsed 29 s, estimated 29868875083653808 s (947135815 years), iters = {MDP: 334}, opt = 5.1716
2025-01-28 12:29:30,252 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.07 s
number of holes: 249, family size: 1e61, quotient: 2039 states / 2375 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 335

optimum: 5.171563
--------------------
2025-01-28 12:29:30,253 - decision_tree.py - families considered: 335
2025-01-28 12:29:30,253 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:29:30,253 - decision_tree.py - families with schedulers preserved: 98
2025-01-28 12:29:30,254 - decision_tree.py - families model checked: 237
2025-01-28 12:29:30,254 - decision_tree.py - harmonizations attempted: 26
2025-01-28 12:29:30,254 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:29:30,254 - decision_tree.py - admissible subtree found from node 72
2025-01-28 12:29:30,255 - decision_tree.py - new tree has depth 15 and 85 nodes
2025-01-28 12:29:32,555 - decision_tree.py - new dtcontrol tree has depth 12 and 96 nodes
2025-01-28 12:29:32,556 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:29:32,557 - decision_tree.py - starting iteration with subtree depth 5
2025-01-28 12:29:32,563 - decision_tree.py - starting iteration 25 with 5 nodes in node queue
2025-01-28 12:29:32,564 - decision_tree.py - current tree size: 171 nodes
2025-01-28 12:29:32,666 - decision_tree.py - subtree quotient has 2039 states and 3711 choices
2025-01-28 12:29:32,673 - mdp.py - MDP has 418/2039 relevant states
2025-01-28 12:29:32,678 - mdp.py - MDP has 5 actions
2025-01-28 12:29:32,692 - mdp.py - found the following 8 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked5:[0..1]', 'picked6:[0..1]', 'x:[0..9]']

2025-01-28 12:29:32,693 - mdp.py - building tree of depth 0
2025-01-28 12:29:32,701 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 1, family size: 5, quotient: 2039 states / 3711 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:29:32,835 - decision_tree.py - families considered: 4
2025-01-28 12:29:32,835 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:29:32,836 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:29:32,836 - decision_tree.py - families model checked: 4
2025-01-28 12:29:32,836 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:29:32,836 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:29:32,836 - mdp.py - building tree of depth 1
2025-01-28 12:29:32,875 - statistic.py - synthesis initiated, design space: 1800
2025-01-28 12:29:33,565 - synthesizer_ar.py - value 5.1282 achieved after 379.11 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.29 s
number of holes: 11, family size: 1800, quotient: 2039 states / 3711 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 32

optimum: 5.128171
--------------------
2025-01-28 12:29:34,167 - decision_tree.py - families considered: 32
2025-01-28 12:29:34,168 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:29:34,168 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 12:29:34,168 - decision_tree.py - families model checked: 26
2025-01-28 12:29:34,168 - decision_tree.py - harmonizations attempted: 5
2025-01-28 12:29:34,168 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:29:34,168 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:29:34,168 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked5_0=0, picked6_0=0, x_0=7, A_1=r, A_2=d
2025-01-28 12:29:34,174 - decision_tree.py - double-checking specification satisfiability:  : 5.12817133315515

2025-01-28 12:29:34,174 - mdp.py - building tree of depth 2
2025-01-28 12:29:34,246 - statistic.py - synthesis initiated, design space: 1e8
2025-01-28 12:29:34,378 - synthesizer_ar.py - value 5.1715 achieved after 379.92 seconds
> progress 0.277%, elapsed 3 s, estimated 1082 s, iters = {MDP: 69}, opt = 5.1715
> progress 2.638%, elapsed 6 s, estimated 227 s, iters = {MDP: 130}, opt = 5.1715
2025-01-28 12:29:39,297 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.53 s
number of holes: 31, family size: 1e8, quotient: 2039 states / 3711 actions
explored: 3 %
MDP stats: avg MDP size: 2039, iterations: 164

optimum: 5.171481
--------------------
2025-01-28 12:29:39,298 - decision_tree.py - families considered: 164
2025-01-28 12:29:39,298 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:29:39,298 - decision_tree.py - families with schedulers preserved: 50
2025-01-28 12:29:39,298 - decision_tree.py - families model checked: 114
2025-01-28 12:29:39,298 - decision_tree.py - harmonizations attempted: 10
2025-01-28 12:29:39,298 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:29:39,298 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:29:39,298 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked5_0=0, picked6_0=0, x_0=7, V_1=picked4, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked5_1=0, picked6_1=0, x_1=0, A_2=r, A_3=u, V_4=x, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked5_4=0, picked6_4=0, x_4=8, A_5=d, A_6=l
2025-01-28 12:29:39,311 - decision_tree.py - double-checking specification satisfiability:  : 5.171481060139798

2025-01-28 12:29:39,312 - mdp.py - building tree of depth 3
2025-01-28 12:29:39,577 - statistic.py - synthesis initiated, design space: 1e18
> progress 0.0%, elapsed 3 s, estimated 14957269 s (173 days), iters = {MDP: 32}, opt = 5.1715
> progress 0.0%, elapsed 6 s, estimated 27697020 s (320 days), iters = {MDP: 63}, opt = 5.1715
2025-01-28 12:29:47,307 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:29:47,307 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.73 s
number of holes: 71, family size: 1e18, quotient: 2039 states / 3711 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 78

optimum: 5.171481
--------------------
2025-01-28 12:29:47,307 - decision_tree.py - families considered: 78
2025-01-28 12:29:47,307 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:29:47,308 - decision_tree.py - families with schedulers preserved: 23
2025-01-28 12:29:47,308 - decision_tree.py - families model checked: 55
2025-01-28 12:29:47,308 - decision_tree.py - harmonizations attempted: 9
2025-01-28 12:29:47,308 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:29:47,308 - mdp.py - building tree of depth 4
2025-01-28 12:29:47,670 - statistic.py - synthesis initiated, design space: 1e39
> progress 0.0%, elapsed 3 s, estimated 4372418195 s (138 years), iters = {MDP: 21}, opt = 5.1715
> progress 0.0%, elapsed 6 s, estimated 8930644486 s (283 years), iters = {MDP: 34}, opt = 5.1715
> progress 0.0%, elapsed 9 s, estimated 13382067285 s (424 years), iters = {MDP: 60}, opt = 5.1715
> progress 0.0%, elapsed 12 s, estimated 17826805206 s (565 years), iters = {MDP: 84}, opt = 5.1715
> progress 0.0%, elapsed 15 s, estimated 22396938449 s (710 years), iters = {MDP: 111}, opt = 5.1715
> progress 0.0%, elapsed 19 s, estimated 26906762269 s (853 years), iters = {MDP: 132}, opt = 5.1715
> progress 0.0%, elapsed 22 s, estimated 31149699058 s (987 years), iters = {MDP: 161}, opt = 5.1715
> progress 0.0%, elapsed 25 s, estimated 35651802254 s (1130 years), iters = {MDP: 183}, opt = 5.1715
> progress 0.0%, elapsed 28 s, estimated 40206426365 s (1274 years), iters = {MDP: 209}, opt = 5.1715
2025-01-28 12:30:15,291 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:30:15,292 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.1 s
number of holes: 151, family size: 1e39, quotient: 2039 states / 3711 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 224

optimum: 5.171481
--------------------
2025-01-28 12:30:15,292 - decision_tree.py - families considered: 224
2025-01-28 12:30:15,292 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:30:15,292 - decision_tree.py - families with schedulers preserved: 70
2025-01-28 12:30:15,292 - decision_tree.py - families model checked: 154
2025-01-28 12:30:15,292 - decision_tree.py - harmonizations attempted: 18
2025-01-28 12:30:15,292 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:30:15,292 - decision_tree.py - admissible subtree found from node 115
2025-01-28 12:30:15,293 - decision_tree.py - new tree has depth 15 and 82 nodes
2025-01-28 12:30:17,113 - decision_tree.py - new dtcontrol tree has depth 13 and 120 nodes
2025-01-28 12:30:17,114 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:30:17,115 - decision_tree.py - starting iteration 26 with 4 nodes in node queue
2025-01-28 12:30:17,115 - decision_tree.py - current tree size: 165 nodes
2025-01-28 12:30:17,205 - decision_tree.py - subtree quotient has 2039 states and 2123 choices
2025-01-28 12:30:17,212 - mdp.py - MDP has 21/2039 relevant states
2025-01-28 12:30:17,216 - mdp.py - MDP has 5 actions
2025-01-28 12:30:17,232 - mdp.py - found the following 5 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]']

2025-01-28 12:30:17,232 - mdp.py - building tree of depth 0
2025-01-28 12:30:17,237 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:30:17,354 - synthesizer_ar.py - value 5.1348 achieved after 427.86 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.15 s
number of holes: 1, family size: 5, quotient: 2039 states / 2123 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.134754
--------------------
2025-01-28 12:30:17,389 - decision_tree.py - families considered: 4
2025-01-28 12:30:17,390 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:30:17,390 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:30:17,390 - decision_tree.py - families model checked: 4
2025-01-28 12:30:17,390 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:30:17,390 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:30:17,390 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:30:17,390 - decision_tree.py - A_0=r
2025-01-28 12:30:17,402 - decision_tree.py - double-checking specification satisfiability:  : 5.134754019714968

2025-01-28 12:30:17,403 - mdp.py - building tree of depth 1
2025-01-28 12:30:17,414 - statistic.py - synthesis initiated, design space: 125
2025-01-28 12:30:17,702 - synthesizer_ar.py - value 5.1376 achieved after 428.21 seconds
2025-01-28 12:30:18,338 - synthesizer_ar.py - value 5.1668 achieved after 428.85 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.37 s
number of holes: 8, family size: 125, quotient: 2039 states / 2123 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 59

optimum: 5.166765
--------------------
2025-01-28 12:30:19,788 - decision_tree.py - families considered: 59
2025-01-28 12:30:19,788 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:30:19,788 - decision_tree.py - families with schedulers preserved: 10
2025-01-28 12:30:19,788 - decision_tree.py - families model checked: 49
2025-01-28 12:30:19,788 - decision_tree.py - harmonizations attempted: 9
2025-01-28 12:30:19,788 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:30:19,788 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:30:19,788 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, A_1=r, A_2=d
2025-01-28 12:30:19,799 - decision_tree.py - double-checking specification satisfiability:  : 5.166765317297943

2025-01-28 12:30:19,799 - mdp.py - building tree of depth 2
2025-01-28 12:30:19,809 - statistic.py - synthesis initiated, design space: 78125
2025-01-28 12:30:20,522 - synthesizer_ar.py - value 5.1692 achieved after 431.03 seconds
2025-01-28 12:30:20,931 - synthesizer_ar.py - value 5.1693 achieved after 431.44 seconds
2025-01-28 12:30:21,163 - synthesizer_ar.py - value 5.1707 achieved after 431.67 seconds
2025-01-28 12:30:21,645 - synthesizer_ar.py - value 5.1708 achieved after 432.15 seconds
2025-01-28 12:30:22,025 - synthesizer_ar.py - value 5.171 achieved after 432.53 seconds
> progress 9.6%, elapsed 3 s, estimated 31 s, iters = {MDP: 68}, opt = 5.171
> progress 60.0%, elapsed 6 s, estimated 10 s, iters = {MDP: 142}, opt = 5.171
2025-01-28 12:30:27,386 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.58 s
number of holes: 22, family size: 78125, quotient: 2039 states / 2123 actions
explored: 62 %
MDP stats: avg MDP size: 2039, iterations: 178

optimum: 5.170957
--------------------
2025-01-28 12:30:27,386 - decision_tree.py - families considered: 178
2025-01-28 12:30:27,386 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:30:27,386 - decision_tree.py - families with schedulers preserved: 34
2025-01-28 12:30:27,386 - decision_tree.py - families model checked: 144
2025-01-28 12:30:27,386 - decision_tree.py - harmonizations attempted: 28
2025-01-28 12:30:27,386 - decision_tree.py - harmonizations succeeded: 5

2025-01-28 12:30:27,386 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:30:27,386 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, V_1=picked6, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, A_2=l, A_3=r, V_4=picked6, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, A_5=l, A_6=d
2025-01-28 12:30:27,397 - decision_tree.py - double-checking specification satisfiability:  : 5.170956643244171

2025-01-28 12:30:27,397 - mdp.py - building tree of depth 3
2025-01-28 12:30:27,411 - statistic.py - synthesis initiated, design space: 1e10
2025-01-28 12:30:27,976 - synthesizer_ar.py - value 5.1711 achieved after 438.48 seconds
> progress 8.16%, elapsed 3 s, estimated 37 s, iters = {MDP: 72}, opt = 5.1711
> progress 17.6%, elapsed 6 s, estimated 34 s, iters = {MDP: 144}, opt = 5.1711
2025-01-28 12:30:32,558 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.63 s
number of holes: 50, family size: 1e10, quotient: 2039 states / 2123 actions
explored: 19 %
MDP stats: avg MDP size: 2039, iterations: 175

optimum: 5.171099
--------------------
2025-01-28 12:30:32,558 - decision_tree.py - families considered: 175
2025-01-28 12:30:32,558 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:30:32,558 - decision_tree.py - families with schedulers preserved: 49
2025-01-28 12:30:32,558 - decision_tree.py - families model checked: 126
2025-01-28 12:30:32,558 - decision_tree.py - harmonizations attempted: 12
2025-01-28 12:30:32,558 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:30:32,558 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:30:32,558 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, V_1=picked6, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, V_2=picked3, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, A_3=r, A_4=l, V_5=picked6, picked0_5=0, picked1_5=0, picked3_5=0, picked4_5=0, picked6_5=0, A_6=__random__, A_7=r, V_8=picked6, picked0_8=0, picked1_8=0, picked3_8=0, picked4_8=0, picked6_8=0, V_9=picked3, picked0_9=0, picked1_9=0, picked3_9=0, picked4_9=0, picked6_9=0, A_10=r, A_11=l, V_12=picked3, picked0_12=0, picked1_12=0, picked3_12=0, picked4_12=0, picked6_12=0, A_13=r, A_14=d
2025-01-28 12:30:32,571 - decision_tree.py - double-checking specification satisfiability:  : 5.171098984196098

2025-01-28 12:30:32,572 - mdp.py - building tree of depth 4
2025-01-28 12:30:32,598 - statistic.py - synthesis initiated, design space: 1e21
2025-01-28 12:30:34,348 - synthesizer_ar.py - value 5.1716 achieved after 447.34 seconds
> progress 4.807%, elapsed 3 s, estimated 62 s, iters = {MDP: 50}, opt = 5.1716
> progress 8.001%, elapsed 6 s, estimated 76 s, iters = {MDP: 118}, opt = 5.1716
> progress 12.325%, elapsed 9 s, estimated 73 s, iters = {MDP: 169}, opt = 5.1716
> progress 12.345%, elapsed 12 s, estimated 98 s, iters = {MDP: 230}, opt = 5.1716
> progress 12.393%, elapsed 15 s, estimated 122 s, iters = {MDP: 289}, opt = 5.1716
> progress 20.165%, elapsed 18 s, estimated 90 s, iters = {MDP: 352}, opt = 5.1716
> progress 20.195%, elapsed 21 s, estimated 105 s, iters = {MDP: 422}, opt = 5.1716
> progress 20.234%, elapsed 24 s, estimated 120 s, iters = {MDP: 494}, opt = 5.1716
> progress 20.282%, elapsed 27 s, estimated 134 s, iters = {MDP: 566}, opt = 5.1716
2025-01-28 12:31:02,636 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.04 s
number of holes: 106, family size: 1e21, quotient: 2039 states / 2123 actions
explored: 20 %
MDP stats: avg MDP size: 2039, iterations: 620

optimum: 5.171619
--------------------
2025-01-28 12:31:02,636 - decision_tree.py - families considered: 620
2025-01-28 12:31:02,637 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:31:02,637 - decision_tree.py - families with schedulers preserved: 208
2025-01-28 12:31:02,637 - decision_tree.py - families model checked: 412
2025-01-28 12:31:02,637 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:31:02,637 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:31:02,637 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:31:02,637 - decision_tree.py - V_0=picked0, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, V_1=picked4, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, V_2=picked1, picked0_2=0, picked1_2=0, picked3_2=0, picked4_2=0, picked6_2=0, V_3=picked3, picked0_3=0, picked1_3=0, picked3_3=0, picked4_3=0, picked6_3=0, A_4=r, A_5=d, V_6=picked6, picked0_6=0, picked1_6=0, picked3_6=0, picked4_6=0, picked6_6=0, A_7=u, A_8=r, V_9=picked4, picked0_9=0, picked1_9=0, picked3_9=0, picked4_9=0, picked6_9=0, V_10=picked0, picked0_10=0, picked1_10=0, picked3_10=0, picked4_10=0, picked6_10=0, A_11=__random__, A_12=__random__, V_13=picked3, picked0_13=0, picked1_13=0, picked3_13=0, picked4_13=0, picked6_13=0, A_14=r, A_15=d, V_16=picked1, picked0_16=0, picked1_16=0, picked3_16=0, picked4_16=0, picked6_16=0, V_17=picked6, picked0_17=0, picked1_17=0, picked3_17=0, picked4_17=0, picked6_17=0, V_18=picked3, picked0_18=0, picked1_18=0, picked3_18=0, picked4_18=0, picked6_18=0, A_19=r, A_20=l, V_21=picked4, picked0_21=0, picked1_21=0, picked3_21=0, picked4_21=0, picked6_21=0, A_22=r, A_23=d, V_24=picked6, picked0_24=0, picked1_24=0, picked3_24=0, picked4_24=0, picked6_24=0, V_25=picked3, picked0_25=0, picked1_25=0, picked3_25=0, picked4_25=0, picked6_25=0, A_26=r, A_27=l, V_28=picked4, picked0_28=0, picked1_28=0, picked3_28=0, picked4_28=0, picked6_28=0, A_29=r, A_30=u
2025-01-28 12:31:02,651 - decision_tree.py - double-checking specification satisfiability:  : 5.171618914321347
2025-01-28 12:31:02,651 - decision_tree.py - admissible subtree found from node 91
2025-01-28 12:31:02,652 - decision_tree.py - new tree has depth 14 and 87 nodes
2025-01-28 12:31:02,457 - decision_tree.py - new dtcontrol tree has depth 13 and 123 nodes
2025-01-28 12:31:02,457 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:31:02,459 - decision_tree.py - starting iteration 27 with 3 nodes in node queue
2025-01-28 12:31:02,459 - decision_tree.py - current tree size: 165 nodes
2025-01-28 12:31:02,583 - decision_tree.py - subtree quotient has 2039 states and 2435 choices
2025-01-28 12:31:02,594 - mdp.py - MDP has 99/2039 relevant states
2025-01-28 12:31:02,602 - mdp.py - MDP has 5 actions
2025-01-28 12:31:02,620 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[3..9]']

2025-01-28 12:31:02,620 - mdp.py - building tree of depth 0
2025-01-28 12:31:02,628 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.31 s
number of holes: 1, family size: 5, quotient: 2039 states / 2435 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 7

optimum: 5.127782
--------------------
2025-01-28 12:31:02,935 - decision_tree.py - families considered: 7
2025-01-28 12:31:02,935 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:31:02,935 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:31:02,935 - decision_tree.py - families model checked: 7
2025-01-28 12:31:02,935 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:31:02,935 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:31:02,935 - mdp.py - building tree of depth 1
2025-01-28 12:31:02,948 - statistic.py - synthesis initiated, design space: 900
2025-01-28 12:31:03,869 - synthesizer_ar.py - value 5.1601 achieved after 479.35 seconds
2025-01-28 12:31:04,522 - synthesizer_ar.py - value 5.1686 achieved after 480.0 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.23 s
number of holes: 9, family size: 900, quotient: 2039 states / 2435 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 45

optimum: 5.168614
--------------------
2025-01-28 12:31:05,178 - decision_tree.py - families considered: 45
2025-01-28 12:31:05,179 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:31:05,179 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 12:31:05,179 - decision_tree.py - families model checked: 39
2025-01-28 12:31:05,179 - decision_tree.py - harmonizations attempted: 9
2025-01-28 12:31:05,179 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:31:05,179 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:31:05,179 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, A_1=r, A_2=l
2025-01-28 12:31:05,191 - decision_tree.py - double-checking specification satisfiability:  : 5.168613909108644

2025-01-28 12:31:05,192 - mdp.py - building tree of depth 2
2025-01-28 12:31:05,216 - statistic.py - synthesis initiated, design space: 1e7
2025-01-28 12:31:06,260 - synthesizer_ar.py - value 5.1697 achieved after 481.74 seconds
2025-01-28 12:31:06,712 - synthesizer_ar.py - value 5.1699 achieved after 482.19 seconds
> progress 0.37%, elapsed 3 s, estimated 823 s, iters = {MDP: 47}, opt = 5.1699
> progress 2.982%, elapsed 6 s, estimated 202 s, iters = {MDP: 112}, opt = 5.1699
2025-01-28 12:31:12,786 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:31:12,786 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.57 s
number of holes: 25, family size: 1e7, quotient: 2039 states / 2435 actions
explored: 3 %
MDP stats: avg MDP size: 2039, iterations: 141

optimum: 5.169871
--------------------
2025-01-28 12:31:12,786 - decision_tree.py - families considered: 141
2025-01-28 12:31:12,786 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:31:12,786 - decision_tree.py - families with schedulers preserved: 19
2025-01-28 12:31:12,786 - decision_tree.py - families model checked: 122
2025-01-28 12:31:12,786 - decision_tree.py - harmonizations attempted: 32
2025-01-28 12:31:12,786 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:31:12,786 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:31:12,786 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=picked6, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, A_2=r, A_3=r, V_4=picked4, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=3, A_5=r, A_6=l
2025-01-28 12:31:12,796 - decision_tree.py - double-checking specification satisfiability:  : 5.169871094147511

2025-01-28 12:31:12,796 - mdp.py - building tree of depth 3
2025-01-28 12:31:12,838 - statistic.py - synthesis initiated, design space: 1e16
2025-01-28 12:31:14,403 - synthesizer_ar.py - value 5.1703 achieved after 489.88 seconds
> progress 0.0%, elapsed 3 s, estimated 497959 s (5 days), iters = {MDP: 54}, opt = 5.1703
> progress 0.0%, elapsed 6 s, estimated 799758 s (9 days), iters = {MDP: 107}, opt = 5.1703
2025-01-28 12:31:20,344 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:31:20,345 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.51 s
number of holes: 57, family size: 1e16, quotient: 2039 states / 2435 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 136

optimum: 5.170314
--------------------
2025-01-28 12:31:20,345 - decision_tree.py - families considered: 136
2025-01-28 12:31:20,345 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:31:20,345 - decision_tree.py - families with schedulers preserved: 31
2025-01-28 12:31:20,345 - decision_tree.py - families model checked: 105
2025-01-28 12:31:20,345 - decision_tree.py - harmonizations attempted: 18
2025-01-28 12:31:20,345 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:31:20,345 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:31:20,345 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=picked6, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, V_2=picked2, picked1_2=0, picked2_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=3, A_3=r, A_4=l, V_5=picked6, picked1_5=0, picked2_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=3, A_6=l, A_7=r, V_8=picked4, picked1_8=0, picked2_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=3, V_9=picked3, picked1_9=0, picked2_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=3, A_10=u, A_11=r, V_12=picked2, picked1_12=0, picked2_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=3, A_13=u, A_14=l
2025-01-28 12:31:20,358 - decision_tree.py - double-checking specification satisfiability:  : 5.170313742366944

2025-01-28 12:31:20,358 - mdp.py - building tree of depth 4
2025-01-28 12:31:20,438 - statistic.py - synthesis initiated, design space: 1e34
2025-01-28 12:31:22,162 - synthesizer_ar.py - value 5.1706 achieved after 497.64 seconds
> progress 0.0%, elapsed 3 s, estimated 2091679624504 s (66326 years), iters = {MDP: 35}, opt = 5.1706
2025-01-28 12:31:23,775 - synthesizer_ar.py - value 5.171 achieved after 499.26 seconds
2025-01-28 12:31:25,878 - synthesizer_ar.py - value 5.1714 achieved after 501.36 seconds
> progress 0.0%, elapsed 6 s, estimated 918426869312 s (29123 years), iters = {MDP: 86}, opt = 5.1714
> progress 0.0%, elapsed 9 s, estimated 327173601583 s (10374 years), iters = {MDP: 138}, opt = 5.1714
> progress 0.0%, elapsed 12 s, estimated 331970995560 s (10526 years), iters = {MDP: 196}, opt = 5.1714
> progress 0.0%, elapsed 15 s, estimated 363590892214 s (11529 years), iters = {MDP: 247}, opt = 5.1714
2025-01-28 12:31:36,207 - synthesizer_ar.py - value 5.1715 achieved after 514.16 seconds
> progress 0.0%, elapsed 18 s, estimated 185560510706 s (5884 years), iters = {MDP: 284}, opt = 5.1715
> progress 0.0%, elapsed 21 s, estimated 268730186 s (8 years), iters = {MDP: 333}, opt = 5.1715
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 22.2 s
number of holes: 121, family size: 1e34, quotient: 2039 states / 2435 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 356

optimum: 5.171483
--------------------
2025-01-28 12:31:40,172 - decision_tree.py - families considered: 356
2025-01-28 12:31:40,172 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:31:40,172 - decision_tree.py - families with schedulers preserved: 97
2025-01-28 12:31:40,172 - decision_tree.py - families model checked: 259
2025-01-28 12:31:40,172 - decision_tree.py - harmonizations attempted: 25
2025-01-28 12:31:40,172 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:31:40,172 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:31:40,172 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=picked6, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, V_2=picked2, picked1_2=0, picked2_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=3, V_3=picked4, picked1_3=0, picked2_3=0, picked3_3=0, picked4_3=0, picked6_3=0, x_3=3, A_4=r, A_5=r, V_6=picked3, picked1_6=0, picked2_6=0, picked3_6=0, picked4_6=0, picked6_6=0, x_6=3, A_7=r, A_8=r, V_9=picked6, picked1_9=0, picked2_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=3, V_10=picked3, picked1_10=0, picked2_10=0, picked3_10=0, picked4_10=0, picked6_10=0, x_10=3, A_11=r, A_12=r, V_13=picked6, picked1_13=0, picked2_13=0, picked3_13=0, picked4_13=0, picked6_13=0, x_13=3, A_14=r, A_15=r, V_16=picked4, picked1_16=0, picked2_16=0, picked3_16=0, picked4_16=0, picked6_16=0, x_16=3, V_17=picked3, picked1_17=0, picked2_17=0, picked3_17=0, picked4_17=0, picked6_17=0, x_17=3, V_18=x, picked1_18=0, picked2_18=0, picked3_18=0, picked4_18=0, picked6_18=0, x_18=8, A_19=r, A_20=u, V_21=x, picked1_21=0, picked2_21=0, picked3_21=0, picked4_21=0, picked6_21=0, x_21=3, A_22=r, A_23=l, V_24=picked2, picked1_24=0, picked2_24=0, picked3_24=0, picked4_24=0, picked6_24=0, x_24=3, V_25=x, picked1_25=0, picked2_25=0, picked3_25=0, picked4_25=0, picked6_25=0, x_25=8, A_26=r, A_27=u, V_28=x, picked1_28=0, picked2_28=0, picked3_28=0, picked4_28=0, picked6_28=0, x_28=3, A_29=u, A_30=l
2025-01-28 12:31:40,185 - decision_tree.py - double-checking specification satisfiability:  : 5.171482795883037
2025-01-28 12:31:40,185 - decision_tree.py - admissible subtree found from node 8
2025-01-28 12:31:40,194 - decision_tree.py - new tree has depth 15 and 81 nodes
2025-01-28 12:31:42,186 - decision_tree.py - new dtcontrol tree has depth 13 and 127 nodes
2025-01-28 12:31:42,187 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:31:42,188 - decision_tree.py - starting iteration 28 with 2 nodes in node queue
2025-01-28 12:31:42,188 - decision_tree.py - current tree size: 163 nodes
2025-01-28 12:31:42,289 - decision_tree.py - subtree quotient has 2039 states and 2687 choices
2025-01-28 12:31:42,298 - mdp.py - MDP has 162/2039 relevant states
2025-01-28 12:31:42,302 - mdp.py - MDP has 5 actions
2025-01-28 12:31:42,320 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'x:[10..14]', 'y:[2..4]']

2025-01-28 12:31:42,321 - mdp.py - building tree of depth 0
2025-01-28 12:31:42,328 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:31:42,455 - synthesizer_ar.py - value 5.139 achieved after 520.41 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.16 s
number of holes: 1, family size: 5, quotient: 2039 states / 2687 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.138983
--------------------
2025-01-28 12:31:42,493 - decision_tree.py - families considered: 4
2025-01-28 12:31:42,493 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:31:42,493 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:31:42,493 - decision_tree.py - families model checked: 4
2025-01-28 12:31:42,493 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:31:42,493 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:31:42,493 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:31:42,493 - decision_tree.py - A_0=l
2025-01-28 12:31:42,505 - decision_tree.py - double-checking specification satisfiability:  : 5.138982975612597

2025-01-28 12:31:42,505 - mdp.py - building tree of depth 1
2025-01-28 12:31:42,526 - statistic.py - synthesis initiated, design space: 1400
> progress 91.428%, elapsed 3 s, estimated 3 s, iters = {MDP: 57}, opt = 5.139
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.66 s
number of holes: 10, family size: 1400, quotient: 2039 states / 2687 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 121

optimum: 5.138983
--------------------
2025-01-28 12:31:48,190 - decision_tree.py - families considered: 121
2025-01-28 12:31:48,190 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:31:48,190 - decision_tree.py - families with schedulers preserved: 16
2025-01-28 12:31:48,190 - decision_tree.py - families model checked: 105
2025-01-28 12:31:48,190 - decision_tree.py - harmonizations attempted: 24
2025-01-28 12:31:48,190 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:31:48,190 - mdp.py - building tree of depth 2
2025-01-28 12:31:48,219 - statistic.py - synthesis initiated, design space: 1e8
2025-01-28 12:31:48,865 - synthesizer_ar.py - value 5.1408 achieved after 526.81 seconds
> progress 0.291%, elapsed 3 s, estimated 1057 s, iters = {MDP: 56}, opt = 5.1408
> progress 1.224%, elapsed 6 s, estimated 505 s, iters = {MDP: 125}, opt = 5.1408
2025-01-28 12:31:55,740 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:31:55,740 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.52 s
number of holes: 28, family size: 1e8, quotient: 2039 states / 2687 actions
explored: 1 %
MDP stats: avg MDP size: 2039, iterations: 157

optimum: 5.140792
--------------------
2025-01-28 12:31:55,740 - decision_tree.py - families considered: 157
2025-01-28 12:31:55,740 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:31:55,740 - decision_tree.py - families with schedulers preserved: 23
2025-01-28 12:31:55,740 - decision_tree.py - families model checked: 134
2025-01-28 12:31:55,740 - decision_tree.py - harmonizations attempted: 34
2025-01-28 12:31:55,740 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:31:55,740 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:31:55,740 - decision_tree.py - V_0=y, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=12, y_0=3, V_1=picked3, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, x_1=10, y_1=2, A_2=u, A_3=l, V_4=y, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked6_4=0, x_4=10, y_4=3, A_5=l, A_6=l
2025-01-28 12:31:55,751 - decision_tree.py - double-checking specification satisfiability:  : 5.140792176775927

2025-01-28 12:31:55,751 - mdp.py - building tree of depth 3
2025-01-28 12:31:55,810 - statistic.py - synthesis initiated, design space: 1e17
2025-01-28 12:31:57,109 - synthesizer_ar.py - value 5.1427 achieved after 535.06 seconds
2025-01-28 12:31:58,828 - synthesizer_ar.py - value 5.149 achieved after 536.78 seconds
> progress 0.0%, elapsed 3 s, estimated 3185650 s (36 days), iters = {MDP: 46}, opt = 5.149
> progress 0.001%, elapsed 6 s, estimated 483801 s (5 days), iters = {MDP: 108}, opt = 5.149
2025-01-28 12:32:03,385 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:32:03,385 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.58 s
number of holes: 64, family size: 1e17, quotient: 2039 states / 2687 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 137

optimum: 5.148979
--------------------
2025-01-28 12:32:03,386 - decision_tree.py - families considered: 137
2025-01-28 12:32:03,386 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:03,386 - decision_tree.py - families with schedulers preserved: 40
2025-01-28 12:32:03,386 - decision_tree.py - families model checked: 97
2025-01-28 12:32:03,386 - decision_tree.py - harmonizations attempted: 10
2025-01-28 12:32:03,386 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:32:03,386 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:32:03,386 - decision_tree.py - V_0=y, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=10, y_0=3, V_1=picked3, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, x_1=10, y_1=2, V_2=y, picked0_2=0, picked1_2=0, picked2_2=0, picked3_2=0, picked6_2=0, x_2=10, y_2=3, A_3=u, A_4=u, V_5=y, picked0_5=0, picked1_5=0, picked2_5=0, picked3_5=0, picked6_5=0, x_5=10, y_5=2, A_6=l, A_7=d, V_8=y, picked0_8=0, picked1_8=0, picked2_8=0, picked3_8=0, picked6_8=0, x_8=10, y_8=3, V_9=picked3, picked0_9=0, picked1_9=0, picked2_9=0, picked3_9=0, picked6_9=0, x_9=10, y_9=2, A_10=u, A_11=u, V_12=picked3, picked0_12=0, picked1_12=0, picked2_12=0, picked3_12=0, picked6_12=0, x_12=10, y_12=2, A_13=l, A_14=l
2025-01-28 12:32:03,400 - decision_tree.py - double-checking specification satisfiability:  : 5.148978917782499

2025-01-28 12:32:03,401 - mdp.py - building tree of depth 4
2025-01-28 12:32:03,561 - statistic.py - synthesis initiated, design space: 1e37
> progress 0.0%, elapsed 3 s, estimated 2259992014 s (71 years), iters = {MDP: 44}, opt = 5.149
> progress 0.0%, elapsed 6 s, estimated 3687628894 s (116 years), iters = {MDP: 92}, opt = 5.149
> progress 0.0%, elapsed 9 s, estimated 4733972509 s (150 years), iters = {MDP: 132}, opt = 5.149
> progress 0.0%, elapsed 12 s, estimated 6256134135 s (198 years), iters = {MDP: 186}, opt = 5.149
> progress 0.0%, elapsed 15 s, estimated 7871430785 s (249 years), iters = {MDP: 213}, opt = 5.149
> progress 0.0%, elapsed 18 s, estimated 9426921756 s (298 years), iters = {MDP: 261}, opt = 5.149
> progress 0.0%, elapsed 21 s, estimated 1997390467 s (63 years), iters = {MDP: 309}, opt = 5.149
> progress 0.0%, elapsed 24 s, estimated 2267758166 s (71 years), iters = {MDP: 358}, opt = 5.149
> progress 0.0%, elapsed 27 s, estimated 2503608310 s (79 years), iters = {MDP: 406}, opt = 5.149
2025-01-28 12:32:31,197 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:32:31,197 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.13 s
number of holes: 136, family size: 1e37, quotient: 2039 states / 2687 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 439

optimum: 5.148979
--------------------
2025-01-28 12:32:31,198 - decision_tree.py - families considered: 439
2025-01-28 12:32:31,198 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:31,198 - decision_tree.py - families with schedulers preserved: 124
2025-01-28 12:32:31,198 - decision_tree.py - families model checked: 315
2025-01-28 12:32:31,198 - decision_tree.py - harmonizations attempted: 33
2025-01-28 12:32:31,198 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:32:31,199 - decision_tree.py - admissible subtree found from node 135
2025-01-28 12:32:31,199 - decision_tree.py - new tree has depth 15 and 76 nodes
2025-01-28 12:32:30,998 - decision_tree.py - new dtcontrol tree has depth 13 and 129 nodes
2025-01-28 12:32:30,998 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:32:30,999 - decision_tree.py - starting iteration 29 with 1 nodes in node queue
2025-01-28 12:32:30,999 - decision_tree.py - current tree size: 153 nodes
2025-01-28 12:32:31,087 - decision_tree.py - subtree quotient has 2039 states and 2599 choices
2025-01-28 12:32:31,095 - mdp.py - MDP has 140/2039 relevant states
2025-01-28 12:32:31,099 - mdp.py - MDP has 5 actions
2025-01-28 12:32:31,114 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'x:[10..14]']

2025-01-28 12:32:31,115 - mdp.py - building tree of depth 0
2025-01-28 12:32:31,120 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:32:31,225 - synthesizer_ar.py - value 5.149 achieved after 574.14 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.15 s
number of holes: 1, family size: 5, quotient: 2039 states / 2599 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.148979
--------------------
2025-01-28 12:32:31,275 - decision_tree.py - families considered: 4
2025-01-28 12:32:31,275 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:31,275 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:32:31,275 - decision_tree.py - families model checked: 4
2025-01-28 12:32:31,275 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:32:31,276 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:32:31,276 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:32:31,276 - decision_tree.py - A_0=l
2025-01-28 12:32:31,287 - decision_tree.py - double-checking specification satisfiability:  : 5.148978917782499

2025-01-28 12:32:31,287 - mdp.py - building tree of depth 1
2025-01-28 12:32:31,308 - statistic.py - synthesis initiated, design space: 600
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 9, family size: 600, quotient: 2039 states / 2599 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 2

optimum: 5.148979
--------------------
2025-01-28 12:32:31,346 - decision_tree.py - families considered: 2
2025-01-28 12:32:31,346 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:31,346 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:32:31,346 - decision_tree.py - families model checked: 2
2025-01-28 12:32:31,347 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:32:31,347 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:32:31,347 - mdp.py - building tree of depth 2
2025-01-28 12:32:31,381 - statistic.py - synthesis initiated, design space: 1e6
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2599 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 2

optimum: 5.148979
--------------------
2025-01-28 12:32:31,423 - decision_tree.py - families considered: 2
2025-01-28 12:32:31,423 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:31,423 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:32:31,423 - decision_tree.py - families model checked: 2
2025-01-28 12:32:31,423 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:32:31,423 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:32:31,424 - mdp.py - building tree of depth 3
2025-01-28 12:32:31,487 - statistic.py - synthesis initiated, design space: 1e15
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.03 s
number of holes: 57, family size: 1e15, quotient: 2039 states / 2599 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 2

optimum: 5.148979
--------------------
2025-01-28 12:32:31,522 - decision_tree.py - families considered: 2
2025-01-28 12:32:31,522 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:31,522 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:32:31,522 - decision_tree.py - families model checked: 2
2025-01-28 12:32:31,522 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:32:31,522 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:32:31,522 - mdp.py - building tree of depth 4
2025-01-28 12:32:31,614 - statistic.py - synthesis initiated, design space: 1e31
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 121, family size: 1e31, quotient: 2039 states / 2599 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 2

optimum: 5.148979
--------------------
2025-01-28 12:32:31,655 - decision_tree.py - families considered: 2
2025-01-28 12:32:31,655 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:31,655 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:32:31,655 - decision_tree.py - families model checked: 2
2025-01-28 12:32:31,655 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:32:31,655 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:32:31,656 - decision_tree.py - admissible subtree found from node 142
2025-01-28 12:32:31,656 - decision_tree.py - new tree has depth 15 and 71 nodes
2025-01-28 12:32:33,580 - decision_tree.py - new dtcontrol tree has depth 13 and 123 nodes
2025-01-28 12:32:33,580 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:32:33,582 - decision_tree.py - starting iteration with subtree depth 4
2025-01-28 12:32:33,593 - decision_tree.py - starting iteration 30 with 5 nodes in node queue
2025-01-28 12:32:33,594 - decision_tree.py - current tree size: 143 nodes
2025-01-28 12:32:33,710 - decision_tree.py - subtree quotient has 2039 states and 2211 choices
2025-01-28 12:32:33,724 - mdp.py - MDP has 43/2039 relevant states
2025-01-28 12:32:33,729 - mdp.py - MDP has 5 actions
2025-01-28 12:32:33,752 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]']

2025-01-28 12:32:33,752 - mdp.py - building tree of depth 0
2025-01-28 12:32:33,760 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:32:33,974 - synthesizer_ar.py - value 5.1482 achieved after 576.89 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.29 s
number of holes: 1, family size: 5, quotient: 2039 states / 2211 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.1482
--------------------
2025-01-28 12:32:34,048 - decision_tree.py - families considered: 4
2025-01-28 12:32:34,049 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:34,049 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:32:34,049 - decision_tree.py - families model checked: 4
2025-01-28 12:32:34,049 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:32:34,049 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:32:34,049 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:32:34,049 - decision_tree.py - A_0=l
2025-01-28 12:32:34,062 - decision_tree.py - double-checking specification satisfiability:  : 5.1482004254757285

2025-01-28 12:32:34,063 - mdp.py - building tree of depth 1
2025-01-28 12:32:34,075 - statistic.py - synthesis initiated, design space: 150
2025-01-28 12:32:34,537 - synthesizer_ar.py - value 5.149 achieved after 577.45 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.53 s
number of holes: 9, family size: 150, quotient: 2039 states / 2211 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 11

optimum: 5.148978
--------------------
2025-01-28 12:32:34,604 - decision_tree.py - families considered: 11
2025-01-28 12:32:34,604 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:34,604 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:32:34,604 - decision_tree.py - families model checked: 9
2025-01-28 12:32:34,604 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:32:34,604 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:32:34,604 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:32:34,604 - decision_tree.py - V_0=picked0, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, A_1=l, A_2=u
2025-01-28 12:32:34,616 - decision_tree.py - double-checking specification satisfiability:  : 5.148978245166845

2025-01-28 12:32:34,617 - mdp.py - building tree of depth 2
2025-01-28 12:32:34,633 - statistic.py - synthesis initiated, design space: 135000
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 25, family size: 135000, quotient: 2039 states / 2211 actions
explored: 116 %
MDP stats: avg MDP size: 2039, iterations: 2

optimum: 5.148978
--------------------
2025-01-28 12:32:34,670 - decision_tree.py - families considered: 2
2025-01-28 12:32:34,670 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:34,670 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:32:34,670 - decision_tree.py - families model checked: 2
2025-01-28 12:32:34,670 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:32:34,670 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:32:34,670 - mdp.py - building tree of depth 3
2025-01-28 12:32:34,697 - statistic.py - synthesis initiated, design space: 1e11
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 57, family size: 1e11, quotient: 2039 states / 2211 actions
explored: 116 %
MDP stats: avg MDP size: 2039, iterations: 2

optimum: 5.148978
--------------------
2025-01-28 12:32:34,736 - decision_tree.py - families considered: 2
2025-01-28 12:32:34,736 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:34,736 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:32:34,736 - decision_tree.py - families model checked: 2
2025-01-28 12:32:34,736 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:32:34,736 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:32:34,737 - decision_tree.py - admissible subtree found from node 60
2025-01-28 12:32:34,742 - decision_tree.py - new tree has depth 15 and 68 nodes
2025-01-28 12:32:36,623 - decision_tree.py - new dtcontrol tree has depth 13 and 117 nodes
2025-01-28 12:32:36,624 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:32:36,625 - decision_tree.py - starting iteration 31 with 4 nodes in node queue
2025-01-28 12:32:36,625 - decision_tree.py - current tree size: 137 nodes
2025-01-28 12:32:36,726 - decision_tree.py - subtree quotient has 2039 states and 3383 choices
2025-01-28 12:32:36,737 - mdp.py - MDP has 336/2039 relevant states
2025-01-28 12:32:36,743 - mdp.py - MDP has 5 actions
2025-01-28 12:32:36,764 - mdp.py - found the following 8 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[10..14]', 'y:[2..4]']

2025-01-28 12:32:36,764 - mdp.py - building tree of depth 0
2025-01-28 12:32:36,771 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.23 s
number of holes: 1, family size: 5, quotient: 2039 states / 3383 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:32:37,003 - decision_tree.py - families considered: 4
2025-01-28 12:32:37,003 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:37,003 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:32:37,003 - decision_tree.py - families model checked: 4
2025-01-28 12:32:37,003 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:32:37,004 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:32:37,004 - mdp.py - building tree of depth 1
2025-01-28 12:32:37,032 - statistic.py - synthesis initiated, design space: 1600
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.74 s
number of holes: 11, family size: 1600, quotient: 2039 states / 3383 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 53

optimum: 5.127782
--------------------
2025-01-28 12:32:39,774 - decision_tree.py - families considered: 53
2025-01-28 12:32:39,774 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:39,775 - decision_tree.py - families with schedulers preserved: 4
2025-01-28 12:32:39,775 - decision_tree.py - families model checked: 49
2025-01-28 12:32:39,775 - decision_tree.py - harmonizations attempted: 15
2025-01-28 12:32:39,775 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:32:39,775 - mdp.py - building tree of depth 2
2025-01-28 12:32:39,831 - statistic.py - synthesis initiated, design space: 1e8
> progress 3.487%, elapsed 3 s, estimated 86 s, iters = {MDP: 51}, opt = 5.1278
> progress 3.515%, elapsed 6 s, estimated 172 s, iters = {MDP: 108}, opt = 5.1278
> progress 3.636%, elapsed 9 s, estimated 250 s, iters = {MDP: 165}, opt = 5.1278
2025-01-28 12:32:49,897 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 10.07 s
number of holes: 31, family size: 1e8, quotient: 2039 states / 3383 actions
explored: 3 %
MDP stats: avg MDP size: 2039, iterations: 189

optimum: 5.127782
--------------------
2025-01-28 12:32:49,897 - decision_tree.py - families considered: 189
2025-01-28 12:32:49,897 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:32:49,898 - decision_tree.py - families with schedulers preserved: 31
2025-01-28 12:32:49,898 - decision_tree.py - families model checked: 158
2025-01-28 12:32:49,898 - decision_tree.py - harmonizations attempted: 38
2025-01-28 12:32:49,898 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:32:49,898 - mdp.py - building tree of depth 3
2025-01-28 12:32:50,039 - statistic.py - synthesis initiated, design space: 1e18
> progress 1.015%, elapsed 3 s, estimated 306 s, iters = {MDP: 48}, opt = 5.1278
> progress 1.953%, elapsed 6 s, estimated 318 s, iters = {MDP: 92}, opt = 5.1278
> progress 1.953%, elapsed 9 s, estimated 477 s, iters = {MDP: 157}, opt = 5.1278
> progress 1.953%, elapsed 12 s, estimated 632 s, iters = {MDP: 209}, opt = 5.1278
> progress 1.953%, elapsed 15 s, estimated 790 s, iters = {MDP: 270}, opt = 5.1278
> progress 1.953%, elapsed 18 s, estimated 945 s, iters = {MDP: 324}, opt = 5.1278
> progress 1.953%, elapsed 21 s, estimated 1099 s, iters = {MDP: 382}, opt = 5.1278
> progress 1.953%, elapsed 24 s, estimated 1255 s, iters = {MDP: 437}, opt = 5.1278
> progress 1.953%, elapsed 27 s, estimated 1415 s, iters = {MDP: 496}, opt = 5.1278
2025-01-28 12:33:17,583 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.03 s
number of holes: 71, family size: 1e18, quotient: 2039 states / 3383 actions
explored: 1 %
MDP stats: avg MDP size: 2039, iterations: 546

optimum: 5.127782
--------------------
2025-01-28 12:33:17,584 - decision_tree.py - families considered: 546
2025-01-28 12:33:17,584 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:33:17,584 - decision_tree.py - families with schedulers preserved: 117
2025-01-28 12:33:17,584 - decision_tree.py - families model checked: 429
2025-01-28 12:33:17,584 - decision_tree.py - harmonizations attempted: 78
2025-01-28 12:33:17,584 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:33:17,584 - decision_tree.py - no admissible subtree found from node 115
2025-01-28 12:33:17,584 - decision_tree.py - starting iteration 32 with 3 nodes in node queue
2025-01-28 12:33:17,585 - decision_tree.py - current tree size: 137 nodes
2025-01-28 12:33:17,679 - decision_tree.py - subtree quotient has 2039 states and 2375 choices
2025-01-28 12:33:17,687 - mdp.py - MDP has 84/2039 relevant states
2025-01-28 12:33:17,701 - mdp.py - MDP has 5 actions
2025-01-28 12:33:17,719 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[6..9]']

2025-01-28 12:33:17,719 - mdp.py - building tree of depth 0
2025-01-28 12:33:17,725 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.17 s
number of holes: 1, family size: 5, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:33:17,898 - decision_tree.py - families considered: 4
2025-01-28 12:33:17,898 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:33:17,899 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:33:17,899 - decision_tree.py - families model checked: 4
2025-01-28 12:33:17,899 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:33:17,899 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:33:17,899 - mdp.py - building tree of depth 1
2025-01-28 12:33:17,912 - statistic.py - synthesis initiated, design space: 450
2025-01-28 12:33:18,694 - synthesizer_ar.py - value 5.1446 achieved after 624.09 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.89 s
number of holes: 9, family size: 450, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 22

optimum: 5.144632
--------------------
2025-01-28 12:33:18,806 - decision_tree.py - families considered: 22
2025-01-28 12:33:18,806 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:33:18,806 - decision_tree.py - families with schedulers preserved: 4
2025-01-28 12:33:18,806 - decision_tree.py - families model checked: 18
2025-01-28 12:33:18,806 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:33:18,806 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:33:18,806 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:33:18,806 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=6, A_1=r, A_2=l
2025-01-28 12:33:18,817 - decision_tree.py - double-checking specification satisfiability:  : 5.1446319577556485

2025-01-28 12:33:18,817 - mdp.py - building tree of depth 2
2025-01-28 12:33:18,834 - statistic.py - synthesis initiated, design space: 1e6
> progress 7.777%, elapsed 3 s, estimated 38 s, iters = {MDP: 63}, opt = 5.1446
2025-01-28 12:33:23,252 - synthesizer_ar.py - value 5.1471 achieved after 628.65 seconds
> progress 9.422%, elapsed 6 s, estimated 63 s, iters = {MDP: 120}, opt = 5.1471
2025-01-28 12:33:26,500 - synthesizer_ar.py - value 5.1523 achieved after 631.9 seconds
> progress 14.148%, elapsed 9 s, estimated 63 s, iters = {MDP: 188}, opt = 5.1523
2025-01-28 12:33:28,903 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 10.07 s
number of holes: 25, family size: 1e6, quotient: 2039 states / 2375 actions
explored: 22 %
MDP stats: avg MDP size: 2039, iterations: 210

optimum: 5.15228
--------------------
2025-01-28 12:33:28,903 - decision_tree.py - families considered: 210
2025-01-28 12:33:28,904 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:33:28,904 - decision_tree.py - families with schedulers preserved: 57
2025-01-28 12:33:28,904 - decision_tree.py - families model checked: 153
2025-01-28 12:33:28,904 - decision_tree.py - harmonizations attempted: 19
2025-01-28 12:33:28,904 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:33:28,904 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:33:28,904 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=8, V_1=x, picked0_1=0, picked1_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=6, A_2=r, A_3=l, V_4=picked3, picked0_4=0, picked1_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=6, A_5=r, A_6=l
2025-01-28 12:33:28,915 - decision_tree.py - double-checking specification satisfiability:  : 5.152280341985815

2025-01-28 12:33:28,916 - mdp.py - building tree of depth 3
2025-01-28 12:33:28,963 - statistic.py - synthesis initiated, design space: 1e14
> progress 0.002%, elapsed 3 s, estimated 145968 s (40 hours), iters = {MDP: 60}, opt = 5.1523
> progress 0.002%, elapsed 6 s, estimated 285341 s (3 days), iters = {MDP: 117}, opt = 5.1523
> progress 0.004%, elapsed 9 s, estimated 195349 s (2 days), iters = {MDP: 179}, opt = 5.1523
> progress 0.019%, elapsed 12 s, estimated 62876 s (17 hours), iters = {MDP: 244}, opt = 5.1523
> progress 0.028%, elapsed 15 s, estimated 54236 s (15 hours), iters = {MDP: 307}, opt = 5.1523
> progress 0.038%, elapsed 18 s, estimated 47781 s (13 hours), iters = {MDP: 375}, opt = 5.1523
> progress 0.051%, elapsed 21 s, estimated 41408 s (11 hours), iters = {MDP: 429}, opt = 5.1523
> progress 6.069%, elapsed 24 s, estimated 400 s, iters = {MDP: 490}, opt = 5.1523
> progress 6.532%, elapsed 27 s, estimated 417 s, iters = {MDP: 545}, opt = 5.1523
2025-01-28 12:33:56,488 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.01 s
number of holes: 57, family size: 1e14, quotient: 2039 states / 2375 actions
explored: 6 %
MDP stats: avg MDP size: 2039, iterations: 606

optimum: 5.15228
--------------------
2025-01-28 12:33:56,489 - decision_tree.py - families considered: 606
2025-01-28 12:33:56,489 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:33:56,489 - decision_tree.py - families with schedulers preserved: 164
2025-01-28 12:33:56,489 - decision_tree.py - families model checked: 442
2025-01-28 12:33:56,489 - decision_tree.py - harmonizations attempted: 55
2025-01-28 12:33:56,489 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:33:56,489 - decision_tree.py - admissible subtree found from node 64
2025-01-28 12:33:56,490 - decision_tree.py - new tree has depth 15 and 65 nodes
2025-01-28 12:33:58,223 - decision_tree.py - new dtcontrol tree has depth 13 and 115 nodes
2025-01-28 12:33:58,223 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:33:58,224 - decision_tree.py - starting iteration 33 with 2 nodes in node queue
2025-01-28 12:33:58,225 - decision_tree.py - current tree size: 131 nodes
2025-01-28 12:33:58,317 - decision_tree.py - subtree quotient has 2039 states and 2087 choices
2025-01-28 12:33:58,325 - mdp.py - MDP has 12/2039 relevant states
2025-01-28 12:33:58,328 - mdp.py - MDP has 5 actions
2025-01-28 12:33:58,344 - mdp.py - found the following 4 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]']

2025-01-28 12:33:58,344 - mdp.py - building tree of depth 0
2025-01-28 12:33:58,349 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:33:58,454 - synthesizer_ar.py - value 5.1371 achieved after 666.34 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.17 s
number of holes: 1, family size: 5, quotient: 2039 states / 2087 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.137101
--------------------
2025-01-28 12:33:58,515 - decision_tree.py - families considered: 4
2025-01-28 12:33:58,515 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:33:58,515 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:33:58,515 - decision_tree.py - families model checked: 4
2025-01-28 12:33:58,515 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:33:58,515 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:33:58,515 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:33:58,515 - decision_tree.py - A_0=d
2025-01-28 12:33:58,529 - decision_tree.py - double-checking specification satisfiability:  : 5.137101213819966

2025-01-28 12:33:58,529 - mdp.py - building tree of depth 1
2025-01-28 12:33:58,541 - statistic.py - synthesis initiated, design space: 100
2025-01-28 12:33:58,865 - synthesizer_ar.py - value 5.1407 achieved after 666.75 seconds
2025-01-28 12:33:59,054 - synthesizer_ar.py - value 5.1448 achieved after 666.94 seconds
2025-01-28 12:33:59,783 - synthesizer_ar.py - value 5.1481 achieved after 667.67 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.12 s
number of holes: 7, family size: 100, quotient: 2039 states / 2087 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 51

optimum: 5.148078
--------------------
2025-01-28 12:34:00,658 - decision_tree.py - families considered: 51
2025-01-28 12:34:00,659 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:34:00,659 - decision_tree.py - families with schedulers preserved: 9
2025-01-28 12:34:00,659 - decision_tree.py - families model checked: 42
2025-01-28 12:34:00,659 - decision_tree.py - harmonizations attempted: 8
2025-01-28 12:34:00,659 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:34:00,659 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:34:00,659 - decision_tree.py - V_0=picked0, picked0_0=0, picked1_0=0, picked4_0=0, picked6_0=0, A_1=d, A_2=r
2025-01-28 12:34:00,669 - decision_tree.py - double-checking specification satisfiability:  : 5.148078102930114

2025-01-28 12:34:00,669 - mdp.py - building tree of depth 2
2025-01-28 12:34:00,678 - statistic.py - synthesis initiated, design space: 40000
2025-01-28 12:34:00,788 - synthesizer_ar.py - value 5.151 achieved after 668.67 seconds
> progress 15.312%, elapsed 3 s, estimated 19 s, iters = {MDP: 73}, opt = 5.151
> progress 25.0%, elapsed 6 s, estimated 24 s, iters = {MDP: 152}, opt = 5.151
> progress 38.0%, elapsed 9 s, estimated 24 s, iters = {MDP: 230}, opt = 5.151
2025-01-28 12:34:08,213 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 10.01 s
number of holes: 19, family size: 40000, quotient: 2039 states / 2087 actions
explored: 45 %
MDP stats: avg MDP size: 2039, iterations: 251

optimum: 5.151016
--------------------
2025-01-28 12:34:08,213 - decision_tree.py - families considered: 251
2025-01-28 12:34:08,214 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:34:08,214 - decision_tree.py - families with schedulers preserved: 56
2025-01-28 12:34:08,214 - decision_tree.py - families model checked: 195
2025-01-28 12:34:08,214 - decision_tree.py - harmonizations attempted: 33
2025-01-28 12:34:08,214 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:34:08,214 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:34:08,214 - decision_tree.py - V_0=picked0, picked0_0=0, picked1_0=0, picked4_0=0, picked6_0=0, V_1=picked6, picked0_1=0, picked1_1=0, picked4_1=0, picked6_1=0, A_2=u, A_3=d, V_4=picked6, picked0_4=0, picked1_4=0, picked4_4=0, picked6_4=0, A_5=l, A_6=r
2025-01-28 12:34:08,224 - decision_tree.py - double-checking specification satisfiability:  : 5.151015500451474

2025-01-28 12:34:08,224 - mdp.py - building tree of depth 3
2025-01-28 12:34:08,234 - statistic.py - synthesis initiated, design space: 1e9
2025-01-28 12:34:08,580 - synthesizer_ar.py - value 5.1512 achieved after 678.94 seconds
2025-01-28 12:34:08,778 - synthesizer_ar.py - value 5.1519 achieved after 679.14 seconds
2025-01-28 12:34:10,037 - synthesizer_ar.py - value 5.152 achieved after 680.4 seconds
2025-01-28 12:34:10,401 - synthesizer_ar.py - value 5.1523 achieved after 680.76 seconds
> progress 51.562%, elapsed 3 s, estimated 5 s, iters = {MDP: 68}, opt = 5.1523
> progress 55.156%, elapsed 6 s, estimated 10 s, iters = {MDP: 147}, opt = 5.1523
> progress 56.406%, elapsed 9 s, estimated 16 s, iters = {MDP: 225}, opt = 5.1523
> progress 64.223%, elapsed 12 s, estimated 18 s, iters = {MDP: 292}, opt = 5.1523
> progress 65.625%, elapsed 15 s, estimated 23 s, iters = {MDP: 365}, opt = 5.1523
> progress 70.656%, elapsed 18 s, estimated 25 s, iters = {MDP: 436}, opt = 5.1523
> progress 72.246%, elapsed 21 s, estimated 29 s, iters = {MDP: 511}, opt = 5.1523
> progress 72.953%, elapsed 24 s, estimated 33 s, iters = {MDP: 591}, opt = 5.1523
> progress 76.781%, elapsed 27 s, estimated 35 s, iters = {MDP: 668}, opt = 5.1523
2025-01-28 12:34:35,815 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.07 s
number of holes: 43, family size: 1e9, quotient: 2039 states / 2087 actions
explored: 78 %
MDP stats: avg MDP size: 2039, iterations: 740

optimum: 5.152338
--------------------
2025-01-28 12:34:35,815 - decision_tree.py - families considered: 740
2025-01-28 12:34:35,815 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:34:35,815 - decision_tree.py - families with schedulers preserved: 267
2025-01-28 12:34:35,815 - decision_tree.py - families model checked: 473
2025-01-28 12:34:35,815 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:34:35,815 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:34:35,815 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:34:35,815 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked4_0=0, picked6_0=0, V_1=picked0, picked0_1=0, picked1_1=0, picked4_1=0, picked6_1=0, V_2=picked1, picked0_2=0, picked1_2=0, picked4_2=0, picked6_2=0, A_3=d, A_4=r, V_5=picked6, picked0_5=0, picked1_5=0, picked4_5=0, picked6_5=0, A_6=l, A_7=r, V_8=picked0, picked0_8=0, picked1_8=0, picked4_8=0, picked6_8=0, V_9=picked1, picked0_9=0, picked1_9=0, picked4_9=0, picked6_9=0, A_10=d, A_11=d, V_12=picked6, picked0_12=0, picked1_12=0, picked4_12=0, picked6_12=0, A_13=l, A_14=d
2025-01-28 12:34:35,827 - decision_tree.py - double-checking specification satisfiability:  : 5.152337545617383
2025-01-28 12:34:35,828 - decision_tree.py - admissible subtree found from node 79
2025-01-28 12:34:35,837 - decision_tree.py - new tree has depth 14 and 65 nodes
2025-01-28 12:34:37,484 - decision_tree.py - new dtcontrol tree has depth 13 and 114 nodes
2025-01-28 12:34:37,484 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:34:37,485 - decision_tree.py - starting iteration 34 with 1 nodes in node queue
2025-01-28 12:34:37,485 - decision_tree.py - current tree size: 131 nodes
2025-01-28 12:34:37,574 - decision_tree.py - subtree quotient has 2039 states and 2435 choices
2025-01-28 12:34:37,581 - mdp.py - MDP has 99/2039 relevant states
2025-01-28 12:34:37,584 - mdp.py - MDP has 5 actions
2025-01-28 12:34:37,599 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[3..9]']

2025-01-28 12:34:37,599 - mdp.py - building tree of depth 0
2025-01-28 12:34:37,603 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.15 s
number of holes: 1, family size: 5, quotient: 2039 states / 2435 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:34:37,756 - decision_tree.py - families considered: 4
2025-01-28 12:34:37,756 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:34:37,756 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:34:37,756 - decision_tree.py - families model checked: 4
2025-01-28 12:34:37,756 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:34:37,756 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:34:37,756 - mdp.py - building tree of depth 1
2025-01-28 12:34:37,774 - statistic.py - synthesis initiated, design space: 900
2025-01-28 12:34:38,805 - synthesizer_ar.py - value 5.1492 achieved after 711.65 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.47 s
number of holes: 9, family size: 900, quotient: 2039 states / 2435 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 36

optimum: 5.14918
--------------------
2025-01-28 12:34:39,246 - decision_tree.py - families considered: 36
2025-01-28 12:34:39,246 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:34:39,246 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 12:34:39,246 - decision_tree.py - families model checked: 30
2025-01-28 12:34:39,246 - decision_tree.py - harmonizations attempted: 6
2025-01-28 12:34:39,246 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:34:39,246 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:34:39,246 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, A_1=r, A_2=l
2025-01-28 12:34:39,257 - decision_tree.py - double-checking specification satisfiability:  : 5.149180024266106

2025-01-28 12:34:39,257 - mdp.py - building tree of depth 2
2025-01-28 12:34:39,275 - statistic.py - synthesis initiated, design space: 1e7
2025-01-28 12:34:40,016 - synthesizer_ar.py - value 5.1502 achieved after 712.87 seconds
2025-01-28 12:34:40,459 - synthesizer_ar.py - value 5.1503 achieved after 713.31 seconds
> progress 0.416%, elapsed 3 s, estimated 721 s, iters = {MDP: 61}, opt = 5.1503
2025-01-28 12:34:42,746 - synthesizer_ar.py - value 5.1504 achieved after 715.6 seconds
> progress 3.222%, elapsed 6 s, estimated 187 s, iters = {MDP: 130}, opt = 5.1504
> progress 5.638%, elapsed 9 s, estimated 161 s, iters = {MDP: 202}, opt = 5.1504
2025-01-28 12:34:49,282 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:34:49,282 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 10.0 s
number of holes: 25, family size: 1e7, quotient: 2039 states / 2435 actions
explored: 5 %
MDP stats: avg MDP size: 2039, iterations: 223

optimum: 5.150442
--------------------
2025-01-28 12:34:49,282 - decision_tree.py - families considered: 223
2025-01-28 12:34:49,282 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:34:49,282 - decision_tree.py - families with schedulers preserved: 32
2025-01-28 12:34:49,282 - decision_tree.py - families model checked: 191
2025-01-28 12:34:49,282 - decision_tree.py - harmonizations attempted: 46
2025-01-28 12:34:49,282 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:34:49,282 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:34:49,282 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=picked6, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, A_2=r, A_3=r, V_4=picked3, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=3, A_5=u, A_6=l
2025-01-28 12:34:49,293 - decision_tree.py - double-checking specification satisfiability:  : 5.1504423987143335

2025-01-28 12:34:49,293 - mdp.py - building tree of depth 3
2025-01-28 12:34:49,325 - statistic.py - synthesis initiated, design space: 1e16
2025-01-28 12:34:50,586 - synthesizer_ar.py - value 5.1511 achieved after 723.44 seconds
2025-01-28 12:34:50,876 - synthesizer_ar.py - value 5.1515 achieved after 723.73 seconds
> progress 0.0%, elapsed 3 s, estimated 21592221 s (249 days), iters = {MDP: 49}, opt = 5.1515
2025-01-28 12:34:52,851 - synthesizer_ar.py - value 5.1517 achieved after 725.7 seconds
> progress 0.0%, elapsed 6 s, estimated 2936862 s (33 days), iters = {MDP: 113}, opt = 5.1517
> progress 0.002%, elapsed 9 s, estimated 435496 s (5 days), iters = {MDP: 184}, opt = 5.1517
> progress 0.002%, elapsed 12 s, estimated 523372 s (6 days), iters = {MDP: 256}, opt = 5.1517
> progress 0.016%, elapsed 15 s, estimated 92365 s (25 hours), iters = {MDP: 330}, opt = 5.1517
> progress 0.016%, elapsed 18 s, estimated 110944 s (30 hours), iters = {MDP: 373}, opt = 5.1517
> progress 0.016%, elapsed 21 s, estimated 129435 s (35 hours), iters = {MDP: 441}, opt = 5.1517
> progress 0.016%, elapsed 24 s, estimated 147869 s (41 hours), iters = {MDP: 512}, opt = 5.1517
> progress 0.017%, elapsed 27 s, estimated 156527 s (43 hours), iters = {MDP: 581}, opt = 5.1517
2025-01-28 12:35:16,956 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:35:16,956 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.11 s
number of holes: 57, family size: 1e16, quotient: 2039 states / 2435 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 642

optimum: 5.151678
--------------------
2025-01-28 12:35:16,957 - decision_tree.py - families considered: 642
2025-01-28 12:35:16,957 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:16,957 - decision_tree.py - families with schedulers preserved: 132
2025-01-28 12:35:16,957 - decision_tree.py - families model checked: 510
2025-01-28 12:35:16,957 - decision_tree.py - harmonizations attempted: 93
2025-01-28 12:35:16,957 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:35:16,957 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:35:16,957 - decision_tree.py - V_0=picked1, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=picked6, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, V_2=picked6, picked1_2=0, picked2_2=0, picked3_2=0, picked4_2=0, picked6_2=0, x_2=3, A_3=r, A_4=u, V_5=picked6, picked1_5=0, picked2_5=0, picked3_5=0, picked4_5=0, picked6_5=0, x_5=3, A_6=r, A_7=r, V_8=picked3, picked1_8=0, picked2_8=0, picked3_8=0, picked4_8=0, picked6_8=0, x_8=3, V_9=x, picked1_9=0, picked2_9=0, picked3_9=0, picked4_9=0, picked6_9=0, x_9=8, A_10=r, A_11=u, V_12=x, picked1_12=0, picked2_12=0, picked3_12=0, picked4_12=0, picked6_12=0, x_12=3, A_13=r, A_14=l
2025-01-28 12:35:16,967 - decision_tree.py - double-checking specification satisfiability:  : 5.151678146831272
2025-01-28 12:35:16,967 - decision_tree.py - admissible subtree found from node 8
2025-01-28 12:35:16,968 - decision_tree.py - new tree has depth 15 and 61 nodes
2025-01-28 12:35:18,680 - decision_tree.py - new dtcontrol tree has depth 13 and 105 nodes
2025-01-28 12:35:18,680 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:35:18,681 - decision_tree.py - starting iteration with subtree depth 3
2025-01-28 12:35:18,691 - decision_tree.py - starting iteration 35 with 7 nodes in node queue
2025-01-28 12:35:18,691 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:35:18,779 - decision_tree.py - subtree quotient has 2039 states and 2071 choices
2025-01-28 12:35:18,786 - mdp.py - MDP has 8/2039 relevant states
2025-01-28 12:35:18,789 - mdp.py - MDP has 5 actions
2025-01-28 12:35:18,804 - mdp.py - found the following 3 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked4:[0..1]']

2025-01-28 12:35:18,804 - mdp.py - building tree of depth 0
2025-01-28 12:35:18,808 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:35:18,909 - synthesizer_ar.py - value 5.1401 achieved after 754.23 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.15 s
number of holes: 1, family size: 5, quotient: 2039 states / 2071 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.140115
--------------------
2025-01-28 12:35:18,959 - decision_tree.py - families considered: 4
2025-01-28 12:35:18,959 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:18,959 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:35:18,959 - decision_tree.py - families model checked: 4
2025-01-28 12:35:18,959 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:35:18,959 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:35:18,959 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:35:18,959 - decision_tree.py - A_0=d
2025-01-28 12:35:18,970 - decision_tree.py - double-checking specification satisfiability:  : 5.140115062438368

2025-01-28 12:35:18,971 - mdp.py - building tree of depth 1
2025-01-28 12:35:18,979 - statistic.py - synthesis initiated, design space: 75
2025-01-28 12:35:19,079 - synthesizer_ar.py - value 5.1504 achieved after 754.4 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.24 s
number of holes: 6, family size: 75, quotient: 2039 states / 2071 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 26

optimum: 5.150414
--------------------
2025-01-28 12:35:20,215 - decision_tree.py - families considered: 26
2025-01-28 12:35:20,215 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:20,215 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:35:20,215 - decision_tree.py - families model checked: 24
2025-01-28 12:35:20,215 - decision_tree.py - harmonizations attempted: 6
2025-01-28 12:35:20,215 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:35:20,216 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:35:20,216 - decision_tree.py - V_0=picked0, picked0_0=0, picked1_0=0, picked4_0=0, A_1=d, A_2=r
2025-01-28 12:35:20,235 - decision_tree.py - double-checking specification satisfiability:  : 5.150414245488598

2025-01-28 12:35:20,236 - mdp.py - building tree of depth 2
2025-01-28 12:35:20,255 - statistic.py - synthesis initiated, design space: 16875
2025-01-28 12:35:20,977 - synthesizer_ar.py - value 5.1512 achieved after 756.3 seconds
2025-01-28 12:35:22,169 - synthesizer_ar.py - value 5.1517 achieved after 757.49 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.67 s
number of holes: 16, family size: 16875, quotient: 2039 states / 2071 actions
explored: 133 %
MDP stats: avg MDP size: 2039, iterations: 68

optimum: 5.151678
--------------------
2025-01-28 12:35:22,922 - decision_tree.py - families considered: 68
2025-01-28 12:35:22,922 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:22,922 - decision_tree.py - families with schedulers preserved: 17
2025-01-28 12:35:22,922 - decision_tree.py - families model checked: 51
2025-01-28 12:35:22,922 - decision_tree.py - harmonizations attempted: 5
2025-01-28 12:35:22,922 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:35:22,922 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:35:22,922 - decision_tree.py - V_0=picked1, picked0_0=0, picked1_0=0, picked4_0=0, V_1=picked1, picked0_1=0, picked1_1=0, picked4_1=0, A_2=d, A_3=r, V_4=picked4, picked0_4=0, picked1_4=0, picked4_4=0, A_5=r, A_6=d
2025-01-28 12:35:22,934 - decision_tree.py - double-checking specification satisfiability:  : 5.151678146831272
2025-01-28 12:35:22,934 - decision_tree.py - admissible subtree found from node 77
2025-01-28 12:35:22,935 - decision_tree.py - new tree has depth 14 and 60 nodes
2025-01-28 12:35:24,595 - decision_tree.py - new dtcontrol tree has depth 13 and 104 nodes
2025-01-28 12:35:24,595 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:35:24,597 - decision_tree.py - starting iteration 36 with 6 nodes in node queue
2025-01-28 12:35:24,597 - decision_tree.py - current tree size: 121 nodes
2025-01-28 12:35:24,689 - decision_tree.py - subtree quotient has 2039 states and 2383 choices
2025-01-28 12:35:24,696 - mdp.py - MDP has 86/2039 relevant states
2025-01-28 12:35:24,699 - mdp.py - MDP has 5 actions
2025-01-28 12:35:24,715 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[2..3]']

2025-01-28 12:35:24,715 - mdp.py - building tree of depth 0
2025-01-28 12:35:24,721 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.16 s
number of holes: 1, family size: 5, quotient: 2039 states / 2383 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:35:24,879 - decision_tree.py - families considered: 4
2025-01-28 12:35:24,879 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:24,879 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:35:24,880 - decision_tree.py - families model checked: 4
2025-01-28 12:35:24,880 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:35:24,880 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:35:24,880 - mdp.py - building tree of depth 1
2025-01-28 12:35:24,893 - statistic.py - synthesis initiated, design space: 175
2025-01-28 12:35:25,197 - synthesizer_ar.py - value 5.1517 achieved after 760.52 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.4 s
number of holes: 10, family size: 175, quotient: 2039 states / 2383 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 10

optimum: 5.151697
--------------------
2025-01-28 12:35:25,289 - decision_tree.py - families considered: 10
2025-01-28 12:35:25,289 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:25,289 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:35:25,289 - decision_tree.py - families model checked: 9
2025-01-28 12:35:25,289 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:35:25,289 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:35:25,289 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:35:25,289 - decision_tree.py - V_0=x, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=2, A_1=r, A_2=d
2025-01-28 12:35:25,301 - decision_tree.py - double-checking specification satisfiability:  : 5.1516971249387735

2025-01-28 12:35:25,301 - mdp.py - building tree of depth 2
2025-01-28 12:35:25,320 - statistic.py - synthesis initiated, design space: 214375
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.03 s
number of holes: 28, family size: 214375, quotient: 2039 states / 2383 actions
explored: 114 %
MDP stats: avg MDP size: 2039, iterations: 2

optimum: 5.151697
--------------------
2025-01-28 12:35:25,351 - decision_tree.py - families considered: 2
2025-01-28 12:35:25,351 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:25,351 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:35:25,351 - decision_tree.py - families model checked: 2
2025-01-28 12:35:25,351 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:35:25,351 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:35:25,351 - decision_tree.py - admissible subtree found from node 38
2025-01-28 12:35:25,352 - decision_tree.py - new tree has depth 14 and 55 nodes
2025-01-28 12:35:27,043 - decision_tree.py - new dtcontrol tree has depth 13 and 94 nodes
2025-01-28 12:35:27,043 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:35:27,045 - decision_tree.py - starting iteration 37 with 5 nodes in node queue
2025-01-28 12:35:27,045 - decision_tree.py - current tree size: 111 nodes
2025-01-28 12:35:27,133 - decision_tree.py - subtree quotient has 2039 states and 2379 choices
2025-01-28 12:35:27,140 - mdp.py - MDP has 85/2039 relevant states
2025-01-28 12:35:27,143 - mdp.py - MDP has 5 actions
2025-01-28 12:35:27,157 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[3..9]']

2025-01-28 12:35:27,157 - mdp.py - building tree of depth 0
2025-01-28 12:35:27,161 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.14 s
number of holes: 1, family size: 5, quotient: 2039 states / 2379 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:35:27,298 - decision_tree.py - families considered: 4
2025-01-28 12:35:27,298 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:27,298 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:35:27,298 - decision_tree.py - families model checked: 4
2025-01-28 12:35:27,298 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:35:27,298 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:35:27,298 - mdp.py - building tree of depth 1
2025-01-28 12:35:27,309 - statistic.py - synthesis initiated, design space: 175
2025-01-28 12:35:28,353 - synthesizer_ar.py - value 5.141 achieved after 763.68 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.09 s
number of holes: 10, family size: 175, quotient: 2039 states / 2379 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 28

optimum: 5.140958
--------------------
2025-01-28 12:35:28,395 - decision_tree.py - families considered: 28
2025-01-28 12:35:28,395 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:28,395 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:35:28,395 - decision_tree.py - families model checked: 23
2025-01-28 12:35:28,395 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:35:28,395 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:35:28,395 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:35:28,396 - decision_tree.py - V_0=picked0, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, A_1=d, A_2=u
2025-01-28 12:35:28,405 - decision_tree.py - double-checking specification satisfiability:  : 5.140958432180289

2025-01-28 12:35:28,405 - mdp.py - building tree of depth 2
2025-01-28 12:35:28,423 - statistic.py - synthesis initiated, design space: 214375
2025-01-28 12:35:29,201 - synthesizer_ar.py - value 5.1417 achieved after 764.53 seconds
2025-01-28 12:35:29,795 - synthesizer_ar.py - value 5.142 achieved after 765.12 seconds
2025-01-28 12:35:29,949 - synthesizer_ar.py - value 5.1425 achieved after 765.27 seconds
2025-01-28 12:35:30,840 - synthesizer_ar.py - value 5.1491 achieved after 766.16 seconds
> progress 3.323%, elapsed 3 s, estimated 90 s, iters = {MDP: 65}, opt = 5.1491
> progress 4.361%, elapsed 6 s, estimated 138 s, iters = {MDP: 146}, opt = 5.1491
> progress 5.481%, elapsed 9 s, estimated 166 s, iters = {MDP: 228}, opt = 5.1491
2025-01-28 12:35:36,553 - synthesizer_ar.py - value 5.1492 achieved after 774.36 seconds
2025-01-28 12:35:36,823 - synthesizer_ar.py - value 5.1499 achieved after 774.63 seconds
2025-01-28 12:35:37,921 - synthesizer_ar.py - value 5.1503 achieved after 775.73 seconds
> progress 18.376%, elapsed 12 s, estimated 66 s, iters = {MDP: 301}, opt = 5.1503
2025-01-28 12:35:38,752 - synthesizer_ar.py - value 5.1514 achieved after 776.56 seconds
> progress 31.526%, elapsed 15 s, estimated 48 s, iters = {MDP: 378}, opt = 5.1514
> progress 32.373%, elapsed 18 s, estimated 56 s, iters = {MDP: 455}, opt = 5.1514
> progress 33.215%, elapsed 21 s, estimated 63 s, iters = {MDP: 528}, opt = 5.1514
> progress 57.42%, elapsed 24 s, estimated 42 s, iters = {MDP: 606}, opt = 5.1514
2025-01-28 12:35:52,066 - synthesizer_ar.py - value 5.1517 achieved after 789.88 seconds
2025-01-28 12:35:52,483 - synthesizer_ar.py - value 5.152 achieved after 790.29 seconds
> progress 63.02%, elapsed 27 s, estimated 43 s, iters = {MDP: 683}, opt = 5.152
2025-01-28 12:35:55,939 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.0 s
number of holes: 28, family size: 214375, quotient: 2039 states / 2379 actions
explored: 65 %
MDP stats: avg MDP size: 2039, iterations: 753

optimum: 5.152014
--------------------
2025-01-28 12:35:55,940 - decision_tree.py - families considered: 753
2025-01-28 12:35:55,940 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:55,940 - decision_tree.py - families with schedulers preserved: 148
2025-01-28 12:35:55,940 - decision_tree.py - families model checked: 605
2025-01-28 12:35:55,940 - decision_tree.py - harmonizations attempted: 104
2025-01-28 12:35:55,940 - decision_tree.py - harmonizations succeeded: 8

2025-01-28 12:35:55,940 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:35:55,940 - decision_tree.py - V_0=picked4, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=3, V_1=picked1, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=3, A_2=d, A_3=u, V_4=picked2, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=3, A_5=u, A_6=d
2025-01-28 12:35:55,951 - decision_tree.py - double-checking specification satisfiability:  : 5.152014388005979
2025-01-28 12:35:55,952 - decision_tree.py - admissible subtree found from node 26
2025-01-28 12:35:55,952 - decision_tree.py - new tree has depth 14 and 53 nodes
2025-01-28 12:35:57,624 - decision_tree.py - new dtcontrol tree has depth 12 and 92 nodes
2025-01-28 12:35:57,625 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:35:57,626 - decision_tree.py - starting iteration 38 with 4 nodes in node queue
2025-01-28 12:35:57,626 - decision_tree.py - current tree size: 107 nodes
2025-01-28 12:35:57,714 - decision_tree.py - subtree quotient has 2039 states and 2687 choices
2025-01-28 12:35:57,720 - mdp.py - MDP has 162/2039 relevant states
2025-01-28 12:35:57,724 - mdp.py - MDP has 5 actions
2025-01-28 12:35:57,738 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'x:[10..14]', 'y:[2..4]']

2025-01-28 12:35:57,738 - mdp.py - building tree of depth 0
2025-01-28 12:35:57,742 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:35:57,854 - synthesizer_ar.py - value 5.1417 achieved after 795.67 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.15 s
number of holes: 1, family size: 5, quotient: 2039 states / 2687 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.141705
--------------------
2025-01-28 12:35:57,889 - decision_tree.py - families considered: 4
2025-01-28 12:35:57,889 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:35:57,889 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:35:57,889 - decision_tree.py - families model checked: 4
2025-01-28 12:35:57,889 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:35:57,889 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:35:57,889 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:35:57,889 - decision_tree.py - A_0=l
2025-01-28 12:35:57,900 - decision_tree.py - double-checking specification satisfiability:  : 5.141704508835898

2025-01-28 12:35:57,900 - mdp.py - building tree of depth 1
2025-01-28 12:35:57,915 - statistic.py - synthesis initiated, design space: 1400
> progress 114.285%, elapsed 3 s, estimated 2 s, iters = {MDP: 75}, opt = 5.1417
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 4.72 s
number of holes: 10, family size: 1400, quotient: 2039 states / 2687 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 123

optimum: 5.141705
--------------------
2025-01-28 12:36:00,151 - decision_tree.py - families considered: 123
2025-01-28 12:36:00,151 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:36:00,151 - decision_tree.py - families with schedulers preserved: 23
2025-01-28 12:36:00,151 - decision_tree.py - families model checked: 100
2025-01-28 12:36:00,151 - decision_tree.py - harmonizations attempted: 19
2025-01-28 12:36:00,151 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:36:00,151 - mdp.py - building tree of depth 2
2025-01-28 12:36:00,177 - statistic.py - synthesis initiated, design space: 1e8
> progress 1.457%, elapsed 3 s, estimated 211 s, iters = {MDP: 69}, opt = 5.1417
> progress 2.145%, elapsed 6 s, estimated 283 s, iters = {MDP: 145}, opt = 5.1417
> progress 4.081%, elapsed 9 s, estimated 224 s, iters = {MDP: 225}, opt = 5.1417
2025-01-28 12:36:09,875 - synthesizer_ar.py - value 5.1419 achieved after 810.17 seconds
2025-01-28 12:36:10,637 - synthesizer_ar.py - value 5.1496 achieved after 810.93 seconds
> progress 4.956%, elapsed 12 s, estimated 245 s, iters = {MDP: 295}, opt = 5.1496
> progress 5.871%, elapsed 15 s, estimated 258 s, iters = {MDP: 368}, opt = 5.1496
> progress 11.836%, elapsed 18 s, estimated 153 s, iters = {MDP: 433}, opt = 5.1496
> progress 18.367%, elapsed 21 s, estimated 115 s, iters = {MDP: 498}, opt = 5.1496
> progress 20.676%, elapsed 24 s, estimated 117 s, iters = {MDP: 564}, opt = 5.1496
> progress 22.507%, elapsed 27 s, estimated 121 s, iters = {MDP: 613}, opt = 5.1496
2025-01-28 12:36:30,202 - synthesizer.py - time limit reached, aborting...
2025-01-28 12:36:30,202 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.02 s
number of holes: 28, family size: 1e8, quotient: 2039 states / 2687 actions
explored: 23 %
MDP stats: avg MDP size: 2039, iterations: 672

optimum: 5.14956
--------------------
2025-01-28 12:36:30,202 - decision_tree.py - families considered: 672
2025-01-28 12:36:30,202 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:36:30,202 - decision_tree.py - families with schedulers preserved: 147
2025-01-28 12:36:30,202 - decision_tree.py - families model checked: 525
2025-01-28 12:36:30,202 - decision_tree.py - harmonizations attempted: 90
2025-01-28 12:36:30,202 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 12:36:30,202 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:36:30,202 - decision_tree.py - V_0=y, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=10, y_0=2, V_1=picked6, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, x_1=10, y_1=2, A_2=l, A_3=l, V_4=y, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked6_4=0, x_4=10, y_4=3, A_5=d, A_6=l
2025-01-28 12:36:30,213 - decision_tree.py - double-checking specification satisfiability:  : 5.1495599909060275
2025-01-28 12:36:30,213 - decision_tree.py - admissible subtree found from node 99
2025-01-28 12:36:30,213 - decision_tree.py - new tree has depth 14 and 52 nodes
2025-01-28 12:36:30,007 - decision_tree.py - new dtcontrol tree has depth 12 and 79 nodes
2025-01-28 12:36:30,007 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:36:30,009 - decision_tree.py - starting iteration 39 with 3 nodes in node queue
2025-01-28 12:36:30,009 - decision_tree.py - current tree size: 105 nodes
2025-01-28 12:36:30,094 - decision_tree.py - subtree quotient has 2039 states and 2735 choices
2025-01-28 12:36:30,100 - mdp.py - MDP has 174/2039 relevant states
2025-01-28 12:36:30,103 - mdp.py - MDP has 5 actions
2025-01-28 12:36:30,117 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'x:[10..14]', 'y:[2..4]']

2025-01-28 12:36:30,118 - mdp.py - building tree of depth 0
2025-01-28 12:36:30,123 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.14 s
number of holes: 1, family size: 5, quotient: 2039 states / 2735 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:36:30,259 - decision_tree.py - families considered: 4
2025-01-28 12:36:30,260 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:36:30,260 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:36:30,260 - decision_tree.py - families model checked: 4
2025-01-28 12:36:30,260 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:36:30,260 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:36:30,260 - mdp.py - building tree of depth 1
2025-01-28 12:36:30,276 - statistic.py - synthesis initiated, design space: 1400
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.14 s
number of holes: 10, family size: 1400, quotient: 2039 states / 2735 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 52

optimum: 5.127782
--------------------
2025-01-28 12:36:32,418 - decision_tree.py - families considered: 52
2025-01-28 12:36:32,418 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:36:32,418 - decision_tree.py - families with schedulers preserved: 11
2025-01-28 12:36:32,418 - decision_tree.py - families model checked: 41
2025-01-28 12:36:32,418 - decision_tree.py - harmonizations attempted: 7
2025-01-28 12:36:32,418 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:36:32,418 - mdp.py - building tree of depth 2
2025-01-28 12:36:32,446 - statistic.py - synthesis initiated, design space: 1e8
2025-01-28 12:36:33,526 - synthesizer_ar.py - value 5.1289 achieved after 836.3 seconds
> progress 6.18%, elapsed 3 s, estimated 48 s, iters = {MDP: 66}, opt = 5.1289
> progress 6.32%, elapsed 6 s, estimated 96 s, iters = {MDP: 133}, opt = 5.1289
> progress 6.78%, elapsed 9 s, estimated 135 s, iters = {MDP: 206}, opt = 5.1289
> progress 6.892%, elapsed 12 s, estimated 177 s, iters = {MDP: 277}, opt = 5.1289
> progress 7.708%, elapsed 15 s, estimated 197 s, iters = {MDP: 350}, opt = 5.1289
> progress 14.439%, elapsed 18 s, estimated 127 s, iters = {MDP: 424}, opt = 5.1289
> progress 20.772%, elapsed 21 s, estimated 103 s, iters = {MDP: 497}, opt = 5.1289
> progress 21.177%, elapsed 24 s, estimated 115 s, iters = {MDP: 571}, opt = 5.1289
> progress 24.489%, elapsed 27 s, estimated 112 s, iters = {MDP: 647}, opt = 5.1289
2025-01-28 12:37:00,020 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.05 s
number of holes: 28, family size: 1e8, quotient: 2039 states / 2735 actions
explored: 28 %
MDP stats: avg MDP size: 2039, iterations: 700

optimum: 5.128891
--------------------
2025-01-28 12:37:00,020 - decision_tree.py - families considered: 700
2025-01-28 12:37:00,020 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:00,020 - decision_tree.py - families with schedulers preserved: 132
2025-01-28 12:37:00,021 - decision_tree.py - families model checked: 568
2025-01-28 12:37:00,021 - decision_tree.py - harmonizations attempted: 114
2025-01-28 12:37:00,021 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:00,021 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:37:00,021 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked6_0=0, x_0=10, y_0=2, V_1=picked6, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked6_1=0, x_1=10, y_1=2, A_2=l, A_3=l, V_4=y, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked6_4=0, x_4=10, y_4=2, A_5=l, A_6=r
2025-01-28 12:37:00,030 - decision_tree.py - double-checking specification satisfiability:  : 5.128891311182637
2025-01-28 12:37:00,030 - decision_tree.py - admissible subtree found from node 86
2025-01-28 12:37:00,031 - decision_tree.py - new tree has depth 14 and 48 nodes
2025-01-28 12:37:01,654 - decision_tree.py - new dtcontrol tree has depth 14 and 69 nodes
2025-01-28 12:37:01,655 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:37:01,656 - decision_tree.py - starting iteration 40 with 2 nodes in node queue
2025-01-28 12:37:01,656 - decision_tree.py - current tree size: 97 nodes
2025-01-28 12:37:01,747 - decision_tree.py - subtree quotient has 2039 states and 2551 choices
2025-01-28 12:37:01,755 - mdp.py - MDP has 128/2039 relevant states
2025-01-28 12:37:01,758 - mdp.py - MDP has 5 actions
2025-01-28 12:37:01,775 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[2..8]']

2025-01-28 12:37:01,775 - mdp.py - building tree of depth 0
2025-01-28 12:37:01,780 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.15 s
number of holes: 1, family size: 5, quotient: 2039 states / 2551 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:01,929 - decision_tree.py - families considered: 4
2025-01-28 12:37:01,930 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:01,930 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:01,930 - decision_tree.py - families model checked: 4
2025-01-28 12:37:01,930 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:01,930 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:01,930 - mdp.py - building tree of depth 1
2025-01-28 12:37:01,943 - statistic.py - synthesis initiated, design space: 350
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.35 s
number of holes: 10, family size: 350, quotient: 2039 states / 2551 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 10

optimum: 5.127782
--------------------
2025-01-28 12:37:02,292 - decision_tree.py - families considered: 10
2025-01-28 12:37:02,292 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:02,292 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:37:02,293 - decision_tree.py - families model checked: 9
2025-01-28 12:37:02,293 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:37:02,293 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:02,293 - mdp.py - building tree of depth 2
2025-01-28 12:37:02,314 - statistic.py - synthesis initiated, design space: 1e6
2025-01-28 12:37:03,286 - synthesizer_ar.py - value 5.1289 achieved after 868.54 seconds
2025-01-28 12:37:03,667 - synthesizer_ar.py - value 5.1295 achieved after 868.92 seconds
> progress 23.673%, elapsed 3 s, estimated 12 s, iters = {MDP: 69}, opt = 5.1295
> progress 30.682%, elapsed 6 s, estimated 19 s, iters = {MDP: 141}, opt = 5.1295
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.78 s
number of holes: 28, family size: 1e6, quotient: 2039 states / 2551 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 165

optimum: 5.129486
--------------------
2025-01-28 12:37:09,091 - decision_tree.py - families considered: 165
2025-01-28 12:37:09,091 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:09,091 - decision_tree.py - families with schedulers preserved: 29
2025-01-28 12:37:09,091 - decision_tree.py - families model checked: 136
2025-01-28 12:37:09,091 - decision_tree.py - harmonizations attempted: 28
2025-01-28 12:37:09,091 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:37:09,091 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:37:09,091 - decision_tree.py - V_0=picked6, picked0_0=0, picked1_0=0, picked2_0=0, picked3_0=0, picked4_0=0, picked6_0=0, x_0=2, V_1=x, picked0_1=0, picked1_1=0, picked2_1=0, picked3_1=0, picked4_1=0, picked6_1=0, x_1=2, A_2=d, A_3=u, V_4=x, picked0_4=0, picked1_4=0, picked2_4=0, picked3_4=0, picked4_4=0, picked6_4=0, x_4=4, A_5=u, A_6=d
2025-01-28 12:37:09,100 - decision_tree.py - double-checking specification satisfiability:  : 5.129485590658206
2025-01-28 12:37:09,101 - decision_tree.py - admissible subtree found from node 68
2025-01-28 12:37:09,101 - decision_tree.py - new tree has depth 14 and 47 nodes
2025-01-28 12:37:10,666 - decision_tree.py - new dtcontrol tree has depth 13 and 58 nodes
2025-01-28 12:37:10,667 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:37:10,668 - decision_tree.py - starting iteration 41 with 1 nodes in node queue
2025-01-28 12:37:10,668 - decision_tree.py - current tree size: 95 nodes
2025-01-28 12:37:10,760 - decision_tree.py - subtree quotient has 2039 states and 10195 choices
2025-01-28 12:37:10,767 - mdp.py - MDP has 2039/2039 relevant states
2025-01-28 12:37:10,778 - mdp.py - MDP has 5 actions
2025-01-28 12:37:10,794 - mdp.py - found the following 9 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked5:[0..1]', 'picked6:[0..1]', 'x:[0..14]', 'y:[0..6]']

2025-01-28 12:37:10,794 - mdp.py - building tree of depth 0
2025-01-28 12:37:10,811 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.12 s
number of holes: 1, family size: 5, quotient: 2039 states / 10195 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:10,933 - decision_tree.py - families considered: 4
2025-01-28 12:37:10,933 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:10,933 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:10,933 - decision_tree.py - families model checked: 4
2025-01-28 12:37:10,933 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:10,933 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:10,934 - mdp.py - building tree of depth 1
2025-01-28 12:37:11,052 - statistic.py - synthesis initiated, design space: 18900
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.73 s
number of holes: 12, family size: 18900, quotient: 2039 states / 10195 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 18

optimum: 5.127782
--------------------
2025-01-28 12:37:11,785 - decision_tree.py - families considered: 18
2025-01-28 12:37:11,785 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:11,785 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:37:11,785 - decision_tree.py - families model checked: 13
2025-01-28 12:37:11,785 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:11,785 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:11,785 - mdp.py - building tree of depth 2
2025-01-28 12:37:12,116 - statistic.py - synthesis initiated, design space: 1e11
> progress 0.009%, elapsed 3 s, estimated 34032 s (9 hours), iters = {MDP: 38}, opt = 5.1278
> progress 0.205%, elapsed 6 s, estimated 3000 s, iters = {MDP: 100}, opt = 5.1278
> progress 0.377%, elapsed 9 s, estimated 2436 s, iters = {MDP: 158}, opt = 5.1278
> progress 2.661%, elapsed 12 s, estimated 462 s, iters = {MDP: 212}, opt = 5.1278
> progress 5.031%, elapsed 15 s, estimated 304 s, iters = {MDP: 262}, opt = 5.1278
> progress 13.58%, elapsed 18 s, estimated 135 s, iters = {MDP: 313}, opt = 5.1278
> progress 22.371%, elapsed 21 s, estimated 95 s, iters = {MDP: 349}, opt = 5.1278
> progress 22.384%, elapsed 24 s, estimated 109 s, iters = {MDP: 399}, opt = 5.1278
> progress 22.402%, elapsed 27 s, estimated 122 s, iters = {MDP: 446}, opt = 5.1278
2025-01-28 12:37:39,667 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.04 s
number of holes: 34, family size: 1e11, quotient: 2039 states / 10195 actions
explored: 22 %
MDP stats: avg MDP size: 2039, iterations: 494

optimum: 5.127782
--------------------
2025-01-28 12:37:39,668 - decision_tree.py - families considered: 494
2025-01-28 12:37:39,668 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:39,668 - decision_tree.py - families with schedulers preserved: 150
2025-01-28 12:37:39,668 - decision_tree.py - families model checked: 344
2025-01-28 12:37:39,668 - decision_tree.py - harmonizations attempted: 31
2025-01-28 12:37:39,668 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:39,668 - decision_tree.py - no admissible subtree found from node 8
2025-01-28 12:37:39,668 - decision_tree.py - starting iteration with subtree depth 2
2025-01-28 12:37:39,682 - decision_tree.py - starting iteration 42 with 11 nodes in node queue
2025-01-28 12:37:39,682 - decision_tree.py - current tree size: 95 nodes
2025-01-28 12:37:39,761 - decision_tree.py - subtree quotient has 2039 states and 2291 choices
2025-01-28 12:37:39,767 - mdp.py - MDP has 63/2039 relevant states
2025-01-28 12:37:39,790 - mdp.py - MDP has 5 actions
2025-01-28 12:37:39,803 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[6..8]']

2025-01-28 12:37:39,803 - mdp.py - building tree of depth 0
2025-01-28 12:37:39,812 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 1, family size: 5, quotient: 2039 states / 2291 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:39,942 - decision_tree.py - families considered: 4
2025-01-28 12:37:39,942 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:39,942 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:39,942 - decision_tree.py - families model checked: 4
2025-01-28 12:37:39,942 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:39,942 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:39,942 - mdp.py - building tree of depth 1
2025-01-28 12:37:39,959 - statistic.py - synthesis initiated, design space: 300
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.11 s
number of holes: 9, family size: 300, quotient: 2039 states / 2291 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 30

optimum: 5.127782
--------------------
2025-01-28 12:37:41,070 - decision_tree.py - families considered: 30
2025-01-28 12:37:41,070 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:41,071 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 12:37:41,071 - decision_tree.py - families model checked: 24
2025-01-28 12:37:41,071 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:37:41,071 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:41,071 - decision_tree.py - no admissible subtree found from node 50
2025-01-28 12:37:41,071 - decision_tree.py - starting iteration 43 with 10 nodes in node queue
2025-01-28 12:37:41,071 - decision_tree.py - current tree size: 95 nodes
2025-01-28 12:37:41,149 - decision_tree.py - subtree quotient has 2039 states and 2687 choices
2025-01-28 12:37:41,154 - mdp.py - MDP has 162/2039 relevant states
2025-01-28 12:37:41,162 - mdp.py - MDP has 5 actions
2025-01-28 12:37:41,263 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'x:[10..14]', 'y:[2..4]']

2025-01-28 12:37:41,264 - mdp.py - building tree of depth 0
2025-01-28 12:37:41,269 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.17 s
number of holes: 1, family size: 5, quotient: 2039 states / 2687 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:41,437 - decision_tree.py - families considered: 4
2025-01-28 12:37:41,437 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:41,437 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:41,437 - decision_tree.py - families model checked: 4
2025-01-28 12:37:41,437 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:41,437 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:41,437 - mdp.py - building tree of depth 1
2025-01-28 12:37:41,452 - statistic.py - synthesis initiated, design space: 1400
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.99 s
number of holes: 10, family size: 1400, quotient: 2039 states / 2687 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 51

optimum: 5.127782
--------------------
2025-01-28 12:37:43,447 - decision_tree.py - families considered: 51
2025-01-28 12:37:43,447 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:43,447 - decision_tree.py - families with schedulers preserved: 8
2025-01-28 12:37:43,447 - decision_tree.py - families model checked: 43
2025-01-28 12:37:43,447 - decision_tree.py - harmonizations attempted: 9
2025-01-28 12:37:43,447 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:43,447 - decision_tree.py - no admissible subtree found from node 89
2025-01-28 12:37:43,447 - decision_tree.py - starting iteration 44 with 9 nodes in node queue
2025-01-28 12:37:43,447 - decision_tree.py - current tree size: 95 nodes
2025-01-28 12:37:43,536 - decision_tree.py - subtree quotient has 2039 states and 2375 choices
2025-01-28 12:37:43,542 - mdp.py - MDP has 84/2039 relevant states
2025-01-28 12:37:43,547 - mdp.py - MDP has 5 actions
2025-01-28 12:37:43,564 - mdp.py - found the following 6 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[6..9]']

2025-01-28 12:37:43,564 - mdp.py - building tree of depth 0
2025-01-28 12:37:43,568 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.14 s
number of holes: 1, family size: 5, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:43,712 - decision_tree.py - families considered: 4
2025-01-28 12:37:43,712 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:43,712 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:43,712 - decision_tree.py - families model checked: 4
2025-01-28 12:37:43,712 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:43,712 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:43,712 - mdp.py - building tree of depth 1
2025-01-28 12:37:43,723 - statistic.py - synthesis initiated, design space: 450
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.74 s
number of holes: 9, family size: 450, quotient: 2039 states / 2375 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 22

optimum: 5.127782
--------------------
2025-01-28 12:37:44,465 - decision_tree.py - families considered: 22
2025-01-28 12:37:44,465 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:44,465 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 12:37:44,465 - decision_tree.py - families model checked: 16
2025-01-28 12:37:44,465 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:44,465 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:44,465 - decision_tree.py - no admissible subtree found from node 42
2025-01-28 12:37:44,465 - decision_tree.py - starting iteration 45 with 8 nodes in node queue
2025-01-28 12:37:44,465 - decision_tree.py - current tree size: 95 nodes
2025-01-28 12:37:44,542 - decision_tree.py - subtree quotient has 2039 states and 2379 choices
2025-01-28 12:37:44,548 - mdp.py - MDP has 85/2039 relevant states
2025-01-28 12:37:44,555 - mdp.py - MDP has 5 actions
2025-01-28 12:37:44,569 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[3..9]']

2025-01-28 12:37:44,569 - mdp.py - building tree of depth 0
2025-01-28 12:37:44,572 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 1, family size: 5, quotient: 2039 states / 2379 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:44,701 - decision_tree.py - families considered: 4
2025-01-28 12:37:44,701 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:44,701 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:44,701 - decision_tree.py - families model checked: 4
2025-01-28 12:37:44,701 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:44,701 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:44,701 - mdp.py - building tree of depth 1
2025-01-28 12:37:44,713 - statistic.py - synthesis initiated, design space: 175
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.66 s
number of holes: 10, family size: 175, quotient: 2039 states / 2379 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 19

optimum: 5.127782
--------------------
2025-01-28 12:37:45,373 - decision_tree.py - families considered: 19
2025-01-28 12:37:45,373 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:45,373 - decision_tree.py - families with schedulers preserved: 4
2025-01-28 12:37:45,373 - decision_tree.py - families model checked: 15
2025-01-28 12:37:45,373 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:37:45,373 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:45,373 - decision_tree.py - no admissible subtree found from node 26
2025-01-28 12:37:45,374 - decision_tree.py - starting iteration 46 with 7 nodes in node queue
2025-01-28 12:37:45,374 - decision_tree.py - current tree size: 95 nodes
2025-01-28 12:37:45,466 - decision_tree.py - subtree quotient has 2039 states and 10195 choices
2025-01-28 12:37:45,473 - mdp.py - MDP has 2039/2039 relevant states
2025-01-28 12:37:45,490 - mdp.py - MDP has 5 actions
2025-01-28 12:37:45,511 - mdp.py - found the following 9 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked5:[0..1]', 'picked6:[0..1]', 'x:[0..14]', 'y:[0..6]']

2025-01-28 12:37:45,511 - mdp.py - building tree of depth 0
2025-01-28 12:37:45,530 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.14 s
number of holes: 1, family size: 5, quotient: 2039 states / 10195 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:45,667 - decision_tree.py - families considered: 4
2025-01-28 12:37:45,667 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:45,667 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:45,667 - decision_tree.py - families model checked: 4
2025-01-28 12:37:45,667 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:45,668 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:45,668 - mdp.py - building tree of depth 1
2025-01-28 12:37:45,774 - statistic.py - synthesis initiated, design space: 18900
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.72 s
number of holes: 12, family size: 18900, quotient: 2039 states / 10195 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 18

optimum: 5.127782
--------------------
2025-01-28 12:37:46,494 - decision_tree.py - families considered: 18
2025-01-28 12:37:46,494 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:46,494 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:37:46,494 - decision_tree.py - families model checked: 13
2025-01-28 12:37:46,494 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:46,494 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:46,494 - decision_tree.py - no admissible subtree found from node 68
2025-01-28 12:37:46,495 - decision_tree.py - starting iteration 47 with 6 nodes in node queue
2025-01-28 12:37:46,495 - decision_tree.py - current tree size: 95 nodes
2025-01-28 12:37:46,572 - decision_tree.py - subtree quotient has 2039 states and 2055 choices
2025-01-28 12:37:46,577 - mdp.py - MDP has 4/2039 relevant states
2025-01-28 12:37:46,584 - mdp.py - MDP has 5 actions
2025-01-28 12:37:46,597 - mdp.py - found the following 2 variables: ['picked1:[0..1]', 'picked4:[0..1]']

2025-01-28 12:37:46,597 - mdp.py - building tree of depth 0
2025-01-28 12:37:46,600 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:37:46,700 - synthesizer_ar.py - value 5.1295 achieved after 914.44 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 1, family size: 5, quotient: 2039 states / 2055 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.129486
--------------------
2025-01-28 12:37:46,729 - decision_tree.py - families considered: 4
2025-01-28 12:37:46,729 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:46,729 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:46,729 - decision_tree.py - families model checked: 4
2025-01-28 12:37:46,729 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:46,729 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:37:46,729 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:37:46,729 - decision_tree.py - A_0=l
2025-01-28 12:37:46,738 - decision_tree.py - double-checking specification satisfiability:  : 5.1294855961654235

2025-01-28 12:37:46,739 - mdp.py - building tree of depth 1
2025-01-28 12:37:46,749 - statistic.py - synthesis initiated, design space: 50
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 50, quotient: 2039 states / 2055 actions
explored: 200 %
MDP stats: avg MDP size: 2039, iterations: 2

optimum: 5.129486
--------------------
2025-01-28 12:37:46,772 - decision_tree.py - families considered: 2
2025-01-28 12:37:46,772 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:46,772 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:46,772 - decision_tree.py - families model checked: 2
2025-01-28 12:37:46,772 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:37:46,772 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:46,773 - decision_tree.py - admissible subtree found from node 58
2025-01-28 12:37:46,773 - decision_tree.py - new tree has depth 14 and 45 nodes
2025-01-28 12:37:48,351 - decision_tree.py - new dtcontrol tree has depth 13 and 56 nodes
2025-01-28 12:37:48,352 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:37:48,353 - decision_tree.py - starting iteration 48 with 5 nodes in node queue
2025-01-28 12:37:48,353 - decision_tree.py - current tree size: 91 nodes
2025-01-28 12:37:48,442 - decision_tree.py - subtree quotient has 2039 states and 2071 choices
2025-01-28 12:37:48,449 - mdp.py - MDP has 8/2039 relevant states
2025-01-28 12:37:48,451 - mdp.py - MDP has 5 actions
2025-01-28 12:37:48,465 - mdp.py - found the following 3 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked4:[0..1]']

2025-01-28 12:37:48,465 - mdp.py - building tree of depth 0
2025-01-28 12:37:48,468 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.15 s
number of holes: 1, family size: 5, quotient: 2039 states / 2071 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:48,618 - decision_tree.py - families considered: 4
2025-01-28 12:37:48,618 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:48,618 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:48,618 - decision_tree.py - families model checked: 4
2025-01-28 12:37:48,618 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:48,618 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:48,619 - mdp.py - building tree of depth 1
2025-01-28 12:37:48,630 - statistic.py - synthesis initiated, design space: 75
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.43 s
number of holes: 6, family size: 75, quotient: 2039 states / 2071 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 13

optimum: 5.127782
--------------------
2025-01-28 12:37:49,059 - decision_tree.py - families considered: 13
2025-01-28 12:37:49,059 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:49,059 - decision_tree.py - families with schedulers preserved: 3
2025-01-28 12:37:49,059 - decision_tree.py - families model checked: 10
2025-01-28 12:37:49,059 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:49,059 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:49,059 - decision_tree.py - no admissible subtree found from node 59
2025-01-28 12:37:49,059 - decision_tree.py - starting iteration 49 with 4 nodes in node queue
2025-01-28 12:37:49,059 - decision_tree.py - current tree size: 91 nodes
2025-01-28 12:37:49,135 - decision_tree.py - subtree quotient has 2039 states and 2263 choices
2025-01-28 12:37:49,140 - mdp.py - MDP has 56/2039 relevant states
2025-01-28 12:37:49,145 - mdp.py - MDP has 5 actions
2025-01-28 12:37:49,157 - mdp.py - found the following 4 variables: ['picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'x:[3..9]']

2025-01-28 12:37:49,157 - mdp.py - building tree of depth 0
2025-01-28 12:37:49,160 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 1, family size: 5, quotient: 2039 states / 2263 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:49,295 - decision_tree.py - families considered: 4
2025-01-28 12:37:49,295 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:49,295 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:49,295 - decision_tree.py - families model checked: 4
2025-01-28 12:37:49,295 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:49,295 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:49,296 - mdp.py - building tree of depth 1
2025-01-28 12:37:49,313 - statistic.py - synthesis initiated, design space: 600
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.14 s
number of holes: 7, family size: 600, quotient: 2039 states / 2263 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 28

optimum: 5.127782
--------------------
2025-01-28 12:37:50,450 - decision_tree.py - families considered: 28
2025-01-28 12:37:50,450 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:50,450 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:37:50,450 - decision_tree.py - families model checked: 23
2025-01-28 12:37:50,450 - decision_tree.py - harmonizations attempted: 5
2025-01-28 12:37:50,450 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:50,450 - decision_tree.py - no admissible subtree found from node 10
2025-01-28 12:37:50,451 - decision_tree.py - starting iteration 50 with 3 nodes in node queue
2025-01-28 12:37:50,451 - decision_tree.py - current tree size: 91 nodes
2025-01-28 12:37:50,537 - decision_tree.py - subtree quotient has 2039 states and 2735 choices
2025-01-28 12:37:50,543 - mdp.py - MDP has 174/2039 relevant states
2025-01-28 12:37:50,550 - mdp.py - MDP has 5 actions
2025-01-28 12:37:50,563 - mdp.py - found the following 7 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked6:[0..1]', 'x:[10..14]', 'y:[2..4]']

2025-01-28 12:37:50,563 - mdp.py - building tree of depth 0
2025-01-28 12:37:50,570 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.2 s
number of holes: 1, family size: 5, quotient: 2039 states / 2735 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:50,775 - decision_tree.py - families considered: 4
2025-01-28 12:37:50,775 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:50,775 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:50,775 - decision_tree.py - families model checked: 4
2025-01-28 12:37:50,775 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:50,775 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:50,776 - mdp.py - building tree of depth 1
2025-01-28 12:37:50,814 - statistic.py - synthesis initiated, design space: 1400
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.07 s
number of holes: 10, family size: 1400, quotient: 2039 states / 2735 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 50

optimum: 5.127782
--------------------
2025-01-28 12:37:52,884 - decision_tree.py - families considered: 50
2025-01-28 12:37:52,884 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:52,884 - decision_tree.py - families with schedulers preserved: 7
2025-01-28 12:37:52,884 - decision_tree.py - families model checked: 43
2025-01-28 12:37:52,884 - decision_tree.py - harmonizations attempted: 10
2025-01-28 12:37:52,884 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:52,884 - decision_tree.py - no admissible subtree found from node 80
2025-01-28 12:37:52,884 - decision_tree.py - starting iteration 51 with 2 nodes in node queue
2025-01-28 12:37:52,884 - decision_tree.py - current tree size: 91 nodes
2025-01-28 12:37:52,966 - decision_tree.py - subtree quotient has 2039 states and 3711 choices
2025-01-28 12:37:52,973 - mdp.py - MDP has 418/2039 relevant states
2025-01-28 12:37:52,977 - mdp.py - MDP has 5 actions
2025-01-28 12:37:52,992 - mdp.py - found the following 8 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked5:[0..1]', 'picked6:[0..1]', 'x:[0..9]']

2025-01-28 12:37:52,993 - mdp.py - building tree of depth 0
2025-01-28 12:37:52,998 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.11 s
number of holes: 1, family size: 5, quotient: 2039 states / 3711 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:53,103 - decision_tree.py - families considered: 4
2025-01-28 12:37:53,103 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:53,103 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:53,103 - decision_tree.py - families model checked: 4
2025-01-28 12:37:53,103 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:53,103 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:53,103 - mdp.py - building tree of depth 1
2025-01-28 12:37:53,137 - statistic.py - synthesis initiated, design space: 1800
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.66 s
number of holes: 11, family size: 1800, quotient: 2039 states / 3711 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 22

optimum: 5.127782
--------------------
2025-01-28 12:37:53,798 - decision_tree.py - families considered: 22
2025-01-28 12:37:53,798 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:53,798 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:37:53,798 - decision_tree.py - families model checked: 17
2025-01-28 12:37:53,798 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:37:53,798 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:53,798 - decision_tree.py - no admissible subtree found from node 71
2025-01-28 12:37:53,798 - decision_tree.py - starting iteration 52 with 1 nodes in node queue
2025-01-28 12:37:53,799 - decision_tree.py - current tree size: 91 nodes
2025-01-28 12:37:53,879 - decision_tree.py - subtree quotient has 2039 states and 3159 choices
2025-01-28 12:37:53,885 - mdp.py - MDP has 280/2039 relevant states
2025-01-28 12:37:53,892 - mdp.py - MDP has 5 actions
2025-01-28 12:37:53,905 - mdp.py - found the following 6 variables: ['picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked6:[0..1]', 'x:[0..9]']

2025-01-28 12:37:53,905 - mdp.py - building tree of depth 0
2025-01-28 12:37:53,910 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.16 s
number of holes: 1, family size: 5, quotient: 2039 states / 3159 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 5.127782
--------------------
2025-01-28 12:37:54,068 - decision_tree.py - families considered: 4
2025-01-28 12:37:54,069 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:54,069 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:54,069 - decision_tree.py - families model checked: 4
2025-01-28 12:37:54,069 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:54,069 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:54,069 - mdp.py - building tree of depth 1
2025-01-28 12:37:54,092 - statistic.py - synthesis initiated, design space: 1350
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.13 s
number of holes: 9, family size: 1350, quotient: 2039 states / 3159 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 28

optimum: 5.127782
--------------------
2025-01-28 12:37:55,219 - decision_tree.py - families considered: 28
2025-01-28 12:37:55,219 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:55,219 - decision_tree.py - families with schedulers preserved: 3
2025-01-28 12:37:55,220 - decision_tree.py - families model checked: 25
2025-01-28 12:37:55,220 - decision_tree.py - harmonizations attempted: 6
2025-01-28 12:37:55,220 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:37:55,220 - decision_tree.py - no admissible subtree found from node 17
2025-01-28 12:37:55,324 - decision_tree.py - final tree has value 5.1294855961654235 with depth 14 and 45 nodes
5.1294855961654235 922.84 14 45
2025-01-28 12:37:55,324 - decision_tree.py - the optimal scheduler has value: 5.179578174110294
2025-01-28 12:37:55,324 - decision_tree.py - the random scheduler has value: 1.2183016282364878
2025-01-28 12:37:55,326 - decision_tree.py - synthesized tree of depth 14 with 44 decision nodes
2025-01-28 12:37:55,326 - decision_tree.py - the synthesized tree has value 5.1294855961654235
2025-01-28 12:37:55,326 - decision_tree.py - the synthesized tree has relative value: 0.9873544355298676
2025-01-28 12:37:55,326 - decision_tree.py - printing the synthesized tree below:
2025-01-28 12:37:55,326 - decision_tree.py - dtcontrol calls: 41
2025-01-28 12:37:55,326 - decision_tree.py - dtcontrol successes: 4
2025-01-28 12:37:55,326 - decision_tree.py - paynt calls: 53
2025-01-28 12:37:55,326 - decision_tree.py - paynt successes smaller: 32
2025-01-28 12:37:55,326 - decision_tree.py - paynt tree found: 41
2025-01-28 12:37:55,326 - decision_tree.py - both larger: 5
2025-01-28 12:37:55,329 - decision_tree.py - exported decision tree to logs/01-28-initial/integration/maze-7/tree.dot
2025-01-28 12:37:55,488 - decision_tree.py - exported decision tree visualization to logs/01-28-initial/integration/maze-7/tree.png
2025-01-28 12:37:55,488 - decision_tree.py - synthesis finished after 923.23 seconds

--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.149.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.146.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.124.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.133.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.125.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.145.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.265.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.150.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.150.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.244.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.138.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.121.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.147.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.123.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.169.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.095.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.092.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.106.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.097.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.121.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.096.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.093.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.088.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.082.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.083.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.090.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.102.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.134.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.126.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.136.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.107.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.093.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.078.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.083.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.074.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.070.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.087.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.088.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.056.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.050.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.066.
All benchmarks completed. Shutting down dtControl.
