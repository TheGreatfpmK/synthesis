2025-01-28 12:37:55,732 - cli.py - This is Paynt version 0.1.0.
2025-01-28 12:37:55,732 - sketch.py - loading sketch from /home/fpmk/synthesis-playground/models/dts-backup/omdt/frozenlake_12x12/model-random.drn ...
2025-01-28 12:37:55,732 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-28 12:37:55,734 - sketch.py - assuming sketch in DRN format...
2025-01-28 12:37:55,736 - prism_parser.py - loading properties from /home/fpmk/synthesis-playground/models/dts-backup/omdt/frozenlake_12x12/discounted.props ...
2025-01-28 12:37:55,736 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-28 12:37:55,736 - sketch.py - found state valuations in /home/fpmk/synthesis-playground/models/dts-backup/omdt/frozenlake_12x12/state-valuations.json, adding to the model...
2025-01-28 12:37:55,737 - sketch.py - sketch parsing OK
2025-01-28 12:37:55,738 - sketch.py - tree helper loaded
2025-01-28 12:37:55,739 - sketch.py - constructed explicit quotient having 144 states and 720 choices
2025-01-28 12:37:55,739 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-28 12:37:55,740 - mdp.py - MDP has 126/144 relevant states
2025-01-28 12:37:55,741 - mdp.py - MDP has 5 actions
2025-01-28 12:37:55,742 - mdp.py - found the following 2 variables: ['X:[0..11]', 'Y:[0..11]']
2025-01-28 12:37:55,747 - decision_tree.py - the optimal scheduler has value: 0.34872056868406615
2025-01-28 12:37:55,747 - decision_tree.py - the random scheduler has value: 0.0001721308046831764
2025-01-28 12:37:55,748 - decision_tree.py - initial external tree has depth 11 and 67 nodes
2025-01-28 12:37:55,748 - decision_tree.py - starting iteration with subtree depth 7
2025-01-28 12:37:55,749 - decision_tree.py - starting iteration 0 with 3 nodes in node queue
2025-01-28 12:37:55,749 - decision_tree.py - current tree size: 135 nodes
2025-01-28 12:37:55,750 - decision_tree.py - subtree quotient has 134 states and 270 choices
2025-01-28 12:37:55,751 - mdp.py - MDP has 24/134 relevant states
2025-01-28 12:37:55,751 - mdp.py - MDP has 5 actions
2025-01-28 12:37:55,752 - mdp.py - found the following 2 variables: ['X:[8..11]', 'Y:[4..10]']

2025-01-28 12:37:55,752 - mdp.py - building tree of depth 0
2025-01-28 12:37:55,756 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 270 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:37:55,766 - decision_tree.py - families considered: 4
2025-01-28 12:37:55,766 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:55,766 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:37:55,766 - decision_tree.py - families model checked: 4
2025-01-28 12:37:55,766 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:55,766 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:55,766 - mdp.py - building tree of depth 1
2025-01-28 12:37:55,775 - statistic.py - synthesis initiated, design space: 900
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 5, family size: 900, quotient: 134 states / 270 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 6

optimum: 0.345233
--------------------
2025-01-28 12:37:55,789 - decision_tree.py - families considered: 6
2025-01-28 12:37:55,789 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:55,789 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:37:55,789 - decision_tree.py - families model checked: 5
2025-01-28 12:37:55,789 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:55,789 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:55,789 - mdp.py - building tree of depth 2
2025-01-28 12:37:55,798 - statistic.py - synthesis initiated, design space: 1e7
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.13 s
number of holes: 13, family size: 1e7, quotient: 134 states / 270 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 40

optimum: 0.345233
--------------------
2025-01-28 12:37:55,927 - decision_tree.py - families considered: 40
2025-01-28 12:37:55,927 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:55,927 - decision_tree.py - families with schedulers preserved: 14
2025-01-28 12:37:55,927 - decision_tree.py - families model checked: 26
2025-01-28 12:37:55,927 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:37:55,927 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:55,927 - mdp.py - building tree of depth 3
2025-01-28 12:37:55,940 - statistic.py - synthesis initiated, design space: 1e16
> progress 24.045%, elapsed 3 s, estimated 12 s, iters = {MDP: 707}, opt = 0.3452
2025-01-28 12:37:58,462 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.0 s
number of holes: 29, family size: 1e16, quotient: 134 states / 270 actions
explored: 24 %
MDP stats: avg MDP size: 134, iterations: 1252

optimum: 0.345233
--------------------
2025-01-28 12:37:58,462 - decision_tree.py - families considered: 1252
2025-01-28 12:37:58,462 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:37:58,462 - decision_tree.py - families with schedulers preserved: 499
2025-01-28 12:37:58,463 - decision_tree.py - families model checked: 753
2025-01-28 12:37:58,463 - decision_tree.py - harmonizations attempted: 16
2025-01-28 12:37:58,463 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:37:58,463 - mdp.py - building tree of depth 4
2025-01-28 12:37:58,480 - statistic.py - synthesis initiated, design space: 1e34
> progress 0.143%, elapsed 3 s, estimated 2093 s, iters = {MDP: 368}, opt = 0.3452
2025-01-28 12:38:03,481 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.0 s
number of holes: 61, family size: 1e34, quotient: 134 states / 270 actions
explored: 0 %
MDP stats: avg MDP size: 134, iterations: 655

optimum: 0.345233
--------------------
2025-01-28 12:38:03,481 - decision_tree.py - families considered: 655
2025-01-28 12:38:03,481 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:03,481 - decision_tree.py - families with schedulers preserved: 272
2025-01-28 12:38:03,481 - decision_tree.py - families model checked: 383
2025-01-28 12:38:03,481 - decision_tree.py - harmonizations attempted: 20
2025-01-28 12:38:03,481 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:03,481 - mdp.py - building tree of depth 5
2025-01-28 12:38:03,508 - statistic.py - synthesis initiated, design space: 1e70
2025-01-28 12:38:03,548 - synthesizer_ar.py - value 0.3487 achieved after 10.3 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 125, family size: 1e70, quotient: 134 states / 270 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:38:03,548 - decision_tree.py - families considered: 1
2025-01-28 12:38:03,548 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:03,548 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:38:03,548 - decision_tree.py - families model checked: 1
2025-01-28 12:38:03,548 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:38:03,548 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:03,548 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:03,548 - decision_tree.py - V_0=Y, X_0=8, Y_0=6, V_1=Y, X_1=8, Y_1=5, V_2=X, X_2=8, Y_2=5, V_3=Y, X_3=8, Y_3=5, V_4=Y, X_4=8, Y_4=4, A_5=(Down), A_6=(Left), V_7=X, X_7=9, Y_7=9, A_8=(Down), A_9=(Left), V_10=Y, X_10=9, Y_10=4, V_11=X, X_11=9, Y_11=5, A_12=(Up), A_13=(Down), V_14=X, X_14=10, Y_14=7, A_15=(Right), A_16=(Down), V_17=Y, X_17=8, Y_17=9, V_18=Y, X_18=8, Y_18=6, V_19=Y, X_19=8, Y_19=5, A_20=(Right), A_21=(Down), V_22=Y, X_22=8, Y_22=6, A_23=__random__, A_24=(Up), V_25=Y, X_25=8, Y_25=9, V_26=Y, X_26=8, Y_26=7, A_27=(Up), A_28=__random__, V_29=Y, X_29=8, Y_29=7, A_30=__random__, A_31=__random__, V_32=Y, X_32=8, Y_32=9, V_33=Y, X_33=10, Y_33=7, V_34=X, X_34=9, Y_34=8, V_35=X, X_35=8, Y_35=9, A_36=(Up), A_37=(Down), V_38=X, X_38=10, Y_38=6, A_39=(Left), A_40=(Down), V_41=Y, X_41=8, Y_41=8, V_42=X, X_42=9, Y_42=7, A_43=(Right), A_44=(Up), V_45=X, X_45=8, Y_45=8, A_46=(Down), A_47=(Left), V_48=Y, X_48=8, Y_48=8, V_49=Y, X_49=8, Y_49=9, V_50=Y, X_50=8, Y_50=9, A_51=__random__, A_52=(Left), V_53=Y, X_53=8, Y_53=7, A_54=(Down), A_55=(Down), V_56=Y, X_56=8, Y_56=8, V_57=Y, X_57=8, Y_57=9, A_58=__random__, A_59=__random__, V_60=Y, X_60=8, Y_60=9, A_61=__random__, A_62=(Down)
2025-01-28 12:38:03,551 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:38:03,551 - decision_tree.py - admissible subtree found from node 99
2025-01-28 12:38:03,552 - decision_tree.py - new tree has depth 11 and 66 nodes
2025-01-28 12:38:04,857 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:38:04,857 - decision_tree.py - New DtControl tree is smaller
2025-01-28 12:38:04,859 - decision_tree.py - starting iteration 1 with 3 nodes in node queue
2025-01-28 12:38:04,859 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:38:04,860 - decision_tree.py - subtree quotient has 134 states and 254 choices
2025-01-28 12:38:04,861 - mdp.py - MDP has 20/134 relevant states
2025-01-28 12:38:04,861 - mdp.py - MDP has 5 actions
2025-01-28 12:38:04,862 - mdp.py - found the following 2 variables: ['X:[8..11]', 'Y:[4..9]']

2025-01-28 12:38:04,862 - mdp.py - building tree of depth 0
2025-01-28 12:38:04,865 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:38:04,875 - decision_tree.py - families considered: 4
2025-01-28 12:38:04,875 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:04,875 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:38:04,875 - decision_tree.py - families model checked: 4
2025-01-28 12:38:04,875 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:04,875 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:04,875 - mdp.py - building tree of depth 1
2025-01-28 12:38:04,886 - statistic.py - synthesis initiated, design space: 750
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 5, family size: 750, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 6

optimum: 0.345233
--------------------
2025-01-28 12:38:04,901 - decision_tree.py - families considered: 6
2025-01-28 12:38:04,901 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:04,901 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:38:04,901 - decision_tree.py - families model checked: 5
2025-01-28 12:38:04,901 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:04,901 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:04,901 - mdp.py - building tree of depth 2
2025-01-28 12:38:04,908 - statistic.py - synthesis initiated, design space: 1e7
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.05 s
number of holes: 13, family size: 1e7, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 16

optimum: 0.345233
--------------------
2025-01-28 12:38:04,959 - decision_tree.py - families considered: 16
2025-01-28 12:38:04,959 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:04,959 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:38:04,959 - decision_tree.py - families model checked: 11
2025-01-28 12:38:04,959 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:04,959 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:04,960 - mdp.py - building tree of depth 3
2025-01-28 12:38:04,972 - statistic.py - synthesis initiated, design space: 1e15
> progress 24.21%, elapsed 3 s, estimated 12 s, iters = {MDP: 677}, opt = 0.3452
2025-01-28 12:38:09,975 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.0 s
number of holes: 29, family size: 1e15, quotient: 134 states / 254 actions
explored: 25 %
MDP stats: avg MDP size: 134, iterations: 1162

optimum: 0.345233
--------------------
2025-01-28 12:38:09,975 - decision_tree.py - families considered: 1162
2025-01-28 12:38:09,975 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:09,975 - decision_tree.py - families with schedulers preserved: 473
2025-01-28 12:38:09,975 - decision_tree.py - families model checked: 689
2025-01-28 12:38:09,975 - decision_tree.py - harmonizations attempted: 34
2025-01-28 12:38:09,975 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:09,975 - mdp.py - building tree of depth 4
2025-01-28 12:38:09,988 - statistic.py - synthesis initiated, design space: 1e33
> progress 0.237%, elapsed 3 s, estimated 1269 s, iters = {MDP: 389}, opt = 0.3452
2025-01-28 12:38:14,991 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.0 s
number of holes: 61, family size: 1e33, quotient: 134 states / 254 actions
explored: 0 %
MDP stats: avg MDP size: 134, iterations: 686

optimum: 0.345233
--------------------
2025-01-28 12:38:14,991 - decision_tree.py - families considered: 686
2025-01-28 12:38:14,992 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:14,992 - decision_tree.py - families with schedulers preserved: 294
2025-01-28 12:38:14,992 - decision_tree.py - families model checked: 392
2025-01-28 12:38:14,992 - decision_tree.py - harmonizations attempted: 14
2025-01-28 12:38:14,992 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:14,992 - mdp.py - building tree of depth 5
2025-01-28 12:38:15,020 - statistic.py - synthesis initiated, design space: 1e68
2025-01-28 12:38:15,058 - synthesizer_ar.py - value 0.3487 achieved after 21.81 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 125, family size: 1e68, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:38:15,058 - decision_tree.py - families considered: 1
2025-01-28 12:38:15,058 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:15,058 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:38:15,058 - decision_tree.py - families model checked: 1
2025-01-28 12:38:15,058 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:38:15,058 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:15,058 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:15,059 - decision_tree.py - V_0=Y, X_0=8, Y_0=4, V_1=Y, X_1=8, Y_1=6, V_2=Y, X_2=8, Y_2=4, V_3=X, X_3=9, Y_3=4, V_4=X, X_4=8, Y_4=4, A_5=(Down), A_6=(Up), V_7=Y, X_7=8, Y_7=4, A_8=(Down), A_9=(Up), V_10=Y, X_10=8, Y_10=4, V_11=Y, X_11=8, Y_11=4, A_12=__random__, A_13=__random__, V_14=Y, X_14=8, Y_14=8, A_15=(Left), A_16=__random__, V_17=Y, X_17=8, Y_17=7, V_18=Y, X_18=8, Y_18=6, V_19=Y, X_19=8, Y_19=4, A_20=__random__, A_21=(Right), V_22=Y, X_22=8, Y_22=8, A_23=__random__, A_24=(Up), V_25=Y, X_25=8, Y_25=7, V_26=Y, X_26=8, Y_26=7, A_27=(Right), A_28=__random__, V_29=Y, X_29=8, Y_29=7, A_30=(Right), A_31=(Right), V_32=X, X_32=9, Y_32=4, V_33=Y, X_33=9, Y_33=7, V_34=Y, X_34=8, Y_34=6, V_35=Y, X_35=9, Y_35=5, A_36=(Left), A_37=(Down), V_38=X, X_38=8, Y_38=4, A_39=(Up), A_40=(Down), V_41=X, X_41=8, Y_41=8, V_42=Y, X_42=9, Y_42=7, A_43=(Down), A_44=(Down), V_45=Y, X_45=8, Y_45=8, A_46=(Right), A_47=(Left), V_48=Y, X_48=8, Y_48=6, V_49=Y, X_49=10, Y_49=5, V_50=X, X_50=10, Y_50=8, A_51=(Right), A_52=(Down), V_53=X, X_53=10, Y_53=8, A_54=(Down), A_55=(Down), V_56=Y, X_56=10, Y_56=7, V_57=X, X_57=10, Y_57=8, A_58=(Left), A_59=(Down), V_60=Y, X_60=8, Y_60=8, A_61=(Up), A_62=(Right)
2025-01-28 12:38:15,061 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:38:15,061 - decision_tree.py - admissible subtree found from node 88
2025-01-28 12:38:15,062 - decision_tree.py - new tree has depth 10 and 61 nodes
2025-01-28 12:38:16,319 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:38:16,320 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:38:16,321 - decision_tree.py - starting iteration 2 with 2 nodes in node queue
2025-01-28 12:38:16,321 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:38:16,322 - decision_tree.py - subtree quotient has 135 states and 295 choices
2025-01-28 12:38:16,323 - mdp.py - MDP has 29/135 relevant states
2025-01-28 12:38:16,323 - mdp.py - MDP has 5 actions
2025-01-28 12:38:16,324 - mdp.py - found the following 2 variables: ['X:[0..5]', 'Y:[1..6]']

2025-01-28 12:38:16,324 - mdp.py - building tree of depth 0
2025-01-28 12:38:16,326 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:38:16,335 - decision_tree.py - families considered: 4
2025-01-28 12:38:16,335 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:16,335 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:38:16,335 - decision_tree.py - families model checked: 4
2025-01-28 12:38:16,335 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:16,335 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:16,336 - mdp.py - building tree of depth 1
2025-01-28 12:38:16,348 - statistic.py - synthesis initiated, design space: 1250
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 5, family size: 1250, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 15

optimum: 0.345233
--------------------
2025-01-28 12:38:16,386 - decision_tree.py - families considered: 15
2025-01-28 12:38:16,386 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:16,386 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:38:16,386 - decision_tree.py - families model checked: 13
2025-01-28 12:38:16,386 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:38:16,386 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:16,386 - mdp.py - building tree of depth 2
2025-01-28 12:38:16,395 - statistic.py - synthesis initiated, design space: 1e7
2025-01-28 12:38:16,472 - synthesizer_ar.py - value 0.3454 achieved after 23.22 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.69 s
number of holes: 13, family size: 1e7, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 210

optimum: 0.345426
--------------------
2025-01-28 12:38:17,088 - decision_tree.py - families considered: 210
2025-01-28 12:38:17,088 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:17,088 - decision_tree.py - families with schedulers preserved: 55
2025-01-28 12:38:17,088 - decision_tree.py - families model checked: 155
2025-01-28 12:38:17,088 - decision_tree.py - harmonizations attempted: 30
2025-01-28 12:38:17,088 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:17,088 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:17,088 - decision_tree.py - V_0=X, X_0=0, Y_0=1, V_1=Y, X_1=0, Y_1=1, A_2=(Down), A_3=(Left), V_4=Y, X_4=0, Y_4=1, A_5=(Up), A_6=(Down)
2025-01-28 12:38:17,089 - decision_tree.py - double-checking specification satisfiability:  : 0.34542558896055797

2025-01-28 12:38:17,089 - mdp.py - building tree of depth 3
2025-01-28 12:38:17,100 - statistic.py - synthesis initiated, design space: 1e17
2025-01-28 12:38:19,857 - synthesizer_ar.py - value 0.3457 achieved after 26.61 seconds
> progress 14.56%, elapsed 3 s, estimated 20 s, iters = {MDP: 588}, opt = 0.3457
2025-01-28 12:38:22,103 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.0 s
number of holes: 29, family size: 1e17, quotient: 135 states / 295 actions
explored: 18 %
MDP stats: avg MDP size: 135, iterations: 1024

optimum: 0.345665
--------------------
2025-01-28 12:38:22,104 - decision_tree.py - families considered: 1024
2025-01-28 12:38:22,104 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:22,104 - decision_tree.py - families with schedulers preserved: 269
2025-01-28 12:38:22,104 - decision_tree.py - families model checked: 755
2025-01-28 12:38:22,104 - decision_tree.py - harmonizations attempted: 160
2025-01-28 12:38:22,104 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:22,104 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:22,104 - decision_tree.py - V_0=X, X_0=0, Y_0=2, V_1=Y, X_1=0, Y_1=3, V_2=Y, X_2=0, Y_2=1, A_3=(Down), A_4=(Left), V_5=X, X_5=2, Y_5=1, A_6=(Left), A_7=(Down), V_8=Y, X_8=0, Y_8=4, V_9=Y, X_9=0, Y_9=1, A_10=(Up), A_11=(Down), V_12=Y, X_12=0, Y_12=5, A_13=(Left), A_14=(Down)
2025-01-28 12:38:22,105 - decision_tree.py - double-checking specification satisfiability:  : 0.3456649578975002

2025-01-28 12:38:22,106 - mdp.py - building tree of depth 4
2025-01-28 12:38:22,129 - statistic.py - synthesis initiated, design space: 1e36
2025-01-28 12:38:22,428 - synthesizer_ar.py - value 0.3458 achieved after 29.18 seconds
2025-01-28 12:38:22,526 - synthesizer_ar.py - value 0.3461 achieved after 29.27 seconds
2025-01-28 12:38:23,586 - synthesizer_ar.py - value 0.3465 achieved after 30.33 seconds
> progress 0.0%, elapsed 3 s, estimated 360133 s (4 days), iters = {MDP: 363}, opt = 0.3465
2025-01-28 12:38:27,133 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.0 s
number of holes: 61, family size: 1e36, quotient: 135 states / 295 actions
explored: 0 %
MDP stats: avg MDP size: 135, iterations: 642

optimum: 0.34651
--------------------
2025-01-28 12:38:27,133 - decision_tree.py - families considered: 642
2025-01-28 12:38:27,133 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:27,133 - decision_tree.py - families with schedulers preserved: 231
2025-01-28 12:38:27,133 - decision_tree.py - families model checked: 411
2025-01-28 12:38:27,133 - decision_tree.py - harmonizations attempted: 31
2025-01-28 12:38:27,133 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:27,133 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:27,133 - decision_tree.py - V_0=X, X_0=0, Y_0=1, V_1=Y, X_1=0, Y_1=3, V_2=Y, X_2=0, Y_2=1, V_3=X, X_3=0, Y_3=1, A_4=(Down), A_5=(Down), V_6=Y, X_6=0, Y_6=3, A_7=(Left), A_8=(Down), V_9=X, X_9=2, Y_9=1, V_10=Y, X_10=0, Y_10=1, A_11=(Left), A_12=(Left), V_13=X, X_13=0, Y_13=1, A_14=(Down), A_15=(Down), V_16=Y, X_16=0, Y_16=4, V_17=Y, X_17=0, Y_17=1, V_18=X, X_18=0, Y_18=1, A_19=(Down), A_20=(Up), V_21=X, X_21=4, Y_21=1, A_22=(Right), A_23=(Down), V_24=Y, X_24=0, Y_24=5, V_25=X, X_25=4, Y_25=1, A_26=(Up), A_27=(Left), V_28=X, X_28=2, Y_28=1, A_29=(Down), A_30=(Left)
2025-01-28 12:38:27,135 - decision_tree.py - double-checking specification satisfiability:  : 0.3465099522526254

2025-01-28 12:38:27,135 - mdp.py - building tree of depth 5
2025-01-28 12:38:27,162 - statistic.py - synthesis initiated, design space: 1e75
2025-01-28 12:38:27,246 - synthesizer_ar.py - value 0.3467 achieved after 34.0 seconds
2025-01-28 12:38:27,664 - synthesizer_ar.py - value 0.3487 achieved after 34.41 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.5 s
number of holes: 125, family size: 1e75, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 40

optimum: 0.348721
--------------------
2025-01-28 12:38:27,664 - decision_tree.py - families considered: 40
2025-01-28 12:38:27,664 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:27,664 - decision_tree.py - families with schedulers preserved: 14
2025-01-28 12:38:27,664 - decision_tree.py - families model checked: 26
2025-01-28 12:38:27,664 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:27,665 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:27,665 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:27,665 - decision_tree.py - V_0=Y, X_0=0, Y_0=3, V_1=Y, X_1=4, Y_1=1, V_2=Y, X_2=3, Y_2=1, V_3=X, X_3=4, Y_3=1, V_4=X, X_4=0, Y_4=1, A_5=(Down), A_6=(Up), V_7=Y, X_7=4, Y_7=1, A_8=(Right), A_9=__random__, V_10=Y, X_10=4, Y_10=1, V_11=X, X_11=3, Y_11=1, A_12=__random__, A_13=__random__, V_14=Y, X_14=0, Y_14=1, A_15=__random__, A_16=__random__, V_17=X, X_17=4, Y_17=4, V_18=X, X_18=3, Y_18=4, V_19=X, X_19=2, Y_19=1, A_20=(Left), A_21=(Down), V_22=Y, X_22=2, Y_22=2, A_23=(Right), A_24=(Left), V_25=Y, X_25=4, Y_25=3, V_26=Y, X_26=3, Y_26=4, A_27=(Up), A_28=__random__, V_29=Y, X_29=4, Y_29=3, A_30=__random__, A_31=__random__, V_32=X, X_32=4, Y_32=5, V_33=X, X_33=2, Y_33=5, V_34=X, X_34=1, Y_34=4, V_35=X, X_35=0, Y_35=1, A_36=(Left), A_37=(Up), V_38=Y, X_38=1, Y_38=4, A_39=(Left), A_40=(Down), V_41=X, X_41=3, Y_41=5, V_42=Y, X_42=2, Y_42=5, A_43=(Down), A_44=(Left), V_45=Y, X_45=3, Y_45=4, A_46=(Right), A_47=(Up), V_48=Y, X_48=1, Y_48=3, V_49=Y, X_49=1, Y_49=4, V_50=Y, X_50=4, Y_50=2, A_51=__random__, A_52=__random__, V_53=X, X_53=1, Y_53=5, A_54=__random__, A_55=__random__, V_56=Y, X_56=1, Y_56=5, V_57=Y, X_57=1, Y_57=4, A_58=(Down), A_59=(Left), V_60=Y, X_60=2, Y_60=4, A_61=__random__, A_62=(Left)
2025-01-28 12:38:27,667 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:38:27,667 - decision_tree.py - admissible subtree found from node 9
2025-01-28 12:38:27,668 - decision_tree.py - new tree has depth 11 and 63 nodes
2025-01-28 12:38:28,980 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:38:28,980 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:38:28,981 - decision_tree.py - starting iteration 3 with 1 nodes in node queue
2025-01-28 12:38:28,981 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:38:28,982 - decision_tree.py - subtree quotient has 134 states and 286 choices
2025-01-28 12:38:28,984 - mdp.py - MDP has 28/134 relevant states
2025-01-28 12:38:28,984 - mdp.py - MDP has 5 actions
2025-01-28 12:38:28,985 - mdp.py - found the following 2 variables: ['X:[0..7]', 'Y:[7..10]']

2025-01-28 12:38:28,985 - mdp.py - building tree of depth 0
2025-01-28 12:38:28,987 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 286 actions
explored: 100 %
MDP stats: avg MDP size: 130, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:38:28,997 - decision_tree.py - families considered: 4
2025-01-28 12:38:28,997 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:28,997 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:38:28,997 - decision_tree.py - families model checked: 4
2025-01-28 12:38:28,997 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:28,997 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:28,997 - mdp.py - building tree of depth 1
2025-01-28 12:38:29,011 - statistic.py - synthesis initiated, design space: 1050
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 1050, quotient: 134 states / 286 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 6

optimum: 0.345233
--------------------
2025-01-28 12:38:29,026 - decision_tree.py - families considered: 6
2025-01-28 12:38:29,027 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:29,027 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:38:29,027 - decision_tree.py - families model checked: 5
2025-01-28 12:38:29,027 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:29,027 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:29,027 - mdp.py - building tree of depth 2
2025-01-28 12:38:29,035 - statistic.py - synthesis initiated, design space: 1e7
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.2 s
number of holes: 13, family size: 1e7, quotient: 134 states / 286 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 70

optimum: 0.345233
--------------------
2025-01-28 12:38:29,240 - decision_tree.py - families considered: 70
2025-01-28 12:38:29,240 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:29,240 - decision_tree.py - families with schedulers preserved: 27
2025-01-28 12:38:29,240 - decision_tree.py - families model checked: 43
2025-01-28 12:38:29,240 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:38:29,240 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:29,240 - mdp.py - building tree of depth 3
2025-01-28 12:38:29,253 - statistic.py - synthesis initiated, design space: 1e16
> progress 0.945%, elapsed 3 s, estimated 317 s, iters = {MDP: 774}, opt = 0.3452
2025-01-28 12:38:31,771 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.0 s
number of holes: 29, family size: 1e16, quotient: 134 states / 286 actions
explored: 3 %
MDP stats: avg MDP size: 132, iterations: 1286

optimum: 0.345233
--------------------
2025-01-28 12:38:31,771 - decision_tree.py - families considered: 1286
2025-01-28 12:38:31,771 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:31,771 - decision_tree.py - families with schedulers preserved: 552
2025-01-28 12:38:31,771 - decision_tree.py - families model checked: 734
2025-01-28 12:38:31,771 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:38:31,771 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:31,771 - mdp.py - building tree of depth 4
2025-01-28 12:38:31,789 - statistic.py - synthesis initiated, design space: 1e35
> progress 0.574%, elapsed 3 s, estimated 522 s, iters = {MDP: 345}, opt = 0.3452
2025-01-28 12:38:36,793 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.0 s
number of holes: 61, family size: 1e35, quotient: 134 states / 286 actions
explored: 0 %
MDP stats: avg MDP size: 133, iterations: 649

optimum: 0.345233
--------------------
2025-01-28 12:38:36,793 - decision_tree.py - families considered: 649
2025-01-28 12:38:36,793 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:36,793 - decision_tree.py - families with schedulers preserved: 274
2025-01-28 12:38:36,793 - decision_tree.py - families model checked: 375
2025-01-28 12:38:36,793 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:38:36,793 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:36,793 - mdp.py - building tree of depth 5
2025-01-28 12:38:36,825 - statistic.py - synthesis initiated, design space: 1e72
2025-01-28 12:38:36,867 - synthesizer_ar.py - value 0.3487 achieved after 46.1 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 125, family size: 1e72, quotient: 134 states / 286 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:38:36,867 - decision_tree.py - families considered: 1
2025-01-28 12:38:36,867 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:36,867 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:38:36,867 - decision_tree.py - families model checked: 1
2025-01-28 12:38:36,867 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:38:36,867 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:36,867 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:36,867 - decision_tree.py - V_0=Y, X_0=0, Y_0=8, V_1=X, X_1=3, Y_1=8, V_2=Y, X_2=0, Y_2=8, V_3=Y, X_3=5, Y_3=7, V_4=X, X_4=1, Y_4=7, A_5=(Down), A_6=(Left), V_7=X, X_7=0, Y_7=7, A_8=(Up), A_9=(Down), V_10=Y, X_10=2, Y_10=7, V_11=Y, X_11=0, Y_11=7, A_12=__random__, A_13=__random__, V_14=X, X_14=0, Y_14=7, A_15=(Left), A_16=__random__, V_17=Y, X_17=0, Y_17=7, V_18=Y, X_18=0, Y_18=8, V_19=Y, X_19=0, Y_19=8, A_20=(Down), A_21=__random__, V_22=Y, X_22=0, Y_22=9, A_23=(Left), A_24=(Right), V_25=X, X_25=5, Y_25=8, V_26=X, X_26=4, Y_26=9, A_27=(Down), A_28=(Up), V_29=X, X_29=6, Y_29=8, A_30=(Down), A_31=(Left), V_32=X, X_32=3, Y_32=8, V_33=Y, X_33=0, Y_33=9, V_34=Y, X_34=0, Y_34=8, V_35=Y, X_35=0, Y_35=9, A_36=__random__, A_37=(Right), V_38=X, X_38=1, Y_38=8, A_39=(Right), A_40=(Down), V_41=Y, X_41=0, Y_41=9, V_42=Y, X_42=0, Y_42=8, A_43=(Left), A_44=(Up), V_45=Y, X_45=0, Y_45=8, A_46=__random__, A_47=(Down), V_48=X, X_48=5, Y_48=9, V_49=Y, X_49=4, Y_49=9, V_50=X, X_50=1, Y_50=9, A_51=(Up), A_52=(Left), V_53=X, X_53=3, Y_53=9, A_54=(Up), A_55=(Down), V_56=Y, X_56=4, Y_56=8, V_57=X, X_57=0, Y_57=9, A_58=__random__, A_59=(Up), V_60=X, X_60=6, Y_60=9, A_61=(Right), A_62=(Down)
2025-01-28 12:38:36,870 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:38:36,870 - decision_tree.py - admissible subtree found from node 48
2025-01-28 12:38:36,870 - decision_tree.py - new tree has depth 11 and 63 nodes
2025-01-28 12:38:38,203 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:38:38,204 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:38:38,205 - decision_tree.py - starting iteration with subtree depth 6
2025-01-28 12:38:38,206 - decision_tree.py - starting iteration 4 with 3 nodes in node queue
2025-01-28 12:38:38,206 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:38:38,207 - decision_tree.py - subtree quotient has 134 states and 254 choices
2025-01-28 12:38:38,208 - mdp.py - MDP has 20/134 relevant states
2025-01-28 12:38:38,208 - mdp.py - MDP has 5 actions
2025-01-28 12:38:38,209 - mdp.py - found the following 2 variables: ['X:[8..11]', 'Y:[4..9]']

2025-01-28 12:38:38,209 - mdp.py - building tree of depth 0
2025-01-28 12:38:38,211 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:38:38,219 - decision_tree.py - families considered: 4
2025-01-28 12:38:38,219 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:38,219 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:38:38,219 - decision_tree.py - families model checked: 4
2025-01-28 12:38:38,219 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:38,219 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:38,220 - mdp.py - building tree of depth 1
2025-01-28 12:38:38,231 - statistic.py - synthesis initiated, design space: 750
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 750, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 6

optimum: 0.345233
--------------------
2025-01-28 12:38:38,247 - decision_tree.py - families considered: 6
2025-01-28 12:38:38,247 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:38,247 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:38:38,247 - decision_tree.py - families model checked: 5
2025-01-28 12:38:38,247 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:38,247 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:38,247 - mdp.py - building tree of depth 2
2025-01-28 12:38:38,256 - statistic.py - synthesis initiated, design space: 1e7
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.05 s
number of holes: 13, family size: 1e7, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 16

optimum: 0.345233
--------------------
2025-01-28 12:38:38,308 - decision_tree.py - families considered: 16
2025-01-28 12:38:38,308 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:38,308 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:38:38,308 - decision_tree.py - families model checked: 11
2025-01-28 12:38:38,308 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:38,308 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:38,308 - mdp.py - building tree of depth 3
2025-01-28 12:38:38,320 - statistic.py - synthesis initiated, design space: 1e15
> progress 24.21%, elapsed 3 s, estimated 12 s, iters = {MDP: 685}, opt = 0.3452
2025-01-28 12:38:44,326 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.01 s
number of holes: 29, family size: 1e15, quotient: 134 states / 254 actions
explored: 25 %
MDP stats: avg MDP size: 134, iterations: 1442

optimum: 0.345233
--------------------
2025-01-28 12:38:44,326 - decision_tree.py - families considered: 1442
2025-01-28 12:38:44,326 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:44,326 - decision_tree.py - families with schedulers preserved: 586
2025-01-28 12:38:44,326 - decision_tree.py - families model checked: 856
2025-01-28 12:38:44,326 - decision_tree.py - harmonizations attempted: 38
2025-01-28 12:38:44,326 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:44,326 - mdp.py - building tree of depth 4
2025-01-28 12:38:44,343 - statistic.py - synthesis initiated, design space: 1e33
> progress 0.237%, elapsed 3 s, estimated 1267 s, iters = {MDP: 373}, opt = 0.3452
2025-01-28 12:38:50,347 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.0 s
number of holes: 61, family size: 1e33, quotient: 134 states / 254 actions
explored: 0 %
MDP stats: avg MDP size: 134, iterations: 785

optimum: 0.345233
--------------------
2025-01-28 12:38:50,348 - decision_tree.py - families considered: 785
2025-01-28 12:38:50,348 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:50,348 - decision_tree.py - families with schedulers preserved: 339
2025-01-28 12:38:50,348 - decision_tree.py - families model checked: 446
2025-01-28 12:38:50,348 - decision_tree.py - harmonizations attempted: 17
2025-01-28 12:38:50,348 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:50,348 - mdp.py - building tree of depth 5
2025-01-28 12:38:50,374 - statistic.py - synthesis initiated, design space: 1e68
2025-01-28 12:38:50,410 - synthesizer_ar.py - value 0.3487 achieved after 59.64 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 125, family size: 1e68, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:38:50,410 - decision_tree.py - families considered: 1
2025-01-28 12:38:50,410 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:50,410 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:38:50,410 - decision_tree.py - families model checked: 1
2025-01-28 12:38:50,410 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:38:50,410 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:50,410 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:50,410 - decision_tree.py - V_0=Y, X_0=8, Y_0=4, V_1=Y, X_1=8, Y_1=6, V_2=Y, X_2=8, Y_2=4, V_3=X, X_3=9, Y_3=4, V_4=X, X_4=8, Y_4=4, A_5=(Down), A_6=(Up), V_7=Y, X_7=8, Y_7=4, A_8=(Down), A_9=(Up), V_10=Y, X_10=8, Y_10=4, V_11=Y, X_11=8, Y_11=4, A_12=__random__, A_13=__random__, V_14=Y, X_14=8, Y_14=8, A_15=(Left), A_16=__random__, V_17=Y, X_17=8, Y_17=7, V_18=Y, X_18=8, Y_18=6, V_19=Y, X_19=8, Y_19=4, A_20=__random__, A_21=(Right), V_22=Y, X_22=8, Y_22=8, A_23=__random__, A_24=(Up), V_25=Y, X_25=8, Y_25=7, V_26=Y, X_26=8, Y_26=7, A_27=(Right), A_28=__random__, V_29=Y, X_29=8, Y_29=7, A_30=(Right), A_31=(Right), V_32=X, X_32=9, Y_32=4, V_33=Y, X_33=9, Y_33=7, V_34=Y, X_34=8, Y_34=6, V_35=Y, X_35=9, Y_35=5, A_36=(Left), A_37=(Down), V_38=X, X_38=8, Y_38=4, A_39=(Up), A_40=(Down), V_41=X, X_41=8, Y_41=8, V_42=Y, X_42=9, Y_42=7, A_43=(Down), A_44=(Down), V_45=Y, X_45=8, Y_45=8, A_46=(Right), A_47=(Left), V_48=Y, X_48=8, Y_48=6, V_49=Y, X_49=10, Y_49=5, V_50=X, X_50=10, Y_50=8, A_51=(Right), A_52=(Down), V_53=X, X_53=10, Y_53=8, A_54=(Down), A_55=(Down), V_56=Y, X_56=10, Y_56=7, V_57=X, X_57=10, Y_57=8, A_58=(Left), A_59=(Down), V_60=Y, X_60=8, Y_60=8, A_61=(Up), A_62=(Right)
2025-01-28 12:38:50,413 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:38:50,413 - decision_tree.py - admissible subtree found from node 88
2025-01-28 12:38:50,413 - decision_tree.py - new tree has depth 10 and 61 nodes
2025-01-28 12:38:51,690 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:38:51,690 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:38:51,691 - decision_tree.py - starting iteration 5 with 2 nodes in node queue
2025-01-28 12:38:51,691 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:38:51,692 - decision_tree.py - subtree quotient has 135 states and 295 choices
2025-01-28 12:38:51,694 - mdp.py - MDP has 29/135 relevant states
2025-01-28 12:38:51,694 - mdp.py - MDP has 5 actions
2025-01-28 12:38:51,695 - mdp.py - found the following 2 variables: ['X:[0..5]', 'Y:[1..6]']

2025-01-28 12:38:51,695 - mdp.py - building tree of depth 0
2025-01-28 12:38:51,697 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:38:51,708 - decision_tree.py - families considered: 4
2025-01-28 12:38:51,708 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:51,708 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:38:51,708 - decision_tree.py - families model checked: 4
2025-01-28 12:38:51,708 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:38:51,708 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:51,708 - mdp.py - building tree of depth 1
2025-01-28 12:38:51,721 - statistic.py - synthesis initiated, design space: 1250
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 5, family size: 1250, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 15

optimum: 0.345233
--------------------
2025-01-28 12:38:51,758 - decision_tree.py - families considered: 15
2025-01-28 12:38:51,758 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:51,758 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:38:51,758 - decision_tree.py - families model checked: 13
2025-01-28 12:38:51,758 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:38:51,758 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:38:51,758 - mdp.py - building tree of depth 2
2025-01-28 12:38:51,766 - statistic.py - synthesis initiated, design space: 1e7
2025-01-28 12:38:51,854 - synthesizer_ar.py - value 0.3454 achieved after 61.09 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.74 s
number of holes: 13, family size: 1e7, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 210

optimum: 0.345426
--------------------
2025-01-28 12:38:52,503 - decision_tree.py - families considered: 210
2025-01-28 12:38:52,503 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:52,503 - decision_tree.py - families with schedulers preserved: 55
2025-01-28 12:38:52,503 - decision_tree.py - families model checked: 155
2025-01-28 12:38:52,503 - decision_tree.py - harmonizations attempted: 30
2025-01-28 12:38:52,503 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:52,503 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:52,503 - decision_tree.py - V_0=X, X_0=0, Y_0=1, V_1=Y, X_1=0, Y_1=1, A_2=(Down), A_3=(Left), V_4=Y, X_4=0, Y_4=1, A_5=(Up), A_6=(Down)
2025-01-28 12:38:52,504 - decision_tree.py - double-checking specification satisfiability:  : 0.34542558896055797

2025-01-28 12:38:52,504 - mdp.py - building tree of depth 3
2025-01-28 12:38:52,516 - statistic.py - synthesis initiated, design space: 1e17
2025-01-28 12:38:55,518 - synthesizer_ar.py - value 0.3457 achieved after 64.75 seconds
> progress 13.665%, elapsed 3 s, estimated 21 s, iters = {MDP: 526}, opt = 0.3457
2025-01-28 12:38:58,290 - synthesizer_ar.py - value 0.3459 achieved after 67.52 seconds
2025-01-28 12:38:58,517 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.0 s
number of holes: 29, family size: 1e17, quotient: 135 states / 295 actions
explored: 18 %
MDP stats: avg MDP size: 135, iterations: 1157

optimum: 0.345883
--------------------
2025-01-28 12:38:58,517 - decision_tree.py - families considered: 1157
2025-01-28 12:38:58,517 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:38:58,517 - decision_tree.py - families with schedulers preserved: 299
2025-01-28 12:38:58,518 - decision_tree.py - families model checked: 858
2025-01-28 12:38:58,518 - decision_tree.py - harmonizations attempted: 180
2025-01-28 12:38:58,518 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:38:58,518 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:38:58,518 - decision_tree.py - V_0=X, X_0=0, Y_0=2, V_1=Y, X_1=0, Y_1=3, V_2=Y, X_2=0, Y_2=1, A_3=(Down), A_4=(Left), V_5=X, X_5=2, Y_5=1, A_6=(Left), A_7=(Down), V_8=Y, X_8=0, Y_8=4, V_9=Y, X_9=0, Y_9=1, A_10=(Up), A_11=(Down), V_12=X, X_12=4, Y_12=1, A_13=(Down), A_14=(Left)
2025-01-28 12:38:58,519 - decision_tree.py - double-checking specification satisfiability:  : 0.345883445962665

2025-01-28 12:38:58,519 - mdp.py - building tree of depth 4
2025-01-28 12:38:58,542 - statistic.py - synthesis initiated, design space: 1e36
2025-01-28 12:38:58,718 - synthesizer_ar.py - value 0.346 achieved after 67.95 seconds
2025-01-28 12:38:58,882 - synthesizer_ar.py - value 0.3461 achieved after 68.11 seconds
2025-01-28 12:39:00,068 - synthesizer_ar.py - value 0.3464 achieved after 69.3 seconds
2025-01-28 12:39:00,249 - synthesizer_ar.py - value 0.3465 achieved after 69.48 seconds
> progress 0.379%, elapsed 3 s, estimated 792 s, iters = {MDP: 368}, opt = 0.3465
2025-01-28 12:39:02,060 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.0 s
number of holes: 61, family size: 1e36, quotient: 135 states / 295 actions
explored: 0 %
MDP stats: avg MDP size: 135, iterations: 772

optimum: 0.34651
--------------------
2025-01-28 12:39:02,061 - decision_tree.py - families considered: 772
2025-01-28 12:39:02,061 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:02,061 - decision_tree.py - families with schedulers preserved: 254
2025-01-28 12:39:02,061 - decision_tree.py - families model checked: 518
2025-01-28 12:39:02,061 - decision_tree.py - harmonizations attempted: 53
2025-01-28 12:39:02,061 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:02,061 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:02,061 - decision_tree.py - V_0=X, X_0=0, Y_0=1, V_1=Y, X_1=0, Y_1=3, V_2=Y, X_2=0, Y_2=1, V_3=X, X_3=0, Y_3=1, A_4=(Down), A_5=(Down), V_6=Y, X_6=0, Y_6=3, A_7=(Left), A_8=(Down), V_9=X, X_9=2, Y_9=1, V_10=Y, X_10=0, Y_10=1, A_11=(Left), A_12=(Left), V_13=X, X_13=0, Y_13=1, A_14=(Down), A_15=(Down), V_16=Y, X_16=0, Y_16=4, V_17=Y, X_17=0, Y_17=1, V_18=X, X_18=0, Y_18=1, A_19=(Up), A_20=(Up), V_21=X, X_21=4, Y_21=1, A_22=(Right), A_23=(Down), V_24=X, X_24=4, Y_24=1, V_25=X, X_25=2, Y_25=1, A_26=(Down), A_27=(Up), V_28=Y, X_28=0, Y_28=1, A_29=(Left), A_30=(Left)
2025-01-28 12:39:02,064 - decision_tree.py - double-checking specification satisfiability:  : 0.3465099522526254

2025-01-28 12:39:02,065 - mdp.py - building tree of depth 5
2025-01-28 12:39:02,095 - statistic.py - synthesis initiated, design space: 1e75
2025-01-28 12:39:04,844 - synthesizer_ar.py - value 0.3487 achieved after 76.56 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.75 s
number of holes: 125, family size: 1e75, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 224

optimum: 0.348721
--------------------
2025-01-28 12:39:04,844 - decision_tree.py - families considered: 224
2025-01-28 12:39:04,844 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:04,844 - decision_tree.py - families with schedulers preserved: 50
2025-01-28 12:39:04,844 - decision_tree.py - families model checked: 174
2025-01-28 12:39:04,844 - decision_tree.py - harmonizations attempted: 33
2025-01-28 12:39:04,844 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:04,844 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:04,844 - decision_tree.py - V_0=X, X_0=2, Y_0=2, V_1=X, X_1=3, Y_1=1, V_2=Y, X_2=0, Y_2=3, V_3=Y, X_3=0, Y_3=1, V_4=X, X_4=0, Y_4=1, A_5=(Down), A_6=(Up), V_7=X, X_7=0, Y_7=1, A_8=(Left), A_9=(Left), V_10=X, X_10=1, Y_10=2, V_11=X, X_11=0, Y_11=2, A_12=(Left), A_13=(Up), V_14=Y, X_14=3, Y_14=4, A_15=(Left), A_16=(Down), V_17=Y, X_17=3, Y_17=1, V_18=X, X_18=1, Y_18=4, V_19=Y, X_19=0, Y_19=1, A_20=__random__, A_21=__random__, V_22=Y, X_22=1, Y_22=4, A_23=__random__, A_24=__random__, V_25=Y, X_25=4, Y_25=1, V_26=Y, X_26=4, Y_26=2, A_27=__random__, A_28=__random__, V_29=X, X_29=4, Y_29=3, A_30=(Right), A_31=(Up), V_32=X, X_32=4, Y_32=2, V_33=Y, X_33=3, Y_33=3, V_34=Y, X_34=2, Y_34=2, V_35=Y, X_35=3, Y_35=1, A_36=(Up), A_37=(Right), V_38=X, X_38=3, Y_38=5, A_39=(Down), A_40=(Left), V_41=X, X_41=3, Y_41=3, V_42=Y, X_42=3, Y_42=5, A_43=(Down), A_44=(Left), V_45=Y, X_45=3, Y_45=4, A_46=(Right), A_47=(Up), V_48=X, X_48=3, Y_48=2, V_49=X, X_49=3, Y_49=4, V_50=Y, X_50=3, Y_50=5, A_51=(Down), A_52=(Left), V_53=X, X_53=3, Y_53=5, A_54=__random__, A_55=__random__, V_56=Y, X_56=4, Y_56=3, V_57=Y, X_57=4, Y_57=1, A_58=(Right), A_59=(Up), V_60=Y, X_60=2, Y_60=4, A_61=(Down), A_62=(Left)
2025-01-28 12:39:04,847 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:04,847 - decision_tree.py - admissible subtree found from node 9
2025-01-28 12:39:04,848 - decision_tree.py - new tree has depth 11 and 63 nodes
2025-01-28 12:39:06,128 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:06,129 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:06,130 - decision_tree.py - starting iteration 6 with 1 nodes in node queue
2025-01-28 12:39:06,130 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:06,131 - decision_tree.py - subtree quotient has 134 states and 286 choices
2025-01-28 12:39:06,132 - mdp.py - MDP has 28/134 relevant states
2025-01-28 12:39:06,133 - mdp.py - MDP has 5 actions
2025-01-28 12:39:06,133 - mdp.py - found the following 2 variables: ['X:[0..7]', 'Y:[7..10]']

2025-01-28 12:39:06,134 - mdp.py - building tree of depth 0
2025-01-28 12:39:06,136 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 286 actions
explored: 100 %
MDP stats: avg MDP size: 130, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:06,146 - decision_tree.py - families considered: 4
2025-01-28 12:39:06,146 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:06,146 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:06,146 - decision_tree.py - families model checked: 4
2025-01-28 12:39:06,146 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:06,146 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:06,146 - mdp.py - building tree of depth 1
2025-01-28 12:39:06,153 - statistic.py - synthesis initiated, design space: 1050
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 1050, quotient: 134 states / 286 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 6

optimum: 0.345233
--------------------
2025-01-28 12:39:06,169 - decision_tree.py - families considered: 6
2025-01-28 12:39:06,169 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:06,169 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:39:06,169 - decision_tree.py - families model checked: 5
2025-01-28 12:39:06,169 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:06,169 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:06,169 - mdp.py - building tree of depth 2
2025-01-28 12:39:06,178 - statistic.py - synthesis initiated, design space: 1e7
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.22 s
number of holes: 13, family size: 1e7, quotient: 134 states / 286 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 70

optimum: 0.345233
--------------------
2025-01-28 12:39:06,396 - decision_tree.py - families considered: 70
2025-01-28 12:39:06,396 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:06,396 - decision_tree.py - families with schedulers preserved: 27
2025-01-28 12:39:06,396 - decision_tree.py - families model checked: 43
2025-01-28 12:39:06,396 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:39:06,396 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:06,396 - mdp.py - building tree of depth 3
2025-01-28 12:39:06,407 - statistic.py - synthesis initiated, design space: 1e16
> progress 0.945%, elapsed 3 s, estimated 317 s, iters = {MDP: 783}, opt = 0.3452
2025-01-28 12:39:12,409 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.0 s
number of holes: 29, family size: 1e16, quotient: 134 states / 286 actions
explored: 4 %
MDP stats: avg MDP size: 133, iterations: 1556

optimum: 0.345233
--------------------
2025-01-28 12:39:12,409 - decision_tree.py - families considered: 1556
2025-01-28 12:39:12,409 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:12,409 - decision_tree.py - families with schedulers preserved: 666
2025-01-28 12:39:12,409 - decision_tree.py - families model checked: 890
2025-01-28 12:39:12,409 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:39:12,409 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:12,409 - mdp.py - building tree of depth 4
2025-01-28 12:39:12,424 - statistic.py - synthesis initiated, design space: 1e35
> progress 0.601%, elapsed 3 s, estimated 500 s, iters = {MDP: 371}, opt = 0.3452
2025-01-28 12:39:18,433 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.01 s
number of holes: 61, family size: 1e35, quotient: 134 states / 286 actions
explored: 0 %
MDP stats: avg MDP size: 133, iterations: 806

optimum: 0.345233
--------------------
2025-01-28 12:39:18,433 - decision_tree.py - families considered: 806
2025-01-28 12:39:18,434 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:18,434 - decision_tree.py - families with schedulers preserved: 340
2025-01-28 12:39:18,434 - decision_tree.py - families model checked: 466
2025-01-28 12:39:18,434 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:39:18,434 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:18,434 - mdp.py - building tree of depth 5
2025-01-28 12:39:18,464 - statistic.py - synthesis initiated, design space: 1e72
2025-01-28 12:39:18,508 - synthesizer_ar.py - value 0.3487 achieved after 90.22 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 125, family size: 1e72, quotient: 134 states / 286 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:39:18,508 - decision_tree.py - families considered: 1
2025-01-28 12:39:18,508 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:18,508 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:18,508 - decision_tree.py - families model checked: 1
2025-01-28 12:39:18,508 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:39:18,508 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:18,508 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:18,508 - decision_tree.py - V_0=Y, X_0=0, Y_0=8, V_1=X, X_1=3, Y_1=8, V_2=Y, X_2=0, Y_2=8, V_3=Y, X_3=5, Y_3=7, V_4=X, X_4=1, Y_4=7, A_5=(Down), A_6=(Left), V_7=X, X_7=0, Y_7=7, A_8=(Up), A_9=(Down), V_10=Y, X_10=2, Y_10=7, V_11=Y, X_11=0, Y_11=7, A_12=__random__, A_13=__random__, V_14=X, X_14=0, Y_14=7, A_15=(Left), A_16=__random__, V_17=Y, X_17=0, Y_17=7, V_18=Y, X_18=0, Y_18=8, V_19=Y, X_19=0, Y_19=8, A_20=(Down), A_21=__random__, V_22=Y, X_22=0, Y_22=9, A_23=(Left), A_24=(Right), V_25=X, X_25=5, Y_25=8, V_26=X, X_26=4, Y_26=9, A_27=(Down), A_28=(Up), V_29=X, X_29=6, Y_29=8, A_30=(Down), A_31=(Left), V_32=X, X_32=3, Y_32=8, V_33=Y, X_33=0, Y_33=9, V_34=Y, X_34=0, Y_34=8, V_35=Y, X_35=0, Y_35=9, A_36=__random__, A_37=(Right), V_38=X, X_38=1, Y_38=8, A_39=(Right), A_40=(Down), V_41=Y, X_41=0, Y_41=9, V_42=Y, X_42=0, Y_42=8, A_43=(Left), A_44=(Up), V_45=Y, X_45=0, Y_45=8, A_46=__random__, A_47=(Down), V_48=X, X_48=5, Y_48=9, V_49=Y, X_49=4, Y_49=9, V_50=X, X_50=1, Y_50=9, A_51=(Up), A_52=(Left), V_53=X, X_53=3, Y_53=9, A_54=(Up), A_55=(Down), V_56=Y, X_56=4, Y_56=8, V_57=X, X_57=0, Y_57=9, A_58=__random__, A_59=(Up), V_60=X, X_60=6, Y_60=9, A_61=(Right), A_62=(Down)
2025-01-28 12:39:18,511 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:18,511 - decision_tree.py - admissible subtree found from node 48
2025-01-28 12:39:18,512 - decision_tree.py - new tree has depth 11 and 63 nodes
2025-01-28 12:39:19,771 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:19,772 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:19,772 - decision_tree.py - starting iteration with subtree depth 5
2025-01-28 12:39:19,773 - decision_tree.py - starting iteration 7 with 4 nodes in node queue
2025-01-28 12:39:19,773 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:19,774 - decision_tree.py - subtree quotient has 135 states and 271 choices
2025-01-28 12:39:19,776 - mdp.py - MDP has 23/135 relevant states
2025-01-28 12:39:19,776 - mdp.py - MDP has 5 actions
2025-01-28 12:39:19,777 - mdp.py - found the following 2 variables: ['X:[0..5]', 'Y:[2..6]']

2025-01-28 12:39:19,777 - mdp.py - building tree of depth 0
2025-01-28 12:39:19,779 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 135 states / 271 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:19,787 - decision_tree.py - families considered: 4
2025-01-28 12:39:19,788 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:19,788 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:19,788 - decision_tree.py - families model checked: 4
2025-01-28 12:39:19,788 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:19,788 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:19,788 - mdp.py - building tree of depth 1
2025-01-28 12:39:19,798 - statistic.py - synthesis initiated, design space: 1000
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.03 s
number of holes: 5, family size: 1000, quotient: 135 states / 271 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 11

optimum: 0.345233
--------------------
2025-01-28 12:39:19,824 - decision_tree.py - families considered: 11
2025-01-28 12:39:19,824 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:19,824 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:19,824 - decision_tree.py - families model checked: 9
2025-01-28 12:39:19,824 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:39:19,824 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:19,824 - mdp.py - building tree of depth 2
2025-01-28 12:39:19,832 - statistic.py - synthesis initiated, design space: 1e7
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.26 s
number of holes: 13, family size: 1e7, quotient: 135 states / 271 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 92

optimum: 0.345233
--------------------
2025-01-28 12:39:20,096 - decision_tree.py - families considered: 92
2025-01-28 12:39:20,096 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:20,096 - decision_tree.py - families with schedulers preserved: 31
2025-01-28 12:39:20,096 - decision_tree.py - families model checked: 61
2025-01-28 12:39:20,096 - decision_tree.py - harmonizations attempted: 5
2025-01-28 12:39:20,096 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:20,096 - mdp.py - building tree of depth 3
2025-01-28 12:39:20,107 - statistic.py - synthesis initiated, design space: 1e16
> progress 10.911%, elapsed 3 s, estimated 27 s, iters = {MDP: 710}, opt = 0.3452
> progress 11.863%, elapsed 6 s, estimated 50 s, iters = {MDP: 1450}, opt = 0.3452
2025-01-28 12:39:27,613 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.51 s
number of holes: 29, family size: 1e16, quotient: 135 states / 271 actions
explored: 14 %
MDP stats: avg MDP size: 135, iterations: 1829

optimum: 0.345233
--------------------
2025-01-28 12:39:27,613 - decision_tree.py - families considered: 1829
2025-01-28 12:39:27,613 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:27,613 - decision_tree.py - families with schedulers preserved: 562
2025-01-28 12:39:27,613 - decision_tree.py - families model checked: 1267
2025-01-28 12:39:27,613 - decision_tree.py - harmonizations attempted: 177
2025-01-28 12:39:27,613 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:27,614 - mdp.py - building tree of depth 4
2025-01-28 12:39:27,631 - statistic.py - synthesis initiated, design space: 1e35
2025-01-28 12:39:27,657 - synthesizer_ar.py - value 0.3487 achieved after 99.37 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.03 s
number of holes: 61, family size: 1e35, quotient: 135 states / 271 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:39:27,658 - decision_tree.py - families considered: 1
2025-01-28 12:39:27,658 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:27,658 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:27,658 - decision_tree.py - families model checked: 1
2025-01-28 12:39:27,658 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:39:27,658 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:27,658 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:27,658 - decision_tree.py - V_0=X, X_0=3, Y_0=4, V_1=X, X_1=1, Y_1=2, V_2=Y, X_2=0, Y_2=3, V_3=X, X_3=2, Y_3=2, A_4=(Left), A_5=__random__, V_6=X, X_6=0, Y_6=2, A_7=(Left), A_8=(Up), V_9=X, X_9=2, Y_9=3, V_10=Y, X_10=2, Y_10=4, A_11=(Left), A_12=(Down), V_13=Y, X_13=3, Y_13=5, A_14=(Down), A_15=(Left), V_16=Y, X_16=1, Y_16=3, V_17=X, X_17=4, Y_17=2, V_18=Y, X_18=4, Y_18=2, A_19=(Right), A_20=(Left), V_21=Y, X_21=4, Y_21=3, A_22=(Up), A_23=__random__, V_24=X, X_24=4, Y_24=4, V_25=Y, X_25=4, Y_25=4, A_26=(Right), A_27=(Up), V_28=Y, X_28=2, Y_28=4, A_29=(Down), A_30=(Left)
2025-01-28 12:39:27,659 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:27,659 - decision_tree.py - admissible subtree found from node 15
2025-01-28 12:39:27,660 - decision_tree.py - new tree has depth 11 and 61 nodes
2025-01-28 12:39:29,023 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:29,023 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:29,024 - decision_tree.py - starting iteration 8 with 3 nodes in node queue
2025-01-28 12:39:29,024 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:29,025 - decision_tree.py - subtree quotient has 134 states and 234 choices
2025-01-28 12:39:29,026 - mdp.py - MDP has 15/134 relevant states
2025-01-28 12:39:29,027 - mdp.py - MDP has 5 actions
2025-01-28 12:39:29,027 - mdp.py - found the following 2 variables: ['X:[0..7]', 'Y:[7..8]']

2025-01-28 12:39:29,027 - mdp.py - building tree of depth 0
2025-01-28 12:39:29,035 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 234 actions
explored: 100 %
MDP stats: avg MDP size: 129, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:29,044 - decision_tree.py - families considered: 4
2025-01-28 12:39:29,045 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:29,045 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:29,045 - decision_tree.py - families model checked: 4
2025-01-28 12:39:29,045 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:29,045 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:29,045 - mdp.py - building tree of depth 1
2025-01-28 12:39:29,058 - statistic.py - synthesis initiated, design space: 350
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 5, family size: 350, quotient: 134 states / 234 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 6

optimum: 0.345233
--------------------
2025-01-28 12:39:29,071 - decision_tree.py - families considered: 6
2025-01-28 12:39:29,072 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:29,072 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:39:29,072 - decision_tree.py - families model checked: 5
2025-01-28 12:39:29,072 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:29,072 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:29,072 - mdp.py - building tree of depth 2
2025-01-28 12:39:29,078 - statistic.py - synthesis initiated, design space: 1e6
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.23 s
number of holes: 13, family size: 1e6, quotient: 134 states / 234 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 96

optimum: 0.345233
--------------------
2025-01-28 12:39:29,308 - decision_tree.py - families considered: 96
2025-01-28 12:39:29,309 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:29,309 - decision_tree.py - families with schedulers preserved: 39
2025-01-28 12:39:29,309 - decision_tree.py - families model checked: 57
2025-01-28 12:39:29,309 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:29,309 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:29,309 - mdp.py - building tree of depth 3
2025-01-28 12:39:29,319 - statistic.py - synthesis initiated, design space: 1e13
> progress 65.235%, elapsed 3 s, estimated 4 s, iters = {MDP: 696}, opt = 0.3452
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.48 s
number of holes: 29, family size: 1e13, quotient: 134 states / 234 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 1384

optimum: 0.345233
--------------------
2025-01-28 12:39:32,320 - decision_tree.py - families considered: 1384
2025-01-28 12:39:32,320 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:32,320 - decision_tree.py - families with schedulers preserved: 561
2025-01-28 12:39:32,320 - decision_tree.py - families model checked: 823
2025-01-28 12:39:32,320 - decision_tree.py - harmonizations attempted: 7
2025-01-28 12:39:32,320 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:32,320 - mdp.py - building tree of depth 4
2025-01-28 12:39:32,333 - statistic.py - synthesis initiated, design space: 1e28
2025-01-28 12:39:32,349 - synthesizer_ar.py - value 0.3487 achieved after 106.54 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 61, family size: 1e28, quotient: 134 states / 234 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:39:32,349 - decision_tree.py - families considered: 1
2025-01-28 12:39:32,349 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:32,349 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:32,349 - decision_tree.py - families model checked: 1
2025-01-28 12:39:32,349 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:39:32,349 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:32,349 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:32,349 - decision_tree.py - V_0=Y, X_0=0, Y_0=7, V_1=X, X_1=6, Y_1=7, V_2=X, X_2=2, Y_2=7, V_3=X, X_3=1, Y_3=7, A_4=(Down), A_5=(Left), V_6=X, X_6=6, Y_6=7, A_7=(Down), A_8=(Left), V_9=X, X_9=0, Y_9=7, V_10=X, X_10=0, Y_10=7, A_11=(Down), A_12=(Down), V_13=X, X_13=0, Y_13=7, A_14=(Down), A_15=(Down), V_16=X, X_16=6, Y_16=7, V_17=X, X_17=4, Y_17=7, V_18=X, X_18=0, Y_18=7, A_19=(Up), A_20=(Down), V_21=X, X_21=5, Y_21=7, A_22=(Up), A_23=(Down), V_24=X, X_24=6, Y_24=7, V_25=X, X_25=6, Y_25=7, A_26=(Right), A_27=(Down), V_28=X, X_28=6, Y_28=7, A_29=(Down), A_30=(Left)
2025-01-28 12:39:32,351 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:32,351 - decision_tree.py - admissible subtree found from node 49
2025-01-28 12:39:32,352 - decision_tree.py - new tree has depth 11 and 62 nodes
2025-01-28 12:39:33,674 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:33,674 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:33,675 - decision_tree.py - starting iteration 9 with 2 nodes in node queue
2025-01-28 12:39:33,675 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:33,676 - decision_tree.py - subtree quotient has 132 states and 224 choices
2025-01-28 12:39:33,677 - mdp.py - MDP has 15/132 relevant states
2025-01-28 12:39:33,678 - mdp.py - MDP has 5 actions
2025-01-28 12:39:33,679 - mdp.py - found the following 2 variables: ['X:[8..11]', 'Y:[4..7]']

2025-01-28 12:39:33,679 - mdp.py - building tree of depth 0
2025-01-28 12:39:33,684 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 132 states / 224 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:33,693 - decision_tree.py - families considered: 4
2025-01-28 12:39:33,693 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:33,693 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:33,693 - decision_tree.py - families model checked: 4
2025-01-28 12:39:33,693 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:33,693 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:33,694 - mdp.py - building tree of depth 1
2025-01-28 12:39:33,708 - statistic.py - synthesis initiated, design space: 450
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 450, quotient: 132 states / 224 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 9

optimum: 0.345233
--------------------
2025-01-28 12:39:33,727 - decision_tree.py - families considered: 9
2025-01-28 12:39:33,727 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:33,727 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:33,727 - decision_tree.py - families model checked: 7
2025-01-28 12:39:33,727 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:33,727 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:33,727 - mdp.py - building tree of depth 2
2025-01-28 12:39:33,734 - statistic.py - synthesis initiated, design space: 1e6
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.05 s
number of holes: 13, family size: 1e6, quotient: 132 states / 224 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 18

optimum: 0.345233
--------------------
2025-01-28 12:39:33,785 - decision_tree.py - families considered: 18
2025-01-28 12:39:33,785 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:33,785 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 12:39:33,785 - decision_tree.py - families model checked: 12
2025-01-28 12:39:33,785 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:33,785 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:33,785 - mdp.py - building tree of depth 3
2025-01-28 12:39:33,796 - statistic.py - synthesis initiated, design space: 1e14
2025-01-28 12:39:35,754 - synthesizer_ar.py - value 0.3459 achieved after 109.94 seconds
> progress 17.024%, elapsed 3 s, estimated 17 s, iters = {MDP: 728}, opt = 0.3459
> progress 76.249%, elapsed 6 s, estimated 7 s, iters = {MDP: 1492}, opt = 0.3459
2025-01-28 12:39:41,300 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.5 s
number of holes: 29, family size: 1e14, quotient: 132 states / 224 actions
explored: 88 %
MDP stats: avg MDP size: 132, iterations: 1878

optimum: 0.345905
--------------------
2025-01-28 12:39:41,301 - decision_tree.py - families considered: 1878
2025-01-28 12:39:41,301 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:41,301 - decision_tree.py - families with schedulers preserved: 743
2025-01-28 12:39:41,301 - decision_tree.py - families model checked: 1135
2025-01-28 12:39:41,301 - decision_tree.py - harmonizations attempted: 59
2025-01-28 12:39:41,301 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:41,301 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:41,301 - decision_tree.py - V_0=X, X_0=8, Y_0=6, V_1=Y, X_1=8, Y_1=5, V_2=Y, X_2=8, Y_2=4, A_3=(Down), A_4=(Left), V_5=Y, X_5=8, Y_5=6, A_6=(Down), A_7=(Up), V_8=Y, X_8=8, Y_8=4, V_9=X, X_9=9, Y_9=4, A_10=(Up), A_11=(Down), V_12=Y, X_12=8, Y_12=5, A_13=(Right), A_14=(Down)
2025-01-28 12:39:41,302 - decision_tree.py - double-checking specification satisfiability:  : 0.34590544842044735

2025-01-28 12:39:41,302 - mdp.py - building tree of depth 4
2025-01-28 12:39:41,314 - statistic.py - synthesis initiated, design space: 1e30
2025-01-28 12:39:41,353 - synthesizer_ar.py - value 0.3472 achieved after 115.54 seconds
2025-01-28 12:39:41,361 - synthesizer_ar.py - value 0.3484 achieved after 115.55 seconds
2025-01-28 12:39:41,476 - synthesizer_ar.py - value 0.3487 achieved after 115.67 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.16 s
number of holes: 61, family size: 1e30, quotient: 132 states / 224 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 23

optimum: 0.348721
--------------------
2025-01-28 12:39:41,477 - decision_tree.py - families considered: 23
2025-01-28 12:39:41,477 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:41,477 - decision_tree.py - families with schedulers preserved: 7
2025-01-28 12:39:41,477 - decision_tree.py - families model checked: 16
2025-01-28 12:39:41,477 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:41,477 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:41,477 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:41,477 - decision_tree.py - V_0=Y, X_0=9, Y_0=5, V_1=Y, X_1=9, Y_1=4, V_2=X, X_2=8, Y_2=4, V_3=X, X_3=8, Y_3=4, A_4=(Down), A_5=(Up), V_6=X, X_6=9, Y_6=5, A_7=(Up), A_8=(Down), V_9=X, X_9=10, Y_9=5, V_10=X, X_10=8, Y_10=6, A_11=(Left), A_12=(Right), V_13=X, X_13=10, Y_13=5, A_14=__random__, A_15=(Down), V_16=X, X_16=9, Y_16=6, V_17=Y, X_17=9, Y_17=6, V_18=Y, X_18=8, Y_18=6, A_19=(Down), A_20=__random__, V_21=X, X_21=8, Y_21=6, A_22=(Up), A_23=(Down), V_24=X, X_24=10, Y_24=6, V_25=Y, X_25=10, Y_25=6, A_26=(Down), A_27=(Left), V_28=X, X_28=10, Y_28=4, A_29=__random__, A_30=(Down)
2025-01-28 12:39:41,478 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:41,479 - decision_tree.py - admissible subtree found from node 89
2025-01-28 12:39:41,480 - decision_tree.py - new tree has depth 10 and 61 nodes
2025-01-28 12:39:42,821 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:42,822 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:42,822 - decision_tree.py - starting iteration 10 with 1 nodes in node queue
2025-01-28 12:39:42,823 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:42,824 - decision_tree.py - subtree quotient has 132 states and 216 choices
2025-01-28 12:39:42,825 - mdp.py - MDP has 13/132 relevant states
2025-01-28 12:39:42,825 - mdp.py - MDP has 5 actions
2025-01-28 12:39:42,826 - mdp.py - found the following 2 variables: ['X:[0..7]', 'Y:[9..10]']

2025-01-28 12:39:42,826 - mdp.py - building tree of depth 0
2025-01-28 12:39:42,830 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 132 states / 216 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:42,839 - decision_tree.py - families considered: 4
2025-01-28 12:39:42,839 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:42,839 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:42,839 - decision_tree.py - families model checked: 4
2025-01-28 12:39:42,839 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:42,839 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:42,839 - mdp.py - building tree of depth 1
2025-01-28 12:39:42,852 - statistic.py - synthesis initiated, design space: 350
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 5, family size: 350, quotient: 132 states / 216 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 25

optimum: 0.345233
--------------------
2025-01-28 12:39:42,892 - decision_tree.py - families considered: 25
2025-01-28 12:39:42,892 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:42,892 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 12:39:42,892 - decision_tree.py - families model checked: 19
2025-01-28 12:39:42,892 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:39:42,892 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:42,892 - mdp.py - building tree of depth 2
2025-01-28 12:39:42,900 - statistic.py - synthesis initiated, design space: 1e6
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.49 s
number of holes: 13, family size: 1e6, quotient: 132 states / 216 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 200

optimum: 0.345233
--------------------
2025-01-28 12:39:43,392 - decision_tree.py - families considered: 200
2025-01-28 12:39:43,392 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:43,392 - decision_tree.py - families with schedulers preserved: 53
2025-01-28 12:39:43,392 - decision_tree.py - families model checked: 147
2025-01-28 12:39:43,392 - decision_tree.py - harmonizations attempted: 26
2025-01-28 12:39:43,392 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:43,393 - mdp.py - building tree of depth 3
2025-01-28 12:39:43,402 - statistic.py - synthesis initiated, design space: 1e13
2025-01-28 12:39:43,412 - synthesizer_ar.py - value 0.3487 achieved after 117.6 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 29, family size: 1e13, quotient: 132 states / 216 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:39:43,413 - decision_tree.py - families considered: 1
2025-01-28 12:39:43,413 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:43,413 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:43,413 - decision_tree.py - families model checked: 1
2025-01-28 12:39:43,413 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:39:43,413 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:43,413 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:43,413 - decision_tree.py - V_0=X, X_0=3, Y_0=9, V_1=Y, X_1=3, Y_1=9, V_2=X, X_2=1, Y_2=9, A_3=(Right), A_4=(Down), V_5=X, X_5=4, Y_5=9, A_6=(Down), A_7=__random__, V_8=X, X_8=5, Y_8=9, V_9=Y, X_9=4, Y_9=9, A_10=(Left), A_11=(Down), V_12=X, X_12=6, Y_12=9, A_13=(Right), A_14=(Down)
2025-01-28 12:39:43,414 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:43,414 - decision_tree.py - admissible subtree found from node 64
2025-01-28 12:39:43,414 - decision_tree.py - new tree has depth 11 and 62 nodes
2025-01-28 12:39:44,853 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:44,853 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:44,854 - decision_tree.py - starting iteration with subtree depth 4
2025-01-28 12:39:44,855 - decision_tree.py - starting iteration 11 with 4 nodes in node queue
2025-01-28 12:39:44,855 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:44,856 - decision_tree.py - subtree quotient has 131 states and 191 choices
2025-01-28 12:39:44,857 - mdp.py - MDP has 8/131 relevant states
2025-01-28 12:39:44,857 - mdp.py - MDP has 5 actions
2025-01-28 12:39:44,858 - mdp.py - found the following 2 variables: ['X:[10..11]', 'Y:[4..7]']

2025-01-28 12:39:44,858 - mdp.py - building tree of depth 0
2025-01-28 12:39:44,860 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 131 states / 191 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:44,870 - decision_tree.py - families considered: 4
2025-01-28 12:39:44,870 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:44,870 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:44,870 - decision_tree.py - families model checked: 4
2025-01-28 12:39:44,870 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:44,870 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:44,870 - mdp.py - building tree of depth 1
2025-01-28 12:39:44,877 - statistic.py - synthesis initiated, design space: 150
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.03 s
number of holes: 5, family size: 150, quotient: 131 states / 191 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 16

optimum: 0.345233
--------------------
2025-01-28 12:39:44,907 - decision_tree.py - families considered: 16
2025-01-28 12:39:44,907 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:44,907 - decision_tree.py - families with schedulers preserved: 3
2025-01-28 12:39:44,907 - decision_tree.py - families model checked: 13
2025-01-28 12:39:44,907 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:39:44,907 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:44,907 - mdp.py - building tree of depth 2
2025-01-28 12:39:44,914 - statistic.py - synthesis initiated, design space: 135000
2025-01-28 12:39:44,942 - synthesizer_ar.py - value 0.3465 achieved after 119.13 seconds
2025-01-28 12:39:44,962 - synthesizer_ar.py - value 0.3476 achieved after 119.15 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.24 s
number of holes: 13, family size: 135000, quotient: 131 states / 191 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 98

optimum: 0.347616
--------------------
2025-01-28 12:39:45,156 - decision_tree.py - families considered: 98
2025-01-28 12:39:45,156 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:45,156 - decision_tree.py - families with schedulers preserved: 37
2025-01-28 12:39:45,156 - decision_tree.py - families model checked: 61
2025-01-28 12:39:45,156 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:39:45,156 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:45,156 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:45,156 - decision_tree.py - V_0=Y, X_0=10, Y_0=5, V_1=X, X_1=10, Y_1=5, A_2=(Right), A_3=(Down), V_4=Y, X_4=10, Y_4=5, A_5=(Left), A_6=(Down)
2025-01-28 12:39:45,157 - decision_tree.py - double-checking specification satisfiability:  : 0.3476160653211103

2025-01-28 12:39:45,157 - mdp.py - building tree of depth 3
2025-01-28 12:39:45,167 - statistic.py - synthesis initiated, design space: 1e11
2025-01-28 12:39:45,195 - synthesizer_ar.py - value 0.3484 achieved after 119.39 seconds
2025-01-28 12:39:45,213 - synthesizer_ar.py - value 0.3487 achieved after 119.4 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.05 s
number of holes: 29, family size: 1e11, quotient: 131 states / 191 actions
explored: 101 %
MDP stats: avg MDP size: 131, iterations: 10

optimum: 0.348721
--------------------
2025-01-28 12:39:45,213 - decision_tree.py - families considered: 10
2025-01-28 12:39:45,213 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:45,213 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:45,213 - decision_tree.py - families model checked: 8
2025-01-28 12:39:45,213 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:45,213 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:45,213 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:45,213 - decision_tree.py - V_0=Y, X_0=10, Y_0=5, V_1=Y, X_1=10, Y_1=4, V_2=X, X_2=10, Y_2=4, A_3=(Down), A_4=(Down), V_5=X, X_5=10, Y_5=6, A_6=(Right), A_7=(Down), V_8=X, X_8=10, Y_8=4, V_9=Y, X_9=10, Y_9=6, A_10=(Down), A_11=(Left), V_12=Y, X_12=10, Y_12=4, A_13=(Down), A_14=(Down)
2025-01-28 12:39:45,214 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:45,214 - decision_tree.py - admissible subtree found from node 101
2025-01-28 12:39:45,215 - decision_tree.py - new tree has depth 10 and 61 nodes
2025-01-28 12:39:46,491 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:46,492 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:46,493 - decision_tree.py - starting iteration 12 with 3 nodes in node queue
2025-01-28 12:39:46,493 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:46,494 - decision_tree.py - subtree quotient has 134 states and 206 choices
2025-01-28 12:39:46,495 - mdp.py - MDP has 8/134 relevant states
2025-01-28 12:39:46,496 - mdp.py - MDP has 5 actions
2025-01-28 12:39:46,497 - mdp.py - found the following 2 variables: ['X:[4..5]', 'Y:[2..6]']

2025-01-28 12:39:46,497 - mdp.py - building tree of depth 0
2025-01-28 12:39:46,499 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 206 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:46,509 - decision_tree.py - families considered: 4
2025-01-28 12:39:46,510 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:46,510 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:46,510 - decision_tree.py - families model checked: 4
2025-01-28 12:39:46,510 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:46,510 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:46,510 - mdp.py - building tree of depth 1
2025-01-28 12:39:46,518 - statistic.py - synthesis initiated, design space: 200
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 200, quotient: 134 states / 206 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 12

optimum: 0.345233
--------------------
2025-01-28 12:39:46,542 - decision_tree.py - families considered: 12
2025-01-28 12:39:46,543 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:46,543 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:46,543 - decision_tree.py - families model checked: 10
2025-01-28 12:39:46,543 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:39:46,543 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:46,543 - mdp.py - building tree of depth 2
2025-01-28 12:39:46,549 - statistic.py - synthesis initiated, design space: 320000
2025-01-28 12:39:46,629 - synthesizer_ar.py - value 0.3457 achieved after 120.82 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.24 s
number of holes: 13, family size: 320000, quotient: 134 states / 206 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 105

optimum: 0.345721
--------------------
2025-01-28 12:39:46,791 - decision_tree.py - families considered: 105
2025-01-28 12:39:46,791 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:46,791 - decision_tree.py - families with schedulers preserved: 30
2025-01-28 12:39:46,791 - decision_tree.py - families model checked: 75
2025-01-28 12:39:46,791 - decision_tree.py - harmonizations attempted: 14
2025-01-28 12:39:46,791 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:46,791 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:46,791 - decision_tree.py - V_0=Y, X_0=4, Y_0=2, V_1=X, X_1=4, Y_1=2, A_2=(Right), A_3=(Up), V_4=Y, X_4=4, Y_4=3, A_5=(Left), A_6=(Right)
2025-01-28 12:39:46,792 - decision_tree.py - double-checking specification satisfiability:  : 0.34572078899336506

2025-01-28 12:39:46,792 - mdp.py - building tree of depth 3
2025-01-28 12:39:46,800 - statistic.py - synthesis initiated, design space: 1e11
2025-01-28 12:39:46,895 - synthesizer_ar.py - value 0.3459 achieved after 121.09 seconds
2025-01-28 12:39:46,929 - synthesizer_ar.py - value 0.3465 achieved after 121.12 seconds
2025-01-28 12:39:47,007 - synthesizer_ar.py - value 0.3487 achieved after 121.2 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.21 s
number of holes: 29, family size: 1e11, quotient: 134 states / 206 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 44

optimum: 0.348721
--------------------
2025-01-28 12:39:47,007 - decision_tree.py - families considered: 44
2025-01-28 12:39:47,007 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:47,007 - decision_tree.py - families with schedulers preserved: 10
2025-01-28 12:39:47,007 - decision_tree.py - families model checked: 34
2025-01-28 12:39:47,007 - decision_tree.py - harmonizations attempted: 7
2025-01-28 12:39:47,007 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:47,007 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:47,007 - decision_tree.py - V_0=X, X_0=4, Y_0=4, V_1=Y, X_1=4, Y_1=3, V_2=Y, X_2=4, Y_2=2, A_3=(Right), A_4=(Left), V_5=Y, X_5=4, Y_5=4, A_6=(Right), A_7=(Up), V_8=Y, X_8=4, Y_8=3, V_9=Y, X_9=4, Y_9=2, A_10=(Up), A_11=__random__, V_12=Y, X_12=4, Y_12=4, A_13=(Down), A_14=(Left)
2025-01-28 12:39:47,008 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:47,009 - decision_tree.py - admissible subtree found from node 29
2025-01-28 12:39:47,009 - decision_tree.py - new tree has depth 11 and 61 nodes
2025-01-28 12:39:48,315 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:48,316 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:48,317 - decision_tree.py - starting iteration 13 with 2 nodes in node queue
2025-01-28 12:39:48,317 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:48,318 - decision_tree.py - subtree quotient has 133 states and 201 choices
2025-01-28 12:39:48,319 - mdp.py - MDP has 8/133 relevant states
2025-01-28 12:39:48,319 - mdp.py - MDP has 5 actions
2025-01-28 12:39:48,320 - mdp.py - found the following 1 variables: ['X:[0..7]']

2025-01-28 12:39:48,320 - mdp.py - building tree of depth 0
2025-01-28 12:39:48,322 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 133 states / 201 actions
explored: 100 %
MDP stats: avg MDP size: 128, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:48,333 - decision_tree.py - families considered: 4
2025-01-28 12:39:48,333 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:48,333 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:48,333 - decision_tree.py - families model checked: 4
2025-01-28 12:39:48,333 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:48,333 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:48,334 - mdp.py - building tree of depth 1
2025-01-28 12:39:48,342 - statistic.py - synthesis initiated, design space: 175
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 4, family size: 175, quotient: 133 states / 201 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 9

optimum: 0.345233
--------------------
2025-01-28 12:39:48,378 - decision_tree.py - families considered: 9
2025-01-28 12:39:48,379 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:48,379 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:48,379 - decision_tree.py - families model checked: 7
2025-01-28 12:39:48,379 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:48,379 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:48,380 - mdp.py - building tree of depth 2
2025-01-28 12:39:48,390 - statistic.py - synthesis initiated, design space: 214375
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.25 s
number of holes: 10, family size: 214375, quotient: 133 states / 201 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 111

optimum: 0.345233
--------------------
2025-01-28 12:39:48,637 - decision_tree.py - families considered: 111
2025-01-28 12:39:48,637 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:48,637 - decision_tree.py - families with schedulers preserved: 40
2025-01-28 12:39:48,637 - decision_tree.py - families model checked: 71
2025-01-28 12:39:48,637 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:39:48,637 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:48,637 - mdp.py - building tree of depth 3
2025-01-28 12:39:48,644 - statistic.py - synthesis initiated, design space: 1e11
2025-01-28 12:39:48,654 - synthesizer_ar.py - value 0.3487 achieved after 122.84 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 22, family size: 1e11, quotient: 133 states / 201 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:39:48,654 - decision_tree.py - families considered: 1
2025-01-28 12:39:48,654 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:48,654 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:48,654 - decision_tree.py - families model checked: 1
2025-01-28 12:39:48,654 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:39:48,654 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:48,654 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:48,655 - decision_tree.py - V_0=X, X_0=6, V_1=X, X_1=4, V_2=X, X_2=0, A_3=(Up), A_4=(Down), V_5=X, X_5=5, A_6=(Up), A_7=(Down), V_8=X, X_8=6, V_9=X, X_9=6, A_10=(Down), A_11=(Down), V_12=X, X_12=6, A_13=__random__, A_14=(Left)
2025-01-28 12:39:48,656 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:48,656 - decision_tree.py - admissible subtree found from node 55
2025-01-28 12:39:48,658 - decision_tree.py - new tree has depth 11 and 61 nodes
2025-01-28 12:39:49,930 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:49,931 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:49,932 - decision_tree.py - starting iteration 14 with 1 nodes in node queue
2025-01-28 12:39:49,932 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:49,933 - decision_tree.py - subtree quotient has 132 states and 188 choices
2025-01-28 12:39:49,934 - mdp.py - MDP has 6/132 relevant states
2025-01-28 12:39:49,934 - mdp.py - MDP has 5 actions
2025-01-28 12:39:49,935 - mdp.py - found the following 1 variables: ['X:[1..7]']

2025-01-28 12:39:49,935 - mdp.py - building tree of depth 0
2025-01-28 12:39:49,937 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 132 states / 188 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:49,946 - decision_tree.py - families considered: 4
2025-01-28 12:39:49,946 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:49,947 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:49,947 - decision_tree.py - families model checked: 4
2025-01-28 12:39:49,947 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:49,947 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:49,947 - mdp.py - building tree of depth 1
2025-01-28 12:39:49,952 - statistic.py - synthesis initiated, design space: 125
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 4, family size: 125, quotient: 132 states / 188 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 9

optimum: 0.345233
--------------------
2025-01-28 12:39:49,969 - decision_tree.py - families considered: 9
2025-01-28 12:39:49,969 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:49,969 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:49,969 - decision_tree.py - families model checked: 7
2025-01-28 12:39:49,969 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:49,969 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:49,970 - mdp.py - building tree of depth 2
2025-01-28 12:39:49,975 - statistic.py - synthesis initiated, design space: 78125
2025-01-28 12:39:49,985 - synthesizer_ar.py - value 0.3477 achieved after 124.18 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.05 s
number of holes: 10, family size: 78125, quotient: 132 states / 188 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 22

optimum: 0.347714
--------------------
2025-01-28 12:39:50,022 - decision_tree.py - families considered: 22
2025-01-28 12:39:50,022 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:50,022 - decision_tree.py - families with schedulers preserved: 7
2025-01-28 12:39:50,022 - decision_tree.py - families model checked: 15
2025-01-28 12:39:50,022 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:50,022 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:39:50,022 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:50,022 - decision_tree.py - V_0=X, X_0=4, V_1=X, X_1=3, A_2=(Right), A_3=(Left), V_4=X, X_4=6, A_5=(Right), A_6=(Down)
2025-01-28 12:39:50,023 - decision_tree.py - double-checking specification satisfiability:  : 0.34771395492489593

2025-01-28 12:39:50,023 - mdp.py - building tree of depth 3
2025-01-28 12:39:50,029 - statistic.py - synthesis initiated, design space: 1e10
2025-01-28 12:39:50,037 - synthesizer_ar.py - value 0.3487 achieved after 124.23 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 22, family size: 1e10, quotient: 132 states / 188 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 2

optimum: 0.348721
--------------------
2025-01-28 12:39:50,039 - decision_tree.py - families considered: 2
2025-01-28 12:39:50,039 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:50,039 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:50,039 - decision_tree.py - families model checked: 2
2025-01-28 12:39:50,039 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:39:50,039 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:50,039 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:50,039 - decision_tree.py - V_0=X, X_0=4, V_1=X, X_1=3, V_2=X, X_2=1, A_3=(Right), A_4=(Down), V_5=X, X_5=4, A_6=(Left), A_7=(Down), V_8=X, X_8=6, V_9=X, X_9=6, A_10=(Right), A_11=(Down), V_12=X, X_12=1, A_13=(Down), A_14=(Down)
2025-01-28 12:39:50,040 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:50,040 - decision_tree.py - admissible subtree found from node 65
2025-01-28 12:39:50,041 - decision_tree.py - new tree has depth 11 and 61 nodes
2025-01-28 12:39:51,378 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:51,378 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:51,379 - decision_tree.py - starting iteration with subtree depth 3
2025-01-28 12:39:51,381 - decision_tree.py - starting iteration 15 with 7 nodes in node queue
2025-01-28 12:39:51,381 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:51,382 - decision_tree.py - subtree quotient has 131 states and 179 choices
2025-01-28 12:39:51,382 - mdp.py - MDP has 5/131 relevant states
2025-01-28 12:39:51,383 - mdp.py - MDP has 5 actions
2025-01-28 12:39:51,384 - mdp.py - found the following 1 variables: ['X:[2..7]']

2025-01-28 12:39:51,384 - mdp.py - building tree of depth 0
2025-01-28 12:39:51,386 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 131 states / 179 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:51,394 - decision_tree.py - families considered: 4
2025-01-28 12:39:51,394 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:51,394 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:51,394 - decision_tree.py - families model checked: 4
2025-01-28 12:39:51,394 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:51,394 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:51,395 - mdp.py - building tree of depth 1
2025-01-28 12:39:51,400 - statistic.py - synthesis initiated, design space: 100
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.03 s
number of holes: 4, family size: 100, quotient: 131 states / 179 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 15

optimum: 0.345233
--------------------
2025-01-28 12:39:51,429 - decision_tree.py - families considered: 15
2025-01-28 12:39:51,429 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:51,429 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:51,429 - decision_tree.py - families model checked: 13
2025-01-28 12:39:51,429 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:39:51,429 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:51,429 - mdp.py - building tree of depth 2
2025-01-28 12:39:51,434 - statistic.py - synthesis initiated, design space: 40000
2025-01-28 12:39:51,441 - synthesizer_ar.py - value 0.3487 achieved after 125.63 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 10, family size: 40000, quotient: 131 states / 179 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:39:51,442 - decision_tree.py - families considered: 1
2025-01-28 12:39:51,442 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:51,442 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:51,442 - decision_tree.py - families model checked: 1
2025-01-28 12:39:51,442 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:39:51,442 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:51,442 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:51,442 - decision_tree.py - V_0=X, X_0=4, V_1=X, X_1=3, A_2=(Down), A_3=(Left), V_4=X, X_4=6, A_5=(Right), A_6=(Down)
2025-01-28 12:39:51,442 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:51,443 - decision_tree.py - admissible subtree found from node 67
2025-01-28 12:39:51,443 - decision_tree.py - new tree has depth 11 and 61 nodes
2025-01-28 12:39:52,696 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:52,696 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:52,697 - decision_tree.py - starting iteration 16 with 6 nodes in node queue
2025-01-28 12:39:52,697 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:52,698 - decision_tree.py - subtree quotient has 133 states and 189 choices
2025-01-28 12:39:52,699 - mdp.py - MDP has 5/133 relevant states
2025-01-28 12:39:52,700 - mdp.py - MDP has 5 actions
2025-01-28 12:39:52,700 - mdp.py - found the following 2 variables: ['X:[8..11]', 'Y:[8..9]']

2025-01-28 12:39:52,701 - mdp.py - building tree of depth 0
2025-01-28 12:39:52,702 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 133 states / 189 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:52,711 - decision_tree.py - families considered: 4
2025-01-28 12:39:52,711 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:52,711 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:52,711 - decision_tree.py - families model checked: 4
2025-01-28 12:39:52,711 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:52,711 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:52,711 - mdp.py - building tree of depth 1
2025-01-28 12:39:52,717 - statistic.py - synthesis initiated, design space: 150
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 150, quotient: 133 states / 189 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 12

optimum: 0.345233
--------------------
2025-01-28 12:39:52,738 - decision_tree.py - families considered: 12
2025-01-28 12:39:52,738 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:52,738 - decision_tree.py - families with schedulers preserved: 3
2025-01-28 12:39:52,738 - decision_tree.py - families model checked: 9
2025-01-28 12:39:52,738 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:52,738 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:52,738 - mdp.py - building tree of depth 2
2025-01-28 12:39:52,745 - statistic.py - synthesis initiated, design space: 135000
2025-01-28 12:39:52,752 - synthesizer_ar.py - value 0.3487 achieved after 126.94 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 13, family size: 135000, quotient: 133 states / 189 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 1

optimum: 0.348721
--------------------
2025-01-28 12:39:52,753 - decision_tree.py - families considered: 1
2025-01-28 12:39:52,753 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:52,753 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:52,753 - decision_tree.py - families model checked: 1
2025-01-28 12:39:52,753 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:39:52,753 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:52,753 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:52,753 - decision_tree.py - V_0=Y, X_0=8, Y_0=8, V_1=X, X_1=9, Y_1=8, A_2=(Right), A_3=(Up), V_4=X, X_4=8, Y_4=8, A_5=(Down), A_6=(Left)
2025-01-28 12:39:52,754 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:52,754 - decision_tree.py - admissible subtree found from node 112
2025-01-28 12:39:52,754 - decision_tree.py - new tree has depth 11 and 61 nodes
2025-01-28 12:39:54,018 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:54,018 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:54,019 - decision_tree.py - starting iteration 17 with 5 nodes in node queue
2025-01-28 12:39:54,019 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:54,021 - decision_tree.py - subtree quotient has 132 states and 192 choices
2025-01-28 12:39:54,022 - mdp.py - MDP has 7/132 relevant states
2025-01-28 12:39:54,023 - mdp.py - MDP has 5 actions
2025-01-28 12:39:54,023 - mdp.py - found the following 2 variables: ['X:[8..9]', 'Y:[4..7]']

2025-01-28 12:39:54,024 - mdp.py - building tree of depth 0
2025-01-28 12:39:54,026 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 132 states / 192 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:54,036 - decision_tree.py - families considered: 4
2025-01-28 12:39:54,036 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:54,036 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:54,036 - decision_tree.py - families model checked: 4
2025-01-28 12:39:54,036 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:54,036 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:54,036 - mdp.py - building tree of depth 1
2025-01-28 12:39:54,042 - statistic.py - synthesis initiated, design space: 150
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 150, quotient: 132 states / 192 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 9

optimum: 0.345233
--------------------
2025-01-28 12:39:54,059 - decision_tree.py - families considered: 9
2025-01-28 12:39:54,059 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:54,059 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:54,059 - decision_tree.py - families model checked: 7
2025-01-28 12:39:54,060 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:54,060 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:54,060 - mdp.py - building tree of depth 2
2025-01-28 12:39:54,066 - statistic.py - synthesis initiated, design space: 135000
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.06 s
number of holes: 13, family size: 135000, quotient: 132 states / 192 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 23

optimum: 0.345233
--------------------
2025-01-28 12:39:54,121 - decision_tree.py - families considered: 23
2025-01-28 12:39:54,121 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:54,121 - decision_tree.py - families with schedulers preserved: 8
2025-01-28 12:39:54,121 - decision_tree.py - families model checked: 15
2025-01-28 12:39:54,121 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:54,121 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:54,122 - decision_tree.py - no admissible subtree found from node 90
2025-01-28 12:39:54,122 - decision_tree.py - starting iteration 18 with 4 nodes in node queue
2025-01-28 12:39:54,122 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:54,123 - decision_tree.py - subtree quotient has 132 states and 180 choices
2025-01-28 12:39:54,124 - mdp.py - MDP has 4/132 relevant states
2025-01-28 12:39:54,124 - mdp.py - MDP has 5 actions
2025-01-28 12:39:54,125 - mdp.py - found the following 1 variables: ['Y:[2..5]']

2025-01-28 12:39:54,125 - mdp.py - building tree of depth 0
2025-01-28 12:39:54,126 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:39:54,132 - synthesizer_ar.py - value 0.3457 achieved after 128.32 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 132 states / 180 actions
explored: 100 %
MDP stats: avg MDP size: 130, iterations: 4

optimum: 0.345671
--------------------
2025-01-28 12:39:54,134 - decision_tree.py - families considered: 4
2025-01-28 12:39:54,134 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:54,134 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:54,134 - decision_tree.py - families model checked: 4
2025-01-28 12:39:54,134 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:54,134 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:39:54,134 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:54,134 - decision_tree.py - A_0=(Right)
2025-01-28 12:39:54,135 - decision_tree.py - double-checking specification satisfiability:  : 0.3456712063679388

2025-01-28 12:39:54,135 - mdp.py - building tree of depth 1
2025-01-28 12:39:54,145 - statistic.py - synthesis initiated, design space: 75
2025-01-28 12:39:54,153 - synthesizer_ar.py - value 0.3462 achieved after 128.34 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.03 s
number of holes: 4, family size: 75, quotient: 132 states / 180 actions
explored: 200 %
MDP stats: avg MDP size: 130, iterations: 18

optimum: 0.346177
--------------------
2025-01-28 12:39:54,174 - decision_tree.py - families considered: 18
2025-01-28 12:39:54,174 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:54,174 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:54,174 - decision_tree.py - families model checked: 16
2025-01-28 12:39:54,174 - decision_tree.py - harmonizations attempted: 4
2025-01-28 12:39:54,174 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:39:54,174 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:54,174 - decision_tree.py - V_0=Y, Y_0=4, A_1=(Right), A_2=(Up)
2025-01-28 12:39:54,175 - decision_tree.py - double-checking specification satisfiability:  : 0.3461765875892924

2025-01-28 12:39:54,175 - mdp.py - building tree of depth 2
2025-01-28 12:39:54,181 - statistic.py - synthesis initiated, design space: 16875
2025-01-28 12:39:54,202 - synthesizer_ar.py - value 0.3487 achieved after 128.39 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 10, family size: 16875, quotient: 132 states / 180 actions
explored: 133 %
MDP stats: avg MDP size: 130, iterations: 10

optimum: 0.348721
--------------------
2025-01-28 12:39:54,202 - decision_tree.py - families considered: 10
2025-01-28 12:39:54,202 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:54,202 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:54,202 - decision_tree.py - families model checked: 8
2025-01-28 12:39:54,203 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:54,203 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:54,203 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:54,203 - decision_tree.py - V_0=Y, Y_0=3, V_1=Y, Y_1=2, A_2=(Right), A_3=(Left), V_4=Y, Y_4=4, A_5=(Right), A_6=(Up)
2025-01-28 12:39:54,203 - decision_tree.py - double-checking specification satisfiability:  : 0.34872067799978756
2025-01-28 12:39:54,203 - decision_tree.py - admissible subtree found from node 30
2025-01-28 12:39:54,204 - decision_tree.py - new tree has depth 11 and 61 nodes
2025-01-28 12:39:55,497 - decision_tree.py - new dtcontrol tree has depth 11 and 61 nodes
2025-01-28 12:39:55,498 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 12:39:55,499 - decision_tree.py - starting iteration 19 with 3 nodes in node queue
2025-01-28 12:39:55,499 - decision_tree.py - current tree size: 123 nodes
2025-01-28 12:39:55,500 - decision_tree.py - subtree quotient has 131 states and 183 choices
2025-01-28 12:39:55,501 - mdp.py - MDP has 6/131 relevant states
2025-01-28 12:39:55,501 - mdp.py - MDP has 5 actions
2025-01-28 12:39:55,502 - mdp.py - found the following 2 variables: ['X:[10..11]', 'Y:[4..6]']

2025-01-28 12:39:55,502 - mdp.py - building tree of depth 0
2025-01-28 12:39:55,504 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 131 states / 183 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:55,517 - decision_tree.py - families considered: 4
2025-01-28 12:39:55,517 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:55,517 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:55,517 - decision_tree.py - families model checked: 4
2025-01-28 12:39:55,517 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:55,517 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:55,517 - mdp.py - building tree of depth 1
2025-01-28 12:39:55,525 - statistic.py - synthesis initiated, design space: 100
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.03 s
number of holes: 5, family size: 100, quotient: 131 states / 183 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 19

optimum: 0.345233
--------------------
2025-01-28 12:39:55,555 - decision_tree.py - families considered: 19
2025-01-28 12:39:55,555 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:55,555 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:39:55,555 - decision_tree.py - families model checked: 14
2025-01-28 12:39:55,555 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:39:55,555 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:55,555 - mdp.py - building tree of depth 2
2025-01-28 12:39:55,562 - statistic.py - synthesis initiated, design space: 40000
2025-01-28 12:39:55,588 - synthesizer_ar.py - value 0.348 achieved after 129.78 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.19 s
number of holes: 13, family size: 40000, quotient: 131 states / 183 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 98

optimum: 0.347964
--------------------
2025-01-28 12:39:55,751 - decision_tree.py - families considered: 98
2025-01-28 12:39:55,751 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:55,751 - decision_tree.py - families with schedulers preserved: 38
2025-01-28 12:39:55,751 - decision_tree.py - families model checked: 60
2025-01-28 12:39:55,751 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:55,752 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:55,752 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:55,752 - decision_tree.py - V_0=Y, X_0=10, Y_0=5, V_1=X, X_1=10, Y_1=5, A_2=(Right), A_3=(Down), V_4=Y, X_4=10, Y_4=5, A_5=(Down), A_6=(Down)
2025-01-28 12:39:55,752 - decision_tree.py - double-checking specification satisfiability:  : 0.3479635610198646
2025-01-28 12:39:55,752 - decision_tree.py - admissible subtree found from node 102
2025-01-28 12:39:55,754 - decision_tree.py - new tree has depth 10 and 60 nodes
2025-01-28 12:39:57,047 - decision_tree.py - new dtcontrol tree has depth 12 and 59 nodes
2025-01-28 12:39:57,047 - decision_tree.py - New DtControl tree is smaller
2025-01-28 12:39:57,048 - decision_tree.py - starting iteration 20 with 2 nodes in node queue
2025-01-28 12:39:57,048 - decision_tree.py - current tree size: 119 nodes
2025-01-28 12:39:57,050 - decision_tree.py - subtree quotient has 134 states and 254 choices
2025-01-28 12:39:57,051 - mdp.py - MDP has 20/134 relevant states
2025-01-28 12:39:57,051 - mdp.py - MDP has 5 actions
2025-01-28 12:39:57,052 - mdp.py - found the following 2 variables: ['X:[8..11]', 'Y:[4..9]']

2025-01-28 12:39:57,052 - mdp.py - building tree of depth 0
2025-01-28 12:39:57,054 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:57,063 - decision_tree.py - families considered: 4
2025-01-28 12:39:57,063 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,063 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:57,063 - decision_tree.py - families model checked: 4
2025-01-28 12:39:57,063 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:57,063 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:57,063 - mdp.py - building tree of depth 1
2025-01-28 12:39:57,069 - statistic.py - synthesis initiated, design space: 750
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 750, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 6

optimum: 0.345233
--------------------
2025-01-28 12:39:57,084 - decision_tree.py - families considered: 6
2025-01-28 12:39:57,084 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,085 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:39:57,085 - decision_tree.py - families model checked: 5
2025-01-28 12:39:57,085 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:57,085 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:57,085 - mdp.py - building tree of depth 2
2025-01-28 12:39:57,091 - statistic.py - synthesis initiated, design space: 1e7
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 13, family size: 1e7, quotient: 134 states / 254 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 16

optimum: 0.345233
--------------------
2025-01-28 12:39:57,136 - decision_tree.py - families considered: 16
2025-01-28 12:39:57,136 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,136 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 12:39:57,136 - decision_tree.py - families model checked: 11
2025-01-28 12:39:57,136 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:57,136 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:57,137 - decision_tree.py - no admissible subtree found from node 82
2025-01-28 12:39:57,137 - decision_tree.py - starting iteration 21 with 1 nodes in node queue
2025-01-28 12:39:57,137 - decision_tree.py - current tree size: 119 nodes
2025-01-28 12:39:57,138 - decision_tree.py - subtree quotient has 135 states and 295 choices
2025-01-28 12:39:57,138 - mdp.py - MDP has 29/135 relevant states
2025-01-28 12:39:57,139 - mdp.py - MDP has 5 actions
2025-01-28 12:39:57,139 - mdp.py - found the following 2 variables: ['X:[0..5]', 'Y:[1..6]']

2025-01-28 12:39:57,140 - mdp.py - building tree of depth 0
2025-01-28 12:39:57,141 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:57,149 - decision_tree.py - families considered: 4
2025-01-28 12:39:57,149 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,149 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:57,149 - decision_tree.py - families model checked: 4
2025-01-28 12:39:57,149 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:57,149 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:57,150 - mdp.py - building tree of depth 1
2025-01-28 12:39:57,160 - statistic.py - synthesis initiated, design space: 1250
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 1250, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 11

optimum: 0.345233
--------------------
2025-01-28 12:39:57,183 - decision_tree.py - families considered: 11
2025-01-28 12:39:57,183 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,183 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:57,183 - decision_tree.py - families model checked: 9
2025-01-28 12:39:57,183 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:39:57,183 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:57,183 - mdp.py - building tree of depth 2
2025-01-28 12:39:57,190 - statistic.py - synthesis initiated, design space: 1e7
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.33 s
number of holes: 13, family size: 1e7, quotient: 135 states / 295 actions
explored: 100 %
MDP stats: avg MDP size: 135, iterations: 103

optimum: 0.345233
--------------------
2025-01-28 12:39:57,524 - decision_tree.py - families considered: 103
2025-01-28 12:39:57,524 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,524 - decision_tree.py - families with schedulers preserved: 31
2025-01-28 12:39:57,524 - decision_tree.py - families model checked: 72
2025-01-28 12:39:57,524 - decision_tree.py - harmonizations attempted: 12
2025-01-28 12:39:57,524 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:57,524 - decision_tree.py - no admissible subtree found from node 10
2025-01-28 12:39:57,524 - decision_tree.py - starting iteration with subtree depth 2
2025-01-28 12:39:57,527 - decision_tree.py - starting iteration 22 with 16 nodes in node queue
2025-01-28 12:39:57,527 - decision_tree.py - current tree size: 119 nodes
2025-01-28 12:39:57,528 - decision_tree.py - subtree quotient has 131 states and 187 choices
2025-01-28 12:39:57,529 - mdp.py - MDP has 7/131 relevant states
2025-01-28 12:39:57,530 - mdp.py - MDP has 5 actions
2025-01-28 12:39:57,531 - mdp.py - found the following 2 variables: ['X:[2..3]', 'Y:[2..6]']

2025-01-28 12:39:57,531 - mdp.py - building tree of depth 0
2025-01-28 12:39:57,535 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:39:57,541 - synthesizer_ar.py - value 0.3471 achieved after 131.73 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 131 states / 187 actions
explored: 100 %
MDP stats: avg MDP size: 130, iterations: 7

optimum: 0.347052
--------------------
2025-01-28 12:39:57,547 - decision_tree.py - families considered: 7
2025-01-28 12:39:57,547 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,547 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:57,547 - decision_tree.py - families model checked: 7
2025-01-28 12:39:57,547 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:39:57,547 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:39:57,547 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:57,547 - decision_tree.py - A_0=(Down)
2025-01-28 12:39:57,548 - decision_tree.py - double-checking specification satisfiability:  : 0.34705206842945374

2025-01-28 12:39:57,548 - mdp.py - building tree of depth 1
2025-01-28 12:39:57,562 - statistic.py - synthesis initiated, design space: 200
2025-01-28 12:39:57,584 - synthesizer_ar.py - value 0.3473 achieved after 131.78 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 5, family size: 200, quotient: 131 states / 187 actions
explored: 200 %
MDP stats: avg MDP size: 130, iterations: 67

optimum: 0.347341
--------------------
2025-01-28 12:39:57,663 - decision_tree.py - families considered: 67
2025-01-28 12:39:57,663 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,663 - decision_tree.py - families with schedulers preserved: 9
2025-01-28 12:39:57,663 - decision_tree.py - families model checked: 58
2025-01-28 12:39:57,663 - decision_tree.py - harmonizations attempted: 15
2025-01-28 12:39:57,663 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:39:57,663 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:57,663 - decision_tree.py - V_0=Y, X_0=2, Y_0=3, A_1=(Up), A_2=(Down)
2025-01-28 12:39:57,664 - decision_tree.py - double-checking specification satisfiability:  : 0.3473413632559857
2025-01-28 12:39:57,664 - decision_tree.py - admissible subtree found from node 23
2025-01-28 12:39:57,678 - decision_tree.py - new tree has depth 12 and 57 nodes
2025-01-28 12:39:58,969 - decision_tree.py - new dtcontrol tree has depth 12 and 60 nodes
2025-01-28 12:39:58,970 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:39:58,971 - decision_tree.py - starting iteration 23 with 15 nodes in node queue
2025-01-28 12:39:58,971 - decision_tree.py - current tree size: 115 nodes
2025-01-28 12:39:58,972 - decision_tree.py - subtree quotient has 132 states and 176 choices
2025-01-28 12:39:58,974 - mdp.py - MDP has 3/132 relevant states
2025-01-28 12:39:58,974 - mdp.py - MDP has 5 actions
2025-01-28 12:39:58,975 - mdp.py - found the following 1 variables: ['Y:[2..4]']

2025-01-28 12:39:58,975 - mdp.py - building tree of depth 0
2025-01-28 12:39:58,977 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 132 states / 176 actions
explored: 100 %
MDP stats: avg MDP size: 130, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:58,988 - decision_tree.py - families considered: 4
2025-01-28 12:39:58,988 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:58,988 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:58,988 - decision_tree.py - families model checked: 4
2025-01-28 12:39:58,988 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:58,988 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:58,988 - mdp.py - building tree of depth 1
2025-01-28 12:39:58,996 - statistic.py - synthesis initiated, design space: 50
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 4, family size: 50, quotient: 132 states / 176 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 7

optimum: 0.345233
--------------------
2025-01-28 12:39:59,012 - decision_tree.py - families considered: 7
2025-01-28 12:39:59,012 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,012 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:39:59,012 - decision_tree.py - families model checked: 6
2025-01-28 12:39:59,012 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,012 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:59,012 - decision_tree.py - no admissible subtree found from node 28
2025-01-28 12:39:59,012 - decision_tree.py - starting iteration 24 with 14 nodes in node queue
2025-01-28 12:39:59,012 - decision_tree.py - current tree size: 115 nodes
2025-01-28 12:39:59,013 - decision_tree.py - subtree quotient has 133 states and 185 choices
2025-01-28 12:39:59,014 - mdp.py - MDP has 4/133 relevant states
2025-01-28 12:39:59,015 - mdp.py - MDP has 5 actions
2025-01-28 12:39:59,016 - mdp.py - found the following 2 variables: ['X:[6..7]', 'Y:[7..8]']

2025-01-28 12:39:59,016 - mdp.py - building tree of depth 0
2025-01-28 12:39:59,018 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 133 states / 185 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:59,029 - decision_tree.py - families considered: 4
2025-01-28 12:39:59,029 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,029 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:59,029 - decision_tree.py - families model checked: 4
2025-01-28 12:39:59,029 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,029 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:59,030 - mdp.py - building tree of depth 1
2025-01-28 12:39:59,036 - statistic.py - synthesis initiated, design space: 50
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 50, quotient: 133 states / 185 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 9

optimum: 0.345233
--------------------
2025-01-28 12:39:59,055 - decision_tree.py - families considered: 9
2025-01-28 12:39:59,055 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,055 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:59,055 - decision_tree.py - families model checked: 7
2025-01-28 12:39:59,055 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,055 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:59,055 - decision_tree.py - no admissible subtree found from node 64
2025-01-28 12:39:59,055 - decision_tree.py - starting iteration 25 with 13 nodes in node queue
2025-01-28 12:39:59,055 - decision_tree.py - current tree size: 115 nodes
2025-01-28 12:39:59,056 - decision_tree.py - subtree quotient has 132 states and 176 choices
2025-01-28 12:39:59,057 - mdp.py - MDP has 3/132 relevant states
2025-01-28 12:39:59,058 - mdp.py - MDP has 5 actions
2025-01-28 12:39:59,059 - mdp.py - found the following 1 variables: ['Y:[6..9]']

2025-01-28 12:39:59,059 - mdp.py - building tree of depth 0
2025-01-28 12:39:59,060 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 132 states / 176 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:59,070 - decision_tree.py - families considered: 4
2025-01-28 12:39:59,070 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,070 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:59,070 - decision_tree.py - families model checked: 4
2025-01-28 12:39:59,070 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,070 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:59,071 - mdp.py - building tree of depth 1
2025-01-28 12:39:59,076 - statistic.py - synthesis initiated, design space: 50
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 4, family size: 50, quotient: 132 states / 176 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 7

optimum: 0.345233
--------------------
2025-01-28 12:39:59,091 - decision_tree.py - families considered: 7
2025-01-28 12:39:59,091 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,091 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:39:59,091 - decision_tree.py - families model checked: 6
2025-01-28 12:39:59,091 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,091 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:59,091 - decision_tree.py - no admissible subtree found from node 84
2025-01-28 12:39:59,091 - decision_tree.py - starting iteration 26 with 12 nodes in node queue
2025-01-28 12:39:59,091 - decision_tree.py - current tree size: 115 nodes
2025-01-28 12:39:59,093 - decision_tree.py - subtree quotient has 132 states and 180 choices
2025-01-28 12:39:59,094 - mdp.py - MDP has 4/132 relevant states
2025-01-28 12:39:59,094 - mdp.py - MDP has 5 actions
2025-01-28 12:39:59,095 - mdp.py - found the following 2 variables: ['X:[9..10]', 'Y:[6..7]']

2025-01-28 12:39:59,095 - mdp.py - building tree of depth 0
2025-01-28 12:39:59,097 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:39:59,104 - synthesizer_ar.py - value 0.347 achieved after 133.29 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 132 states / 180 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 4

optimum: 0.346994
--------------------
2025-01-28 12:39:59,107 - decision_tree.py - families considered: 4
2025-01-28 12:39:59,107 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,107 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:59,107 - decision_tree.py - families model checked: 4
2025-01-28 12:39:59,107 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,107 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:39:59,107 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:59,107 - decision_tree.py - A_0=(Down)
2025-01-28 12:39:59,107 - decision_tree.py - double-checking specification satisfiability:  : 0.3469944075446717

2025-01-28 12:39:59,108 - mdp.py - building tree of depth 1
2025-01-28 12:39:59,122 - statistic.py - synthesis initiated, design space: 50
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 50, quotient: 132 states / 180 actions
explored: 200 %
MDP stats: avg MDP size: 132, iterations: 12

optimum: 0.346994
--------------------
2025-01-28 12:39:59,146 - decision_tree.py - families considered: 12
2025-01-28 12:39:59,146 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,146 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:59,146 - decision_tree.py - families model checked: 10
2025-01-28 12:39:59,146 - decision_tree.py - harmonizations attempted: 2
2025-01-28 12:39:59,146 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:59,147 - decision_tree.py - admissible subtree found from node 94
2025-01-28 12:39:59,147 - decision_tree.py - new tree has depth 12 and 55 nodes
2025-01-28 12:39:57,921 - decision_tree.py - new dtcontrol tree has depth 10 and 60 nodes
2025-01-28 12:39:57,921 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:39:57,922 - decision_tree.py - starting iteration 27 with 11 nodes in node queue
2025-01-28 12:39:57,922 - decision_tree.py - current tree size: 111 nodes
2025-01-28 12:39:57,923 - decision_tree.py - subtree quotient has 133 states and 181 choices
2025-01-28 12:39:57,924 - mdp.py - MDP has 3/133 relevant states
2025-01-28 12:39:57,925 - mdp.py - MDP has 5 actions
2025-01-28 12:39:57,925 - mdp.py - found the following 2 variables: ['X:[9..10]', 'Y:[8..9]']

2025-01-28 12:39:57,925 - mdp.py - building tree of depth 0
2025-01-28 12:39:57,927 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 133 states / 181 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:57,935 - decision_tree.py - families considered: 4
2025-01-28 12:39:57,935 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,935 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:57,935 - decision_tree.py - families model checked: 4
2025-01-28 12:39:57,935 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:57,935 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:57,935 - mdp.py - building tree of depth 1
2025-01-28 12:39:57,946 - statistic.py - synthesis initiated, design space: 50
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 5, family size: 50, quotient: 133 states / 181 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 6

optimum: 0.345233
--------------------
2025-01-28 12:39:57,958 - decision_tree.py - families considered: 6
2025-01-28 12:39:57,958 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,958 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:39:57,958 - decision_tree.py - families model checked: 5
2025-01-28 12:39:57,958 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:57,958 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:57,958 - decision_tree.py - no admissible subtree found from node 95
2025-01-28 12:39:57,958 - decision_tree.py - starting iteration 28 with 10 nodes in node queue
2025-01-28 12:39:57,958 - decision_tree.py - current tree size: 111 nodes
2025-01-28 12:39:57,959 - decision_tree.py - subtree quotient has 131 states and 183 choices
2025-01-28 12:39:57,960 - mdp.py - MDP has 6/131 relevant states
2025-01-28 12:39:57,960 - mdp.py - MDP has 5 actions
2025-01-28 12:39:57,961 - mdp.py - found the following 1 variables: ['X:[0..5]']

2025-01-28 12:39:57,961 - mdp.py - building tree of depth 0
2025-01-28 12:39:57,962 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 131 states / 183 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:57,970 - decision_tree.py - families considered: 4
2025-01-28 12:39:57,970 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,970 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:57,970 - decision_tree.py - families model checked: 4
2025-01-28 12:39:57,970 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:57,970 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:57,970 - mdp.py - building tree of depth 1
2025-01-28 12:39:57,983 - statistic.py - synthesis initiated, design space: 125
2025-01-28 12:39:57,997 - synthesizer_ar.py - value 0.3455 achieved after 134.67 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 4, family size: 125, quotient: 131 states / 183 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 9

optimum: 0.345534
--------------------
2025-01-28 12:39:57,999 - decision_tree.py - families considered: 9
2025-01-28 12:39:57,999 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:57,999 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:57,999 - decision_tree.py - families model checked: 7
2025-01-28 12:39:57,999 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:57,999 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:57,999 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:57,999 - decision_tree.py - V_0=X, X_0=0, A_1=(Down), A_2=(Up)
2025-01-28 12:39:58,000 - decision_tree.py - double-checking specification satisfiability:  : 0.34553413481023176
2025-01-28 12:39:58,000 - decision_tree.py - admissible subtree found from node 11
2025-01-28 12:39:58,000 - decision_tree.py - new tree has depth 12 and 54 nodes
2025-01-28 12:39:59,312 - decision_tree.py - new dtcontrol tree has depth 11 and 58 nodes
2025-01-28 12:39:59,312 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:39:59,314 - decision_tree.py - starting iteration 29 with 9 nodes in node queue
2025-01-28 12:39:59,314 - decision_tree.py - current tree size: 109 nodes
2025-01-28 12:39:59,315 - decision_tree.py - subtree quotient has 133 states and 185 choices
2025-01-28 12:39:59,316 - mdp.py - MDP has 4/133 relevant states
2025-01-28 12:39:59,316 - mdp.py - MDP has 5 actions
2025-01-28 12:39:59,317 - mdp.py - found the following 1 variables: ['X:[1..4]']

2025-01-28 12:39:59,317 - mdp.py - building tree of depth 0
2025-01-28 12:39:59,319 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 133 states / 185 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:59,329 - decision_tree.py - families considered: 4
2025-01-28 12:39:59,329 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,329 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:59,329 - decision_tree.py - families model checked: 4
2025-01-28 12:39:59,329 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,329 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:59,330 - mdp.py - building tree of depth 1
2025-01-28 12:39:59,336 - statistic.py - synthesis initiated, design space: 75
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 4, family size: 75, quotient: 133 states / 185 actions
explored: 100 %
MDP stats: avg MDP size: 133, iterations: 9

optimum: 0.345233
--------------------
2025-01-28 12:39:59,351 - decision_tree.py - families considered: 9
2025-01-28 12:39:59,352 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,352 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:39:59,352 - decision_tree.py - families model checked: 7
2025-01-28 12:39:59,352 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,352 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:59,352 - decision_tree.py - no admissible subtree found from node 49
2025-01-28 12:39:59,352 - decision_tree.py - starting iteration 30 with 8 nodes in node queue
2025-01-28 12:39:59,352 - decision_tree.py - current tree size: 109 nodes
2025-01-28 12:39:59,354 - decision_tree.py - subtree quotient has 131 states and 179 choices
2025-01-28 12:39:59,354 - mdp.py - MDP has 5/131 relevant states
2025-01-28 12:39:59,355 - mdp.py - MDP has 5 actions
2025-01-28 12:39:59,356 - mdp.py - found the following 1 variables: ['X:[0..5]']

2025-01-28 12:39:59,356 - mdp.py - building tree of depth 0
2025-01-28 12:39:59,358 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 131 states / 179 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:59,366 - decision_tree.py - families considered: 4
2025-01-28 12:39:59,366 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,366 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:59,366 - decision_tree.py - families model checked: 4
2025-01-28 12:39:59,366 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,366 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:59,366 - mdp.py - building tree of depth 1
2025-01-28 12:39:59,372 - statistic.py - synthesis initiated, design space: 100
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 4, family size: 100, quotient: 131 states / 179 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 7

optimum: 0.345233
--------------------
2025-01-28 12:39:59,385 - decision_tree.py - families considered: 7
2025-01-28 12:39:59,385 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,385 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:39:59,385 - decision_tree.py - families model checked: 6
2025-01-28 12:39:59,385 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,385 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:59,385 - decision_tree.py - no admissible subtree found from node 39
2025-01-28 12:39:59,385 - decision_tree.py - starting iteration 31 with 7 nodes in node queue
2025-01-28 12:39:59,385 - decision_tree.py - current tree size: 109 nodes
2025-01-28 12:39:59,386 - decision_tree.py - subtree quotient has 133 states and 193 choices
2025-01-28 12:39:59,387 - mdp.py - MDP has 6/133 relevant states
2025-01-28 12:39:59,387 - mdp.py - MDP has 5 actions
2025-01-28 12:39:59,388 - mdp.py - found the following 1 variables: ['X:[0..5]']

2025-01-28 12:39:59,388 - mdp.py - building tree of depth 0
2025-01-28 12:39:59,390 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 133 states / 193 actions
explored: 100 %
MDP stats: avg MDP size: 128, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:59,399 - decision_tree.py - families considered: 4
2025-01-28 12:39:59,399 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,399 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:59,399 - decision_tree.py - families model checked: 4
2025-01-28 12:39:59,399 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,399 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:59,399 - mdp.py - building tree of depth 1
2025-01-28 12:39:59,404 - statistic.py - synthesis initiated, design space: 125
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 4, family size: 125, quotient: 133 states / 193 actions
explored: 100 %
MDP stats: avg MDP size: 130, iterations: 7

optimum: 0.345233
--------------------
2025-01-28 12:39:59,417 - decision_tree.py - families considered: 7
2025-01-28 12:39:59,417 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,417 - decision_tree.py - families with schedulers preserved: 1
2025-01-28 12:39:59,417 - decision_tree.py - families model checked: 6
2025-01-28 12:39:59,417 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,417 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:59,417 - decision_tree.py - no admissible subtree found from node 44
2025-01-28 12:39:59,417 - decision_tree.py - starting iteration 32 with 6 nodes in node queue
2025-01-28 12:39:59,418 - decision_tree.py - current tree size: 109 nodes
2025-01-28 12:39:59,418 - decision_tree.py - subtree quotient has 134 states and 214 choices
2025-01-28 12:39:59,419 - mdp.py - MDP has 10/134 relevant states
2025-01-28 12:39:59,420 - mdp.py - MDP has 5 actions
2025-01-28 12:39:59,420 - mdp.py - found the following 2 variables: ['X:[6..7]', 'Y:[1..6]']

2025-01-28 12:39:59,421 - mdp.py - building tree of depth 0
2025-01-28 12:39:59,422 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 214 actions
explored: 100 %
MDP stats: avg MDP size: 129, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:59,431 - decision_tree.py - families considered: 4
2025-01-28 12:39:59,431 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,431 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:59,431 - decision_tree.py - families model checked: 4
2025-01-28 12:39:59,431 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,431 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:59,431 - mdp.py - building tree of depth 1
2025-01-28 12:39:59,436 - statistic.py - synthesis initiated, design space: 250
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 250, quotient: 134 states / 214 actions
explored: 100 %
MDP stats: avg MDP size: 128, iterations: 11

optimum: 0.345233
--------------------
2025-01-28 12:39:59,456 - decision_tree.py - families considered: 11
2025-01-28 12:39:59,456 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,456 - decision_tree.py - families with schedulers preserved: 3
2025-01-28 12:39:59,456 - decision_tree.py - families model checked: 8
2025-01-28 12:39:59,456 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,456 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:59,457 - decision_tree.py - no admissible subtree found from node 56
2025-01-28 12:39:59,457 - decision_tree.py - starting iteration 33 with 5 nodes in node queue
2025-01-28 12:39:59,457 - decision_tree.py - current tree size: 109 nodes
2025-01-28 12:39:59,458 - decision_tree.py - subtree quotient has 134 states and 190 choices
2025-01-28 12:39:59,459 - mdp.py - MDP has 4/134 relevant states
2025-01-28 12:39:59,459 - mdp.py - MDP has 5 actions
2025-01-28 12:39:59,459 - mdp.py - found the following 1 variables: ['Y:[2..6]']

2025-01-28 12:39:59,460 - mdp.py - building tree of depth 0
2025-01-28 12:39:59,461 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 190 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:39:59,469 - decision_tree.py - families considered: 4
2025-01-28 12:39:59,470 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,470 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:39:59,470 - decision_tree.py - families model checked: 4
2025-01-28 12:39:59,470 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,470 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:39:59,470 - mdp.py - building tree of depth 1
2025-01-28 12:39:59,475 - statistic.py - synthesis initiated, design space: 75
2025-01-28 12:39:59,491 - synthesizer_ar.py - value 0.3455 achieved after 136.16 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 4, family size: 75, quotient: 134 states / 190 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 14

optimum: 0.345468
--------------------
2025-01-28 12:39:59,496 - decision_tree.py - families considered: 14
2025-01-28 12:39:59,496 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:39:59,496 - decision_tree.py - families with schedulers preserved: 4
2025-01-28 12:39:59,496 - decision_tree.py - families model checked: 10
2025-01-28 12:39:59,496 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:39:59,496 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:39:59,496 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:39:59,496 - decision_tree.py - V_0=Y, Y_0=4, A_1=(Down), A_2=(Left)
2025-01-28 12:39:59,497 - decision_tree.py - double-checking specification satisfiability:  : 0.34546806799715335
2025-01-28 12:39:59,497 - decision_tree.py - admissible subtree found from node 32
2025-01-28 12:39:59,497 - decision_tree.py - new tree has depth 12 and 53 nodes
2025-01-28 12:40:00,745 - decision_tree.py - new dtcontrol tree has depth 12 and 56 nodes
2025-01-28 12:40:00,746 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:40:00,747 - decision_tree.py - starting iteration 34 with 4 nodes in node queue
2025-01-28 12:40:00,747 - decision_tree.py - current tree size: 107 nodes
2025-01-28 12:40:00,748 - decision_tree.py - subtree quotient has 132 states and 212 choices
2025-01-28 12:40:00,749 - mdp.py - MDP has 12/132 relevant states
2025-01-28 12:40:00,749 - mdp.py - MDP has 5 actions
2025-01-28 12:40:00,750 - mdp.py - found the following 1 variables: ['X:[0..11]']

2025-01-28 12:40:00,750 - mdp.py - building tree of depth 0
2025-01-28 12:40:00,752 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 132 states / 212 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:40:00,761 - decision_tree.py - families considered: 4
2025-01-28 12:40:00,762 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:40:00,762 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:40:00,762 - decision_tree.py - families model checked: 4
2025-01-28 12:40:00,762 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:40:00,762 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:40:00,762 - mdp.py - building tree of depth 1
2025-01-28 12:40:00,774 - statistic.py - synthesis initiated, design space: 275
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.03 s
number of holes: 4, family size: 275, quotient: 132 states / 212 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 15

optimum: 0.345233
--------------------
2025-01-28 12:40:00,807 - decision_tree.py - families considered: 15
2025-01-28 12:40:00,808 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:40:00,808 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:40:00,808 - decision_tree.py - families model checked: 13
2025-01-28 12:40:00,808 - decision_tree.py - harmonizations attempted: 3
2025-01-28 12:40:00,808 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:40:00,808 - decision_tree.py - no admissible subtree found from node 100
2025-01-28 12:40:00,808 - decision_tree.py - starting iteration 35 with 3 nodes in node queue
2025-01-28 12:40:00,808 - decision_tree.py - current tree size: 107 nodes
2025-01-28 12:40:00,809 - decision_tree.py - subtree quotient has 133 states and 201 choices
2025-01-28 12:40:00,810 - mdp.py - MDP has 8/133 relevant states
2025-01-28 12:40:00,810 - mdp.py - MDP has 5 actions
2025-01-28 12:40:00,811 - mdp.py - found the following 2 variables: ['X:[0..1]', 'Y:[2..6]']

2025-01-28 12:40:00,811 - mdp.py - building tree of depth 0
2025-01-28 12:40:00,813 - statistic.py - synthesis initiated, design space: 5
2025-01-28 12:40:00,819 - synthesizer_ar.py - value 0.3455 achieved after 137.49 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 133 states / 201 actions
explored: 100 %
MDP stats: avg MDP size: 131, iterations: 4

optimum: 0.345466
--------------------
2025-01-28 12:40:00,822 - decision_tree.py - families considered: 4
2025-01-28 12:40:00,822 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:40:00,822 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:40:00,822 - decision_tree.py - families model checked: 4
2025-01-28 12:40:00,822 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:40:00,822 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 12:40:00,822 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:40:00,823 - decision_tree.py - A_0=(Left)
2025-01-28 12:40:00,823 - decision_tree.py - double-checking specification satisfiability:  : 0.3454655468697765

2025-01-28 12:40:00,823 - mdp.py - building tree of depth 1
2025-01-28 12:40:00,837 - statistic.py - synthesis initiated, design space: 200
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 5, family size: 200, quotient: 133 states / 201 actions
explored: 200 %
MDP stats: avg MDP size: 133, iterations: 2

optimum: 0.345466
--------------------
2025-01-28 12:40:00,843 - decision_tree.py - families considered: 2
2025-01-28 12:40:00,843 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:40:00,843 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:40:00,843 - decision_tree.py - families model checked: 2
2025-01-28 12:40:00,843 - decision_tree.py - harmonizations attempted: 0
2025-01-28 12:40:00,843 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:40:00,843 - decision_tree.py - admissible subtree found from node 16
2025-01-28 12:40:00,844 - decision_tree.py - new tree has depth 12 and 51 nodes
2025-01-28 12:40:02,195 - decision_tree.py - new dtcontrol tree has depth 11 and 56 nodes
2025-01-28 12:40:02,195 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:40:02,196 - decision_tree.py - starting iteration 36 with 2 nodes in node queue
2025-01-28 12:40:02,196 - decision_tree.py - current tree size: 103 nodes
2025-01-28 12:40:02,197 - decision_tree.py - subtree quotient has 134 states and 218 choices
2025-01-28 12:40:02,198 - mdp.py - MDP has 12/134 relevant states
2025-01-28 12:40:02,199 - mdp.py - MDP has 5 actions
2025-01-28 12:40:02,199 - mdp.py - found the following 1 variables: ['X:[0..11]']

2025-01-28 12:40:02,199 - mdp.py - building tree of depth 0
2025-01-28 12:40:02,201 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 218 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:40:02,209 - decision_tree.py - families considered: 4
2025-01-28 12:40:02,209 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:40:02,209 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:40:02,209 - decision_tree.py - families model checked: 4
2025-01-28 12:40:02,209 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:40:02,209 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:40:02,209 - mdp.py - building tree of depth 1
2025-01-28 12:40:02,219 - statistic.py - synthesis initiated, design space: 275
2025-01-28 12:40:02,236 - synthesizer_ar.py - value 0.3455 achieved after 138.91 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 4, family size: 275, quotient: 134 states / 218 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 15

optimum: 0.345466
--------------------
2025-01-28 12:40:02,242 - decision_tree.py - families considered: 15
2025-01-28 12:40:02,242 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:40:02,242 - decision_tree.py - families with schedulers preserved: 4
2025-01-28 12:40:02,242 - decision_tree.py - families model checked: 11
2025-01-28 12:40:02,242 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:40:02,242 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:40:02,242 - decision_tree.py - printing synthesized assignment below:
2025-01-28 12:40:02,242 - decision_tree.py - V_0=X, X_0=8, A_1=(Right), A_2=(Left)
2025-01-28 12:40:02,243 - decision_tree.py - double-checking specification satisfiability:  : 0.3454655468697765
2025-01-28 12:40:02,243 - decision_tree.py - admissible subtree found from node 1
2025-01-28 12:40:02,243 - decision_tree.py - new tree has depth 12 and 50 nodes
2025-01-28 12:40:03,583 - decision_tree.py - new dtcontrol tree has depth 11 and 55 nodes
2025-01-28 12:40:03,584 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 12:40:03,584 - decision_tree.py - starting iteration 37 with 1 nodes in node queue
2025-01-28 12:40:03,584 - decision_tree.py - current tree size: 101 nodes
2025-01-28 12:40:03,586 - decision_tree.py - subtree quotient has 134 states and 214 choices
2025-01-28 12:40:03,587 - mdp.py - MDP has 11/134 relevant states
2025-01-28 12:40:03,587 - mdp.py - MDP has 5 actions
2025-01-28 12:40:03,588 - mdp.py - found the following 2 variables: ['X:[8..11]', 'Y:[1..3]']

2025-01-28 12:40:03,588 - mdp.py - building tree of depth 0
2025-01-28 12:40:03,590 - statistic.py - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 134 states / 214 actions
explored: 100 %
MDP stats: avg MDP size: 132, iterations: 4

optimum: 0.345233
--------------------
2025-01-28 12:40:03,600 - decision_tree.py - families considered: 4
2025-01-28 12:40:03,600 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:40:03,600 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 12:40:03,600 - decision_tree.py - families model checked: 4
2025-01-28 12:40:03,600 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:40:03,600 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 12:40:03,600 - mdp.py - building tree of depth 1
2025-01-28 12:40:03,608 - statistic.py - synthesis initiated, design space: 300
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.02 s
number of holes: 5, family size: 300, quotient: 134 states / 214 actions
explored: 100 %
MDP stats: avg MDP size: 134, iterations: 9

optimum: 0.345233
--------------------
2025-01-28 12:40:03,627 - decision_tree.py - families considered: 9
2025-01-28 12:40:03,627 - decision_tree.py - families skipped by construction: 0
2025-01-28 12:40:03,627 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 12:40:03,627 - decision_tree.py - families model checked: 7
2025-01-28 12:40:03,627 - decision_tree.py - harmonizations attempted: 1
2025-01-28 12:40:03,627 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 12:40:03,628 - decision_tree.py - no admissible subtree found from node 63
2025-01-28 12:40:03,628 - decision_tree.py - tree did not induce dtmc?
2025-01-28 12:40:03,629 - decision_tree.py - final tree has value 0.3454655468697765 with depth 12 and 50 nodes
0.3454655468697765 140.28 12 50
2025-01-28 12:40:03,630 - decision_tree.py - the optimal scheduler has value: 0.34872056868406615
2025-01-28 12:40:03,630 - decision_tree.py - the random scheduler has value: 0.0001721308046831764
2025-01-28 12:40:03,630 - decision_tree.py - synthesized tree of depth 12 with 50 decision nodes
2025-01-28 12:40:03,630 - decision_tree.py - the synthesized tree has value 0.3454655468697765
2025-01-28 12:40:03,630 - decision_tree.py - the synthesized tree has relative value: 0.9906612067060359
2025-01-28 12:40:03,630 - decision_tree.py - printing the synthesized tree below:
2025-01-28 12:40:03,630 - decision_tree.py - dtcontrol calls: 25
2025-01-28 12:40:03,630 - decision_tree.py - dtcontrol successes: 2
2025-01-28 12:40:03,630 - decision_tree.py - paynt calls: 38
2025-01-28 12:40:03,630 - decision_tree.py - paynt successes smaller: 6
2025-01-28 12:40:03,630 - decision_tree.py - paynt tree found: 25
2025-01-28 12:40:03,630 - decision_tree.py - both larger: 17
2025-01-28 12:40:03,633 - decision_tree.py - exported decision tree to logs/01-28-initial/integration/omdt-frozenlake_12x12/tree.dot
2025-01-28 12:40:03,820 - decision_tree.py - exported decision tree visualization to logs/01-28-initial/integration/omdt-frozenlake_12x12/tree.png
2025-01-28 12:40:03,820 - decision_tree.py - synthesis finished after 140.49 seconds

--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.036.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.032.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.032.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.032.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.035.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.030.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.032.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.031.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.030.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.030.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.032.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.035.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.030.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.032.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.036.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.031.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.031.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.030.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.037.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.030.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.029.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.033.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.029.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.029.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.031.
All benchmarks completed. Shutting down dtControl.
