2025-01-28 13:04:11,795 - cli.py - This is Paynt version 0.1.0.
2025-01-28 13:04:11,795 - sketch.py - loading sketch from /home/fpmk/synthesis-playground/models/dts-backup/qcomp/wlan-1-2/model-random-enabled.drn ...
2025-01-28 13:04:11,795 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-28 13:04:11,981 - sketch.py - assuming sketch in DRN format...
2025-01-28 13:04:12,338 - prism_parser.py - loading properties from /home/fpmk/synthesis-playground/models/dts-backup/qcomp/wlan-1-2/discounted.props ...
2025-01-28 13:04:12,339 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-28 13:04:12,356 - sketch.py - found state valuations in /home/fpmk/synthesis-playground/models/dts-backup/qcomp/wlan-1-2/state-valuations.json, adding to the model...
2025-01-28 13:04:12,363 - sketch.py - sketch parsing OK
2025-01-28 13:04:12,367 - sketch.py - tree helper loaded
2025-01-28 13:04:12,559 - sketch.py - constructed explicit quotient having 3127 states and 106318 choices
2025-01-28 13:04:12,559 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-28 13:04:12,569 - mdp.py - MDP has 3124/3127 relevant states
2025-01-28 13:04:13,198 - mdp.py - MDP has 34 actions
2025-01-28 13:04:13,224 - mdp.py - found the following 11 variables: ['backoff1:[0..15]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..2]', 'c2:[0..2]', 'col:[0..2]', 's1:[1..12]', 's2:[1..12]', 'x1:[0..10]', 'x2:[0..10]']
2025-01-28 13:04:13,247 - decision_tree.py - the optimal scheduler has value: 0.10827098374814313
2025-01-28 13:04:13,252 - decision_tree.py - the random scheduler has value: 0.02730039610596835
2025-01-28 13:04:13,253 - decision_tree.py - initial external tree has depth 11 and 68 nodes
2025-01-28 13:04:13,253 - decision_tree.py - starting iteration with subtree depth 7
2025-01-28 13:04:13,256 - decision_tree.py - starting iteration 0 with 3 nodes in node queue
2025-01-28 13:04:13,256 - decision_tree.py - current tree size: 137 nodes
2025-01-28 13:04:13,427 - decision_tree.py - subtree quotient has 1607 states and 6293 choices
2025-01-28 13:04:13,431 - mdp.py - MDP has 140/1607 relevant states
2025-01-28 13:04:13,465 - mdp.py - MDP has 34 actions
2025-01-28 13:04:13,477 - mdp.py - found the following 8 variables: ['backoff1:[0..13]', 'backoff2:[0..14]', 'bc1:[0..1]', 'bc2:[0..1]', 'c2:[0..1]', 'col:[0..1]', 's1:[7..12]', 's2:[5..12]']

2025-01-28 13:04:13,477 - mdp.py - building tree of depth 0
2025-01-28 13:04:13,484 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.06 s
number of holes: 1, family size: 34, quotient: 1607 states / 6293 actions
explored: 100 %
MDP stats: avg MDP size: 1562, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:04:13,540 - decision_tree.py - families considered: 4
2025-01-28 13:04:13,540 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:13,540 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:04:13,540 - decision_tree.py - families model checked: 4
2025-01-28 13:04:13,540 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:04:13,540 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:04:13,540 - mdp.py - building tree of depth 1
2025-01-28 13:04:13,562 - statistic.py - synthesis initiated, design space: 1e7
2025-01-28 13:04:13,748 - synthesizer_ar.py - value 0.1079 achieved after 1.95 seconds
2025-01-28 13:04:14,530 - synthesizer_ar.py - value 0.1083 achieved after 2.74 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.22 s
number of holes: 11, family size: 1e7, quotient: 1607 states / 6293 actions
explored: 100 %
MDP stats: avg MDP size: 1573, iterations: 59

optimum: 0.108271
--------------------
2025-01-28 13:04:14,782 - decision_tree.py - families considered: 59
2025-01-28 13:04:14,782 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:14,782 - decision_tree.py - families with schedulers preserved: 11
2025-01-28 13:04:14,782 - decision_tree.py - families model checked: 48
2025-01-28 13:04:14,782 - decision_tree.py - harmonizations attempted: 10
2025-01-28 13:04:14,782 - decision_tree.py - harmonizations succeeded: 2

2025-01-28 13:04:14,782 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:04:14,782 - decision_tree.py - V_0=s2, backoff1_0=0, backoff2_0=0, bc1_0=0, bc2_0=0, c2_0=0, col_0=0, s1_0=7, s2_0=7, A_1=time, A_2=send1
2025-01-28 13:04:14,784 - decision_tree.py - double-checking specification satisfiability:  : 0.10827098374814313
2025-01-28 13:04:14,784 - decision_tree.py - admissible subtree found from node 23
2025-01-28 13:04:14,784 - decision_tree.py - new tree has depth 9 and 56 nodes
2025-01-28 13:04:16,561 - decision_tree.py - new dtcontrol tree has depth 9 and 61 nodes
2025-01-28 13:04:16,561 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 13:04:16,562 - decision_tree.py - starting iteration 1 with 2 nodes in node queue
2025-01-28 13:04:16,563 - decision_tree.py - current tree size: 113 nodes
2025-01-28 13:04:16,788 - decision_tree.py - subtree quotient has 2134 states and 26653 choices
2025-01-28 13:04:16,797 - mdp.py - MDP has 740/2134 relevant states
2025-01-28 13:04:16,966 - mdp.py - MDP has 34 actions
2025-01-28 13:04:17,002 - mdp.py - found the following 10 variables: ['backoff1:[0..15]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..1]', 'c2:[0..2]', 'col:[0..1]', 's1:[2..12]', 's2:[1..11]', 'x2:[1..10]']

2025-01-28 13:04:17,002 - mdp.py - building tree of depth 0
2025-01-28 13:04:17,022 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.09 s
number of holes: 1, family size: 34, quotient: 2134 states / 26653 actions
explored: 100 %
MDP stats: avg MDP size: 2032, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:04:17,116 - decision_tree.py - families considered: 4
2025-01-28 13:04:17,116 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:17,116 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:04:17,116 - decision_tree.py - families model checked: 4
2025-01-28 13:04:17,116 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:04:17,116 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:04:17,117 - mdp.py - building tree of depth 1
2025-01-28 13:04:17,210 - statistic.py - synthesis initiated, design space: 1e9
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.42 s
number of holes: 13, family size: 1e9, quotient: 2134 states / 26653 actions
explored: 100 %
MDP stats: avg MDP size: 2044, iterations: 65

optimum: 0.107188
--------------------
2025-01-28 13:04:19,626 - decision_tree.py - families considered: 65
2025-01-28 13:04:19,627 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:19,627 - decision_tree.py - families with schedulers preserved: 21
2025-01-28 13:04:19,627 - decision_tree.py - families model checked: 44
2025-01-28 13:04:19,627 - decision_tree.py - harmonizations attempted: 2
2025-01-28 13:04:19,627 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:04:19,627 - mdp.py - building tree of depth 2
2025-01-28 13:04:19,887 - statistic.py - synthesis initiated, design space: 1e25
> progress 0.436%, elapsed 3 s, estimated 687 s, iters = {MDP: 60}, opt = 0.1072
2025-01-28 13:04:24,945 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.06 s
number of holes: 37, family size: 1e25, quotient: 2134 states / 26653 actions
explored: 0 %
MDP stats: avg MDP size: 2030, iterations: 102

optimum: 0.107188
--------------------
2025-01-28 13:04:24,945 - decision_tree.py - families considered: 102
2025-01-28 13:04:24,945 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:24,945 - decision_tree.py - families with schedulers preserved: 35
2025-01-28 13:04:24,945 - decision_tree.py - families model checked: 67
2025-01-28 13:04:24,945 - decision_tree.py - harmonizations attempted: 7
2025-01-28 13:04:24,945 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:04:24,945 - mdp.py - building tree of depth 3
2025-01-28 13:04:25,466 - statistic.py - synthesis initiated, design space: 1e57
> progress 0.0%, elapsed 3 s, estimated 2501577 s (28 days), iters = {MDP: 33}, opt = 0.1072
2025-01-28 13:04:30,544 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.08 s
number of holes: 85, family size: 1e57, quotient: 2134 states / 26653 actions
explored: 0 %
MDP stats: avg MDP size: 2047, iterations: 58

optimum: 0.107188
--------------------
2025-01-28 13:04:30,545 - decision_tree.py - families considered: 58
2025-01-28 13:04:30,545 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:30,545 - decision_tree.py - families with schedulers preserved: 25
2025-01-28 13:04:30,545 - decision_tree.py - families model checked: 33
2025-01-28 13:04:30,545 - decision_tree.py - harmonizations attempted: 3
2025-01-28 13:04:30,545 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:04:30,546 - mdp.py - building tree of depth 4
2025-01-28 13:04:31,828 - statistic.py - synthesis initiated, design space: 1e120
2025-01-28 13:04:40,127 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 8.3 s
number of holes: 181, family size: 1e120, quotient: 2134 states / 26653 actions
explored: 0 %
MDP stats: avg MDP size: 2134, iterations: 1

optimum: 0.107188
--------------------
2025-01-28 13:04:40,127 - decision_tree.py - families considered: 1
2025-01-28 13:04:40,127 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:40,127 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:04:40,127 - decision_tree.py - families model checked: 1
2025-01-28 13:04:40,128 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:04:40,128 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:04:40,128 - mdp.py - building tree of depth 5
2025-01-28 13:04:44,004 - statistic.py - synthesis initiated, design space: 1e247
2025-01-28 13:04:48,631 - synthesizer_ar.py - value 0.1083 achieved after 36.84 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 4.63 s
number of holes: 373, family size: 1e247, quotient: 2134 states / 26653 actions
explored: 100 %
MDP stats: avg MDP size: 2134, iterations: 1

optimum: 0.108271
--------------------
2025-01-28 13:04:48,631 - decision_tree.py - families considered: 1
2025-01-28 13:04:48,631 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:48,631 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:04:48,631 - decision_tree.py - families model checked: 1
2025-01-28 13:04:48,631 - decision_tree.py - harmonizations attempted: 0
2025-01-28 13:04:48,631 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:04:48,631 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:04:48,631 - decision_tree.py - V_0=bc2, backoff1_0=1, backoff2_0=13, bc1_0=0, bc2_0=0, c1_0=0, c2_0=0, col_0=0, s1_0=4, s2_0=8, x2_0=2, V_1=backoff2, backoff1_1=0, backoff2_1=3, bc1_1=0, bc2_1=0, c1_1=0, c2_1=0, col_1=0, s1_1=3, s2_1=3, x2_1=1, V_2=bc1, backoff1_2=1, backoff2_2=0, bc1_2=0, bc2_2=0, c1_2=0, c2_2=0, col_2=0, s1_2=6, s2_2=1, x2_2=1, V_3=c2, backoff1_3=1, backoff2_3=0, bc1_3=0, bc2_3=0, c1_3=0, c2_3=0, col_3=0, s1_3=4, s2_3=1, x2_3=1, V_4=x2, backoff1_4=0, backoff2_4=0, bc1_4=0, bc2_4=0, c1_4=0, c2_4=0, col_4=0, s1_4=4, s2_4=5, x2_4=2, A_5=station2_cmd_42, A_6=station2_cmd_74, V_7=col, backoff1_7=0, backoff2_7=0, bc1_7=0, bc2_7=0, c1_7=0, c2_7=0, col_7=0, s1_7=4, s2_7=1, x2_7=1, A_8=send1, A_9=finish2, V_10=backoff1, backoff1_10=1, backoff2_10=0, bc1_10=0, bc2_10=0, c1_10=0, c2_10=1, col_10=0, s1_10=3, s2_10=7, x2_10=2, V_11=s1, backoff1_11=1, backoff2_11=13, bc1_11=0, bc2_11=0, c1_11=0, c2_11=0, col_11=0, s1_11=4, s2_11=7, x2_11=2, A_12=station1_cmd_15, A_13=station2_cmd_48, V_14=x2, backoff1_14=1, backoff2_14=0, bc1_14=0, bc2_14=0, c1_14=0, c2_14=0, col_14=0, s1_14=5, s2_14=8, x2_14=2, A_15=time, A_16=station2_cmd_48, V_17=col, backoff1_17=0, backoff2_17=13, bc1_17=0, bc2_17=0, c1_17=0, c2_17=0, col_17=0, s1_17=5, s2_17=5, x2_17=2, V_18=col, backoff1_18=1, backoff2_18=0, bc1_18=0, bc2_18=0, c1_18=0, c2_18=0, col_18=0, s1_18=4, s2_18=5, x2_18=1, V_19=c1, backoff1_19=0, backoff2_19=0, bc1_19=0, bc2_19=0, c1_19=0, c2_19=0, col_19=0, s1_19=6, s2_19=10, x2_19=1, A_20=__random__, A_21=finish1, V_22=col, backoff1_22=0, backoff2_22=0, bc1_22=0, bc2_22=0, c1_22=0, c2_22=0, col_22=0, s1_22=10, s2_22=1, x2_22=1, A_23=finish2, A_24=station1_cmd_8, V_25=backoff2, backoff1_25=0, backoff2_25=0, bc1_25=0, bc2_25=0, c1_25=0, c2_25=0, col_25=0, s1_25=5, s2_25=5, x2_25=1, V_26=col, backoff1_26=0, backoff2_26=1, bc1_26=0, bc2_26=0, c1_26=0, c2_26=0, col_26=0, s1_26=8, s2_26=1, x2_26=1, A_27=station2_cmd_50, A_28=station2_cmd_74, V_29=backoff1, backoff1_29=0, backoff2_29=0, bc1_29=0, bc2_29=0, c1_29=0, c2_29=0, col_29=0, s1_29=10, s2_29=1, x2_29=1, A_30=station1_cmd_20, A_31=station2_cmd_42, V_32=s2, backoff1_32=0, backoff2_32=0, bc1_32=0, bc2_32=0, c1_32=0, c2_32=1, col_32=0, s1_32=11, s2_32=7, x2_32=2, V_33=s1, backoff1_33=0, backoff2_33=0, bc1_33=0, bc2_33=0, c1_33=0, c2_33=0, col_33=0, s1_33=10, s2_33=3, x2_33=1, V_34=backoff2, backoff1_34=2, backoff2_34=0, bc1_34=0, bc2_34=0, c1_34=0, c2_34=1, col_34=0, s1_34=4, s2_34=3, x2_34=1, V_35=s1, backoff1_35=1, backoff2_35=0, bc1_35=0, bc2_35=0, c1_35=0, c2_35=0, col_35=0, s1_35=8, s2_35=1, x2_35=1, A_36=station2_cmd_54, A_37=station2_cmd_60, V_38=s2, backoff1_38=0, backoff2_38=0, bc1_38=0, bc2_38=0, c1_38=0, c2_38=0, col_38=0, s1_38=4, s2_38=5, x2_38=1, A_39=station2_cmd_52, A_40=station2_cmd_60, V_41=s2, backoff1_41=1, backoff2_41=0, bc1_41=0, bc2_41=0, c1_41=0, c2_41=0, col_41=0, s1_41=10, s2_41=5, x2_41=1, V_42=backoff2, backoff1_42=0, backoff2_42=0, bc1_42=0, bc2_42=0, c1_42=0, c2_42=0, col_42=0, s1_42=10, s2_42=3, x2_42=1, A_43=station2_cmd_54, A_44=station2_cmd_52, V_45=x2, backoff1_45=1, backoff2_45=0, bc1_45=0, bc2_45=0, c1_45=0, c2_45=0, col_45=0, s1_45=9, s2_45=5, x2_45=1, A_46=time, A_47=station2_cmd_59, V_48=c2, backoff1_48=0, backoff2_48=0, bc1_48=0, bc2_48=0, c1_48=0, c2_48=0, col_48=0, s1_48=9, s2_48=10, x2_48=2, V_49=backoff2, backoff1_49=2, backoff2_49=0, bc1_49=0, bc2_49=0, c1_49=0, c2_49=0, col_49=0, s1_49=8, s2_49=5, x2_49=1, V_50=s1, backoff1_50=0, backoff2_50=0, bc1_50=0, bc2_50=0, c1_50=0, c2_50=0, col_50=0, s1_50=8, s2_50=9, x2_50=1, A_51=send1, A_52=send2, V_53=s1, backoff1_53=1, backoff2_53=0, bc1_53=0, bc2_53=0, c1_53=0, c2_53=1, col_53=0, s1_53=6, s2_53=10, x2_53=3, A_54=station1_cmd_39, A_55=station2_cmd_42, V_56=s2, backoff1_56=0, backoff2_56=1, bc1_56=0, bc2_56=0, c1_56=0, c2_56=0, col_56=0, s1_56=5, s2_56=9, x2_56=3, V_57=x2, backoff1_57=3, backoff2_57=0, bc1_57=0, bc2_57=0, c1_57=0, c2_57=0, col_57=0, s1_57=11, s2_57=9, x2_57=3, A_58=time, A_59=finish2, V_60=x2, backoff1_60=13, backoff2_60=0, bc1_60=0, bc2_60=0, c1_60=0, c2_60=0, col_60=0, s1_60=2, s2_60=9, x2_60=2, A_61=time, A_62=finish2
2025-01-28 13:04:48,647 - decision_tree.py - double-checking specification satisfiability:  : 0.10827098374814313
2025-01-28 13:04:48,648 - decision_tree.py - admissible subtree found from node 37
2025-01-28 13:04:48,648 - decision_tree.py - new tree has depth 9 and 61 nodes
2025-01-28 13:04:50,449 - decision_tree.py - new dtcontrol tree has depth 9 and 58 nodes
2025-01-28 13:04:50,449 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 13:04:50,450 - decision_tree.py - starting iteration 2 with 1 nodes in node queue
2025-01-28 13:04:50,450 - decision_tree.py - current tree size: 113 nodes
2025-01-28 13:04:50,673 - decision_tree.py - subtree quotient has 2539 states and 44614 choices
2025-01-28 13:04:50,683 - mdp.py - MDP has 1272/2539 relevant states
2025-01-28 13:04:50,967 - mdp.py - MDP has 34 actions
2025-01-28 13:04:50,992 - mdp.py - found the following 11 variables: ['backoff1:[0..15]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..2]', 'c2:[0..2]', 'col:[0..1]', 's1:[1..11]', 's2:[1..12]', 'x1:[1..10]', 'x2:[0..10]']

2025-01-28 13:04:50,992 - mdp.py - building tree of depth 0
2025-01-28 13:04:51,027 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.11 s
number of holes: 1, family size: 34, quotient: 2539 states / 44614 actions
explored: 100 %
MDP stats: avg MDP size: 2458, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:04:51,142 - decision_tree.py - families considered: 4
2025-01-28 13:04:51,142 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:51,142 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:04:51,142 - decision_tree.py - families model checked: 4
2025-01-28 13:04:51,142 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:04:51,142 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:04:51,142 - mdp.py - building tree of depth 1
2025-01-28 13:04:51,326 - statistic.py - synthesis initiated, design space: 1e10
> progress 40.641%, elapsed 3 s, estimated 7 s, iters = {MDP: 66}, opt = 0.1072
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 3.09 s
number of holes: 14, family size: 1e10, quotient: 2539 states / 44614 actions
explored: 100 %
MDP stats: avg MDP size: 2453, iterations: 70

optimum: 0.107188
--------------------
2025-01-28 13:04:54,420 - decision_tree.py - families considered: 70
2025-01-28 13:04:54,420 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:04:54,420 - decision_tree.py - families with schedulers preserved: 14
2025-01-28 13:04:54,421 - decision_tree.py - families model checked: 56
2025-01-28 13:04:54,421 - decision_tree.py - harmonizations attempted: 10
2025-01-28 13:04:54,421 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:04:54,421 - mdp.py - building tree of depth 2
2025-01-28 13:04:54,888 - statistic.py - synthesis initiated, design space: 1e29
> progress 0.0%, elapsed 3 s, estimated 459330 s (5 days), iters = {MDP: 41}, opt = 0.1072
2025-01-28 13:05:00,005 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.12 s
number of holes: 40, family size: 1e29, quotient: 2539 states / 44614 actions
explored: 0 %
MDP stats: avg MDP size: 2318, iterations: 71

optimum: 0.107188
--------------------
2025-01-28 13:05:00,005 - decision_tree.py - families considered: 71
2025-01-28 13:05:00,005 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:05:00,005 - decision_tree.py - families with schedulers preserved: 16
2025-01-28 13:05:00,005 - decision_tree.py - families model checked: 55
2025-01-28 13:05:00,006 - decision_tree.py - harmonizations attempted: 17
2025-01-28 13:05:00,006 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:05:00,006 - mdp.py - building tree of depth 3
2025-01-28 13:05:01,012 - statistic.py - synthesis initiated, design space: 1e67
> progress 0.001%, elapsed 3 s, estimated 153828 s (42 hours), iters = {MDP: 17}, opt = 0.1072
2025-01-28 13:05:06,065 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.05 s
number of holes: 92, family size: 1e67, quotient: 2539 states / 44614 actions
explored: 0 %
MDP stats: avg MDP size: 2456, iterations: 39

optimum: 0.107188
--------------------
2025-01-28 13:05:06,066 - decision_tree.py - families considered: 39
2025-01-28 13:05:06,066 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:05:06,066 - decision_tree.py - families with schedulers preserved: 15
2025-01-28 13:05:06,066 - decision_tree.py - families model checked: 24
2025-01-28 13:05:06,066 - decision_tree.py - harmonizations attempted: 7
2025-01-28 13:05:06,066 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:05:06,066 - mdp.py - building tree of depth 4
2025-01-28 13:05:08,391 - statistic.py - synthesis initiated, design space: 1e142
> progress 0.0%, elapsed 3 s, estimated 3937163 s (45 days), iters = {MDP: 2}, opt = 0.1072
2025-01-28 13:05:13,772 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 5.38 s
number of holes: 196, family size: 1e142, quotient: 2539 states / 44614 actions
explored: 0 %
MDP stats: avg MDP size: 2539, iterations: 3

optimum: 0.107188
--------------------
2025-01-28 13:05:13,773 - decision_tree.py - families considered: 3
2025-01-28 13:05:13,773 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:05:13,773 - decision_tree.py - families with schedulers preserved: 2
2025-01-28 13:05:13,773 - decision_tree.py - families model checked: 1
2025-01-28 13:05:13,773 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:05:13,773 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:05:13,773 - mdp.py - building tree of depth 5
2025-01-28 13:05:18,920 - statistic.py - synthesis initiated, design space: 1e291
2025-01-28 13:05:45,795 - synthesizer_ar.py - value 0.1083 achieved after 94.0 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 26.88 s
number of holes: 404, family size: 1e291, quotient: 2539 states / 44614 actions
explored: 100 %
MDP stats: avg MDP size: 2539, iterations: 1

optimum: 0.108271
--------------------
2025-01-28 13:05:45,796 - decision_tree.py - families considered: 1
2025-01-28 13:05:45,796 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:05:45,796 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:05:45,796 - decision_tree.py - families model checked: 1
2025-01-28 13:05:45,796 - decision_tree.py - harmonizations attempted: 0
2025-01-28 13:05:45,796 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:05:45,796 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:05:45,796 - decision_tree.py - V_0=backoff1, backoff1_0=0, backoff2_0=3, bc1_0=0, bc2_0=0, c1_0=0, c2_0=0, col_0=0, s1_0=5, s2_0=6, x1_0=1, x2_0=0, V_1=s2, backoff1_1=12, backoff2_1=0, bc1_1=0, bc2_1=0, c1_1=0, c2_1=0, col_1=0, s1_1=9, s2_1=5, x1_1=4, x2_1=1, V_2=s1, backoff1_2=2, backoff2_2=13, bc1_2=0, bc2_2=0, c1_2=0, c2_2=1, col_2=0, s1_2=7, s2_2=4, x1_2=1, x2_2=1, V_3=x1, backoff1_3=12, backoff2_3=6, bc1_3=0, bc2_3=0, c1_3=0, c2_3=0, col_3=0, s1_3=5, s2_3=11, x1_3=1, x2_3=1, V_4=bc1, backoff1_4=0, backoff2_4=0, bc1_4=0, bc2_4=0, c1_4=0, c2_4=0, col_4=0, s1_4=5, s2_4=4, x1_4=1, x2_4=0, A_5=time, A_6=station1_cmd_19, V_7=s1, backoff1_7=14, backoff2_7=0, bc1_7=0, bc2_7=0, c1_7=0, c2_7=0, col_7=0, s1_7=1, s2_7=4, x1_7=1, x2_7=0, A_8=station1_cmd_7, A_9=station1_cmd_13, V_10=x2, backoff1_10=8, backoff2_10=12, bc1_10=0, bc2_10=0, c1_10=0, c2_10=0, col_10=0, s1_10=9, s2_10=9, x1_10=2, x2_10=0, V_11=col, backoff1_11=6, backoff2_11=0, bc1_11=0, bc2_11=0, c1_11=0, c2_11=0, col_11=0, s1_11=8, s2_11=4, x1_11=3, x2_11=0, A_12=station1_cmd_7, A_13=send1, V_14=backoff2, backoff1_14=11, backoff2_14=0, bc1_14=0, bc2_14=0, c1_14=0, c2_14=0, col_14=0, s1_14=3, s2_14=4, x1_14=2, x2_14=5, A_15=station2_cmd_54, A_16=station2_cmd_52, V_17=c1, backoff1_17=12, backoff2_17=4, bc1_17=0, bc2_17=0, c1_17=0, c2_17=0, col_17=0, s1_17=7, s2_17=4, x1_17=1, x2_17=0, V_18=bc1, backoff1_18=14, backoff2_18=1, bc1_18=0, bc2_18=0, c1_18=0, c2_18=0, col_18=0, s1_18=5, s2_18=5, x1_18=1, x2_18=1, V_19=x2, backoff1_19=0, backoff2_19=13, bc1_19=0, bc2_19=0, c1_19=0, c2_19=0, col_19=0, s1_19=5, s2_19=4, x1_19=1, x2_19=5, A_20=time, A_21=station1_cmd_39, V_22=s1, backoff1_22=6, backoff2_22=0, bc1_22=0, bc2_22=0, c1_22=1, c2_22=0, col_22=0, s1_22=5, s2_22=4, x1_22=1, x2_22=1, A_23=station1_cmd_19, A_24=send1, V_25=s1, backoff1_25=11, backoff2_25=4, bc1_25=0, bc2_25=0, c1_25=0, c2_25=0, col_25=0, s1_25=9, s2_25=4, x1_25=1, x2_25=1, V_26=x1, backoff1_26=14, backoff2_26=0, bc1_26=0, bc2_26=0, c1_26=0, c2_26=0, col_26=0, s1_26=5, s2_26=5, x1_26=3, x2_26=1, A_27=time, A_28=finish1, V_29=x1, backoff1_29=11, backoff2_29=0, bc1_29=0, bc2_29=0, c1_29=1, c2_29=0, col_29=0, s1_29=3, s2_29=5, x1_29=2, x2_29=5, A_30=time, A_31=finish1, V_32=s2, backoff1_32=0, backoff2_32=0, bc1_32=0, bc2_32=0, c1_32=0, c2_32=0, col_32=0, s1_32=5, s2_32=4, x1_32=1, x2_32=0, V_33=x2, backoff1_33=0, backoff2_33=4, bc1_33=0, bc2_33=0, c1_33=0, c2_33=1, col_33=0, s1_33=8, s2_33=3, x1_33=1, x2_33=2, V_34=backoff1, backoff1_34=14, backoff2_34=0, bc1_34=0, bc2_34=0, c1_34=0, c2_34=0, col_34=0, s1_34=3, s2_34=10, x1_34=1, x2_34=0, V_35=backoff1, backoff1_35=12, backoff2_35=0, bc1_35=0, bc2_35=0, c1_35=0, c2_35=0, col_35=0, s1_35=7, s2_35=4, x1_35=3, x2_35=3, A_36=station2_cmd_50, A_37=__random__, V_38=x2, backoff1_38=11, backoff2_38=0, bc1_38=0, bc2_38=0, c1_38=0, c2_38=0, col_38=0, s1_38=3, s2_38=4, x1_38=1, x2_38=0, A_39=station2_cmd_50, A_40=station2_cmd_52, V_41=backoff1, backoff1_41=8, backoff2_41=10, bc1_41=0, bc2_41=0, c1_41=0, c2_41=0, col_41=0, s1_41=9, s2_41=6, x1_41=2, x2_41=2, V_42=backoff1, backoff1_42=6, backoff2_42=0, bc1_42=0, bc2_42=0, c1_42=0, c2_42=0, col_42=0, s1_42=5, s2_42=4, x1_42=3, x2_42=0, A_43=station1_cmd_17, A_44=station2_cmd_48, V_45=backoff1, backoff1_45=11, backoff2_45=0, bc1_45=0, bc2_45=0, c1_45=1, c2_45=0, col_45=0, s1_45=3, s2_45=4, x1_45=2, x2_45=0, A_46=station1_cmd_17, A_47=station2_cmd_48, V_48=s1, backoff1_48=0, backoff2_48=0, bc1_48=0, bc2_48=0, c1_48=0, c2_48=1, col_48=0, s1_48=5, s2_48=10, x1_48=3, x2_48=1, V_49=s1, backoff1_49=14, backoff2_49=0, bc1_49=0, bc2_49=0, c1_49=0, c2_49=0, col_49=0, s1_49=3, s2_49=7, x1_49=2, x2_49=0, V_50=x2, backoff1_50=1, backoff2_50=0, bc1_50=0, bc2_50=0, c1_50=0, c2_50=0, col_50=0, s1_50=5, s2_50=7, x1_50=5, x2_50=1, A_51=station2_cmd_45, A_52=station1_cmd_7, V_53=col, backoff1_53=0, backoff2_53=0, bc1_53=0, bc2_53=0, c1_53=0, c2_53=0, col_53=0, s1_53=3, s2_53=4, x1_53=2, x2_53=5, A_54=station2_cmd_55, A_55=station1_cmd_17, V_56=bc2, backoff1_56=13, backoff2_56=3, bc1_56=0, bc2_56=0, c1_56=0, c2_56=1, col_56=0, s1_56=5, s2_56=6, x1_56=1, x2_56=0, V_57=x1, backoff1_57=14, backoff2_57=0, bc1_57=0, bc2_57=0, c1_57=0, c2_57=0, col_57=0, s1_57=5, s2_57=6, x1_57=1, x2_57=5, A_58=time, A_59=station1_cmd_24, V_60=c2, backoff1_60=11, backoff2_60=0, bc1_60=0, bc2_60=0, c1_60=1, c2_60=0, col_60=0, s1_60=7, s2_60=5, x1_60=1, x2_60=3, A_61=send2, A_62=station1_cmd_25
2025-01-28 13:05:45,818 - decision_tree.py - double-checking specification satisfiability:  : 0.10827098374814313
2025-01-28 13:05:45,819 - decision_tree.py - admissible subtree found from node 68
2025-01-28 13:05:45,820 - decision_tree.py - new tree has depth 9 and 62 nodes
2025-01-28 13:05:48,131 - decision_tree.py - new dtcontrol tree has depth 9 and 62 nodes
2025-01-28 13:05:48,131 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 13:05:48,133 - decision_tree.py - starting iteration with subtree depth 6
2025-01-28 13:05:48,137 - decision_tree.py - starting iteration 3 with 3 nodes in node queue
2025-01-28 13:05:48,137 - decision_tree.py - current tree size: 113 nodes
2025-01-28 13:05:48,434 - decision_tree.py - subtree quotient has 1868 states and 9425 choices
2025-01-28 13:05:48,441 - mdp.py - MDP has 227/1868 relevant states
2025-01-28 13:05:48,495 - mdp.py - MDP has 34 actions
2025-01-28 13:05:48,511 - mdp.py - found the following 9 variables: ['backoff1:[0..13]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..2]', 'c2:[0..2]', 'col:[0..2]', 's1:[7..12]', 's2:[2..12]']

2025-01-28 13:05:48,511 - mdp.py - building tree of depth 0
2025-01-28 13:05:48,522 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.08 s
number of holes: 1, family size: 34, quotient: 1868 states / 9425 actions
explored: 100 %
MDP stats: avg MDP size: 1766, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:05:48,600 - decision_tree.py - families considered: 4
2025-01-28 13:05:48,600 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:05:48,600 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:05:48,600 - decision_tree.py - families model checked: 4
2025-01-28 13:05:48,600 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:05:48,600 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:05:48,600 - mdp.py - building tree of depth 1
2025-01-28 13:05:48,636 - statistic.py - synthesis initiated, design space: 1e8
2025-01-28 13:05:49,295 - synthesizer_ar.py - value 0.1075 achieved after 97.5 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.35 s
number of holes: 12, family size: 1e8, quotient: 1868 states / 9425 actions
explored: 100 %
MDP stats: avg MDP size: 1726, iterations: 81

optimum: 0.107545
--------------------
2025-01-28 13:05:50,985 - decision_tree.py - families considered: 81
2025-01-28 13:05:50,985 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:05:50,985 - decision_tree.py - families with schedulers preserved: 18
2025-01-28 13:05:50,985 - decision_tree.py - families model checked: 63
2025-01-28 13:05:50,985 - decision_tree.py - harmonizations attempted: 11
2025-01-28 13:05:50,985 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 13:05:50,985 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:05:50,986 - decision_tree.py - V_0=s2, backoff1_0=0, backoff2_0=0, bc1_0=0, bc2_0=0, c1_0=0, c2_0=0, col_0=0, s1_0=7, s2_0=5, A_1=time, A_2=send2
2025-01-28 13:05:50,988 - decision_tree.py - double-checking specification satisfiability:  : 0.10754468367727653

2025-01-28 13:05:50,989 - mdp.py - building tree of depth 2
2025-01-28 13:05:51,047 - statistic.py - synthesis initiated, design space: 1e23
2025-01-28 13:05:52,094 - synthesizer_ar.py - value 0.1083 achieved after 100.3 seconds
> progress 0.006%, elapsed 3 s, estimated 44247 s (12 hours), iters = {MDP: 91}, opt = 0.1083
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 4.1 s
number of holes: 34, family size: 1e23, quotient: 1868 states / 9425 actions
explored: 101 %
MDP stats: avg MDP size: 1655, iterations: 130

optimum: 0.108271
--------------------
2025-01-28 13:05:55,146 - decision_tree.py - families considered: 130
2025-01-28 13:05:55,146 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:05:55,146 - decision_tree.py - families with schedulers preserved: 40
2025-01-28 13:05:55,146 - decision_tree.py - families model checked: 90
2025-01-28 13:05:55,146 - decision_tree.py - harmonizations attempted: 6
2025-01-28 13:05:55,146 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 13:05:55,146 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:05:55,146 - decision_tree.py - V_0=s2, backoff1_0=0, backoff2_0=0, bc1_0=0, bc2_0=0, c1_0=0, c2_0=0, col_0=0, s1_0=7, s2_0=5, V_1=s1, backoff1_1=0, backoff2_1=0, bc1_1=0, bc2_1=0, c1_1=0, c2_1=0, col_1=0, s1_1=8, s2_1=4, A_2=time, A_3=station2_cmd_55, V_4=s1, backoff1_4=0, backoff2_4=0, bc1_4=0, bc2_4=0, c1_4=0, c2_4=0, col_4=0, s1_4=8, s2_4=2, A_5=send1, A_6=send2
2025-01-28 13:05:55,149 - decision_tree.py - double-checking specification satisfiability:  : 0.10827098374814313
2025-01-28 13:05:55,149 - decision_tree.py - admissible subtree found from node 22
2025-01-28 13:05:55,150 - decision_tree.py - new tree has depth 9 and 52 nodes
2025-01-28 13:05:56,905 - decision_tree.py - new dtcontrol tree has depth 9 and 58 nodes
2025-01-28 13:05:56,906 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 13:05:56,907 - decision_tree.py - starting iteration 4 with 2 nodes in node queue
2025-01-28 13:05:56,907 - decision_tree.py - current tree size: 105 nodes
2025-01-28 13:05:57,106 - decision_tree.py - subtree quotient has 2134 states and 15136 choices
2025-01-28 13:05:57,114 - mdp.py - MDP has 391/2134 relevant states
2025-01-28 13:05:57,210 - mdp.py - MDP has 34 actions
2025-01-28 13:05:57,229 - mdp.py - found the following 9 variables: ['backoff1:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..1]', 'c2:[0..2]', 'col:[0..1]', 's1:[2..12]', 's2:[1..11]', 'x2:[1..10]']

2025-01-28 13:05:57,229 - mdp.py - building tree of depth 0
2025-01-28 13:05:57,246 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 1, family size: 34, quotient: 2134 states / 15136 actions
explored: 100 %
MDP stats: avg MDP size: 2033, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:05:57,345 - decision_tree.py - families considered: 4
2025-01-28 13:05:57,345 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:05:57,345 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:05:57,345 - decision_tree.py - families model checked: 4
2025-01-28 13:05:57,345 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:05:57,345 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:05:57,345 - mdp.py - building tree of depth 1
2025-01-28 13:05:57,391 - statistic.py - synthesis initiated, design space: 1e8
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.68 s
number of holes: 12, family size: 1e8, quotient: 2134 states / 15136 actions
explored: 100 %
MDP stats: avg MDP size: 2055, iterations: 81

optimum: 0.107188
--------------------
2025-01-28 13:06:00,077 - decision_tree.py - families considered: 81
2025-01-28 13:06:00,077 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:00,077 - decision_tree.py - families with schedulers preserved: 24
2025-01-28 13:06:00,077 - decision_tree.py - families model checked: 57
2025-01-28 13:06:00,077 - decision_tree.py - harmonizations attempted: 5
2025-01-28 13:06:00,077 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:00,077 - mdp.py - building tree of depth 2
2025-01-28 13:06:00,178 - statistic.py - synthesis initiated, design space: 1e21
> progress 0.002%, elapsed 3 s, estimated 126873 s (35 hours), iters = {MDP: 64}, opt = 0.1072
2025-01-28 13:06:06,205 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.03 s
number of holes: 34, family size: 1e21, quotient: 2134 states / 15136 actions
explored: 0 %
MDP stats: avg MDP size: 2112, iterations: 135

optimum: 0.107188
--------------------
2025-01-28 13:06:06,206 - decision_tree.py - families considered: 135
2025-01-28 13:06:06,206 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:06,206 - decision_tree.py - families with schedulers preserved: 40
2025-01-28 13:06:06,206 - decision_tree.py - families model checked: 95
2025-01-28 13:06:06,206 - decision_tree.py - harmonizations attempted: 17
2025-01-28 13:06:06,206 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:06,206 - mdp.py - building tree of depth 3
2025-01-28 13:06:06,473 - statistic.py - synthesis initiated, design space: 1e48
> progress 0.0%, elapsed 3 s, estimated 40579189479 s (1286 years), iters = {MDP: 31}, opt = 0.1072
2025-01-28 13:06:12,477 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.0 s
number of holes: 78, family size: 1e48, quotient: 2134 states / 15136 actions
explored: 0 %
MDP stats: avg MDP size: 2080, iterations: 95

optimum: 0.107188
--------------------
2025-01-28 13:06:12,478 - decision_tree.py - families considered: 95
2025-01-28 13:06:12,478 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:12,478 - decision_tree.py - families with schedulers preserved: 39
2025-01-28 13:06:12,478 - decision_tree.py - families model checked: 56
2025-01-28 13:06:12,478 - decision_tree.py - harmonizations attempted: 5
2025-01-28 13:06:12,478 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:12,478 - mdp.py - building tree of depth 4
2025-01-28 13:06:13,042 - statistic.py - synthesis initiated, design space: 1e102
> progress 0.0%, elapsed 3 s, estimated 3707308 s (42 days), iters = {MDP: 3}, opt = 0.1072
2025-01-28 13:06:19,223 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.18 s
number of holes: 166, family size: 1e102, quotient: 2134 states / 15136 actions
explored: 0 %
MDP stats: avg MDP size: 2134, iterations: 6

optimum: 0.107188
--------------------
2025-01-28 13:06:19,224 - decision_tree.py - families considered: 6
2025-01-28 13:06:19,224 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:19,224 - decision_tree.py - families with schedulers preserved: 5
2025-01-28 13:06:19,224 - decision_tree.py - families model checked: 1
2025-01-28 13:06:19,224 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:06:19,224 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:19,224 - mdp.py - building tree of depth 5
2025-01-28 13:06:20,463 - statistic.py - synthesis initiated, design space: 1e209
2025-01-28 13:06:21,905 - synthesizer_ar.py - value 0.1083 achieved after 130.11 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.44 s
number of holes: 342, family size: 1e209, quotient: 2134 states / 15136 actions
explored: 100 %
MDP stats: avg MDP size: 2134, iterations: 1

optimum: 0.108271
--------------------
2025-01-28 13:06:21,905 - decision_tree.py - families considered: 1
2025-01-28 13:06:21,905 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:21,905 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:06:21,905 - decision_tree.py - families model checked: 1
2025-01-28 13:06:21,905 - decision_tree.py - harmonizations attempted: 0
2025-01-28 13:06:21,905 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:06:21,905 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:06:21,905 - decision_tree.py - V_0=s2, backoff1_0=0, bc1_0=0, bc2_0=0, c1_0=0, c2_0=0, col_0=0, s1_0=8, s2_0=7, x2_0=3, V_1=x2, backoff1_1=1, bc1_1=0, bc2_1=0, c1_1=0, c2_1=0, col_1=0, s1_1=3, s2_1=7, x2_1=1, V_2=s2, backoff1_2=1, bc1_2=0, bc2_2=0, c1_2=0, c2_2=0, col_2=0, s1_2=8, s2_2=7, x2_2=1, V_3=bc1, backoff1_3=2, bc1_3=0, bc2_3=0, c1_3=0, c2_3=0, col_3=0, s1_3=10, s2_3=3, x2_3=2, V_4=s2, backoff1_4=1, bc1_4=0, bc2_4=0, c1_4=0, c2_4=0, col_4=0, s1_4=4, s2_4=5, x2_4=1, A_5=station2_cmd_54, A_6=time, V_7=c1, backoff1_7=2, bc1_7=0, bc2_7=0, c1_7=0, c2_7=0, col_7=0, s1_7=4, s2_7=5, x2_7=2, A_8=station2_cmd_54, A_9=station2_cmd_60, V_10=col, backoff1_10=4, bc1_10=0, bc2_10=0, c1_10=0, c2_10=0, col_10=0, s1_10=5, s2_10=5, x2_10=1, V_11=s2, backoff1_11=0, bc1_11=0, bc2_11=0, c1_11=0, c2_11=0, col_11=0, s1_11=9, s2_11=7, x2_11=1, A_12=station1_cmd_7, A_13=station2_cmd_57, V_14=s1, backoff1_14=2, bc1_14=0, bc2_14=0, c1_14=0, c2_14=0, col_14=0, s1_14=8, s2_14=5, x2_14=2, A_15=send1, A_16=send2, V_17=s1, backoff1_17=13, bc1_17=0, bc2_17=0, c1_17=0, c2_17=0, col_17=0, s1_17=6, s2_17=1, x2_17=2, V_18=backoff1, backoff1_18=1, bc1_18=0, bc2_18=0, c1_18=0, c2_18=0, col_18=0, s1_18=4, s2_18=1, x2_18=4, V_19=s1, backoff1_19=0, bc1_19=0, bc2_19=0, c1_19=0, c2_19=1, col_19=0, s1_19=4, s2_19=7, x2_19=1, A_20=station1_cmd_15, A_21=station2_cmd_48, V_22=x2, backoff1_22=1, bc1_22=0, bc2_22=0, c1_22=0, c2_22=0, col_22=0, s1_22=5, s2_22=5, x2_22=2, A_23=time, A_24=station2_cmd_48, V_25=x2, backoff1_25=1, bc1_25=0, bc2_25=0, c1_25=0, c2_25=0, col_25=0, s1_25=5, s2_25=1, x2_25=1, V_26=s2, backoff1_26=0, bc1_26=0, bc2_26=0, c1_26=0, c2_26=0, col_26=0, s1_26=5, s2_26=3, x2_26=1, A_27=station2_cmd_57, A_28=station1_cmd_7, V_29=col, backoff1_29=1, bc1_29=0, bc2_29=0, c1_29=0, c2_29=0, col_29=0, s1_29=4, s2_29=1, x2_29=1, A_30=station2_cmd_42, A_31=station2_cmd_59, V_32=bc1, backoff1_32=9, bc1_32=0, bc2_32=0, c1_32=0, c2_32=1, col_32=0, s1_32=5, s2_32=9, x2_32=1, V_33=s2, backoff1_33=0, bc1_33=0, bc2_33=0, c1_33=0, c2_33=0, col_33=0, s1_33=6, s2_33=9, x2_33=3, V_34=bc1, backoff1_34=13, bc1_34=0, bc2_34=0, c1_34=0, c2_34=1, col_34=0, s1_34=11, s2_34=9, x2_34=3, V_35=x2, backoff1_35=0, bc1_35=0, bc2_35=0, c1_35=0, c2_35=1, col_35=0, s1_35=6, s2_35=9, x2_35=3, A_36=time, A_37=finish2, V_38=c2, backoff1_38=2, bc1_38=0, bc2_38=0, c1_38=0, c2_38=1, col_38=0, s1_38=6, s2_38=9, x2_38=3, A_39=finish2, A_40=finish2, V_41=x2, backoff1_41=1, bc1_41=0, bc2_41=0, c1_41=0, c2_41=0, col_41=0, s1_41=4, s2_41=8, x2_41=2, V_42=s2, backoff1_42=1, bc1_42=0, bc2_42=0, c1_42=0, c2_42=1, col_42=0, s1_42=4, s2_42=10, x2_42=1, A_43=time, A_44=station1_cmd_17, V_45=s2, backoff1_45=4, bc1_45=0, bc2_45=0, c1_45=0, c2_45=1, col_45=0, s1_45=8, s2_45=10, x2_45=2, A_46=finish2, A_47=station2_cmd_74, V_48=c2, backoff1_48=9, bc1_48=0, bc2_48=0, c1_48=0, c2_48=0, col_48=0, s1_48=6, s2_48=5, x2_48=1, V_49=s2, backoff1_49=1, bc1_49=0, bc2_49=0, c1_49=0, c2_49=1, col_49=0, s1_49=6, s2_49=9, x2_49=2, V_50=c1, backoff1_50=13, bc1_50=0, bc2_50=0, c1_50=0, c2_50=0, col_50=0, s1_50=6, s2_50=5, x2_50=2, A_51=send1, A_52=send2, V_53=s2, backoff1_53=2, bc1_53=0, bc2_53=0, c1_53=0, c2_53=1, col_53=0, s1_53=6, s2_53=9, x2_53=1, A_54=__random__, A_55=station2_cmd_42, V_56=s2, backoff1_56=0, bc1_56=0, bc2_56=0, c1_56=0, c2_56=0, col_56=0, s1_56=6, s2_56=9, x2_56=2, V_57=x2, backoff1_57=0, bc1_57=0, bc2_57=0, c1_57=0, c2_57=1, col_57=0, s1_57=9, s2_57=7, x2_57=3, A_58=time, A_59=finish2, V_60=x2, backoff1_60=1, bc1_60=0, bc2_60=0, c1_60=0, c2_60=1, col_60=0, s1_60=9, s2_60=7, x2_60=2, A_61=time, A_62=finish2
2025-01-28 13:06:21,918 - decision_tree.py - double-checking specification satisfiability:  : 0.10827098374814313
2025-01-28 13:06:21,918 - decision_tree.py - admissible subtree found from node 30
2025-01-28 13:06:21,919 - decision_tree.py - new tree has depth 8 and 61 nodes
2025-01-28 13:06:23,641 - decision_tree.py - new dtcontrol tree has depth 9 and 56 nodes
2025-01-28 13:06:23,641 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 13:06:23,643 - decision_tree.py - starting iteration 5 with 1 nodes in node queue
2025-01-28 13:06:23,643 - decision_tree.py - current tree size: 105 nodes
2025-01-28 13:06:23,934 - decision_tree.py - subtree quotient has 2136 states and 24543 choices
2025-01-28 13:06:23,951 - mdp.py - MDP has 676/2136 relevant states
2025-01-28 13:06:24,925 - mdp.py - MDP has 34 actions
2025-01-28 13:06:24,946 - mdp.py - found the following 10 variables: ['backoff1:[0..15]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c2:[0..1]', 'col:[0..1]', 's1:[1..5]', 's2:[1..12]', 'x1:[1..3]', 'x2:[0..3]']

2025-01-28 13:06:24,946 - mdp.py - building tree of depth 0
2025-01-28 13:06:24,971 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 1, family size: 34, quotient: 2136 states / 24543 actions
explored: 100 %
MDP stats: avg MDP size: 2059, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:06:25,069 - decision_tree.py - families considered: 4
2025-01-28 13:06:25,069 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:25,069 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:06:25,069 - decision_tree.py - families model checked: 4
2025-01-28 13:06:25,069 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:06:25,069 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:25,069 - mdp.py - building tree of depth 1
2025-01-28 13:06:25,154 - statistic.py - synthesis initiated, design space: 1e8
> progress 72.058%, elapsed 3 s, estimated 4 s, iters = {MDP: 83}, opt = 0.1072
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 3.14 s
number of holes: 13, family size: 1e8, quotient: 2136 states / 24543 actions
explored: 100 %
MDP stats: avg MDP size: 2057, iterations: 88

optimum: 0.107188
--------------------
2025-01-28 13:06:28,296 - decision_tree.py - families considered: 88
2025-01-28 13:06:28,296 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:28,296 - decision_tree.py - families with schedulers preserved: 18
2025-01-28 13:06:28,296 - decision_tree.py - families model checked: 70
2025-01-28 13:06:28,296 - decision_tree.py - harmonizations attempted: 12
2025-01-28 13:06:28,296 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:28,296 - mdp.py - building tree of depth 2
2025-01-28 13:06:28,516 - statistic.py - synthesis initiated, design space: 1e21
> progress 0.002%, elapsed 3 s, estimated 137909 s (38 hours), iters = {MDP: 60}, opt = 0.1072
2025-01-28 13:06:34,591 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.07 s
number of holes: 37, family size: 1e21, quotient: 2136 states / 24543 actions
explored: 0 %
MDP stats: avg MDP size: 2045, iterations: 127

optimum: 0.107188
--------------------
2025-01-28 13:06:34,591 - decision_tree.py - families considered: 127
2025-01-28 13:06:34,591 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:34,591 - decision_tree.py - families with schedulers preserved: 28
2025-01-28 13:06:34,591 - decision_tree.py - families model checked: 99
2025-01-28 13:06:34,591 - decision_tree.py - harmonizations attempted: 25
2025-01-28 13:06:34,591 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:34,592 - mdp.py - building tree of depth 3
2025-01-28 13:06:35,074 - statistic.py - synthesis initiated, design space: 1e49
> progress 0.0%, elapsed 3 s, estimated 1075868485 s (34 years), iters = {MDP: 17}, opt = 0.1072
2025-01-28 13:06:41,104 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 6.03 s
number of holes: 85, family size: 1e49, quotient: 2136 states / 24543 actions
explored: 0 %
MDP stats: avg MDP size: 2046, iterations: 69

optimum: 0.107188
--------------------
2025-01-28 13:06:41,104 - decision_tree.py - families considered: 69
2025-01-28 13:06:41,104 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:41,104 - decision_tree.py - families with schedulers preserved: 28
2025-01-28 13:06:41,104 - decision_tree.py - families model checked: 41
2025-01-28 13:06:41,104 - decision_tree.py - harmonizations attempted: 4
2025-01-28 13:06:41,104 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:41,105 - mdp.py - building tree of depth 4
2025-01-28 13:06:42,193 - statistic.py - synthesis initiated, design space: 1e103
2025-01-28 13:06:43,094 - synthesizer_ar.py - value 0.1083 achieved after 151.3 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.9 s
number of holes: 181, family size: 1e103, quotient: 2136 states / 24543 actions
explored: 100 %
MDP stats: avg MDP size: 2136, iterations: 1

optimum: 0.108271
--------------------
2025-01-28 13:06:43,094 - decision_tree.py - families considered: 1
2025-01-28 13:06:43,094 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:43,094 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:06:43,094 - decision_tree.py - families model checked: 1
2025-01-28 13:06:43,094 - decision_tree.py - harmonizations attempted: 0
2025-01-28 13:06:43,094 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:06:43,094 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:06:43,094 - decision_tree.py - V_0=s2, backoff1_0=2, backoff2_0=0, bc1_0=0, bc2_0=0, c2_0=0, col_0=0, s1_0=1, s2_0=3, x1_0=1, x2_0=0, V_1=bc1, backoff1_1=0, backoff2_1=0, bc1_1=0, bc2_1=0, c2_1=0, col_1=0, s1_1=1, s2_1=1, x1_1=1, x2_1=0, V_2=col, backoff1_2=6, backoff2_2=0, bc1_2=0, bc2_2=0, c2_2=0, col_2=0, s1_2=1, s2_2=3, x1_2=2, x2_2=0, V_3=x1, backoff1_3=7, backoff2_3=0, bc1_3=0, bc2_3=0, c2_3=0, col_3=0, s1_3=3, s2_3=1, x1_3=1, x2_3=0, A_4=time, A_5=station1_cmd_7, V_6=x1, backoff1_6=7, backoff2_6=0, bc1_6=0, bc2_6=0, c2_6=0, col_6=0, s1_6=1, s2_6=1, x1_6=1, x2_6=2, A_7=time, A_8=station1_cmd_13, V_9=backoff1, backoff1_9=8, backoff2_9=0, bc1_9=0, bc2_9=0, c2_9=0, col_9=0, s1_9=1, s2_9=3, x1_9=1, x2_9=1, V_10=backoff1, backoff1_10=6, backoff2_10=0, bc1_10=0, bc2_10=0, c2_10=0, col_10=0, s1_10=1, s2_10=1, x1_10=1, x2_10=1, A_11=station1_cmd_17, A_12=station2_cmd_48, V_13=backoff1, backoff1_13=11, backoff2_13=0, bc1_13=0, bc2_13=0, c2_13=0, col_13=0, s1_13=1, s2_13=1, x1_13=1, x2_13=1, A_14=station1_cmd_17, A_15=station2_cmd_48, V_16=backoff1, backoff1_16=12, backoff2_16=0, bc1_16=0, bc2_16=0, c2_16=0, col_16=0, s1_16=1, s2_16=4, x1_16=1, x2_16=0, V_17=backoff1, backoff1_17=0, backoff2_17=0, bc1_17=0, bc2_17=0, c2_17=0, col_17=0, s1_17=1, s2_17=4, x1_17=1, x2_17=0, V_18=x1, backoff1_18=12, backoff2_18=0, bc1_18=0, bc2_18=0, c2_18=0, col_18=0, s1_18=3, s2_18=1, x1_18=1, x2_18=1, A_19=station1_cmd_19, A_20=station2_cmd_47, V_21=s2, backoff1_21=0, backoff2_21=0, bc1_21=0, bc2_21=0, c2_21=0, col_21=0, s1_21=1, s2_21=4, x1_21=1, x2_21=0, A_22=station2_cmd_50, A_23=station1_cmd_17, V_24=backoff1, backoff1_24=14, backoff2_24=0, bc1_24=0, bc2_24=0, c2_24=0, col_24=0, s1_24=1, s2_24=3, x1_24=1, x2_24=1, V_25=s2, backoff1_25=7, backoff2_25=0, bc1_25=0, bc2_25=0, c2_25=0, col_25=0, s1_25=1, s2_25=4, x1_25=1, x2_25=0, A_26=__random__, A_27=station1_cmd_17, V_28=s2, backoff1_28=0, backoff2_28=0, bc1_28=0, bc2_28=0, c2_28=0, col_28=0, s1_28=1, s2_28=4, x1_28=1, x2_28=0, A_29=station2_cmd_50, A_30=station1_cmd_17
2025-01-28 13:06:43,103 - decision_tree.py - double-checking specification satisfiability:  : 0.10827098374814313
2025-01-28 13:06:43,103 - decision_tree.py - admissible subtree found from node 61
2025-01-28 13:06:43,104 - decision_tree.py - new tree has depth 9 and 56 nodes
2025-01-28 13:06:44,943 - decision_tree.py - new dtcontrol tree has depth 9 and 58 nodes
2025-01-28 13:06:44,943 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 13:06:44,945 - decision_tree.py - starting iteration with subtree depth 5
2025-01-28 13:06:44,952 - decision_tree.py - starting iteration 6 with 4 nodes in node queue
2025-01-28 13:06:44,953 - decision_tree.py - current tree size: 105 nodes
2025-01-28 13:06:45,168 - decision_tree.py - subtree quotient has 1913 states and 21614 choices
2025-01-28 13:06:45,175 - mdp.py - MDP has 595/1913 relevant states
2025-01-28 13:06:45,306 - mdp.py - MDP has 34 actions
2025-01-28 13:06:45,321 - mdp.py - found the following 9 variables: ['backoff1:[0..14]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..2]', 'c2:[0..2]', 'col:[0..2]', 's1:[1..12]', 's2:[1..12]']

2025-01-28 13:06:45,322 - mdp.py - building tree of depth 0
2025-01-28 13:06:45,339 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.08 s
number of holes: 1, family size: 34, quotient: 1913 states / 21614 actions
explored: 100 %
MDP stats: avg MDP size: 1799, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:06:45,419 - decision_tree.py - families considered: 4
2025-01-28 13:06:45,419 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:45,419 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:06:45,419 - decision_tree.py - families model checked: 4
2025-01-28 13:06:45,419 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:06:45,419 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:45,419 - mdp.py - building tree of depth 1
2025-01-28 13:06:45,489 - statistic.py - synthesis initiated, design space: 1e9
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.9 s
number of holes: 12, family size: 1e9, quotient: 1913 states / 21614 actions
explored: 100 %
MDP stats: avg MDP size: 1802, iterations: 86

optimum: 0.107188
--------------------
2025-01-28 13:06:48,390 - decision_tree.py - families considered: 86
2025-01-28 13:06:48,390 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:48,390 - decision_tree.py - families with schedulers preserved: 18
2025-01-28 13:06:48,390 - decision_tree.py - families model checked: 68
2025-01-28 13:06:48,390 - decision_tree.py - harmonizations attempted: 13
2025-01-28 13:06:48,390 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:48,390 - mdp.py - building tree of depth 2
2025-01-28 13:06:48,549 - statistic.py - synthesis initiated, design space: 1e24
> progress 0.0%, elapsed 3 s, estimated 9355943 s (108 days), iters = {MDP: 43}, opt = 0.1072
> progress 0.0%, elapsed 6 s, estimated 2627964 s (30 days), iters = {MDP: 98}, opt = 0.1072
2025-01-28 13:06:56,055 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.51 s
number of holes: 34, family size: 1e24, quotient: 1913 states / 21614 actions
explored: 0 %
MDP stats: avg MDP size: 1716, iterations: 127

optimum: 0.107188
--------------------
2025-01-28 13:06:56,055 - decision_tree.py - families considered: 127
2025-01-28 13:06:56,055 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:06:56,055 - decision_tree.py - families with schedulers preserved: 28
2025-01-28 13:06:56,055 - decision_tree.py - families model checked: 99
2025-01-28 13:06:56,055 - decision_tree.py - harmonizations attempted: 30
2025-01-28 13:06:56,055 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:06:56,056 - mdp.py - building tree of depth 3
2025-01-28 13:06:56,478 - statistic.py - synthesis initiated, design space: 1e55
> progress 0.0%, elapsed 3 s, estimated 3347006 s (38 days), iters = {MDP: 4}, opt = 0.1072
> progress 0.0%, elapsed 6 s, estimated 6572394 s (76 days), iters = {MDP: 8}, opt = 0.1072
2025-01-28 13:07:04,100 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.62 s
number of holes: 78, family size: 1e55, quotient: 1913 states / 21614 actions
explored: 0 %
MDP stats: avg MDP size: 1816, iterations: 19

optimum: 0.107188
--------------------
2025-01-28 13:07:04,101 - decision_tree.py - families considered: 19
2025-01-28 13:07:04,101 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:07:04,101 - decision_tree.py - families with schedulers preserved: 10
2025-01-28 13:07:04,101 - decision_tree.py - families model checked: 9
2025-01-28 13:07:04,101 - decision_tree.py - harmonizations attempted: 3
2025-01-28 13:07:04,101 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:07:04,101 - mdp.py - building tree of depth 4
2025-01-28 13:07:05,102 - statistic.py - synthesis initiated, design space: 1e117
> progress 0.0%, elapsed 5 s, estimated 5971695 s (69 days), iters = {MDP: 2}, opt = 0.1072
> progress 0.0%, elapsed 11 s, estimated 11555445 s (133 days), iters = {MDP: 3}, opt = 0.1072
> progress 0.0%, elapsed 16 s, estimated 16098241 s (186 days), iters = {MDP: 4}, opt = 0.1072
> progress 0.0%, elapsed 20 s, estimated 20993469 s (242 days), iters = {MDP: 5}, opt = 0.1072
> progress 0.0%, elapsed 24 s, estimated 24238745 s (280 days), iters = {MDP: 6}, opt = 0.1072
> progress 0.0%, elapsed 27 s, estimated 27397894 s (317 days), iters = {MDP: 7}, opt = 0.1072
2025-01-28 13:07:35,927 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.83 s
number of holes: 166, family size: 1e117, quotient: 1913 states / 21614 actions
explored: 0 %
MDP stats: avg MDP size: 1913, iterations: 7

optimum: 0.107188
--------------------
2025-01-28 13:07:35,928 - decision_tree.py - families considered: 7
2025-01-28 13:07:35,928 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:07:35,928 - decision_tree.py - families with schedulers preserved: 6
2025-01-28 13:07:35,928 - decision_tree.py - families model checked: 1
2025-01-28 13:07:35,928 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:07:35,928 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:07:35,929 - decision_tree.py - no admissible subtree found from node 2
2025-01-28 13:07:35,929 - decision_tree.py - starting iteration 7 with 3 nodes in node queue
2025-01-28 13:07:35,929 - decision_tree.py - current tree size: 105 nodes
2025-01-28 13:07:36,156 - decision_tree.py - subtree quotient has 1805 states and 4049 choices
2025-01-28 13:07:36,168 - mdp.py - MDP has 65/1805 relevant states
2025-01-28 13:07:36,222 - mdp.py - MDP has 34 actions
2025-01-28 13:07:36,311 - mdp.py - found the following 8 variables: ['backoff1:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..1]', 'col:[0..1]', 's1:[3..12]', 's2:[1..11]', 'x2:[1..6]']

2025-01-28 13:07:36,311 - mdp.py - building tree of depth 0
2025-01-28 13:07:36,325 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 1, family size: 34, quotient: 1805 states / 4049 actions
explored: 100 %
MDP stats: avg MDP size: 1788, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:07:36,427 - decision_tree.py - families considered: 4
2025-01-28 13:07:36,427 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:07:36,427 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:07:36,427 - decision_tree.py - families model checked: 4
2025-01-28 13:07:36,427 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:07:36,427 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:07:36,427 - mdp.py - building tree of depth 1
2025-01-28 13:07:36,443 - statistic.py - synthesis initiated, design space: 1e7
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.57 s
number of holes: 11, family size: 1e7, quotient: 1805 states / 4049 actions
explored: 100 %
MDP stats: avg MDP size: 1776, iterations: 60

optimum: 0.107188
--------------------
2025-01-28 13:07:38,010 - decision_tree.py - families considered: 60
2025-01-28 13:07:38,010 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:07:38,010 - decision_tree.py - families with schedulers preserved: 14
2025-01-28 13:07:38,011 - decision_tree.py - families model checked: 46
2025-01-28 13:07:38,011 - decision_tree.py - harmonizations attempted: 7
2025-01-28 13:07:38,011 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:07:38,011 - mdp.py - building tree of depth 2
2025-01-28 13:07:38,034 - statistic.py - synthesis initiated, design space: 1e18
> progress 3.331%, elapsed 3 s, estimated 91 s, iters = {MDP: 93}, opt = 0.1072
> progress 4.564%, elapsed 6 s, estimated 133 s, iters = {MDP: 171}, opt = 0.1072
2025-01-28 13:07:45,537 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.5 s
number of holes: 31, family size: 1e18, quotient: 1805 states / 4049 actions
explored: 6 %
MDP stats: avg MDP size: 1779, iterations: 217

optimum: 0.107188
--------------------
2025-01-28 13:07:45,537 - decision_tree.py - families considered: 217
2025-01-28 13:07:45,537 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:07:45,537 - decision_tree.py - families with schedulers preserved: 69
2025-01-28 13:07:45,537 - decision_tree.py - families model checked: 148
2025-01-28 13:07:45,537 - decision_tree.py - harmonizations attempted: 15
2025-01-28 13:07:45,537 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:07:45,538 - mdp.py - building tree of depth 3
2025-01-28 13:07:45,579 - statistic.py - synthesis initiated, design space: 1e40
> progress 0.0%, elapsed 3 s, estimated 415928 s (4 days), iters = {MDP: 58}, opt = 0.1072
> progress 0.0%, elapsed 6 s, estimated 753589 s (8 days), iters = {MDP: 136}, opt = 0.1072
2025-01-28 13:07:53,133 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 7.55 s
number of holes: 71, family size: 1e40, quotient: 1805 states / 4049 actions
explored: 0 %
MDP stats: avg MDP size: 1776, iterations: 166

optimum: 0.107188
--------------------
2025-01-28 13:07:53,134 - decision_tree.py - families considered: 166
2025-01-28 13:07:53,134 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:07:53,134 - decision_tree.py - families with schedulers preserved: 58
2025-01-28 13:07:53,134 - decision_tree.py - families model checked: 108
2025-01-28 13:07:53,134 - decision_tree.py - harmonizations attempted: 11
2025-01-28 13:07:53,134 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:07:53,134 - mdp.py - building tree of depth 4
2025-01-28 13:07:53,216 - statistic.py - synthesis initiated, design space: 1e85
2025-01-28 13:07:53,404 - synthesizer_ar.py - value 0.1083 achieved after 221.61 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.19 s
number of holes: 151, family size: 1e85, quotient: 1805 states / 4049 actions
explored: 100 %
MDP stats: avg MDP size: 1805, iterations: 1

optimum: 0.108271
--------------------
2025-01-28 13:07:53,404 - decision_tree.py - families considered: 1
2025-01-28 13:07:53,404 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:07:53,404 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:07:53,405 - decision_tree.py - families model checked: 1
2025-01-28 13:07:53,405 - decision_tree.py - harmonizations attempted: 0
2025-01-28 13:07:53,405 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:07:53,405 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:07:53,405 - decision_tree.py - V_0=bc1, backoff1_0=0, bc1_0=0, bc2_0=0, c1_0=0, col_0=0, s1_0=9, s2_0=1, x2_0=1, V_1=col, backoff1_1=0, bc1_1=0, bc2_1=0, c1_1=0, col_1=0, s1_1=10, s2_1=3, x2_1=2, V_2=col, backoff1_2=0, bc1_2=0, bc2_2=0, c1_2=0, col_2=0, s1_2=8, s2_2=5, x2_2=2, V_3=col, backoff1_3=0, bc1_3=0, bc2_3=0, c1_3=0, col_3=0, s1_3=4, s2_3=1, x2_3=1, A_4=station2_cmd_42, A_5=finish2, V_6=bc1, backoff1_6=1, bc1_6=0, bc2_6=0, c1_6=0, col_6=0, s1_6=4, s2_6=1, x2_6=2, A_7=station1_cmd_17, A_8=finish2, V_9=x2, backoff1_9=1, bc1_9=0, bc2_9=0, c1_9=0, col_9=0, s1_9=5, s2_9=5, x2_9=1, V_10=s2, backoff1_10=0, bc1_10=0, bc2_10=0, c1_10=0, col_10=0, s1_10=3, s2_10=5, x2_10=1, A_11=station2_cmd_54, A_12=time, V_13=x2, backoff1_13=0, bc1_13=0, bc2_13=0, c1_13=0, col_13=0, s1_13=5, s2_13=1, x2_13=2, A_14=station2_cmd_59, A_15=station2_cmd_74, V_16=bc2, backoff1_16=1, bc1_16=0, bc2_16=0, c1_16=0, col_16=0, s1_16=4, s2_16=3, x2_16=1, V_17=backoff1, backoff1_17=1, bc1_17=0, bc2_17=0, c1_17=0, col_17=0, s1_17=4, s2_17=5, x2_17=2, V_18=s1, backoff1_18=0, bc1_18=0, bc2_18=0, c1_18=0, col_18=0, s1_18=4, s2_18=5, x2_18=1, A_19=station1_cmd_15, A_20=station2_cmd_48, V_21=x2, backoff1_21=1, bc1_21=0, bc2_21=0, c1_21=0, col_21=0, s1_21=4, s2_21=5, x2_21=2, A_22=time, A_23=station2_cmd_48, V_24=s2, backoff1_24=0, bc1_24=0, bc2_24=0, c1_24=0, col_24=0, s1_24=4, s2_24=7, x2_24=1, V_25=s1, backoff1_25=0, bc1_25=0, bc2_25=0, c1_25=0, col_25=0, s1_25=8, s2_25=7, x2_25=1, A_26=station2_cmd_54, A_27=station2_cmd_60, V_28=c1, backoff1_28=0, bc1_28=0, bc2_28=0, c1_28=0, col_28=0, s1_28=9, s2_28=8, x2_28=1, A_29=send1, A_30=send2
2025-01-28 13:07:53,410 - decision_tree.py - double-checking specification satisfiability:  : 0.10827098374814313
2025-01-28 13:07:53,410 - decision_tree.py - admissible subtree found from node 31
2025-01-28 13:07:53,411 - decision_tree.py - new tree has depth 8 and 56 nodes
2025-01-28 13:07:55,371 - decision_tree.py - new dtcontrol tree has depth 9 and 56 nodes
2025-01-28 13:07:55,371 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 13:07:55,372 - decision_tree.py - starting iteration 8 with 2 nodes in node queue
2025-01-28 13:07:55,372 - decision_tree.py - current tree size: 105 nodes
2025-01-28 13:07:55,608 - decision_tree.py - subtree quotient has 2108 states and 19466 choices
2025-01-28 13:07:55,619 - mdp.py - MDP has 524/2108 relevant states
2025-01-28 13:07:56,717 - mdp.py - MDP has 34 actions
2025-01-28 13:07:56,742 - mdp.py - found the following 10 variables: ['backoff1:[0..15]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..2]', 'c2:[0..2]', 's1:[7..11]', 's2:[2..12]', 'x1:[1..10]', 'x2:[0..10]']

2025-01-28 13:07:56,742 - mdp.py - building tree of depth 0
2025-01-28 13:07:56,772 - statistic.py - synthesis initiated, design space: 34
2025-01-28 13:07:56,865 - synthesizer_ar.py - value 0.1083 achieved after 225.07 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.11 s
number of holes: 1, family size: 34, quotient: 2108 states / 19466 actions
explored: 100 %
MDP stats: avg MDP size: 1962, iterations: 4

optimum: 0.108271
--------------------
2025-01-28 13:07:56,883 - decision_tree.py - families considered: 4
2025-01-28 13:07:56,884 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:07:56,884 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:07:56,884 - decision_tree.py - families model checked: 4
2025-01-28 13:07:56,884 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:07:56,884 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 13:07:56,884 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:07:56,884 - decision_tree.py - A_0=finish1
2025-01-28 13:07:56,887 - decision_tree.py - double-checking specification satisfiability:  : 0.10827098374814313
2025-01-28 13:07:56,887 - decision_tree.py - admissible subtree found from node 84
2025-01-28 13:07:56,888 - decision_tree.py - new tree has depth 9 and 42 nodes
2025-01-28 13:07:58,746 - decision_tree.py - new dtcontrol tree has depth 9 and 46 nodes
2025-01-28 13:07:58,746 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 13:07:58,747 - decision_tree.py - starting iteration 9 with 1 nodes in node queue
2025-01-28 13:07:58,748 - decision_tree.py - current tree size: 85 nodes
2025-01-28 13:07:58,980 - decision_tree.py - subtree quotient has 1815 states and 19470 choices
2025-01-28 13:07:58,986 - mdp.py - MDP has 533/1815 relevant states
2025-01-28 13:07:59,110 - mdp.py - MDP has 34 actions
2025-01-28 13:07:59,125 - mdp.py - found the following 6 variables: ['backoff1:[1..15]', 'backoff2:[0..15]', 'bc2:[0..1]', 'c2:[0..1]', 's2:[3..12]', 'x2:[0..3]']

2025-01-28 13:07:59,126 - mdp.py - building tree of depth 0
2025-01-28 13:07:59,141 - statistic.py - synthesis initiated, design space: 34
2025-01-28 13:07:59,201 - synthesizer_ar.py - value 0.1083 achieved after 227.41 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.08 s
number of holes: 1, family size: 34, quotient: 1815 states / 19470 actions
explored: 100 %
MDP stats: avg MDP size: 1731, iterations: 4

optimum: 0.108271
--------------------
2025-01-28 13:07:59,217 - decision_tree.py - families considered: 4
2025-01-28 13:07:59,217 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:07:59,217 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:07:59,217 - decision_tree.py - families model checked: 4
2025-01-28 13:07:59,217 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:07:59,217 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 13:07:59,217 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:07:59,217 - decision_tree.py - A_0=station1_cmd_17
2025-01-28 13:07:59,219 - decision_tree.py - double-checking specification satisfiability:  : 0.1082709837481431
2025-01-28 13:07:59,219 - decision_tree.py - admissible subtree found from node 69
2025-01-28 13:07:59,219 - decision_tree.py - new tree has depth 9 and 35 nodes
2025-01-28 13:08:00,869 - decision_tree.py - new dtcontrol tree has depth 9 and 39 nodes
2025-01-28 13:08:00,870 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 13:08:00,871 - decision_tree.py - starting iteration with subtree depth 4
2025-01-28 13:08:00,875 - decision_tree.py - starting iteration 10 with 3 nodes in node queue
2025-01-28 13:08:00,875 - decision_tree.py - current tree size: 71 nodes
2025-01-28 13:08:01,091 - decision_tree.py - subtree quotient has 1539 states and 13320 choices
2025-01-28 13:08:01,099 - mdp.py - MDP has 355/1539 relevant states
2025-01-28 13:08:01,231 - mdp.py - MDP has 34 actions
2025-01-28 13:08:01,246 - mdp.py - found the following 8 variables: ['backoff1:[0..14]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c2:[0..1]', 'col:[0..1]', 's1:[1..6]', 's2:[1..12]']

2025-01-28 13:08:01,246 - mdp.py - building tree of depth 0
2025-01-28 13:08:01,258 - statistic.py - synthesis initiated, design space: 34
2025-01-28 13:08:01,310 - synthesizer_ar.py - value 0.1083 achieved after 229.52 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.06 s
number of holes: 1, family size: 34, quotient: 1539 states / 13320 actions
explored: 100 %
MDP stats: avg MDP size: 1534, iterations: 4

optimum: 0.108271
--------------------
2025-01-28 13:08:01,321 - decision_tree.py - families considered: 4
2025-01-28 13:08:01,321 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:08:01,321 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:08:01,321 - decision_tree.py - families model checked: 4
2025-01-28 13:08:01,321 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:08:01,321 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 13:08:01,321 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:08:01,321 - decision_tree.py - A_0=time
2025-01-28 13:08:01,323 - decision_tree.py - double-checking specification satisfiability:  : 0.1082709837481431
2025-01-28 13:08:01,323 - decision_tree.py - admissible subtree found from node 3
2025-01-28 13:08:01,324 - decision_tree.py - new tree has depth 9 and 26 nodes
2025-01-28 13:08:03,089 - decision_tree.py - new dtcontrol tree has depth 9 and 32 nodes
2025-01-28 13:08:03,090 - decision_tree.py - Current PAYNT tree is smaller
2025-01-28 13:08:03,091 - decision_tree.py - starting iteration 11 with 2 nodes in node queue
2025-01-28 13:08:03,091 - decision_tree.py - current tree size: 53 nodes
2025-01-28 13:08:03,301 - decision_tree.py - subtree quotient has 2185 states and 25087 choices
2025-01-28 13:08:03,309 - mdp.py - MDP has 691/2185 relevant states
2025-01-28 13:08:03,467 - mdp.py - MDP has 34 actions
2025-01-28 13:08:03,485 - mdp.py - found the following 10 variables: ['backoff1:[0..15]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c2:[0..1]', 'col:[0..1]', 's1:[1..5]', 's2:[1..12]', 'x1:[1..3]', 'x2:[0..3]']

2025-01-28 13:08:03,485 - mdp.py - building tree of depth 0
2025-01-28 13:08:03,504 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 1, family size: 34, quotient: 2185 states / 25087 actions
explored: 100 %
MDP stats: avg MDP size: 2112, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:08:03,601 - decision_tree.py - families considered: 4
2025-01-28 13:08:03,601 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:08:03,601 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:08:03,601 - decision_tree.py - families model checked: 4
2025-01-28 13:08:03,601 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:08:03,601 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:08:03,601 - mdp.py - building tree of depth 1
2025-01-28 13:08:03,676 - statistic.py - synthesis initiated, design space: 1e8
> progress 70.955%, elapsed 3 s, estimated 4 s, iters = {MDP: 83}, opt = 0.1072
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 3.56 s
number of holes: 13, family size: 1e8, quotient: 2185 states / 25087 actions
explored: 100 %
MDP stats: avg MDP size: 2098, iterations: 102

optimum: 0.107188
--------------------
2025-01-28 13:08:07,238 - decision_tree.py - families considered: 102
2025-01-28 13:08:07,238 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:08:07,238 - decision_tree.py - families with schedulers preserved: 24
2025-01-28 13:08:07,238 - decision_tree.py - families model checked: 78
2025-01-28 13:08:07,238 - decision_tree.py - harmonizations attempted: 12
2025-01-28 13:08:07,239 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:08:07,239 - mdp.py - building tree of depth 2
2025-01-28 13:08:07,444 - statistic.py - synthesis initiated, design space: 1e21
> progress 0.001%, elapsed 3 s, estimated 275841 s (3 days), iters = {MDP: 54}, opt = 0.1072
> progress 0.003%, elapsed 6 s, estimated 200850 s (2 days), iters = {MDP: 116}, opt = 0.1072
> progress 0.004%, elapsed 9 s, estimated 195781 s (2 days), iters = {MDP: 184}, opt = 0.1072
2025-01-28 13:08:17,514 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 10.07 s
number of holes: 37, family size: 1e21, quotient: 2185 states / 25087 actions
explored: 0 %
MDP stats: avg MDP size: 2121, iterations: 205

optimum: 0.107188
--------------------
2025-01-28 13:08:17,514 - decision_tree.py - families considered: 205
2025-01-28 13:08:17,514 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:08:17,514 - decision_tree.py - families with schedulers preserved: 61
2025-01-28 13:08:17,514 - decision_tree.py - families model checked: 144
2025-01-28 13:08:17,514 - decision_tree.py - harmonizations attempted: 24
2025-01-28 13:08:17,514 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:08:17,514 - mdp.py - building tree of depth 3
2025-01-28 13:08:17,997 - statistic.py - synthesis initiated, design space: 1e49
2025-01-28 13:08:20,377 - synthesizer_ar.py - value 0.1083 achieved after 248.58 seconds
> progress 0.012%, elapsed 3 s, estimated 24555 s (6 hours), iters = {MDP: 36}, opt = 0.1083
> progress 0.124%, elapsed 6 s, estimated 4860 s, iters = {MDP: 89}, opt = 0.1083
> progress 0.16%, elapsed 9 s, estimated 5701 s, iters = {MDP: 142}, opt = 0.1083
> progress 0.168%, elapsed 12 s, estimated 7222 s (2 hours), iters = {MDP: 192}, opt = 0.1083
> progress 0.172%, elapsed 15 s, estimated 8820 s (2 hours), iters = {MDP: 237}, opt = 0.1083
> progress 0.198%, elapsed 18 s, estimated 9203 s (2 hours), iters = {MDP: 287}, opt = 0.1083
> progress 0.223%, elapsed 21 s, estimated 9512 s (2 hours), iters = {MDP: 342}, opt = 0.1083
> progress 0.244%, elapsed 24 s, estimated 9980 s (2 hours), iters = {MDP: 392}, opt = 0.1083
> progress 0.272%, elapsed 27 s, estimated 10073 s (2 hours), iters = {MDP: 444}, opt = 0.1083
2025-01-28 13:08:48,000 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.0 s
number of holes: 85, family size: 1e49, quotient: 2185 states / 25087 actions
explored: 0 %
MDP stats: avg MDP size: 2162, iterations: 482

optimum: 0.108271
--------------------
2025-01-28 13:08:48,001 - decision_tree.py - families considered: 482
2025-01-28 13:08:48,001 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:08:48,001 - decision_tree.py - families with schedulers preserved: 177
2025-01-28 13:08:48,001 - decision_tree.py - families model checked: 305
2025-01-28 13:08:48,001 - decision_tree.py - harmonizations attempted: 5
2025-01-28 13:08:48,001 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:08:48,001 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:08:48,001 - decision_tree.py - V_0=x1, backoff1_0=0, backoff2_0=0, bc1_0=0, bc2_0=0, c2_0=0, col_0=0, s1_0=1, s2_0=1, x1_0=2, x2_0=0, V_1=x1, backoff1_1=0, backoff2_1=0, bc1_1=0, bc2_1=0, c2_1=0, col_1=0, s1_1=1, s2_1=3, x1_1=1, x2_1=0, V_2=x2, backoff1_2=8, backoff2_2=0, bc1_2=0, bc2_2=0, c2_2=0, col_2=0, s1_2=1, s2_2=1, x1_2=1, x2_2=0, A_3=station1_cmd_19, A_4=station1_cmd_17, V_5=s2, backoff1_5=0, backoff2_5=0, bc1_5=0, bc2_5=0, c2_5=0, col_5=0, s1_5=1, s2_5=1, x1_5=1, x2_5=0, A_6=station1_cmd_7, A_7=station1_cmd_13, V_8=s1, backoff1_8=0, backoff2_8=0, bc1_8=0, bc2_8=0, c2_8=0, col_8=0, s1_8=3, s2_8=3, x1_8=1, x2_8=0, V_9=s1, backoff1_9=0, backoff2_9=0, bc1_9=0, bc2_9=0, c2_9=0, col_9=0, s1_9=3, s2_9=3, x1_9=1, x2_9=0, A_10=station1_cmd_10, A_11=station1_cmd_10, V_12=s2, backoff1_12=0, backoff2_12=0, bc1_12=0, bc2_12=0, c2_12=0, col_12=0, s1_12=1, s2_12=3, x1_12=1, x2_12=0, A_13=station1_cmd_10, A_14=station1_cmd_10
2025-01-28 13:08:48,007 - decision_tree.py - double-checking specification satisfiability:  : 0.1082709837481431
2025-01-28 13:08:48,007 - decision_tree.py - admissible subtree found from node 43
2025-01-28 13:08:48,008 - decision_tree.py - new tree has depth 9 and 26 nodes
2025-01-28 13:08:49,651 - decision_tree.py - new dtcontrol tree has depth 9 and 31 nodes
2025-01-28 13:08:49,651 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 13:08:49,652 - decision_tree.py - starting iteration 12 with 1 nodes in node queue
2025-01-28 13:08:49,652 - decision_tree.py - current tree size: 53 nodes
2025-01-28 13:08:49,844 - decision_tree.py - subtree quotient has 1750 states and 3334 choices
2025-01-28 13:08:49,851 - mdp.py - MDP has 45/1750 relevant states
2025-01-28 13:08:49,873 - mdp.py - MDP has 34 actions
2025-01-28 13:08:49,890 - mdp.py - found the following 7 variables: ['backoff1:[0..15]', 'bc1:[0..1]', 'c1:[0..1]', 'col:[0..1]', 's1:[4..12]', 's2:[1..3]', 'x2:[1..3]']

2025-01-28 13:08:49,890 - mdp.py - building tree of depth 0
2025-01-28 13:08:49,896 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 1, family size: 34, quotient: 1750 states / 3334 actions
explored: 100 %
MDP stats: avg MDP size: 1728, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:08:49,992 - decision_tree.py - families considered: 4
2025-01-28 13:08:49,992 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:08:49,992 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:08:49,992 - decision_tree.py - families model checked: 4
2025-01-28 13:08:49,992 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:08:49,992 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:08:49,992 - mdp.py - building tree of depth 1
2025-01-28 13:08:50,005 - statistic.py - synthesis initiated, design space: 1e6
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.34 s
number of holes: 10, family size: 1e6, quotient: 1750 states / 3334 actions
explored: 100 %
MDP stats: avg MDP size: 1722, iterations: 62

optimum: 0.107188
--------------------
2025-01-28 13:08:51,347 - decision_tree.py - families considered: 62
2025-01-28 13:08:51,347 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:08:51,347 - decision_tree.py - families with schedulers preserved: 20
2025-01-28 13:08:51,347 - decision_tree.py - families model checked: 42
2025-01-28 13:08:51,347 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:08:51,347 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:08:51,348 - mdp.py - building tree of depth 2
2025-01-28 13:08:51,366 - statistic.py - synthesis initiated, design space: 1e15
> progress 36.734%, elapsed 3 s, estimated 8 s, iters = {MDP: 125}, opt = 0.1072
> progress 43.153%, elapsed 6 s, estimated 14 s, iters = {MDP: 238}, opt = 0.1072
> progress 43.172%, elapsed 9 s, estimated 21 s, iters = {MDP: 347}, opt = 0.1072
2025-01-28 13:09:01,408 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 10.04 s
number of holes: 28, family size: 1e15, quotient: 1750 states / 3334 actions
explored: 43 %
MDP stats: avg MDP size: 1724, iterations: 379

optimum: 0.107188
--------------------
2025-01-28 13:09:01,408 - decision_tree.py - families considered: 379
2025-01-28 13:09:01,408 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:01,408 - decision_tree.py - families with schedulers preserved: 142
2025-01-28 13:09:01,408 - decision_tree.py - families model checked: 237
2025-01-28 13:09:01,408 - decision_tree.py - harmonizations attempted: 3
2025-01-28 13:09:01,408 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:09:01,408 - mdp.py - building tree of depth 3
2025-01-28 13:09:01,440 - statistic.py - synthesis initiated, design space: 1e33
2025-01-28 13:09:01,543 - synthesizer_ar.py - value 0.1083 achieved after 289.75 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 64, family size: 1e33, quotient: 1750 states / 3334 actions
explored: 100 %
MDP stats: avg MDP size: 1750, iterations: 1

optimum: 0.108271
--------------------
2025-01-28 13:09:01,544 - decision_tree.py - families considered: 1
2025-01-28 13:09:01,544 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:01,544 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:09:01,544 - decision_tree.py - families model checked: 1
2025-01-28 13:09:01,544 - decision_tree.py - harmonizations attempted: 0
2025-01-28 13:09:01,544 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:09:01,544 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:09:01,544 - decision_tree.py - V_0=s1, backoff1_0=0, bc1_0=0, c1_0=0, col_0=0, s1_0=4, s2_0=1, x2_0=1, V_1=x2, backoff1_1=0, bc1_1=0, c1_1=0, col_1=0, s1_1=4, s2_1=1, x2_1=1, V_2=x2, backoff1_2=0, bc1_2=0, c1_2=0, col_2=0, s1_2=4, s2_2=1, x2_2=1, A_3=finish1, A_4=finish1, V_5=x2, backoff1_5=0, bc1_5=0, c1_5=0, col_5=0, s1_5=4, s2_5=1, x2_5=1, A_6=finish1, A_7=station1_cmd_15, V_8=backoff1, backoff1_8=1, bc1_8=0, c1_8=0, col_8=0, s1_8=4, s2_8=1, x2_8=1, V_9=bc1, backoff1_9=0, bc1_9=0, c1_9=0, col_9=0, s1_9=4, s2_9=1, x2_9=2, A_10=station2_cmd_42, A_11=station2_cmd_48, V_12=x2, backoff1_12=0, bc1_12=0, c1_12=0, col_12=0, s1_12=4, s2_12=1, x2_12=2, A_13=time, A_14=station2_cmd_48
2025-01-28 13:09:01,548 - decision_tree.py - double-checking specification satisfiability:  : 0.1082709837481431
2025-01-28 13:09:01,548 - decision_tree.py - admissible subtree found from node 14
2025-01-28 13:09:01,549 - decision_tree.py - new tree has depth 8 and 26 nodes
2025-01-28 13:09:03,216 - decision_tree.py - new dtcontrol tree has depth 9 and 32 nodes
2025-01-28 13:09:03,216 - decision_tree.py - None of the new trees are smaller, continuing with current tree
2025-01-28 13:09:03,217 - decision_tree.py - starting iteration with subtree depth 3
2025-01-28 13:09:03,224 - decision_tree.py - starting iteration 13 with 5 nodes in node queue
2025-01-28 13:09:03,224 - decision_tree.py - current tree size: 53 nodes
2025-01-28 13:09:03,415 - decision_tree.py - subtree quotient has 1518 states and 2805 choices
2025-01-28 13:09:03,420 - mdp.py - MDP has 37/1518 relevant states
2025-01-28 13:09:03,437 - mdp.py - MDP has 34 actions
2025-01-28 13:09:03,595 - mdp.py - found the following 7 variables: ['backoff1:[0..13]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..1]', 's1:[3..12]', 's2:[5..11]', 'x2:[1..6]']

2025-01-28 13:09:03,595 - mdp.py - building tree of depth 0
2025-01-28 13:09:03,601 - statistic.py - synthesis initiated, design space: 34
2025-01-28 13:09:03,655 - synthesizer_ar.py - value 0.1083 achieved after 291.86 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.06 s
number of holes: 1, family size: 34, quotient: 1518 states / 2805 actions
explored: 100 %
MDP stats: avg MDP size: 1518, iterations: 4

optimum: 0.108271
--------------------
2025-01-28 13:09:03,663 - decision_tree.py - families considered: 4
2025-01-28 13:09:03,663 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:03,663 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:09:03,663 - decision_tree.py - families model checked: 4
2025-01-28 13:09:03,663 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:09:03,663 - decision_tree.py - harmonizations succeeded: 1

2025-01-28 13:09:03,663 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:09:03,663 - decision_tree.py - A_0=station2_cmd_54
2025-01-28 13:09:03,665 - decision_tree.py - double-checking specification satisfiability:  : 0.1082709837481431
2025-01-28 13:09:03,665 - decision_tree.py - admissible subtree found from node 23
2025-01-28 13:09:03,665 - decision_tree.py - new tree has depth 9 and 23 nodes
2025-01-28 13:09:05,325 - decision_tree.py - new dtcontrol tree has depth 9 and 23 nodes
2025-01-28 13:09:05,325 - decision_tree.py - New DtControl tree is smaller
2025-01-28 13:09:05,329 - decision_tree.py - starting iteration 14 with 1 nodes in node queue
2025-01-28 13:09:05,329 - decision_tree.py - current tree size: 47 nodes
2025-01-28 13:09:05,541 - decision_tree.py - subtree quotient has 2081 states and 15743 choices
2025-01-28 13:09:05,549 - mdp.py - MDP has 411/2081 relevant states
2025-01-28 13:09:05,649 - mdp.py - MDP has 34 actions
2025-01-28 13:09:05,669 - mdp.py - found the following 9 variables: ['backoff1:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..1]', 'c2:[0..2]', 'col:[0..1]', 's1:[2..12]', 's2:[1..11]', 'x2:[1..10]']

2025-01-28 13:09:05,669 - mdp.py - building tree of depth 0
2025-01-28 13:09:05,685 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 1, family size: 34, quotient: 2081 states / 15743 actions
explored: 100 %
MDP stats: avg MDP size: 1980, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:09:05,790 - decision_tree.py - families considered: 4
2025-01-28 13:09:05,790 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:05,790 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:09:05,790 - decision_tree.py - families model checked: 4
2025-01-28 13:09:05,790 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:09:05,790 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:09:05,790 - mdp.py - building tree of depth 1
2025-01-28 13:09:05,835 - statistic.py - synthesis initiated, design space: 1e8
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.38 s
number of holes: 12, family size: 1e8, quotient: 2081 states / 15743 actions
explored: 100 %
MDP stats: avg MDP size: 2010, iterations: 79

optimum: 0.107188
--------------------
2025-01-28 13:09:08,212 - decision_tree.py - families considered: 79
2025-01-28 13:09:08,212 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:08,212 - decision_tree.py - families with schedulers preserved: 25
2025-01-28 13:09:08,212 - decision_tree.py - families model checked: 54
2025-01-28 13:09:08,212 - decision_tree.py - harmonizations attempted: 3
2025-01-28 13:09:08,212 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:09:08,212 - mdp.py - building tree of depth 2
2025-01-28 13:09:08,312 - statistic.py - synthesis initiated, design space: 1e21
> progress 0.015%, elapsed 3 s, estimated 18875 s (5 hours), iters = {MDP: 72}, opt = 0.1072
> progress 0.042%, elapsed 6 s, estimated 14188 s (3 hours), iters = {MDP: 148}, opt = 0.1072
> progress 0.095%, elapsed 9 s, estimated 9541 s (2 hours), iters = {MDP: 232}, opt = 0.1072
> progress 0.259%, elapsed 12 s, estimated 4666 s, iters = {MDP: 307}, opt = 0.1072
> progress 0.274%, elapsed 15 s, estimated 5525 s, iters = {MDP: 386}, opt = 0.1072
> progress 0.371%, elapsed 18 s, estimated 4891 s, iters = {MDP: 465}, opt = 0.1072
> progress 0.53%, elapsed 21 s, estimated 4002 s, iters = {MDP: 540}, opt = 0.1072
> progress 0.668%, elapsed 24 s, estimated 3630 s, iters = {MDP: 616}, opt = 0.1072
> progress 0.872%, elapsed 27 s, estimated 3128 s, iters = {MDP: 687}, opt = 0.1072
2025-01-28 13:09:38,315 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 30.0 s
number of holes: 34, family size: 1e21, quotient: 2081 states / 15743 actions
explored: 0 %
MDP stats: avg MDP size: 1984, iterations: 763

optimum: 0.107188
--------------------
2025-01-28 13:09:38,315 - decision_tree.py - families considered: 763
2025-01-28 13:09:38,316 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:38,316 - decision_tree.py - families with schedulers preserved: 226
2025-01-28 13:09:38,316 - decision_tree.py - families model checked: 537
2025-01-28 13:09:38,316 - decision_tree.py - harmonizations attempted: 67
2025-01-28 13:09:38,316 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:09:38,316 - decision_tree.py - no admissible subtree found from node 12
2025-01-28 13:09:38,316 - decision_tree.py - starting iteration with subtree depth 2
2025-01-28 13:09:38,323 - decision_tree.py - starting iteration 15 with 5 nodes in node queue
2025-01-28 13:09:38,324 - decision_tree.py - current tree size: 47 nodes
2025-01-28 13:09:38,520 - decision_tree.py - subtree quotient has 1730 states and 2093 choices
2025-01-28 13:09:38,526 - mdp.py - MDP has 8/1730 relevant states
2025-01-28 13:09:38,542 - mdp.py - MDP has 34 actions
2025-01-28 13:09:38,567 - mdp.py - found the following 7 variables: ['backoff1:[0..1]', 'bc1:[0..1]', 'c1:[0..1]', 'col:[0..1]', 's1:[4..12]', 's2:[1..3]', 'x2:[1..2]']

2025-01-28 13:09:38,567 - mdp.py - building tree of depth 0
2025-01-28 13:09:38,570 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.06 s
number of holes: 1, family size: 34, quotient: 1730 states / 2093 actions
explored: 100 %
MDP stats: avg MDP size: 1690, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:09:38,634 - decision_tree.py - families considered: 4
2025-01-28 13:09:38,634 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:38,634 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:09:38,634 - decision_tree.py - families model checked: 4
2025-01-28 13:09:38,634 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:09:38,634 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:09:38,634 - mdp.py - building tree of depth 1
2025-01-28 13:09:38,642 - statistic.py - synthesis initiated, design space: 40460
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.65 s
number of holes: 10, family size: 40460, quotient: 1730 states / 2093 actions
explored: 100 %
MDP stats: avg MDP size: 1686, iterations: 34

optimum: 0.107188
--------------------
2025-01-28 13:09:39,288 - decision_tree.py - families considered: 34
2025-01-28 13:09:39,288 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:39,288 - decision_tree.py - families with schedulers preserved: 10
2025-01-28 13:09:39,288 - decision_tree.py - families model checked: 24
2025-01-28 13:09:39,288 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:09:39,288 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:09:39,288 - decision_tree.py - no admissible subtree found from node 16
2025-01-28 13:09:39,288 - decision_tree.py - starting iteration 16 with 4 nodes in node queue
2025-01-28 13:09:39,288 - decision_tree.py - current tree size: 47 nodes
2025-01-28 13:09:39,457 - decision_tree.py - subtree quotient has 1885 states and 4393 choices
2025-01-28 13:09:39,463 - mdp.py - MDP has 73/1885 relevant states
2025-01-28 13:09:39,492 - mdp.py - MDP has 34 actions
2025-01-28 13:09:39,506 - mdp.py - found the following 8 variables: ['backoff2:[0..15]', 'bc2:[0..1]', 'c2:[0..1]', 'col:[0..1]', 's1:[1..3]', 's2:[1..12]', 'x1:[1..3]', 'x2:[0..3]']

2025-01-28 13:09:39,507 - mdp.py - building tree of depth 0
2025-01-28 13:09:39,511 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.08 s
number of holes: 1, family size: 34, quotient: 1885 states / 4393 actions
explored: 100 %
MDP stats: avg MDP size: 1808, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:09:39,587 - decision_tree.py - families considered: 4
2025-01-28 13:09:39,587 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:39,587 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:09:39,587 - decision_tree.py - families model checked: 4
2025-01-28 13:09:39,587 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:09:39,587 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:09:39,587 - mdp.py - building tree of depth 1
2025-01-28 13:09:39,601 - statistic.py - synthesis initiated, design space: 1e6
2025-01-28 13:09:41,021 - synthesizer_ar.py - value 0.1083 achieved after 329.23 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.63 s
number of holes: 11, family size: 1e6, quotient: 1885 states / 4393 actions
explored: 100 %
MDP stats: avg MDP size: 1778, iterations: 61

optimum: 0.108271
--------------------
2025-01-28 13:09:41,235 - decision_tree.py - families considered: 61
2025-01-28 13:09:41,235 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:41,236 - decision_tree.py - families with schedulers preserved: 18
2025-01-28 13:09:41,236 - decision_tree.py - families model checked: 43
2025-01-28 13:09:41,236 - decision_tree.py - harmonizations attempted: 4
2025-01-28 13:09:41,236 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:09:41,236 - decision_tree.py - printing synthesized assignment below:
2025-01-28 13:09:41,236 - decision_tree.py - V_0=s2, backoff2_0=0, bc2_0=0, c2_0=0, col_0=0, s1_0=1, s2_0=1, x1_0=1, x2_0=0, A_1=station1_cmd_7, A_2=station1_cmd_13
2025-01-28 13:09:41,237 - decision_tree.py - double-checking specification satisfiability:  : 0.1082709837481431
2025-01-28 13:09:41,238 - decision_tree.py - admissible subtree found from node 39
2025-01-28 13:09:41,238 - decision_tree.py - new tree has depth 9 and 22 nodes
2025-01-28 13:09:42,854 - decision_tree.py - new dtcontrol tree has depth 9 and 22 nodes
2025-01-28 13:09:42,854 - decision_tree.py - New DtControl tree is smaller
2025-01-28 13:09:42,857 - decision_tree.py - starting iteration 17 with 1 nodes in node queue
2025-01-28 13:09:42,857 - decision_tree.py - current tree size: 45 nodes
2025-01-28 13:09:43,061 - decision_tree.py - subtree quotient has 2081 states and 15743 choices
2025-01-28 13:09:43,068 - mdp.py - MDP has 411/2081 relevant states
2025-01-28 13:09:43,164 - mdp.py - MDP has 34 actions
2025-01-28 13:09:43,181 - mdp.py - found the following 9 variables: ['backoff1:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..1]', 'c2:[0..2]', 'col:[0..1]', 's1:[2..12]', 's2:[1..11]', 'x2:[1..10]']

2025-01-28 13:09:43,182 - mdp.py - building tree of depth 0
2025-01-28 13:09:43,195 - statistic.py - synthesis initiated, design space: 34
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.1 s
number of holes: 1, family size: 34, quotient: 2081 states / 15743 actions
explored: 100 %
MDP stats: avg MDP size: 1980, iterations: 4

optimum: 0.107188
--------------------
2025-01-28 13:09:43,296 - decision_tree.py - families considered: 4
2025-01-28 13:09:43,296 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:43,296 - decision_tree.py - families with schedulers preserved: 0
2025-01-28 13:09:43,296 - decision_tree.py - families model checked: 4
2025-01-28 13:09:43,296 - decision_tree.py - harmonizations attempted: 1
2025-01-28 13:09:43,296 - decision_tree.py - harmonizations succeeded: 0


2025-01-28 13:09:43,296 - mdp.py - building tree of depth 1
2025-01-28 13:09:43,348 - statistic.py - synthesis initiated, design space: 1e8
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.55 s
number of holes: 12, family size: 1e8, quotient: 2081 states / 15743 actions
explored: 100 %
MDP stats: avg MDP size: 2010, iterations: 79

optimum: 0.107188
--------------------
2025-01-28 13:09:45,896 - decision_tree.py - families considered: 79
2025-01-28 13:09:45,896 - decision_tree.py - families skipped by construction: 0
2025-01-28 13:09:45,896 - decision_tree.py - families with schedulers preserved: 25
2025-01-28 13:09:45,896 - decision_tree.py - families model checked: 54
2025-01-28 13:09:45,896 - decision_tree.py - harmonizations attempted: 3
2025-01-28 13:09:45,896 - decision_tree.py - harmonizations succeeded: 0

2025-01-28 13:09:45,896 - decision_tree.py - no admissible subtree found from node 12
2025-01-28 13:09:46,062 - decision_tree.py - tree did not induce dtmc?
2025-01-28 13:09:46,062 - decision_tree.py - final tree has value 0.1082709837481431 with depth 9 and 22 nodes
0.1082709837481431 332.64 9 22
2025-01-28 13:09:46,063 - decision_tree.py - the optimal scheduler has value: 0.10827098374814313
2025-01-28 13:09:46,063 - decision_tree.py - the random scheduler has value: 0.02730039610596835
2025-01-28 13:09:46,065 - decision_tree.py - synthesized tree of depth 9 with 22 decision nodes
2025-01-28 13:09:46,065 - decision_tree.py - the synthesized tree has value 0.1082709837481431
2025-01-28 13:09:46,065 - decision_tree.py - the synthesized tree has relative value: 0.9999999999999997
2025-01-28 13:09:46,065 - decision_tree.py - printing the synthesized tree below:
2025-01-28 13:09:46,065 - decision_tree.py - dtcontrol calls: 14
2025-01-28 13:09:46,065 - decision_tree.py - dtcontrol successes: 2
2025-01-28 13:09:46,065 - decision_tree.py - paynt calls: 18
2025-01-28 13:09:46,065 - decision_tree.py - paynt successes smaller: 5
2025-01-28 13:09:46,065 - decision_tree.py - paynt tree found: 14
2025-01-28 13:09:46,065 - decision_tree.py - both larger: 7
2025-01-28 13:09:46,066 - decision_tree.py - exported decision tree to logs/01-28-initial/integration/qcomp-wlan-1-2/tree.dot
2025-01-28 13:09:46,151 - decision_tree.py - exported decision tree visualization to logs/01-28-initial/integration/qcomp-wlan-1-2/tree.png
2025-01-28 13:09:46,152 - decision_tree.py - synthesis finished after 334.36 seconds

--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.113.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.097.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.116.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.098.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.096.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.141.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.132.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.080.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.070.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.070.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.063.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.068.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.058.
All benchmarks completed. Shutting down dtControl.
--benchmark-file/-b was not set. Defaulting to use 'benchmark.json'
INFO: Benchmark statistics will be available in benchmark.json and benchmark.html.
INFO: Constructed trees will be written to decision_trees.

The following configurations would now be run:

 name    | numeric-predicates   | categorical-predicates   | determinize   | impurity   |   tolerance | safe-pruning
---------+----------------------+--------------------------+---------------+------------+-------------+----------------
 default | ['axisonly']         | ['multisplit']           | none          | entropy    |       1e-05 | False


1/1: Evaluating default on scheduler... 
Reading from scheduler.storm.json
INFO: Writing DOT file into decision_trees.

INFO: Writing C file into decision_trees.

1/1: Finished in 00:00:00.055.
All benchmarks completed. Shutting down dtControl.
