2025-02-06 17:00:25,349 - cli.py:170 - This is Paynt version 0.1.0.
2025-02-06 17:00:25,349 - sketch.py:84 - loading sketch from /home/fpmk/synthesis-playground/models/dts-uai-subset/discounted/maze-7/model-random.drn ...
2025-02-06 17:00:25,349 - sketch.py:88 - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-02-06 17:00:25,374 - sketch.py:96 - assuming sketch in DRN format...
2025-02-06 17:00:25,391 - prism_parser.py:202 - loading properties from /home/fpmk/synthesis-playground/models/dts-uai-subset/discounted/maze-7/discounted.props ...
2025-02-06 17:00:25,391 - prism_parser.py:218 - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-02-06 17:00:25,396 - sketch.py:110 - found state valuations in /home/fpmk/synthesis-playground/models/dts-uai-subset/discounted/maze-7/state-valuations.json, adding to the model...
2025-02-06 17:00:25,398 - sketch.py:149 - sketch parsing OK
2025-02-06 17:00:25,405 - sketch.py:154 - tree helper loaded
2025-02-06 17:00:25,408 - sketch.py:170 - constructed explicit quotient having 2039 states and 10195 choices
2025-02-06 17:00:25,408 - sketch.py:176 - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-02-06 17:00:25,413 - mdp.py:497 - MDP has 2039/2039 relevant states
2025-02-06 17:00:25,427 - mdp.py:507 - MDP has 5 actions
2025-02-06 17:00:25,442 - mdp.py:532 - found the following 9 variables: ['picked0:[0..1]', 'picked1:[0..1]', 'picked2:[0..1]', 'picked3:[0..1]', 'picked4:[0..1]', 'picked5:[0..1]', 'picked6:[0..1]', 'x:[0..14]', 'y:[0..6]']
2025-02-06 17:00:25,453 - decision_tree.py:609 - the optimal scheduler has value: 5.179578174110294
2025-02-06 17:00:25,468 - decision_tree.py:616 - the random scheduler has value: 1.2183016282364878
2025-02-06 17:00:25,468 - synthesizer.py:109 - optimality threshold set to 4.783450519522914

2025-02-06 17:00:25,468 - mdp.py:825 - building tree of depth 0
2025-02-06 17:00:25,489 - statistic.py:67 - synthesis initiated, design space: 5
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.11 s
number of holes: 1, family size: 5, quotient: 2039 states / 10195 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 4

optimum: 4.783451
--------------------
2025-02-06 17:00:25,596 - decision_tree.py:120 - families considered: 4
2025-02-06 17:00:25,596 - decision_tree.py:121 - families skipped by construction: 0
2025-02-06 17:00:25,596 - decision_tree.py:122 - families with schedulers preserved: 0
2025-02-06 17:00:25,596 - decision_tree.py:123 - families model checked: 4
2025-02-06 17:00:25,596 - decision_tree.py:124 - harmonizations attempted: 1
2025-02-06 17:00:25,596 - decision_tree.py:125 - harmonizations succeeded: 0


2025-02-06 17:00:25,596 - mdp.py:825 - building tree of depth 1
2025-02-06 17:00:25,674 - statistic.py:67 - synthesis initiated, design space: 18900
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.66 s
number of holes: 12, family size: 18900, quotient: 2039 states / 10195 actions
explored: 100 %
MDP stats: avg MDP size: 2039, iterations: 18

optimum: 4.783451
--------------------
2025-02-06 17:00:26,335 - decision_tree.py:120 - families considered: 18
2025-02-06 17:00:26,335 - decision_tree.py:121 - families skipped by construction: 0
2025-02-06 17:00:26,335 - decision_tree.py:122 - families with schedulers preserved: 5
2025-02-06 17:00:26,335 - decision_tree.py:123 - families model checked: 13
2025-02-06 17:00:26,335 - decision_tree.py:124 - harmonizations attempted: 1
2025-02-06 17:00:26,335 - decision_tree.py:125 - harmonizations succeeded: 0


2025-02-06 17:00:26,335 - mdp.py:825 - building tree of depth 2
2025-02-06 17:00:26,559 - statistic.py:67 - synthesis initiated, design space: 1e11
> progress 0.004%, elapsed 3 s, estimated 64579 s (17 hours), iters = {MDP: 41}, opt = 4.7835
> progress 0.032%, elapsed 6 s, estimated 18396 s (5 hours), iters = {MDP: 85}, opt = 4.7835
> progress 0.048%, elapsed 9 s, estimated 18879 s (5 hours), iters = {MDP: 128}, opt = 4.7835
> progress 0.059%, elapsed 12 s, estimated 20284 s (5 hours), iters = {MDP: 158}, opt = 4.7835
> progress 0.077%, elapsed 15 s, estimated 19472 s (5 hours), iters = {MDP: 200}, opt = 4.7835
> progress 0.169%, elapsed 18 s, estimated 10800 s (3 hours), iters = {MDP: 245}, opt = 4.7835
> progress 0.32%, elapsed 21 s, estimated 6668 s, iters = {MDP: 301}, opt = 4.7835
> progress 0.381%, elapsed 24 s, estimated 6387 s, iters = {MDP: 346}, opt = 4.7835
> progress 0.499%, elapsed 27 s, estimated 5492 s, iters = {MDP: 394}, opt = 4.7835
> progress 1.327%, elapsed 30 s, estimated 2298 s, iters = {MDP: 440}, opt = 4.7835
> progress 2.495%, elapsed 33 s, estimated 1342 s, iters = {MDP: 493}, opt = 4.7835
> progress 6.117%, elapsed 36 s, estimated 598 s, iters = {MDP: 538}, opt = 4.7835
> progress 6.151%, elapsed 39 s, estimated 644 s, iters = {MDP: 588}, opt = 4.7835
> progress 22.222%, elapsed 42 s, estimated 192 s, iters = {MDP: 633}, opt = 4.7835
2025-02-06 17:01:08,869 - synthesizer.py:93 - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 45.06 s
number of holes: 34, family size: 1e11, quotient: 2039 states / 10195 actions
explored: 22 %
MDP stats: avg MDP size: 2039, iterations: 668

optimum: 4.783451
--------------------
2025-02-06 17:01:08,870 - decision_tree.py:120 - families considered: 668
2025-02-06 17:01:08,870 - decision_tree.py:121 - families skipped by construction: 0
2025-02-06 17:01:08,870 - decision_tree.py:122 - families with schedulers preserved: 189
2025-02-06 17:01:08,870 - decision_tree.py:123 - families model checked: 479
2025-02-06 17:01:08,870 - decision_tree.py:124 - harmonizations attempted: 70
2025-02-06 17:01:08,870 - decision_tree.py:125 - harmonizations succeeded: 0


2025-02-06 17:01:08,870 - mdp.py:825 - building tree of depth 3
2025-02-06 17:01:06,832 - statistic.py:67 - synthesis initiated, design space: 1e25
> progress 0.0%, elapsed 3 s, estimated 3162816 s (36 days), iters = {MDP: 7}, opt = 4.7835
> progress 0.0%, elapsed 6 s, estimated 81189598 s (2 years), iters = {MDP: 29}, opt = 4.7835
> progress 0.0%, elapsed 9 s, estimated 114527125 s (3 years), iters = {MDP: 58}, opt = 4.7835
> progress 0.0%, elapsed 12 s, estimated 143499706 s (4 years), iters = {MDP: 85}, opt = 4.7835
> progress 0.0%, elapsed 15 s, estimated 176483307 s (5 years), iters = {MDP: 114}, opt = 4.7835
> progress 0.0%, elapsed 18 s, estimated 205546631 s (6 years), iters = {MDP: 150}, opt = 4.7835
> progress 0.0%, elapsed 21 s, estimated 227803915 s (7 years), iters = {MDP: 176}, opt = 4.7835
> progress 0.0%, elapsed 25 s, estimated 257049090 s (8 years), iters = {MDP: 207}, opt = 4.7835
> progress 0.0%, elapsed 28 s, estimated 282703496 s (8 years), iters = {MDP: 242}, opt = 4.7835
> progress 0.0%, elapsed 31 s, estimated 298823451 s (9 years), iters = {MDP: 271}, opt = 4.7835
> progress 0.0%, elapsed 34 s, estimated 313348084 s (9 years), iters = {MDP: 303}, opt = 4.7835
> progress 0.0%, elapsed 37 s, estimated 283759870 s (8 years), iters = {MDP: 336}, opt = 4.7835
> progress 0.0%, elapsed 40 s, estimated 270397388 s (8 years), iters = {MDP: 370}, opt = 4.7835
> progress 0.0%, elapsed 43 s, estimated 246836849 s (7 years), iters = {MDP: 404}, opt = 4.7835
2025-02-06 17:01:49,097 - synthesizer.py:93 - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 45.07 s
number of holes: 78, family size: 1e25, quotient: 2039 states / 10195 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 427

optimum: 4.783451
--------------------
2025-02-06 17:01:49,098 - decision_tree.py:120 - families considered: 427
2025-02-06 17:01:49,098 - decision_tree.py:121 - families skipped by construction: 0
2025-02-06 17:01:49,098 - decision_tree.py:122 - families with schedulers preserved: 134
2025-02-06 17:01:49,098 - decision_tree.py:123 - families model checked: 293
2025-02-06 17:01:49,098 - decision_tree.py:124 - harmonizations attempted: 40
2025-02-06 17:01:49,098 - decision_tree.py:125 - harmonizations succeeded: 0


2025-02-06 17:01:49,098 - mdp.py:825 - building tree of depth 4
2025-02-06 17:01:50,245 - statistic.py:67 - synthesis initiated, design space: 1e54
> progress 0.0%, elapsed 4 s, estimated 4210405 s (48 days), iters = {MDP: 3}, opt = 4.7835
> progress 0.0%, elapsed 8 s, estimated 8183440 s (94 days), iters = {MDP: 6}, opt = 4.7835
> progress 0.015%, elapsed 11 s, estimated 76607 s (21 hours), iters = {MDP: 12}, opt = 4.7835
> progress 0.015%, elapsed 15 s, estimated 100008 s (27 hours), iters = {MDP: 16}, opt = 4.7835
> progress 0.015%, elapsed 18 s, estimated 120234 s (33 hours), iters = {MDP: 19}, opt = 4.7835
> progress 0.015%, elapsed 21 s, estimated 139870 s (38 hours), iters = {MDP: 22}, opt = 4.7835
> progress 0.015%, elapsed 24 s, estimated 162203 s (45 hours), iters = {MDP: 28}, opt = 4.7835
> progress 0.015%, elapsed 27 s, estimated 182090 s (2 days), iters = {MDP: 57}, opt = 4.7835
> progress 0.015%, elapsed 31 s, estimated 202577 s (2 days), iters = {MDP: 83}, opt = 4.7835
> progress 0.015%, elapsed 34 s, estimated 222635 s (2 days), iters = {MDP: 118}, opt = 4.7835
> progress 0.015%, elapsed 37 s, estimated 243778 s (2 days), iters = {MDP: 154}, opt = 4.7835
> progress 0.015%, elapsed 40 s, estimated 263951 s (3 days), iters = {MDP: 176}, opt = 4.7835
> progress 0.015%, elapsed 43 s, estimated 283568 s (3 days), iters = {MDP: 214}, opt = 4.7835
2025-02-06 17:02:32,747 - synthesizer.py:93 - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 45.22 s
number of holes: 166, family size: 1e54, quotient: 2039 states / 10195 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 227

optimum: 4.783451
--------------------
2025-02-06 17:02:32,749 - decision_tree.py:120 - families considered: 227
2025-02-06 17:02:32,749 - decision_tree.py:121 - families skipped by construction: 0
2025-02-06 17:02:32,749 - decision_tree.py:122 - families with schedulers preserved: 64
2025-02-06 17:02:32,749 - decision_tree.py:123 - families model checked: 163
2025-02-06 17:02:32,749 - decision_tree.py:124 - harmonizations attempted: 36
2025-02-06 17:02:32,749 - decision_tree.py:125 - harmonizations succeeded: 0


2025-02-06 17:02:32,749 - mdp.py:825 - building tree of depth 5
2025-02-06 17:02:35,396 - statistic.py:67 - synthesis initiated, design space: 1e111
> progress 0.0%, elapsed 12 s, estimated 12699391 s (146 days), iters = {MDP: 2}, opt = 4.7835
> progress 0.0%, elapsed 22 s, estimated 22507053 s (260 days), iters = {MDP: 3}, opt = 4.7835
> progress 0.0%, elapsed 27 s, estimated 27913142 s (323 days), iters = {MDP: 4}, opt = 4.7835
> progress 0.0%, elapsed 31 s, estimated 31592595 s (1 year), iters = {MDP: 5}, opt = 4.7835
> progress 0.0%, elapsed 35 s, estimated 35291254 s (1 year), iters = {MDP: 6}, opt = 4.7835
> progress 0.0%, elapsed 39 s, estimated 39187417 s (1 year), iters = {MDP: 7}, opt = 4.7835
> progress 0.0%, elapsed 43 s, estimated 43209891 s (1 year), iters = {MDP: 8}, opt = 4.7835
2025-02-06 17:03:16,565 - synthesizer.py:93 - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 46.53 s
number of holes: 342, family size: 1e111, quotient: 2039 states / 10195 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 8

optimum: 4.783451
--------------------
2025-02-06 17:03:16,566 - decision_tree.py:120 - families considered: 8
2025-02-06 17:03:16,566 - decision_tree.py:121 - families skipped by construction: 0
2025-02-06 17:03:16,566 - decision_tree.py:122 - families with schedulers preserved: 7
2025-02-06 17:03:16,567 - decision_tree.py:123 - families model checked: 1
2025-02-06 17:03:16,567 - decision_tree.py:124 - harmonizations attempted: 1
2025-02-06 17:03:16,567 - decision_tree.py:125 - harmonizations succeeded: 0


2025-02-06 17:03:16,567 - mdp.py:825 - building tree of depth 6
2025-02-06 17:03:23,411 - statistic.py:67 - synthesis initiated, design space: 1e226
2025-02-06 17:04:58,765 - synthesizer.py:93 - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 103.4 s
number of holes: 694, family size: 1e226, quotient: 2039 states / 10195 actions
explored: 0 %
MDP stats: avg MDP size: 2039, iterations: 1

optimum: 4.783451
--------------------
2025-02-06 17:04:58,766 - decision_tree.py:120 - families considered: 1
2025-02-06 17:04:58,766 - decision_tree.py:121 - families skipped by construction: 0
2025-02-06 17:04:58,766 - decision_tree.py:122 - families with schedulers preserved: 0
2025-02-06 17:04:58,766 - decision_tree.py:123 - families model checked: 1
2025-02-06 17:04:58,766 - decision_tree.py:124 - harmonizations attempted: 1
2025-02-06 17:04:58,766 - decision_tree.py:125 - harmonizations succeeded: 0


2025-02-06 17:04:58,766 - mdp.py:825 - building tree of depth 7
2025-02-06 17:05:13,353 - statistic.py:67 - synthesis initiated, design space: 1e455
