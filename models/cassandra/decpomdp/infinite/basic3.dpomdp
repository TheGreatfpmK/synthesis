agents: 2 
#
discount: 0.9
#
values: reward
#
states: s0 s1 s2 s3   
#  
start include: s0
#
actions: 
a
a b
#
observations: 
o
o
#
T : a a : s0 : s1 : 1.0
T : a b : s0 : s1 : 1.0
#
T : a a : s1 : s2 : 1.0
#T : a a : s1 : s2 : 0.5
T : a b : s1 : s2 : 1.0
T : a a : s2 : s3 : 1.0
T : a b : s2 : s3 : 1.0
T : a a : s3 : s3 : 1.0
#T : a b : s3 : s2 : 0.5
T : a b : s3 : s3 : 1.0
#
O : * * : * : o o : 1.0
#
R: * *: * : * : * : 0
R: a a: * : * : * : 1
